{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZmUeX0KMRRE",
        "outputId": "4653ebaa-4d27-4551-e7ac-b215a58d7832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.21.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install keras_applications "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YxwC4ylMh4G",
        "outputId": "7fd97ca9-a336-493f-d8c0-51e057330bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k4kFe31MptM"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, MaxPool2D\n",
        "from keras.layers.core import Lambda\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import *\n",
        "#from keras.utils import multi_gpu_model\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import load_model\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Lambda\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.inception_v3 import InceptionV3 \n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from keras.applications.resnet50 import ResNet50\n",
        "from keras_applications.resnet import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "import os\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iDAAM\n",
        "\n",
        "def self_attention(input_feature, num_channel, base = 'self_attention_base'):\n",
        "    bn_1 = BatchNormalization(axis = -1, name = base + '/bn_1')(input_feature)\n",
        "    dense_1 = Dense(num_channel, name = base + '/dense_1')(bn_1)\n",
        "    act_1 = Activation('relu', name = base + '/act_1')(dense_1)\n",
        "\n",
        "    bn_2 = BatchNormalization(axis = -1, name = base + '/bn_2')(input_feature)\n",
        "    dense_2 = Dense(num_channel, name = base + '/dense_2')(bn_2)\n",
        "    act_2 = Activation('relu', name = base + '/act_2')(dense_2)\n",
        "\n",
        "    bn_3 = BatchNormalization(axis = -1, name = base + '/bn_3')(input_feature)\n",
        "    dense_3 = Dense(num_channel, name = base + '/dense_3')(bn_3)\n",
        "    act_3 = Activation('relu', name = base + '/act_3')(dense_3)\n",
        "\n",
        "    mul_1 = Multiply(name = base + '/mul_1')([act_2, act_3])\n",
        "    mask_part = Activation('softmax', name = base + '/act_4')(mul_1)\n",
        "    mul_2 = Multiply(name = base + '/mul_2')([act_1, mask_part])\n",
        "\n",
        "    output_feature = Add(name = base + '/add_1')([mul_2, input_feature])\n",
        "\n",
        "    return output_feature\n",
        "\n",
        "def CMFA(input_feature, num_channel, base = 'CMFA_base'):\n",
        "    out_1 = self_attention(input_feature, num_channel, base + '/self_att_1')\n",
        "    out_2 = self_attention(input_feature, num_channel, base + '/self_att_2')\n",
        "    out_3 = self_attention(input_feature, num_channel, base + '/self_att_3')\n",
        "    out_4 = self_attention(input_feature, num_channel, base + '/self_att_4')\n",
        "\n",
        "    output_feature = Add(name = base + '/add')([out_1, out_2, out_3, out_4])\n",
        "\n",
        "    return output_feature\n",
        "\n",
        "def SEM(input_feature, num_channel, base = 'SEM_base'):\n",
        "    GAP_output = GlobalAveragePooling2D(name = base + '/gap_layer')(input_feature)\n",
        "\n",
        "    bn_1 = BatchNormalization(axis = -1, name = base + '/bn_1')(GAP_output)\n",
        "    dense_1 = Dense(int(num_channel/4), name = base + '/dense_1')(bn_1)\n",
        "    act_1 = Activation('relu', name = base + '/act_1')(dense_1)\n",
        "\n",
        "    bn_2 = BatchNormalization(axis = -1, name = base + '/bn_2')(act_1)\n",
        "    dense_2 = Dense(num_channel, name = base + '/dense_2')(bn_2)\n",
        "    act_2 = Activation('sigmoid', name = base + '/act_2')(dense_2)\n",
        "\n",
        "    out_channel = Multiply(name = base + '/mul_1')([act_2, input_feature])\n",
        "\n",
        "    strides = (1,1)\n",
        "\n",
        "    bn_3 = BatchNormalization(axis = -1, name = base + '/bn_3')(input_feature)\n",
        "    cn_3 = Conv2D(num_channel, (3,3), strides = strides, padding = 'same', name = base + '/conv_1')(bn_3)\n",
        "    an_3 = Activation('relu', name = base + '/act_3')(cn_3)\n",
        "\n",
        "    bn_4 = BatchNormalization(axis = -1, name = base + '/bn_4')(an_3)\n",
        "    cn_4 = Conv2D(1, (1,1), strides = strides, padding = 'same', name = base + '/conv_2')(bn_4)\n",
        "    an_4 = Activation('sigmoid', name = base + '/act_4')(cn_4)\n",
        "\n",
        "    out_spatial = Multiply(name = base + '/mul_2')([an_4, input_feature])\n",
        "\n",
        "    output_response = Add(name = base + '/add')([input_feature, out_channel, out_spatial])\n",
        "\n",
        "    return output_response\n",
        "\n",
        "def iDAAM(input_feature):\n",
        "  shape=K.int_shape(input_feature)\n",
        "  num_channel = shape[3]\n",
        "  base = 'iDAAM'\n",
        "  sem_feature = SEM(input_feature, num_channel)\n",
        "  print(sem_feature.shape)\n",
        "  cmfa_feature = CMFA(input_feature, num_channel)\n",
        "  print(cmfa_feature.shape)\n",
        "  attend_feature = tf.keras.layers.Add()([sem_feature,cmfa_feature])\n",
        "  return attend_feature"
      ],
      "metadata": {
        "id": "7UxwuBXIxLYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axHjDrWRMr2D"
      },
      "outputs": [],
      "source": [
        "def smooth_curve(points, factor=0.6):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points    \n",
        "   \n",
        "def plotmodel(history,name):\n",
        "    \n",
        "    acc = history.history['acc']\n",
        "    #val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    #val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1) \n",
        "    \n",
        "    plt.figure(1)                  \n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    #plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    plt.legend(['train_acc'], loc='upper left')\n",
        "    plt.savefig('acc_'+name+'.png')\n",
        "    \n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    #plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "    plt.legend(['train_loss'], loc='upper right')\n",
        "    plt.savefig('loss_'+name+'.png')\n",
        "    \n",
        "def get_base_model(model_name,image_size):\n",
        "    if model_name =='vgg16':\n",
        "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='resnet50':\n",
        "        base_model=ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='xception':\n",
        "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
        "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
        "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
        "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenetv2':\n",
        "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='inceptionv3':   \n",
        "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='inceptionv2':\n",
        "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='efficientnetB0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0 (include_top=False, weights = 'imagenet',input_shape = (image_size,image_size,3))\n",
        "    if model_name =='efficientNetV2B0':\n",
        "        base_model = tf.keras.applications.EfficientNetV2B0 (include_top=False, weights = 'imagenet',input_shape = (image_size,image_size,3))\n",
        "    if model_name =='nasnet':\n",
        "        base_model=tf.keras.applications.NASNetMobile (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    \n",
        "    return base_model\n",
        "\n",
        "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
        "    \n",
        "    dataParam={'messidor': [960,240,2,'../content/drive/MyDrive/Mtech Project/Dataset/Messidor_Binary_512/train',\n",
        "                            '../content/drive/MyDrive/Mtech Project/Dataset/Messidor_Binary_512/test'],\n",
        "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
        "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
        "    \n",
        "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
        "    \n",
        "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
        "    valid = ImageDataGenerator()\n",
        "    train_data=train.flow_from_directory(train_dir,\n",
        "                                         target_size=(image_size,image_size),\n",
        "                                         shuffle = True,\n",
        "                                         batch_size=batch_size)\n",
        "    valid_data=valid.flow_from_directory(test_dir,\n",
        "                                         target_size=(image_size,image_size),\n",
        "                                         shuffle = False,\n",
        "                                         batch_size=batch_size)\n",
        "\n",
        "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
        "    \n",
        "    filepath = \"efficientNetV2B0+iDDAM.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False   \n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
        "    model.fit(train_data,\n",
        "                        steps_per_epoch=train_num/batch_size,\n",
        "                        epochs=Epochs1, \n",
        "                        workers=2,\n",
        "                        callbacks=[lr_decay,checkpoint])   \n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = True\n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
        "    history=model.fit(train_data,\n",
        "                        steps_per_epoch=train_num/batch_size,\n",
        "                        epochs=Epochs2,\n",
        "                        workers=2,\n",
        "                        callbacks=[lr_decay,checkpoint])\n",
        "    \n",
        "    score = model.evaluate(valid_data,batch_size = 64)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    \n",
        "    return history,model,valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTUSzdUmMxau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0fe9ef3-d12d-4906-e54b-dc6f06dc40aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24281088/24274472 [==============================] - 0s 0us/step\n",
            "24289280/24274472 [==============================] - 0s 0us/step\n",
            "(None, 16, 16, 640)\n",
            "(None, 16, 16, 640)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 512, 512, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 512, 512, 3)  0           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 256, 256, 32  864         ['normalization[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 256, 256, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 256, 256, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 256, 256, 16  4608        ['stem_activation[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 256, 256, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_activation (Ac  (None, 256, 256, 16  0          ['block1a_project_bn[0][0]']     \n",
            " tivation)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 128, 128, 64  9216        ['block1a_project_activation[0][0\n",
            "                                )                                ]']                              \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 128, 128, 64  256        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 128, 128, 64  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 128, 128, 32  2048        ['block2a_expand_activation[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 128, 128, 32  128        ['block2a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 128, 128, 12  36864       ['block2a_project_bn[0][0]']     \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 128, 128, 12  512        ['block2b_expand_conv[0][0]']    \n",
            " ization)                       8)                                                                \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 128, 128, 12  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                       8)                                                                \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 128, 128, 32  4096        ['block2b_expand_activation[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 128, 128, 32  128        ['block2b_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 128, 128, 32  0           ['block2b_project_bn[0][0]',     \n",
            "                                )                                 'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 64, 64, 128)  36864       ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 64, 64, 128)  512        ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 64, 64, 128)  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 64, 64, 48)   6144        ['block3a_expand_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 64, 64, 48)  192         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 64, 64, 192)  82944       ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 64, 64, 192)  768        ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 64, 64, 192)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 64, 64, 48)   9216        ['block3b_expand_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 64, 64, 48)  192         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 64, 64, 48)   0           ['block3b_project_bn[0][0]',     \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 64, 64, 192)  9216        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 64, 64, 192)  768        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 64, 64, 192)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv2 (DepthwiseConv  (None, 32, 32, 192)  1728       ['block4a_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 32, 32, 192)  768        ['block4a_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 32, 32, 192)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 192)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 12)     2316        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 192)    2496        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 32, 32, 192)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 32, 32, 96)   18432       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 32, 32, 96)  384         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 32, 32, 384)  36864       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 32, 32, 384)  1536       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 32, 32, 384)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv2 (DepthwiseConv  (None, 32, 32, 384)  3456       ['block4b_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 32, 32, 384)  1536       ['block4b_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 32, 32, 384)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 384)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 384)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 24)     9240        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 384)    9600        ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 32, 32, 384)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 32, 32, 96)   36864       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 32, 32, 96)  384         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 32, 32, 96)   0           ['block4b_project_bn[0][0]',     \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 32, 32, 384)  36864       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 32, 32, 384)  1536       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 32, 32, 384)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv2 (DepthwiseConv  (None, 32, 32, 384)  3456       ['block4c_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 32, 32, 384)  1536       ['block4c_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 32, 32, 384)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 384)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 384)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 24)     9240        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 384)    9600        ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 32, 32, 384)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 32, 32, 96)   36864       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 32, 32, 96)  384         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 32, 32, 96)   0           ['block4c_project_bn[0][0]',     \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 32, 32, 576)  55296       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 32, 32, 576)  2304       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 32, 32, 576)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv2 (DepthwiseConv  (None, 32, 32, 576)  5184       ['block5a_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 32, 32, 576)  2304       ['block5a_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 32, 32, 576)  0          ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 576)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 32, 32, 576)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 32, 32, 112)  64512       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 32, 32, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv2 (DepthwiseConv  (None, 32, 32, 672)  6048       ['block5b_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5b_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 32, 32, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 32, 32, 112)  0           ['block5b_project_bn[0][0]',     \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 32, 32, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv2 (DepthwiseConv  (None, 32, 32, 672)  6048       ['block5c_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5c_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 32, 32, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 32, 32, 112)  0           ['block5c_project_bn[0][0]',     \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5d_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5d_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5d_expand_activation (Act  (None, 32, 32, 672)  0          ['block5d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5d_dwconv2 (DepthwiseConv  (None, 32, 32, 672)  6048       ['block5d_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5d_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5d_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5d_activation (Activation  (None, 32, 32, 672)  0          ['block5d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5d_se_squeeze (GlobalAver  (None, 672)         0           ['block5d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5d_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5d_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5d_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5d_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5d_activation[0][0]',     \n",
            "                                                                  'block5d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5d_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5d_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5d_add (Add)              (None, 32, 32, 112)  0           ['block5d_project_bn[0][0]',     \n",
            "                                                                  'block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5e_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5e_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5e_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5e_expand_activation (Act  (None, 32, 32, 672)  0          ['block5e_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5e_dwconv2 (DepthwiseConv  (None, 32, 32, 672)  6048       ['block5e_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5e_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5e_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5e_activation (Activation  (None, 32, 32, 672)  0          ['block5e_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5e_se_squeeze (GlobalAver  (None, 672)         0           ['block5e_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5e_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5e_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5e_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5e_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5e_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5e_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5e_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5e_activation[0][0]',     \n",
            "                                                                  'block5e_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5e_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5e_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5e_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5e_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5e_add (Add)              (None, 32, 32, 112)  0           ['block5e_project_bn[0][0]',     \n",
            "                                                                  'block5d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5e_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 32, 32, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv2 (DepthwiseConv  (None, 16, 16, 672)  6048       ['block6a_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 16, 16, 672)  2688       ['block6a_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 16, 16, 672)  0          ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 16, 16, 672)  0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 16, 16, 192)  129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6b_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 16, 16, 1152  0          ['block6b_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6b_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6b_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6b_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 16, 16, 1152  0          ['block6b_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6b_activation[0][0]',     \n",
            "                                )                                 'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 16, 16, 192)  0           ['block6b_project_bn[0][0]',     \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6b_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6c_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 16, 16, 1152  0          ['block6c_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6c_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6c_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6c_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 16, 16, 1152  0          ['block6c_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6c_activation[0][0]',     \n",
            "                                )                                 'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 16, 16, 192)  0           ['block6c_project_bn[0][0]',     \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6c_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6d_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 16, 16, 1152  0          ['block6d_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6d_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6d_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6d_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 16, 16, 1152  0          ['block6d_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6d_activation[0][0]',     \n",
            "                                )                                 'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 16, 16, 192)  0           ['block6d_project_bn[0][0]',     \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6e_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6d_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6e_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6e_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6e_expand_activation (Act  (None, 16, 16, 1152  0          ['block6e_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6e_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6e_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6e_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6e_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6e_activation (Activation  (None, 16, 16, 1152  0          ['block6e_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6e_se_squeeze (GlobalAver  (None, 1152)        0           ['block6e_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6e_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6e_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6e_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6e_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6e_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6e_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6e_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6e_activation[0][0]',     \n",
            "                                )                                 'block6e_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6e_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6e_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6e_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6e_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6e_add (Add)              (None, 16, 16, 192)  0           ['block6e_project_bn[0][0]',     \n",
            "                                                                  'block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6f_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6e_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6f_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6f_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6f_expand_activation (Act  (None, 16, 16, 1152  0          ['block6f_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6f_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6f_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6f_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6f_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6f_activation (Activation  (None, 16, 16, 1152  0          ['block6f_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6f_se_squeeze (GlobalAver  (None, 1152)        0           ['block6f_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6f_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6f_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6f_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6f_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6f_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6f_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6f_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6f_activation[0][0]',     \n",
            "                                )                                 'block6f_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6f_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6f_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6f_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6f_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6f_add (Add)              (None, 16, 16, 192)  0           ['block6f_project_bn[0][0]',     \n",
            "                                                                  'block6e_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6g_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6f_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6g_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6g_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6g_expand_activation (Act  (None, 16, 16, 1152  0          ['block6g_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6g_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6g_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6g_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6g_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6g_activation (Activation  (None, 16, 16, 1152  0          ['block6g_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6g_se_squeeze (GlobalAver  (None, 1152)        0           ['block6g_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6g_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6g_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6g_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6g_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6g_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6g_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6g_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6g_activation[0][0]',     \n",
            "                                )                                 'block6g_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6g_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6g_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6g_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6g_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6g_add (Add)              (None, 16, 16, 192)  0           ['block6g_project_bn[0][0]',     \n",
            "                                                                  'block6f_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6h_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6g_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6h_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6h_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6h_expand_activation (Act  (None, 16, 16, 1152  0          ['block6h_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6h_dwconv2 (DepthwiseConv  (None, 16, 16, 1152  10368      ['block6h_expand_activation[0][0]\n",
            " 2D)                            )                                ']                               \n",
            "                                                                                                  \n",
            " block6h_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6h_dwconv2[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6h_activation (Activation  (None, 16, 16, 1152  0          ['block6h_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6h_se_squeeze (GlobalAver  (None, 1152)        0           ['block6h_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6h_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6h_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6h_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6h_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6h_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6h_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6h_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6h_activation[0][0]',     \n",
            "                                )                                 'block6h_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6h_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6h_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6h_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6h_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6h_add (Add)              (None, 16, 16, 192)  0           ['block6h_project_bn[0][0]',     \n",
            "                                                                  'block6g_add[0][0]']            \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 16, 16, 1280  245760      ['block6h_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 16, 16, 1280  5120        ['top_conv[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 16, 16, 1280  0           ['top_bn[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 640)  819840      ['top_activation[0][0]']         \n",
            "                                                                                                  \n",
            " SEM_base/gap_layer (GlobalAver  (None, 640)         0           ['conv2d[0][0]']                 \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " SEM_base/bn_1 (BatchNormalizat  (None, 640)         2560        ['SEM_base/gap_layer[0][0]']     \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " SEM_base/bn_3 (BatchNormalizat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " SEM_base/dense_1 (Dense)       (None, 160)          102560      ['SEM_base/bn_1[0][0]']          \n",
            "                                                                                                  \n",
            " SEM_base/conv_1 (Conv2D)       (None, 16, 16, 640)  3687040     ['SEM_base/bn_3[0][0]']          \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_1/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_1/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_2/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_2/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_3/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_3/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_4/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_4/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " SEM_base/act_1 (Activation)    (None, 160)          0           ['SEM_base/dense_1[0][0]']       \n",
            "                                                                                                  \n",
            " SEM_base/act_3 (Activation)    (None, 16, 16, 640)  0           ['SEM_base/conv_1[0][0]']        \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d[0][0]']                 \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " SEM_base/bn_2 (BatchNormalizat  (None, 160)         640         ['SEM_base/act_1[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " SEM_base/bn_4 (BatchNormalizat  (None, 16, 16, 640)  2560       ['SEM_base/act_3[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_1/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_1/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_2/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_2/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_3/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_3/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_4/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_4/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " SEM_base/dense_2 (Dense)       (None, 640)          103040      ['SEM_base/bn_2[0][0]']          \n",
            "                                                                                                  \n",
            " SEM_base/conv_2 (Conv2D)       (None, 16, 16, 1)    641         ['SEM_base/bn_4[0][0]']          \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " SEM_base/act_2 (Activation)    (None, 640)          0           ['SEM_base/dense_2[0][0]']       \n",
            "                                                                                                  \n",
            " SEM_base/act_4 (Activation)    (None, 16, 16, 1)    0           ['SEM_base/conv_2[0][0]']        \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_1/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_2/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_3/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_4/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " SEM_base/mul_1 (Multiply)      (None, 16, 16, 640)  0           ['SEM_base/act_2[0][0]',         \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " SEM_base/mul_2 (Multiply)      (None, 16, 16, 640)  0           ['SEM_base/act_4[0][0]',         \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " SEM_base/add (Add)             (None, 16, 16, 640)  0           ['conv2d[0][0]',                 \n",
            "                                                                  'SEM_base/mul_1[0][0]',         \n",
            "                                                                  'SEM_base/mul_2[0][0]']         \n",
            "                                                                                                  \n",
            " CMFA_base/add (Add)            (None, 16, 16, 640)  0           ['CMFA_base/self_att_1/add_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'CMFA_base/self_att_2/add_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'CMFA_base/self_att_3/add_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'CMFA_base/self_att_4/add_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 640)  0           ['SEM_base/add[0][0]',           \n",
            "                                                                  'CMFA_base/add[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 640)         0           ['add[0][0]']                    \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            1282        ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 15,595,635\n",
            "Trainable params: 15,515,507\n",
            "Non-trainable params: 80,128\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
        "loss_fun= 'binary_crossentropy'  \n",
        "gpu_num=1\n",
        "k=3\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "batch_size= 16\n",
        "image_size=512\n",
        "classes=2\n",
        "\n",
        "base_model=get_base_model('efficientNetV2B0',image_size)  \n",
        "base_in=base_model.input\n",
        "base_out=base_model.output\n",
        "\n",
        "shape = K.int_shape(base_out)\n",
        "channel_val = shape[3]/2\n",
        "red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
        "x=iDAAM(red_feat)\n",
        "#base_out=Category_attention_block(x,classes,k)\n",
        "\n",
        "shape=K.int_shape(x)  \n",
        "x=GlobalAveragePooling2D()(x)\n",
        "out=Dense(classes,activation='softmax')(x)\n",
        "\n",
        "parallel_model=keras.Model(base_model.input,out)\n",
        "parallel_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qgw4L6PM6bU",
        "outputId": "dc7961ed-ded0-4b82-da7a-507c05e0d5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 960 images belonging to 2 classes.\n",
            "Found 240 images belonging to 2 classes.\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6527 - acc: 0.7427\n",
            "Epoch 1: acc improved from -inf to 0.74271, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 68s 934ms/step - loss: 0.6527 - acc: 0.7427 - lr: 0.0050\n",
            "Epoch 1/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5383 - acc: 0.7865\n",
            "Epoch 1: acc improved from 0.74271 to 0.78646, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 95s 1s/step - loss: 0.5383 - acc: 0.7865 - lr: 1.0000e-04\n",
            "Epoch 2/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4012 - acc: 0.8365\n",
            "Epoch 2: acc improved from 0.78646 to 0.83646, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.4012 - acc: 0.8365 - lr: 1.0000e-04\n",
            "Epoch 3/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3278 - acc: 0.8531\n",
            "Epoch 3: acc improved from 0.83646 to 0.85312, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.3278 - acc: 0.8531 - lr: 1.0000e-04\n",
            "Epoch 4/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2994 - acc: 0.8823\n",
            "Epoch 4: acc improved from 0.85312 to 0.88229, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 82s 1s/step - loss: 0.2994 - acc: 0.8823 - lr: 1.0000e-04\n",
            "Epoch 5/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2785 - acc: 0.8875\n",
            "Epoch 5: acc improved from 0.88229 to 0.88750, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.2785 - acc: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 6/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2664 - acc: 0.8917\n",
            "Epoch 6: acc improved from 0.88750 to 0.89167, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.2664 - acc: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 7/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2285 - acc: 0.9094\n",
            "Epoch 7: acc improved from 0.89167 to 0.90938, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.2285 - acc: 0.9094 - lr: 1.0000e-04\n",
            "Epoch 8/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2111 - acc: 0.9229\n",
            "Epoch 8: acc improved from 0.90938 to 0.92292, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.2111 - acc: 0.9229 - lr: 1.0000e-04\n",
            "Epoch 9/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1913 - acc: 0.9260\n",
            "Epoch 9: acc improved from 0.92292 to 0.92604, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.1913 - acc: 0.9260 - lr: 1.0000e-04\n",
            "Epoch 10/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1442 - acc: 0.9417\n",
            "Epoch 10: acc improved from 0.92604 to 0.94167, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.1442 - acc: 0.9417 - lr: 1.0000e-04\n",
            "Epoch 11/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1660 - acc: 0.9333\n",
            "Epoch 11: acc did not improve from 0.94167\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.1660 - acc: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 12/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1318 - acc: 0.9479\n",
            "Epoch 12: acc improved from 0.94167 to 0.94792, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.1318 - acc: 0.9479 - lr: 1.0000e-04\n",
            "Epoch 13/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1138 - acc: 0.9510\n",
            "Epoch 13: acc improved from 0.94792 to 0.95104, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 80s 1s/step - loss: 0.1138 - acc: 0.9510 - lr: 1.0000e-04\n",
            "Epoch 14/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1377 - acc: 0.9448\n",
            "Epoch 14: acc did not improve from 0.95104\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.1377 - acc: 0.9448 - lr: 1.0000e-04\n",
            "Epoch 15/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.9542\n",
            "Epoch 15: acc improved from 0.95104 to 0.95417, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.1177 - acc: 0.9542 - lr: 1.0000e-04\n",
            "Epoch 16/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0897 - acc: 0.9646\n",
            "Epoch 16: acc improved from 0.95417 to 0.96458, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0897 - acc: 0.9646 - lr: 1.0000e-04\n",
            "Epoch 17/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0810 - acc: 0.9729\n",
            "Epoch 17: acc improved from 0.96458 to 0.97292, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0810 - acc: 0.9729 - lr: 1.0000e-04\n",
            "Epoch 18/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.9635\n",
            "Epoch 18: acc did not improve from 0.97292\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0815 - acc: 0.9635 - lr: 1.0000e-04\n",
            "Epoch 19/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0858 - acc: 0.9677\n",
            "Epoch 19: acc did not improve from 0.97292\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0858 - acc: 0.9677 - lr: 1.0000e-04\n",
            "Epoch 20/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0696 - acc: 0.9771\n",
            "Epoch 20: acc improved from 0.97292 to 0.97708, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0696 - acc: 0.9771 - lr: 1.0000e-04\n",
            "Epoch 21/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.9812\n",
            "Epoch 21: acc improved from 0.97708 to 0.98125, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0508 - acc: 0.9812 - lr: 1.0000e-04\n",
            "Epoch 22/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.9667\n",
            "Epoch 22: acc did not improve from 0.98125\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0767 - acc: 0.9667 - lr: 1.0000e-04\n",
            "Epoch 23/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1059 - acc: 0.9688\n",
            "Epoch 23: acc did not improve from 0.98125\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.1059 - acc: 0.9688 - lr: 1.0000e-04\n",
            "Epoch 24/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0530 - acc: 0.9823\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
            "\n",
            "Epoch 24: acc improved from 0.98125 to 0.98229, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 82s 1s/step - loss: 0.0530 - acc: 0.9823 - lr: 1.0000e-04\n",
            "Epoch 25/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0467 - acc: 0.9812\n",
            "Epoch 25: acc did not improve from 0.98229\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0467 - acc: 0.9812 - lr: 8.0000e-05\n",
            "Epoch 26/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0305 - acc: 0.9896\n",
            "Epoch 26: acc improved from 0.98229 to 0.98958, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0305 - acc: 0.9896 - lr: 8.0000e-05\n",
            "Epoch 27/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0448 - acc: 0.9812\n",
            "Epoch 27: acc did not improve from 0.98958\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0448 - acc: 0.9812 - lr: 8.0000e-05\n",
            "Epoch 28/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0276 - acc: 0.9917\n",
            "Epoch 28: acc improved from 0.98958 to 0.99167, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 82s 1s/step - loss: 0.0276 - acc: 0.9917 - lr: 8.0000e-05\n",
            "Epoch 29/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9958\n",
            "Epoch 29: acc improved from 0.99167 to 0.99583, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 82s 1s/step - loss: 0.0146 - acc: 0.9958 - lr: 8.0000e-05\n",
            "Epoch 30/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.9875\n",
            "Epoch 30: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0304 - acc: 0.9875 - lr: 8.0000e-05\n",
            "Epoch 31/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.9917\n",
            "Epoch 31: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0239 - acc: 0.9917 - lr: 8.0000e-05\n",
            "Epoch 32/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.9865\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
            "\n",
            "Epoch 32: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0418 - acc: 0.9865 - lr: 8.0000e-05\n",
            "Epoch 33/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0142 - acc: 0.9979\n",
            "Epoch 33: acc improved from 0.99583 to 0.99792, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0142 - acc: 0.9979 - lr: 6.4000e-05\n",
            "Epoch 34/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9937\n",
            "Epoch 34: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0138 - acc: 0.9937 - lr: 6.4000e-05\n",
            "Epoch 35/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9948\n",
            "Epoch 35: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0138 - acc: 0.9948 - lr: 6.4000e-05\n",
            "Epoch 36/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0226 - acc: 0.9927\n",
            "Epoch 36: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0226 - acc: 0.9927 - lr: 6.4000e-05\n",
            "Epoch 37/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.9927\n",
            "Epoch 37: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0127 - acc: 0.9927 - lr: 6.4000e-05\n",
            "Epoch 38/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0146 - acc: 0.9917\n",
            "Epoch 38: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0146 - acc: 0.9917 - lr: 6.4000e-05\n",
            "Epoch 39/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9958\n",
            "Epoch 39: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0081 - acc: 0.9958 - lr: 6.4000e-05\n",
            "Epoch 40/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9969\n",
            "Epoch 40: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0124 - acc: 0.9969 - lr: 6.4000e-05\n",
            "Epoch 41/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0349 - acc: 0.9917\n",
            "Epoch 41: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0349 - acc: 0.9917 - lr: 6.4000e-05\n",
            "Epoch 42/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.9927\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
            "\n",
            "Epoch 42: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0151 - acc: 0.9927 - lr: 6.4000e-05\n",
            "Epoch 43/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9927\n",
            "Epoch 43: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0158 - acc: 0.9927 - lr: 5.1200e-05\n",
            "Epoch 44/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.9958\n",
            "Epoch 44: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0097 - acc: 0.9958 - lr: 5.1200e-05\n",
            "Epoch 45/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0128 - acc: 0.9937\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
            "\n",
            "Epoch 45: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0128 - acc: 0.9937 - lr: 5.1200e-05\n",
            "Epoch 46/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0135 - acc: 0.9958\n",
            "Epoch 46: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0135 - acc: 0.9958 - lr: 4.0960e-05\n",
            "Epoch 47/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0109 - acc: 0.9969\n",
            "Epoch 47: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0109 - acc: 0.9969 - lr: 4.0960e-05\n",
            "Epoch 48/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9969\n",
            "Epoch 48: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0076 - acc: 0.9969 - lr: 4.0960e-05\n",
            "Epoch 49/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 49: acc improved from 0.99792 to 1.00000, saving model to efficientNetV2B0+iDDAM.hdf5\n",
            "60/60 [==============================] - 81s 1s/step - loss: 0.0031 - acc: 1.0000 - lr: 4.0960e-05\n",
            "Epoch 50/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
            "Epoch 50: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0036 - acc: 0.9990 - lr: 4.0960e-05\n",
            "Epoch 51/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9990\n",
            "Epoch 51: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0056 - acc: 0.9990 - lr: 4.0960e-05\n",
            "Epoch 52/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
            "\n",
            "Epoch 52: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0031 - acc: 0.9990 - lr: 4.0960e-05\n",
            "Epoch 53/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9937\n",
            "Epoch 53: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0150 - acc: 0.9937 - lr: 3.2768e-05\n",
            "Epoch 54/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 54: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0033 - acc: 1.0000 - lr: 3.2768e-05\n",
            "Epoch 55/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 0.9990\n",
            "Epoch 55: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0023 - acc: 0.9990 - lr: 3.2768e-05\n",
            "Epoch 56/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 56: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0019 - acc: 1.0000 - lr: 3.2768e-05\n",
            "Epoch 57/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
            "Epoch 57: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0031 - acc: 0.9990 - lr: 3.2768e-05\n",
            "Epoch 58/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9990\n",
            "Epoch 58: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0046 - acc: 0.9990 - lr: 3.2768e-05\n",
            "Epoch 59/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 59: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0012 - acc: 1.0000 - lr: 3.2768e-05\n",
            "Epoch 60/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
            "Epoch 60: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0044 - acc: 0.9990 - lr: 3.2768e-05\n",
            "Epoch 61/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9990\n",
            "Epoch 61: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0054 - acc: 0.9990 - lr: 3.2768e-05\n",
            "Epoch 62/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0201 - acc: 0.9969\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
            "\n",
            "Epoch 62: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0201 - acc: 0.9969 - lr: 3.2768e-05\n",
            "Epoch 63/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9958\n",
            "Epoch 63: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0087 - acc: 0.9958 - lr: 2.6214e-05\n",
            "Epoch 64/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
            "Epoch 64: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0060 - acc: 0.9990 - lr: 2.6214e-05\n",
            "Epoch 65/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0040 - acc: 0.9979\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
            "\n",
            "Epoch 65: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0040 - acc: 0.9979 - lr: 2.6214e-05\n",
            "Epoch 66/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 0.9990\n",
            "Epoch 66: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0021 - acc: 0.9990 - lr: 2.0972e-05\n",
            "Epoch 67/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0027 - acc: 0.9990\n",
            "Epoch 67: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0027 - acc: 0.9990 - lr: 2.0972e-05\n",
            "Epoch 68/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 0.9990\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
            "\n",
            "Epoch 68: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0021 - acc: 0.9990 - lr: 2.0972e-05\n",
            "Epoch 69/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 69: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0014 - acc: 1.0000 - lr: 1.6777e-05\n",
            "Epoch 70/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9990\n",
            "Epoch 70: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 0.0043 - acc: 0.9990 - lr: 1.6777e-05\n",
            "Epoch 71/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 7.7051e-04 - acc: 1.0000\n",
            "Epoch 71: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 77s 1s/step - loss: 7.7051e-04 - acc: 1.0000 - lr: 1.6777e-05\n",
            "Epoch 72/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 9.2397e-04 - acc: 1.0000\n",
            "Epoch 72: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 9.2397e-04 - acc: 1.0000 - lr: 1.6777e-05\n",
            "Epoch 73/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9969\n",
            "Epoch 73: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0086 - acc: 0.9969 - lr: 1.6777e-05\n",
            "Epoch 74/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9979\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
            "\n",
            "Epoch 74: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0028 - acc: 0.9979 - lr: 1.6777e-05\n",
            "Epoch 75/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
            "Epoch 75: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0031 - acc: 0.9990 - lr: 1.3422e-05\n",
            "Epoch 76/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0033 - acc: 0.9990\n",
            "Epoch 76: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0033 - acc: 0.9990 - lr: 1.3422e-05\n",
            "Epoch 77/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
            "\n",
            "Epoch 77: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0037 - acc: 0.9990 - lr: 1.3422e-05\n",
            "Epoch 78/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 78: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0015 - acc: 1.0000 - lr: 1.0737e-05\n",
            "Epoch 79/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 79: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0011 - acc: 1.0000 - lr: 1.0737e-05\n",
            "Epoch 80/80\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9979\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
            "\n",
            "Epoch 80: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 78s 1s/step - loss: 0.0053 - acc: 0.9979 - lr: 1.0737e-05\n",
            "15/15 [==============================] - 9s 369ms/step - loss: 0.6852 - acc: 0.9042\n",
            "Test loss: 0.6852230429649353\n",
            "Test accuracy: 0.9041666388511658\n"
          ]
        }
      ],
      "source": [
        "history,model,valid_data=train_model(parallel_model,\n",
        "                                     'messidor',\n",
        "                                     image_size,\n",
        "                                     batch_size,\n",
        "                                     'efficientNetV2B0',\n",
        "                                     lr1,lr2,1,80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsEEInLtND3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "928902c1-03e5-494c-f8ad-2dac368b80ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[[9.77844357e-01 2.21556146e-02]\n",
            " [1.00000000e+00 1.00714074e-13]\n",
            " [9.99999881e-01 9.47315755e-08]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 3.55899720e-28]\n",
            " [1.00000000e+00 2.13333370e-24]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.01001494e-01 8.98998499e-01]\n",
            " [1.00000000e+00 4.03532961e-23]\n",
            " [1.00000000e+00 3.17192640e-22]\n",
            " [1.00000000e+00 1.74447783e-12]\n",
            " [1.00000000e+00 9.15254743e-13]\n",
            " [1.00000000e+00 4.68204975e-29]\n",
            " [1.00000000e+00 3.31890379e-15]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.99999523e-01 5.06613162e-07]\n",
            " [9.99999881e-01 1.43027464e-07]\n",
            " [1.00000000e+00 2.28174445e-29]\n",
            " [1.00000000e+00 5.46322738e-08]\n",
            " [1.00000000e+00 5.35888364e-17]\n",
            " [1.00000000e+00 1.49314093e-24]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 4.31270442e-26]\n",
            " [1.00000000e+00 6.05126037e-22]\n",
            " [1.00000000e+00 1.27984334e-09]\n",
            " [1.00000000e+00 2.81541576e-16]\n",
            " [9.99999762e-01 2.87390492e-07]\n",
            " [8.73053074e-01 1.26946911e-01]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 5.53254154e-23]\n",
            " [1.00000000e+00 5.31920699e-14]\n",
            " [1.00000000e+00 3.18770179e-18]\n",
            " [9.06604946e-01 9.33950320e-02]\n",
            " [1.00000000e+00 1.50113297e-10]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 2.15896058e-22]\n",
            " [1.00000000e+00 5.44308293e-26]\n",
            " [1.00000000e+00 7.55140484e-20]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 3.35514080e-25]\n",
            " [1.00000000e+00 1.96390074e-11]\n",
            " [1.00000000e+00 1.05514946e-11]\n",
            " [1.00000000e+00 3.40602351e-12]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.35513308e-34]\n",
            " [9.99999285e-01 7.50472680e-07]\n",
            " [1.00000000e+00 6.31401603e-18]\n",
            " [9.99977112e-01 2.29307643e-05]\n",
            " [1.00000000e+00 5.53575740e-13]\n",
            " [9.99993563e-01 6.39775726e-06]\n",
            " [9.99975920e-01 2.40457448e-05]\n",
            " [1.00000000e+00 1.53661849e-38]\n",
            " [1.00000000e+00 3.60472654e-22]\n",
            " [1.00000000e+00 4.99031171e-37]\n",
            " [1.00000000e+00 1.15199816e-16]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.35238421e-01 6.47616088e-02]\n",
            " [3.64437629e-03 9.96355653e-01]\n",
            " [1.00000000e+00 3.29978758e-17]\n",
            " [1.00000000e+00 1.05396756e-17]\n",
            " [1.00000000e+00 2.95118025e-18]\n",
            " [9.99996185e-01 3.81882137e-06]\n",
            " [1.00000000e+00 1.74148926e-08]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.57961975e-22]\n",
            " [1.00000000e+00 4.06321154e-15]\n",
            " [1.00000000e+00 1.14147399e-15]\n",
            " [1.00000000e+00 8.87855171e-17]\n",
            " [1.00000000e+00 7.42861212e-18]\n",
            " [1.00000000e+00 2.81176312e-26]\n",
            " [1.00000000e+00 2.47059462e-19]\n",
            " [1.00000000e+00 2.05017356e-18]\n",
            " [9.91997182e-01 8.00282042e-03]\n",
            " [1.00000000e+00 1.18546877e-17]\n",
            " [1.00000000e+00 2.87594083e-25]\n",
            " [1.00000000e+00 1.46672008e-10]\n",
            " [1.00000000e+00 5.80580285e-37]\n",
            " [9.99913931e-01 8.61002700e-05]\n",
            " [1.00000000e+00 2.93344653e-18]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 4.59247224e-10]\n",
            " [1.00000000e+00 1.32858446e-09]\n",
            " [1.00000000e+00 3.58424115e-22]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.99988675e-01 1.12744992e-05]\n",
            " [9.99999881e-01 8.45183763e-08]\n",
            " [1.00000000e+00 4.48303313e-33]\n",
            " [1.00000000e+00 5.84229339e-26]\n",
            " [1.00000000e+00 1.97615117e-25]\n",
            " [1.00000000e+00 2.03833498e-19]\n",
            " [1.00000000e+00 6.63738809e-24]\n",
            " [1.00000000e+00 6.77656401e-17]\n",
            " [9.99981403e-01 1.86405268e-05]\n",
            " [9.99999642e-01 4.08016064e-07]\n",
            " [3.27382386e-01 6.72617614e-01]\n",
            " [1.00000000e+00 8.07027804e-23]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.52283405e-17]\n",
            " [1.00000000e+00 1.50639375e-13]\n",
            " [1.00000000e+00 1.01928049e-14]\n",
            " [1.00000000e+00 3.94318379e-26]\n",
            " [1.00000000e+00 5.15529357e-19]\n",
            " [1.00000000e+00 2.64910537e-19]\n",
            " [1.00000000e+00 2.68080474e-10]\n",
            " [1.00000000e+00 2.23832453e-10]\n",
            " [9.99973059e-01 2.69621269e-05]\n",
            " [1.00000000e+00 1.05323288e-08]\n",
            " [9.99972343e-01 2.77110848e-05]\n",
            " [9.99884844e-01 1.15188690e-04]\n",
            " [1.00000000e+00 7.99335424e-13]\n",
            " [9.99999166e-01 8.03390662e-07]\n",
            " [1.00000000e+00 1.18115077e-14]\n",
            " [1.00000000e+00 1.09370314e-37]\n",
            " [1.00000000e+00 4.31019359e-16]\n",
            " [1.00000000e+00 1.04644765e-10]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 2.37111571e-24]\n",
            " [1.00000000e+00 3.77943038e-10]\n",
            " [1.00000000e+00 1.57455046e-34]\n",
            " [1.00000000e+00 9.42067948e-25]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.99536991e-01 4.63045639e-04]\n",
            " [9.99999762e-01 2.82343279e-07]\n",
            " [7.55428628e-04 9.99244571e-01]\n",
            " [1.00000000e+00 2.48398471e-27]\n",
            " [9.99994040e-01 5.95850270e-06]\n",
            " [1.00000000e+00 1.52183794e-21]\n",
            " [1.00000000e+00 1.11648993e-18]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 6.97749566e-26]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 6.61668881e-30]\n",
            " [1.00000000e+00 3.85967375e-29]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [9.74764168e-01 2.52358690e-02]\n",
            " [1.00000000e+00 1.39704666e-33]\n",
            " [1.00000000e+00 2.46193042e-26]\n",
            " [1.00000000e+00 3.49963388e-16]\n",
            " [9.99749720e-01 2.50306068e-04]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 2.96871949e-08]\n",
            " [3.86617211e-14 1.00000000e+00]\n",
            " [9.99998569e-01 1.37647783e-06]\n",
            " [6.73115437e-21 1.00000000e+00]\n",
            " [1.21954533e-16 1.00000000e+00]\n",
            " [5.77540415e-16 1.00000000e+00]\n",
            " [1.77168843e-07 9.99999881e-01]\n",
            " [1.03132182e-03 9.98968720e-01]\n",
            " [2.57576919e-22 1.00000000e+00]\n",
            " [6.79986933e-17 1.00000000e+00]\n",
            " [1.51678493e-20 1.00000000e+00]\n",
            " [1.64114772e-05 9.99983549e-01]\n",
            " [9.77493525e-01 2.25064512e-02]\n",
            " [9.99999046e-01 9.27323242e-07]\n",
            " [3.46458137e-07 9.99999642e-01]\n",
            " [8.51633012e-01 1.48366973e-01]\n",
            " [1.00000000e+00 2.01576941e-36]\n",
            " [5.91033399e-01 4.08966631e-01]\n",
            " [8.40175152e-01 1.59824848e-01]\n",
            " [2.50110332e-09 1.00000000e+00]\n",
            " [9.43830423e-03 9.90561664e-01]\n",
            " [2.19014147e-11 1.00000000e+00]\n",
            " [7.80188246e-03 9.92198050e-01]\n",
            " [2.05407948e-11 1.00000000e+00]\n",
            " [1.57262164e-03 9.98427391e-01]\n",
            " [9.98816609e-01 1.18337548e-03]\n",
            " [7.42727480e-08 9.99999881e-01]\n",
            " [2.21755001e-13 1.00000000e+00]\n",
            " [8.24041508e-15 1.00000000e+00]\n",
            " [4.70263568e-21 1.00000000e+00]\n",
            " [1.50954700e-04 9.99849081e-01]\n",
            " [1.23048219e-13 1.00000000e+00]\n",
            " [1.00000000e+00 1.73157354e-22]\n",
            " [1.00000000e+00 5.20390877e-08]\n",
            " [2.93461341e-16 1.00000000e+00]\n",
            " [9.98010695e-01 1.98927498e-03]\n",
            " [1.83985685e-05 9.99981642e-01]\n",
            " [1.60827429e-09 1.00000000e+00]\n",
            " [1.12190543e-11 1.00000000e+00]\n",
            " [1.88992172e-23 1.00000000e+00]\n",
            " [2.10966314e-12 1.00000000e+00]\n",
            " [1.01512096e-21 1.00000000e+00]\n",
            " [2.48881769e-08 1.00000000e+00]\n",
            " [2.40474814e-15 1.00000000e+00]\n",
            " [4.11420420e-12 1.00000000e+00]\n",
            " [2.75488600e-19 1.00000000e+00]\n",
            " [4.47646948e-03 9.95523572e-01]\n",
            " [1.38234326e-15 1.00000000e+00]\n",
            " [3.19645738e-14 1.00000000e+00]\n",
            " [2.63459550e-25 1.00000000e+00]\n",
            " [6.58055228e-08 9.99999881e-01]\n",
            " [9.32515987e-14 1.00000000e+00]\n",
            " [5.64774769e-18 1.00000000e+00]\n",
            " [4.08152603e-02 9.59184766e-01]\n",
            " [8.30506719e-10 1.00000000e+00]\n",
            " [5.42797754e-03 9.94571984e-01]\n",
            " [2.38095126e-08 1.00000000e+00]\n",
            " [3.18300445e-04 9.99681711e-01]\n",
            " [9.87563908e-01 1.24360779e-02]\n",
            " [9.75112379e-01 2.48876642e-02]\n",
            " [9.19497013e-01 8.05030391e-02]\n",
            " [5.76106654e-13 1.00000000e+00]\n",
            " [3.50697696e-20 1.00000000e+00]\n",
            " [7.82119730e-14 1.00000000e+00]\n",
            " [9.92782245e-12 1.00000000e+00]\n",
            " [9.34073478e-02 9.06592607e-01]\n",
            " [4.37130808e-17 1.00000000e+00]\n",
            " [9.19434679e-05 9.99908090e-01]\n",
            " [4.62991778e-07 9.99999523e-01]\n",
            " [1.00000000e+00 2.43595322e-09]\n",
            " [1.28236380e-07 9.99999881e-01]\n",
            " [3.37120569e-16 1.00000000e+00]\n",
            " [3.51871043e-01 6.48128986e-01]\n",
            " [4.24373291e-13 1.00000000e+00]\n",
            " [9.97839570e-01 2.16039480e-03]\n",
            " [1.60157773e-15 1.00000000e+00]\n",
            " [3.98833789e-02 9.60116625e-01]\n",
            " [1.00000000e+00 8.42414269e-26]\n",
            " [7.50486695e-09 1.00000000e+00]\n",
            " [1.77361559e-09 1.00000000e+00]\n",
            " [4.77244871e-13 1.00000000e+00]\n",
            " [2.02595928e-07 9.99999762e-01]\n",
            " [4.89241590e-12 1.00000000e+00]\n",
            " [1.91539160e-10 1.00000000e+00]\n",
            " [3.96528833e-07 9.99999642e-01]\n",
            " [7.72213002e-15 1.00000000e+00]\n",
            " [1.45527271e-10 1.00000000e+00]\n",
            " [9.54093993e-01 4.59059812e-02]\n",
            " [1.38082914e-05 9.99986172e-01]\n",
            " [1.28698313e-14 1.00000000e+00]\n",
            " [4.97740150e-15 1.00000000e+00]\n",
            " [1.34753294e-14 1.00000000e+00]\n",
            " [3.84034093e-09 1.00000000e+00]\n",
            " [1.25760415e-18 1.00000000e+00]\n",
            " [4.37980781e-08 1.00000000e+00]\n",
            " [1.54193999e-21 1.00000000e+00]\n",
            " [2.84079552e-12 1.00000000e+00]\n",
            " [9.98701692e-01 1.29823235e-03]]\n",
            "Confusion Matrix\n",
            "[[139   4]\n",
            " [ 19  78]]\n",
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "non-referable       0.88      0.97      0.92       143\n",
            "    referable       0.95      0.80      0.87        97\n",
            "\n",
            "     accuracy                           0.90       240\n",
            "    macro avg       0.92      0.89      0.90       240\n",
            " weighted avg       0.91      0.90      0.90       240\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plotmodel(history,'efficientNetV2B0')            \n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "Y_pred = model.predict(valid_data, 240 // 4)\n",
        "#print(Y_pred.shape)\n",
        "#print(type(Y_pred))\n",
        "print(valid_data.classes)  \n",
        "print(Y_pred)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "#print(y_pred)\n",
        "print('Confusion Matrix')\n",
        "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
        "\n",
        "print(confusion_matrix(valid_data.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['non-referable', 'referable']\n",
        "print(classification_report(valid_data.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(matrix,annot=True,fmt='d')\n",
        "plt.xlabel('Predicted value')\n",
        "plt.ylabel('Truth')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDiyJtvhNDuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e1853a-eb10-4bd6-808f-df1446b8e44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plot_metric\n",
            "  Downloading plot_metric-0.0.6-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.21.5)\n",
            "Requirement already satisfied: colorlover>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (0.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.2->plot_metric) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->plot_metric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->plot_metric) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot_metric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot_metric) (3.1.0)\n",
            "Installing collected packages: plot-metric\n",
            "Successfully installed plot-metric-0.0.6\n"
          ]
        }
      ],
      "source": [
        "pip install plot_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3J5q1SLNMkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "da5eccd8-8786-41ff-e480-7b59bf627743"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from plot_metric.functions import BinaryClassification\n",
        "# Visualisation with plot_metric\n",
        "y_true = valid_data.classes\n",
        "y_probas = y_pred\n",
        "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
        "\n",
        "# Figures\n",
        "plt.figure(figsize=(5,5))\n",
        "bc.plot_roc_curve()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "EfficientNetV2B0+iDDAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}