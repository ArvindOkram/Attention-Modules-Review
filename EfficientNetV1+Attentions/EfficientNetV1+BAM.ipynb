{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZmUeX0KMRRE",
        "outputId": "298d3094-9262-46e4-90ea-6c5b41825c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "pip install keras_applications "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YxwC4ylMh4G",
        "outputId": "2f6a23ab-681b-42c7-c21c-cd46e6d5ea36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k4kFe31MptM"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, MaxPool2D\n",
        "from keras.layers.core import Lambda\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import *\n",
        "#from keras.utils import multi_gpu_model\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import load_model\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Lambda\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.inception_v3 import InceptionV3 \n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from keras.applications.resnet50 import ResNet50\n",
        "from keras_applications.resnet import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "import os\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axHjDrWRMr2D"
      },
      "outputs": [],
      "source": [
        "def Bottleneck_Attention_Block(inputs,ratio = 16):\n",
        "  image = tf.zeros([16,16,1024])\n",
        "  shape=K.int_shape(inputs)\n",
        "  ch = shape[3]\n",
        "  x = tf.keras.layers.AveragePooling2D(pool_size=(shape[1],shape[2]))(inputs)\n",
        "  x = Dense(ch//ratio, activation='relu')(x)\n",
        "  F1 = Dense(ch, activation='sigmoid')(x)\n",
        "  #x=tf.keras.layers.BatchNormalization() (x)\n",
        "  #print(x.shape)\n",
        "  #F1 =  tf.keras.layers.experimental.preprocessing.Resizing(shape[0], shape[1], interpolation=\"bilinear\", crop_to_aspect_ratio=False)\n",
        "  #print(F1.shape)\n",
        "  con_val = ch//ratio\n",
        "  \"\"\"-----------------------------------------\"\"\"\n",
        "  x1 = Conv2D(con_val,1, padding='same') (inputs)\n",
        "  #print(x1.shape)\n",
        "  x=tf.keras.layers.BatchNormalization() (x1)\n",
        "  act1=Activation('relu') (x)\n",
        "\n",
        "  x2 = Conv2D(con_val,3, strides = (1,1), dilation_rate = (4,4), padding='same') (act1)\n",
        "  #print(x2.shape)\n",
        "  x=tf.keras.layers.BatchNormalization() (x2)\n",
        "  act2=Activation('relu') (x)\n",
        "\n",
        "  x3 = Conv2D(con_val,3, strides = (1,1), dilation_rate = (4,4), padding='same') (act2)\n",
        "  #print(x3.shape)\n",
        "  x=tf.keras.layers.BatchNormalization() (x3)\n",
        "  act3=Activation('relu') (x)\n",
        "\n",
        "  x4 = Conv2D(1,1, padding='same') (x)\n",
        "  #print(x4.shape)\n",
        "  x=tf.keras.layers.BatchNormalization() (x4)\n",
        "  #print(x.shape)\n",
        "  F2 = x\n",
        "\n",
        "  add_ele = tf.keras.layers.Add()([F1,F2])\n",
        "  B_A= Activation('sigmoid') (add_ele)\n",
        "\n",
        "  #print(B_A.shape)\n",
        "\n",
        "  mul_input_BA = tf.keras.layers.Multiply()([B_A,inputs])\n",
        "  out = tf.keras.layers.Add()([mul_input_BA,inputs])\n",
        "\n",
        "  return out\n",
        "\n",
        "def smooth_curve(points, factor=0.6):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points    \n",
        "   \n",
        "def plotmodel(history,name):\n",
        "    \n",
        "    acc = history.history['acc']\n",
        "    #val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    #val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1) \n",
        "    \n",
        "    plt.figure(1)                  \n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    #plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    plt.legend(['train_acc'], loc='upper left')\n",
        "    plt.savefig('acc_'+name+'.png')\n",
        "    \n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    #plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "    plt.legend(['train_loss'], loc='upper right')\n",
        "    plt.savefig('loss_'+name+'.png')\n",
        "    \n",
        "def get_base_model(model_name,image_size):\n",
        "    if model_name =='vgg16':\n",
        "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='resnet50':\n",
        "        base_model=ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='xception':\n",
        "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
        "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
        "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
        "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenetv2':\n",
        "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='inceptionv3':   \n",
        "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='inceptionv2':\n",
        "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='efficientnetB0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0 (include_top=False, weights = 'imagenet',input_shape = (image_size,image_size,3))\n",
        "    if model_name =='efficientNetV2B0':\n",
        "        base_model = tf.keras.applications.EfficientNetV2B0 (include_top=False, weights = 'imagenet',input_shape = (image_size,image_size,3))\n",
        "    if model_name =='nasnet':\n",
        "        base_model=tf.keras.applications.NASNetMobile (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    \n",
        "    return base_model\n",
        "\n",
        "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
        "    \n",
        "    dataParam={'messidor': [960,240,2,'../content/drive/MyDrive/Dataset/Messidor_512/train',\n",
        "                            '../content/drive/MyDrive/Dataset/Messidor_512/test'],\n",
        "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
        "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
        "    \n",
        "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
        "    \n",
        "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
        "    valid = ImageDataGenerator()\n",
        "    train_data=train.flow_from_directory(train_dir,\n",
        "                                         target_size=(image_size,image_size),\n",
        "                                         shuffle = True,\n",
        "                                         batch_size=batch_size)\n",
        "    valid_data=valid.flow_from_directory(test_dir,\n",
        "                                         target_size=(image_size,image_size),\n",
        "                                         shuffle = False,\n",
        "                                         batch_size=batch_size)\n",
        "\n",
        "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
        "    \n",
        "    filepath = \"efficientnetB0+BAM.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False   \n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
        "    model.fit(train_data,\n",
        "                        steps_per_epoch=train_num/batch_size,\n",
        "                        epochs=Epochs1, \n",
        "                        workers=2,\n",
        "                        callbacks=[lr_decay,checkpoint])   \n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = True\n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
        "    history=model.fit(train_data,\n",
        "                        steps_per_epoch=train_num/batch_size,\n",
        "                        epochs=Epochs2,\n",
        "                        workers=2,\n",
        "                        callbacks=[lr_decay,checkpoint])\n",
        "    \n",
        "    score = model.evaluate(valid_data,batch_size = 64)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    \n",
        "    return history,model,valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTUSzdUmMxau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd66225-7680-48a4-c9c7-945ced712ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 512, 512, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 512, 512, 3)  7           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 513, 513, 3)  0           ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 256, 256, 32  864         ['stem_conv_pad[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 256, 256, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 256, 256, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 256, 256, 32  288        ['stem_activation[0][0]']        \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 256, 256, 32  128        ['block1a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 256, 256, 32  0          ['block1a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 256, 256, 32  0           ['block1a_activation[0][0]',     \n",
            "                                )                                 'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 256, 256, 16  512         ['block1a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 256, 256, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 256, 256, 96  1536        ['block1a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 256, 256, 96  384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 256, 256, 96  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 257, 257, 96  0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 128, 128, 96  864        ['block2a_dwconv_pad[0][0]']     \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 128, 128, 96  384        ['block2a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 128, 128, 96  0          ['block2a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 128, 128, 96  0           ['block2a_activation[0][0]',     \n",
            "                                )                                 'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 128, 128, 24  2304        ['block2a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 128, 128, 24  96         ['block2a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 128, 128, 14  3456        ['block2a_project_bn[0][0]']     \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 128, 128, 14  576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                       4)                                                                \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 128, 128, 14  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                       4)                                                                \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 128, 128, 14  1296       ['block2b_expand_activation[0][0]\n",
            " D)                             4)                               ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 128, 128, 14  576        ['block2b_dwconv[0][0]']         \n",
            " )                              4)                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 128, 128, 14  0          ['block2b_bn[0][0]']             \n",
            " )                              4)                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 128, 128, 14  0           ['block2b_activation[0][0]',     \n",
            "                                4)                                'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 128, 128, 24  3456        ['block2b_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 128, 128, 24  96         ['block2b_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 128, 128, 24  0           ['block2b_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 128, 128, 24  0           ['block2b_drop[0][0]',           \n",
            "                                )                                 'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 128, 128, 14  3456        ['block2b_add[0][0]']            \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 128, 128, 14  576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                       4)                                                                \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 128, 128, 14  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                       4)                                                                \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 131, 131, 14  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                           4)                               ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 64, 64, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 64, 64, 144)  576        ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 64, 64, 144)  0          ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 64, 64, 144)  0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 64, 64, 40)   5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 64, 64, 40)  160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 64, 64, 240)  9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 64, 64, 240)  960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 64, 64, 240)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 64, 64, 240)  6000       ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 64, 64, 240)  960        ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 64, 64, 240)  0          ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 64, 64, 240)  0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 64, 64, 40)   9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 64, 64, 40)  160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 64, 64, 40)   0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 64, 64, 40)   0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 64, 64, 240)  9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 64, 64, 240)  960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 64, 64, 240)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 65, 65, 240)  0          ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 32, 32, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 32, 32, 240)  960        ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 32, 32, 240)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 32, 32, 240)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 32, 32, 80)   19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 32, 32, 80)  320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 32, 32, 480)  38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 32, 32, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 32, 32, 480)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 32, 32, 480)  4320       ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 32, 32, 480)  1920       ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 32, 32, 480)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 32, 32, 480)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 32, 32, 80)   38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 32, 32, 80)  320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 32, 32, 80)   0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 32, 32, 80)   0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 32, 32, 480)  38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 32, 32, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 32, 32, 480)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 32, 32, 480)  4320       ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 32, 32, 480)  1920       ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 32, 32, 480)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 32, 32, 480)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 32, 32, 80)   38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 32, 32, 80)  320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 32, 32, 80)   0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 32, 32, 80)   0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 32, 32, 480)  38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 32, 32, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 32, 32, 480)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 32, 32, 480)  12000      ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 32, 32, 480)  1920       ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 32, 32, 480)  0          ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 32, 32, 480)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 32, 32, 112)  53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 32, 32, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 32, 32, 672)  16800      ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 32, 32, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 32, 32, 112)  0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 32, 32, 112)  0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 32, 32, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 32, 32, 672)  16800      ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 32, 32, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 32, 32, 112)  0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 32, 32, 112)  0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 32, 32, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 35, 35, 672)  0          ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 16, 16, 672)  16800      ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 16, 16, 672)  2688       ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 16, 16, 672)  0          ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 16, 16, 672)  0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 16, 16, 192)  129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6b_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 16, 16, 1152  0          ['block6b_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 16, 16, 1152  28800      ['block6b_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6b_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 16, 16, 1152  0          ['block6b_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6b_activation[0][0]',     \n",
            "                                )                                 'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 16, 16, 192)  0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 16, 16, 192)  0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6b_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6c_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 16, 16, 1152  0          ['block6c_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 16, 16, 1152  28800      ['block6c_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6c_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 16, 16, 1152  0          ['block6c_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6c_activation[0][0]',     \n",
            "                                )                                 'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 16, 16, 192)  0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 16, 16, 192)  0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6c_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6d_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 16, 16, 1152  0          ['block6d_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 16, 16, 1152  28800      ['block6d_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6d_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 16, 16, 1152  0          ['block6d_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6d_activation[0][0]',     \n",
            "                                )                                 'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 16, 16, 192)  0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 16, 16, 192)  0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6d_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block7a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 16, 16, 1152  0          ['block7a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 16, 16, 1152  10368      ['block7a_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block7a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 16, 16, 1152  0          ['block7a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block7a_activation[0][0]',     \n",
            "                                )                                 'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 16, 16, 320)  368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 16, 16, 320)  1280       ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 16, 16, 1280  409600      ['block7a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 16, 16, 1280  5120        ['top_conv[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 16, 16, 1280  0           ['top_bn[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 640)  819840      ['top_activation[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 40)   25640       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 40)  160         ['conv2d_1[0][0]']               \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 40)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 40)   14440       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 40)  160         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 16, 16, 40)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 40)   14440       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 640)   0           ['conv2d[0][0]']                 \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 40)  160         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1, 1, 40)     25640       ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 1)    41          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1, 1, 640)    26240       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 1)   4           ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 640)  0           ['dense_1[0][0]',                \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 16, 16, 640)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 16, 16, 640)  0           ['activation_3[0][0]',           \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 640)  0           ['multiply[0][0]',               \n",
            "                                                                  'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 640)         0           ['add_1[0][0]']                  \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2)            1282        ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,977,618\n",
            "Trainable params: 4,935,353\n",
            "Non-trainable params: 42,265\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
        "loss_fun= 'binary_crossentropy'  \n",
        "gpu_num=1\n",
        "k=3\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "batch_size= 16\n",
        "image_size=512\n",
        "classes=2\n",
        "\n",
        "base_model=get_base_model('efficientnetB0',image_size)  \n",
        "base_in=base_model.input\n",
        "base_out=base_model.output\n",
        "\n",
        "shape = K.int_shape(base_out)\n",
        "channel_val = shape[3]/2\n",
        "red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
        "x=Bottleneck_Attention_Block(red_feat)\n",
        "#base_out=Category_attention_block(x,classes,k)\n",
        "\n",
        "shape=K.int_shape(x)  \n",
        "x=GlobalAveragePooling2D()(x)\n",
        "out=Dense(classes,activation='softmax')(x)\n",
        "\n",
        "parallel_model=keras.Model(base_model.input,out)\n",
        "parallel_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qgw4L6PM6bU",
        "outputId": "7df93507-f7a0-439f-dc96-110c90d98f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 960 images belonging to 2 classes.\n",
            "Found 240 images belonging to 2 classes.\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6259 - acc: 0.7260\n",
            "Epoch 1: acc improved from -inf to 0.72604, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 63s 847ms/step - loss: 0.6259 - acc: 0.7260 - lr: 0.0050\n",
            "Epoch 1/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4854 - acc: 0.7708\n",
            "Epoch 1: acc improved from 0.72604 to 0.77083, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 106s 2s/step - loss: 0.4854 - acc: 0.7708 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3763 - acc: 0.8385\n",
            "Epoch 2: acc improved from 0.77083 to 0.83854, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.3763 - acc: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3372 - acc: 0.8687\n",
            "Epoch 3: acc improved from 0.83854 to 0.86875, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.3372 - acc: 0.8687 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3040 - acc: 0.8823\n",
            "Epoch 4: acc improved from 0.86875 to 0.88229, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.3040 - acc: 0.8823 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2793 - acc: 0.8802\n",
            "Epoch 5: acc did not improve from 0.88229\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.2793 - acc: 0.8802 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2721 - acc: 0.8896\n",
            "Epoch 6: acc improved from 0.88229 to 0.88958, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.2721 - acc: 0.8896 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2783 - acc: 0.8938\n",
            "Epoch 7: acc improved from 0.88958 to 0.89375, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.2783 - acc: 0.8938 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2143 - acc: 0.9167\n",
            "Epoch 8: acc improved from 0.89375 to 0.91667, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.2143 - acc: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2386 - acc: 0.9021\n",
            "Epoch 9: acc did not improve from 0.91667\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.2386 - acc: 0.9021 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2115 - acc: 0.9167\n",
            "Epoch 10: acc did not improve from 0.91667\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.2115 - acc: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1775 - acc: 0.9271\n",
            "Epoch 11: acc improved from 0.91667 to 0.92708, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.1775 - acc: 0.9271 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2009 - acc: 0.9167\n",
            "Epoch 12: acc did not improve from 0.92708\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.2009 - acc: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1784 - acc: 0.9156\n",
            "Epoch 13: acc did not improve from 0.92708\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.1784 - acc: 0.9156 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1648 - acc: 0.9365\n",
            "Epoch 14: acc improved from 0.92708 to 0.93646, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.1648 - acc: 0.9365 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1418 - acc: 0.9385\n",
            "Epoch 15: acc improved from 0.93646 to 0.93854, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.1418 - acc: 0.9385 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9406\n",
            "Epoch 16: acc improved from 0.93854 to 0.94063, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.1440 - acc: 0.9406 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1599 - acc: 0.9292\n",
            "Epoch 17: acc did not improve from 0.94063\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.1599 - acc: 0.9292 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.9458\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
            "\n",
            "Epoch 18: acc improved from 0.94063 to 0.94583, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.1572 - acc: 0.9458 - lr: 1.0000e-04\n",
            "Epoch 19/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1122 - acc: 0.9594\n",
            "Epoch 19: acc improved from 0.94583 to 0.95938, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.1122 - acc: 0.9594 - lr: 8.0000e-05\n",
            "Epoch 20/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1271 - acc: 0.9531\n",
            "Epoch 20: acc did not improve from 0.95938\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.1271 - acc: 0.9531 - lr: 8.0000e-05\n",
            "Epoch 21/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1080 - acc: 0.9646\n",
            "Epoch 21: acc improved from 0.95938 to 0.96458, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.1080 - acc: 0.9646 - lr: 8.0000e-05\n",
            "Epoch 22/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0929 - acc: 0.9667\n",
            "Epoch 22: acc improved from 0.96458 to 0.96667, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.0929 - acc: 0.9667 - lr: 8.0000e-05\n",
            "Epoch 23/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0840 - acc: 0.9667\n",
            "Epoch 23: acc did not improve from 0.96667\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0840 - acc: 0.9667 - lr: 8.0000e-05\n",
            "Epoch 24/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0791 - acc: 0.9677\n",
            "Epoch 24: acc improved from 0.96667 to 0.96771, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.0791 - acc: 0.9677 - lr: 8.0000e-05\n",
            "Epoch 25/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0806 - acc: 0.9750\n",
            "Epoch 25: acc improved from 0.96771 to 0.97500, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.0806 - acc: 0.9750 - lr: 8.0000e-05\n",
            "Epoch 26/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0585 - acc: 0.9823\n",
            "Epoch 26: acc improved from 0.97500 to 0.98229, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.0585 - acc: 0.9823 - lr: 8.0000e-05\n",
            "Epoch 27/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0673 - acc: 0.9781\n",
            "Epoch 27: acc did not improve from 0.98229\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0673 - acc: 0.9781 - lr: 8.0000e-05\n",
            "Epoch 28/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.9771\n",
            "Epoch 28: acc did not improve from 0.98229\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0590 - acc: 0.9771 - lr: 8.0000e-05\n",
            "Epoch 29/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0668 - acc: 0.9750\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
            "\n",
            "Epoch 29: acc did not improve from 0.98229\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0668 - acc: 0.9750 - lr: 8.0000e-05\n",
            "Epoch 30/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0489 - acc: 0.9792\n",
            "Epoch 30: acc did not improve from 0.98229\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0489 - acc: 0.9792 - lr: 6.4000e-05\n",
            "Epoch 31/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.9854\n",
            "Epoch 31: acc improved from 0.98229 to 0.98542, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.0417 - acc: 0.9854 - lr: 6.4000e-05\n",
            "Epoch 32/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0574 - acc: 0.9781\n",
            "Epoch 32: acc did not improve from 0.98542\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0574 - acc: 0.9781 - lr: 6.4000e-05\n",
            "Epoch 33/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.9760\n",
            "Epoch 33: acc did not improve from 0.98542\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0596 - acc: 0.9760 - lr: 6.4000e-05\n",
            "Epoch 34/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0480 - acc: 0.9844\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
            "\n",
            "Epoch 34: acc did not improve from 0.98542\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0480 - acc: 0.9844 - lr: 6.4000e-05\n",
            "Epoch 35/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.9771\n",
            "Epoch 35: acc did not improve from 0.98542\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0551 - acc: 0.9771 - lr: 5.1200e-05\n",
            "Epoch 36/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0349 - acc: 0.9906\n",
            "Epoch 36: acc improved from 0.98542 to 0.99063, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.0349 - acc: 0.9906 - lr: 5.1200e-05\n",
            "Epoch 37/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9854\n",
            "Epoch 37: acc did not improve from 0.99063\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0456 - acc: 0.9854 - lr: 5.1200e-05\n",
            "Epoch 38/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0450 - acc: 0.9833\n",
            "Epoch 38: acc did not improve from 0.99063\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0450 - acc: 0.9833 - lr: 5.1200e-05\n",
            "Epoch 39/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0332 - acc: 0.9854\n",
            "Epoch 39: acc did not improve from 0.99063\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0332 - acc: 0.9854 - lr: 5.1200e-05\n",
            "Epoch 40/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0227 - acc: 0.9937\n",
            "Epoch 40: acc improved from 0.99063 to 0.99375, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.0227 - acc: 0.9937 - lr: 5.1200e-05\n",
            "Epoch 41/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0326 - acc: 0.9875\n",
            "Epoch 41: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0326 - acc: 0.9875 - lr: 5.1200e-05\n",
            "Epoch 42/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0331 - acc: 0.9885\n",
            "Epoch 42: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0331 - acc: 0.9885 - lr: 5.1200e-05\n",
            "Epoch 43/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.9937\n",
            "Epoch 43: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0213 - acc: 0.9937 - lr: 5.1200e-05\n",
            "Epoch 44/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0390 - acc: 0.9854\n",
            "Epoch 44: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0390 - acc: 0.9854 - lr: 5.1200e-05\n",
            "Epoch 45/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9958\n",
            "Epoch 45: acc improved from 0.99375 to 0.99583, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.0214 - acc: 0.9958 - lr: 5.1200e-05\n",
            "Epoch 46/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0444 - acc: 0.9844\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
            "\n",
            "Epoch 46: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0444 - acc: 0.9844 - lr: 5.1200e-05\n",
            "Epoch 47/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.9865\n",
            "Epoch 47: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0429 - acc: 0.9865 - lr: 4.0960e-05\n",
            "Epoch 48/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.9917\n",
            "Epoch 48: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0232 - acc: 0.9917 - lr: 4.0960e-05\n",
            "Epoch 49/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9948\n",
            "Epoch 49: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0149 - acc: 0.9948 - lr: 4.0960e-05\n",
            "Epoch 50/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9958\n",
            "Epoch 50: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0117 - acc: 0.9958 - lr: 4.0960e-05\n",
            "Epoch 51/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.9937\n",
            "Epoch 51: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0229 - acc: 0.9937 - lr: 4.0960e-05\n",
            "Epoch 52/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0252 - acc: 0.9906\n",
            "Epoch 52: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0252 - acc: 0.9906 - lr: 4.0960e-05\n",
            "Epoch 53/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.9906\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
            "\n",
            "Epoch 53: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0228 - acc: 0.9906 - lr: 4.0960e-05\n",
            "Epoch 54/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0246 - acc: 0.9948\n",
            "Epoch 54: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0246 - acc: 0.9948 - lr: 3.2768e-05\n",
            "Epoch 55/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9958\n",
            "Epoch 55: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0164 - acc: 0.9958 - lr: 3.2768e-05\n",
            "Epoch 56/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0268 - acc: 0.9906\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
            "\n",
            "Epoch 56: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0268 - acc: 0.9906 - lr: 3.2768e-05\n",
            "Epoch 57/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0226 - acc: 0.9917\n",
            "Epoch 57: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0226 - acc: 0.9917 - lr: 2.6214e-05\n",
            "Epoch 58/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0221 - acc: 0.9917\n",
            "Epoch 58: acc did not improve from 0.99583\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0221 - acc: 0.9917 - lr: 2.6214e-05\n",
            "Epoch 59/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9969\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
            "\n",
            "Epoch 59: acc improved from 0.99583 to 0.99687, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 94s 2s/step - loss: 0.0139 - acc: 0.9969 - lr: 2.6214e-05\n",
            "Epoch 60/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0187 - acc: 0.9927\n",
            "Epoch 60: acc did not improve from 0.99687\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0187 - acc: 0.9927 - lr: 2.0972e-05\n",
            "Epoch 61/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0130 - acc: 0.9969\n",
            "Epoch 61: acc did not improve from 0.99687\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0130 - acc: 0.9969 - lr: 2.0972e-05\n",
            "Epoch 62/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9979\n",
            "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
            "\n",
            "Epoch 62: acc improved from 0.99687 to 0.99792, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.0137 - acc: 0.9979 - lr: 2.0972e-05\n",
            "Epoch 63/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0182 - acc: 0.9927\n",
            "Epoch 63: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0182 - acc: 0.9927 - lr: 1.6777e-05\n",
            "Epoch 64/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9969\n",
            "Epoch 64: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0126 - acc: 0.9969 - lr: 1.6777e-05\n",
            "Epoch 65/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9979\n",
            "Epoch 65: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0087 - acc: 0.9979 - lr: 1.6777e-05\n",
            "Epoch 66/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0209 - acc: 0.9927\n",
            "Epoch 66: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0209 - acc: 0.9927 - lr: 1.6777e-05\n",
            "Epoch 67/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.9948\n",
            "Epoch 67: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0131 - acc: 0.9948 - lr: 1.6777e-05\n",
            "Epoch 68/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9990\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
            "\n",
            "Epoch 68: acc improved from 0.99792 to 0.99896, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.0105 - acc: 0.9990 - lr: 1.6777e-05\n",
            "Epoch 69/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.9958\n",
            "Epoch 69: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0089 - acc: 0.9958 - lr: 1.3422e-05\n",
            "Epoch 70/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9927\n",
            "Epoch 70: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0179 - acc: 0.9927 - lr: 1.3422e-05\n",
            "Epoch 71/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9969\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
            "\n",
            "Epoch 71: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0100 - acc: 0.9969 - lr: 1.3422e-05\n",
            "Epoch 72/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.9979\n",
            "Epoch 72: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 92s 1s/step - loss: 0.0089 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 73/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0159 - acc: 0.9958\n",
            "Epoch 73: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0159 - acc: 0.9958 - lr: 1.0737e-05\n",
            "Epoch 74/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0069 - acc: 0.9979\n",
            "Epoch 74: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0069 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 75/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0116 - acc: 0.9948\n",
            "Epoch 75: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0116 - acc: 0.9948 - lr: 1.0737e-05\n",
            "Epoch 76/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9979\n",
            "Epoch 76: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0071 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 77/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 77: acc improved from 0.99896 to 1.00000, saving model to efficientnetB0+BAM.hdf5\n",
            "60/60 [==============================] - 93s 2s/step - loss: 0.0036 - acc: 1.0000 - lr: 1.0737e-05\n",
            "Epoch 78/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 78: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0045 - acc: 1.0000 - lr: 1.0737e-05\n",
            "Epoch 79/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
            "Epoch 79: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0044 - acc: 0.9990 - lr: 1.0737e-05\n",
            "Epoch 80/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0072 - acc: 0.9979\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
            "\n",
            "Epoch 80: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0072 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 81/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 81: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0033 - acc: 1.0000 - lr: 8.5899e-06\n",
            "Epoch 82/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0077 - acc: 0.9969\n",
            "Epoch 82: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0077 - acc: 0.9969 - lr: 8.5899e-06\n",
            "Epoch 83/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9990\n",
            "Epoch 83: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 90s 1s/step - loss: 0.0066 - acc: 0.9990 - lr: 8.5899e-06\n",
            "Epoch 84/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0216 - acc: 0.9948\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
            "\n",
            "Epoch 84: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 90s 1s/step - loss: 0.0216 - acc: 0.9948 - lr: 8.5899e-06\n",
            "Epoch 85/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9948\n",
            "Epoch 85: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 90s 1s/step - loss: 0.0140 - acc: 0.9948 - lr: 6.8719e-06\n",
            "Epoch 86/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
            "Epoch 86: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0141 - acc: 0.9958 - lr: 6.8719e-06\n",
            "Epoch 87/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9990\n",
            "Epoch 87: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n",
            "\n",
            "Epoch 87: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0071 - acc: 0.9990 - lr: 6.8719e-06\n",
            "Epoch 88/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9969\n",
            "Epoch 88: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0112 - acc: 0.9969 - lr: 5.4976e-06\n",
            "Epoch 89/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0094 - acc: 0.9958\n",
            "Epoch 89: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0094 - acc: 0.9958 - lr: 5.4976e-06\n",
            "Epoch 90/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9979\n",
            "Epoch 90: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n",
            "\n",
            "Epoch 90: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 91s 1s/step - loss: 0.0067 - acc: 0.9979 - lr: 5.4976e-06\n",
            "15/15 [==============================] - 7s 319ms/step - loss: 0.4424 - acc: 0.9042\n",
            "Test loss: 0.44237348437309265\n",
            "Test accuracy: 0.9041666388511658\n"
          ]
        }
      ],
      "source": [
        "history,model,valid_data=train_model(parallel_model,\n",
        "                                     'messidor',\n",
        "                                     image_size,\n",
        "                                     batch_size,\n",
        "                                     'efficientnetB0',\n",
        "                                     lr1,lr2,1,90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsEEInLtND3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0784c55-6164-4259-aae0-ebafe7c21bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[[1.51254177e-01 8.48745823e-01]\n",
            " [9.96574283e-01 3.42570757e-03]\n",
            " [9.99982357e-01 1.76712510e-05]\n",
            " [1.00000000e+00 1.39380599e-24]\n",
            " [1.00000000e+00 1.02419192e-13]\n",
            " [1.00000000e+00 3.26505445e-09]\n",
            " [1.00000000e+00 1.71464920e-13]\n",
            " [4.75547284e-01 5.24452686e-01]\n",
            " [1.00000000e+00 5.17499176e-21]\n",
            " [1.00000000e+00 2.82318151e-08]\n",
            " [1.00000000e+00 1.77397021e-21]\n",
            " [1.00000000e+00 1.85572026e-11]\n",
            " [1.00000000e+00 2.17118402e-22]\n",
            " [1.00000000e+00 8.56619243e-15]\n",
            " [1.00000000e+00 9.68767261e-24]\n",
            " [9.99999404e-01 5.94547600e-07]\n",
            " [9.99984860e-01 1.51350505e-05]\n",
            " [1.00000000e+00 4.38871857e-17]\n",
            " [9.99959111e-01 4.08971900e-05]\n",
            " [1.00000000e+00 3.44795264e-13]\n",
            " [1.00000000e+00 8.88724223e-21]\n",
            " [1.00000000e+00 6.90343807e-20]\n",
            " [9.99998927e-01 1.08625056e-06]\n",
            " [1.00000000e+00 7.39233761e-12]\n",
            " [9.97428954e-01 2.57100491e-03]\n",
            " [9.97095346e-01 2.90470407e-03]\n",
            " [7.46006012e-01 2.53993988e-01]\n",
            " [1.74171055e-06 9.99998212e-01]\n",
            " [1.00000000e+00 4.52830729e-17]\n",
            " [1.00000000e+00 5.96461769e-11]\n",
            " [9.99619126e-01 3.80903919e-04]\n",
            " [1.00000000e+00 9.95044593e-18]\n",
            " [9.98698592e-01 1.30142912e-03]\n",
            " [9.86190081e-01 1.38098383e-02]\n",
            " [1.00000000e+00 3.06537462e-09]\n",
            " [1.00000000e+00 5.28919051e-14]\n",
            " [1.00000000e+00 7.23205878e-14]\n",
            " [1.00000000e+00 7.81439857e-10]\n",
            " [1.00000000e+00 2.54612039e-14]\n",
            " [1.00000000e+00 1.61209801e-09]\n",
            " [1.00000000e+00 2.99487730e-18]\n",
            " [9.99952197e-01 4.77637441e-05]\n",
            " [1.00000000e+00 1.22915527e-08]\n",
            " [1.00000000e+00 6.18701410e-15]\n",
            " [1.00000000e+00 7.04020303e-23]\n",
            " [9.99999166e-01 7.87968929e-07]\n",
            " [9.95710254e-01 4.28975606e-03]\n",
            " [1.00000000e+00 5.74101833e-08]\n",
            " [1.00000000e+00 3.57896539e-08]\n",
            " [4.97735947e-01 5.02264023e-01]\n",
            " [3.15603077e-01 6.84396923e-01]\n",
            " [1.00000000e+00 2.35290760e-15]\n",
            " [9.99999881e-01 1.11359945e-07]\n",
            " [1.00000000e+00 4.38991937e-19]\n",
            " [1.00000000e+00 1.77951751e-10]\n",
            " [1.00000000e+00 6.78483772e-18]\n",
            " [9.63121235e-01 3.68787348e-02]\n",
            " [6.08809702e-02 9.39118981e-01]\n",
            " [1.00000000e+00 1.02730715e-12]\n",
            " [1.00000000e+00 1.77711609e-10]\n",
            " [9.99952078e-01 4.79017763e-05]\n",
            " [9.99999881e-01 1.35167951e-07]\n",
            " [9.99992847e-01 7.16476097e-06]\n",
            " [1.00000000e+00 6.24257861e-13]\n",
            " [1.00000000e+00 1.79359434e-21]\n",
            " [1.00000000e+00 2.70384947e-19]\n",
            " [1.00000000e+00 1.55235366e-10]\n",
            " [1.00000000e+00 1.99826067e-09]\n",
            " [1.00000000e+00 2.18428828e-19]\n",
            " [9.96484399e-01 3.51555995e-03]\n",
            " [1.00000000e+00 4.06146725e-08]\n",
            " [9.99999762e-01 2.40956211e-07]\n",
            " [1.00000000e+00 2.05262474e-09]\n",
            " [9.89146113e-01 1.08538531e-02]\n",
            " [1.00000000e+00 5.28036672e-08]\n",
            " [1.00000000e+00 2.37770859e-10]\n",
            " [1.01025798e-03 9.98989761e-01]\n",
            " [1.00000000e+00 2.25179423e-19]\n",
            " [1.00000000e+00 2.74886121e-11]\n",
            " [1.00000000e+00 1.73739512e-08]\n",
            " [1.00000000e+00 7.20534595e-22]\n",
            " [9.99742687e-01 2.57321488e-04]\n",
            " [9.99992013e-01 8.04208685e-06]\n",
            " [9.99999404e-01 6.24906193e-07]\n",
            " [1.00000000e+00 2.42461299e-18]\n",
            " [9.99964356e-01 3.56598903e-05]\n",
            " [9.05146658e-01 9.48532596e-02]\n",
            " [9.99880552e-01 1.19389370e-04]\n",
            " [1.00000000e+00 1.66186865e-14]\n",
            " [1.00000000e+00 2.87073760e-08]\n",
            " [9.99999285e-01 7.16731790e-07]\n",
            " [1.00000000e+00 2.78331723e-15]\n",
            " [1.00000000e+00 9.10081429e-20]\n",
            " [9.99892354e-01 1.07578890e-04]\n",
            " [9.99999166e-01 8.07447861e-07]\n",
            " [9.99999404e-01 6.55499719e-07]\n",
            " [9.99997616e-01 2.38980169e-06]\n",
            " [1.00000000e+00 4.83609885e-20]\n",
            " [1.00000000e+00 1.76742876e-09]\n",
            " [9.99983311e-01 1.66743976e-05]\n",
            " [1.00000000e+00 2.04236916e-09]\n",
            " [1.00000000e+00 4.05882662e-23]\n",
            " [1.00000000e+00 2.83099146e-14]\n",
            " [1.00000000e+00 1.09986835e-18]\n",
            " [8.76881242e-01 1.23118781e-01]\n",
            " [9.99672890e-01 3.27156740e-04]\n",
            " [9.99999523e-01 4.44107314e-07]\n",
            " [9.99995470e-01 4.53600614e-06]\n",
            " [9.99731004e-01 2.69033510e-04]\n",
            " [1.00000000e+00 5.51284085e-09]\n",
            " [1.00000000e+00 6.25437152e-26]\n",
            " [8.34854424e-01 1.65145606e-01]\n",
            " [1.00000000e+00 2.22552688e-11]\n",
            " [1.00000000e+00 7.23116845e-16]\n",
            " [1.00000000e+00 5.49146579e-12]\n",
            " [1.00000000e+00 5.01360766e-08]\n",
            " [1.00000000e+00 7.97582622e-09]\n",
            " [1.00000000e+00 1.87190554e-15]\n",
            " [1.00000000e+00 2.03982822e-08]\n",
            " [9.99999642e-01 4.06727793e-07]\n",
            " [9.99991059e-01 8.99427232e-06]\n",
            " [1.00000000e+00 1.48423916e-13]\n",
            " [1.00000000e+00 1.79867996e-08]\n",
            " [9.99999881e-01 1.12708079e-07]\n",
            " [3.14933597e-04 9.99685049e-01]\n",
            " [1.00000000e+00 1.87306046e-10]\n",
            " [9.67123389e-01 3.28766145e-02]\n",
            " [1.00000000e+00 7.86266142e-17]\n",
            " [1.00000000e+00 1.53296362e-10]\n",
            " [1.00000000e+00 3.60413700e-21]\n",
            " [1.00000000e+00 7.33384419e-16]\n",
            " [9.99999523e-01 4.47380927e-07]\n",
            " [1.00000000e+00 3.86450800e-13]\n",
            " [1.00000000e+00 7.09653182e-15]\n",
            " [1.00000000e+00 7.53418866e-15]\n",
            " [1.00000000e+00 4.49925313e-20]\n",
            " [9.99216080e-01 7.83917087e-04]\n",
            " [1.00000000e+00 1.43987860e-12]\n",
            " [9.99996781e-01 3.26967597e-06]\n",
            " [1.00000000e+00 5.14630365e-08]\n",
            " [1.88423366e-09 1.00000000e+00]\n",
            " [1.00000000e+00 6.15219100e-27]\n",
            " [1.11377731e-05 9.99988914e-01]\n",
            " [3.34632318e-06 9.99996662e-01]\n",
            " [9.81673717e-01 1.83262732e-02]\n",
            " [3.16856910e-19 1.00000000e+00]\n",
            " [1.36690721e-13 1.00000000e+00]\n",
            " [2.71189538e-12 1.00000000e+00]\n",
            " [5.86420690e-08 1.00000000e+00]\n",
            " [1.45294994e-08 1.00000000e+00]\n",
            " [2.75169605e-17 1.00000000e+00]\n",
            " [9.54228252e-09 1.00000000e+00]\n",
            " [8.03072192e-12 1.00000000e+00]\n",
            " [2.09894006e-05 9.99979019e-01]\n",
            " [1.72746311e-07 9.99999881e-01]\n",
            " [1.00000000e+00 6.88042830e-14]\n",
            " [1.49637259e-07 9.99999881e-01]\n",
            " [3.99591960e-03 9.96004045e-01]\n",
            " [1.00000000e+00 8.32855098e-16]\n",
            " [4.26724972e-03 9.95732725e-01]\n",
            " [9.81405079e-01 1.85948852e-02]\n",
            " [1.38438118e-04 9.99861598e-01]\n",
            " [2.11117385e-05 9.99978900e-01]\n",
            " [1.75461903e-08 1.00000000e+00]\n",
            " [1.29837805e-04 9.99870181e-01]\n",
            " [9.84166050e-04 9.99015808e-01]\n",
            " [9.94663119e-01 5.33689931e-03]\n",
            " [5.64013375e-04 9.99435961e-01]\n",
            " [3.23110491e-01 6.76889539e-01]\n",
            " [1.15087061e-14 1.00000000e+00]\n",
            " [4.03428345e-07 9.99999642e-01]\n",
            " [4.11498108e-16 1.00000000e+00]\n",
            " [4.33637709e-11 1.00000000e+00]\n",
            " [5.00529495e-07 9.99999523e-01]\n",
            " [1.00000000e+00 1.55242930e-08]\n",
            " [8.90724838e-01 1.09275132e-01]\n",
            " [1.88807752e-15 1.00000000e+00]\n",
            " [8.38631749e-01 1.61368236e-01]\n",
            " [9.99769986e-01 2.30018661e-04]\n",
            " [2.68054737e-06 9.99997377e-01]\n",
            " [3.28967028e-04 9.99671102e-01]\n",
            " [2.78197570e-18 1.00000000e+00]\n",
            " [7.48579851e-07 9.99999285e-01]\n",
            " [6.37186762e-11 1.00000000e+00]\n",
            " [5.87105617e-08 1.00000000e+00]\n",
            " [5.10008736e-14 1.00000000e+00]\n",
            " [3.72371647e-11 1.00000000e+00]\n",
            " [7.64011077e-09 1.00000000e+00]\n",
            " [1.81616321e-02 9.81838346e-01]\n",
            " [7.40721789e-11 1.00000000e+00]\n",
            " [1.79362830e-10 1.00000000e+00]\n",
            " [3.63182385e-13 1.00000000e+00]\n",
            " [1.36142564e-08 1.00000000e+00]\n",
            " [2.45979154e-10 1.00000000e+00]\n",
            " [8.08671441e-09 1.00000000e+00]\n",
            " [8.13971996e-01 1.86027974e-01]\n",
            " [6.62178779e-03 9.93378222e-01]\n",
            " [2.93832738e-04 9.99706089e-01]\n",
            " [3.49418855e-10 1.00000000e+00]\n",
            " [1.26169715e-03 9.98738348e-01]\n",
            " [1.86827401e-05 9.99981284e-01]\n",
            " [1.40917633e-04 9.99859095e-01]\n",
            " [6.11988216e-05 9.99938846e-01]\n",
            " [4.16275348e-10 1.00000000e+00]\n",
            " [1.81440518e-09 1.00000000e+00]\n",
            " [7.36773628e-11 1.00000000e+00]\n",
            " [5.93975187e-07 9.99999404e-01]\n",
            " [9.45946693e-01 5.40533178e-02]\n",
            " [2.14136756e-14 1.00000000e+00]\n",
            " [2.69924271e-06 9.99997258e-01]\n",
            " [1.76208115e-08 1.00000000e+00]\n",
            " [5.23543172e-02 9.47645664e-01]\n",
            " [1.57460944e-09 1.00000000e+00]\n",
            " [2.84176826e-14 1.00000000e+00]\n",
            " [8.38358402e-02 9.16164160e-01]\n",
            " [9.41406952e-10 1.00000000e+00]\n",
            " [6.12967722e-02 9.38703239e-01]\n",
            " [4.96920238e-09 1.00000000e+00]\n",
            " [1.21987426e-07 9.99999881e-01]\n",
            " [9.99999404e-01 5.79208461e-07]\n",
            " [5.81446358e-09 1.00000000e+00]\n",
            " [1.36625954e-11 1.00000000e+00]\n",
            " [1.63266112e-08 1.00000000e+00]\n",
            " [7.04908701e-11 1.00000000e+00]\n",
            " [9.19653063e-15 1.00000000e+00]\n",
            " [5.31989075e-09 1.00000000e+00]\n",
            " [6.66791400e-10 1.00000000e+00]\n",
            " [1.37328012e-14 1.00000000e+00]\n",
            " [7.87987022e-16 1.00000000e+00]\n",
            " [9.29169357e-01 7.08305836e-02]\n",
            " [6.94974139e-02 9.30502534e-01]\n",
            " [2.14171486e-10 1.00000000e+00]\n",
            " [3.58472592e-11 1.00000000e+00]\n",
            " [4.28654801e-09 1.00000000e+00]\n",
            " [5.70770826e-11 1.00000000e+00]\n",
            " [1.19099432e-13 1.00000000e+00]\n",
            " [5.54463680e-12 1.00000000e+00]\n",
            " [5.95188655e-12 1.00000000e+00]\n",
            " [2.00660497e-06 9.99997973e-01]\n",
            " [5.26940767e-06 9.99994755e-01]]\n",
            "Confusion Matrix\n",
            "[[133  10]\n",
            " [ 13  84]]\n",
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "non-referable       0.91      0.93      0.92       143\n",
            "    referable       0.89      0.87      0.88        97\n",
            "\n",
            "     accuracy                           0.90       240\n",
            "    macro avg       0.90      0.90      0.90       240\n",
            " weighted avg       0.90      0.90      0.90       240\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyV5Z338c8vJ/sekpBAQkgAQRBZFMF9HRXRurQuWO2otaU+tT52madjp07b0TptZ2w7OnWwblVcaq1tlU6tigsCroCCsi9hS4BsZF/Pcj1/nAMGOEBYTk6S832/Xrw893by4/Zwvrnv67qvy5xziIiI7Csu2gWIiEjfpIAQEZGwFBAiIhKWAkJERMJSQIiISFjx0S7gWMnLy3OlpaXRLkNEpF9ZunRprXMuP9y2ARMQpaWlLFmyJNpliIj0K2a25UDbdItJRETCUkCIiEhYCggREQlrwLRBhOP1eqmoqKCjoyPapfRbycnJFBcXk5CQEO1SRKSXRSwgzOwJ4DKg2jk3Psx2Ax4AZgBtwM3OuY9D224C7g7t+lPn3FNHUkNFRQUZGRmUlpYS/HFyOJxz1NXVUVFRQVlZWbTLEZFeFslbTE8C0w+y/RLguNCfWcBsADMbBPwYmAZMBX5sZjlHUkBHRwe5ubkKhyNkZuTm5uoKTCRGRSwgnHMLgF0H2eUKYI4L+gDINrMhwMXAPOfcLudcPTCPgwfNQSkcjo7On0jsimYbRBGwrdtyRWjdgdbvx8xmEbz6oKSkJDJVikhM6vD6WbOzmbqWTvwBR8A5zIy89EQGZySTn5FEY7uX8ppWymtbaO30MaE4m4nF2aQkeqJd/jHRrxupnXOPAI8ATJkyRRNbiMgRa+/y8866at5YXc1nFY1sqGnBHzj8r5X4OGN0QQZm0NDmpb6ti5zURK6cPJSrTx5GWV5aBKqPjGgGRCUwrNtycWhdJXDuPuvn91pVx1hDQwPPPfcc3/zmNw/ruBkzZvDcc8+RnZ0docpEeldTh5eN1S2MG5pJUvyBf8N2zrFqRxNtXX6yUxLISk1gUGoi8Z6D3xGvaupgzc5mUhM95KQmkJ2aSH1rF+uqWlhX1Ux9WxcnDM1k0rAcRg1Op93rZ+3OJlZtb+LdDXXMX1dNhzdAdmoCk4dlc+G4AsYXZTIkKwVPnBFnRsA5als6qW7qpLq5g8yUBMry0hiRn05Kgodl2+pZuqWeTysaSfDEMaYwg5zURMprWpg9fyMPvb2Rk4fncMaoPE4ensOkYdlkpXzeQzAQcHxW2cibq6t4Z30tbZ0+khLiSI73kJEcT1FOCsU5qRRmJlPb0smWuja27GpjSGYyv7h6wjH7f7VbNANiLvAtM3ueYIN0o3Nuh5m9Bvx7t4bpi4AfRKvIo9XQ0MD//M//7BcQPp+P+PgDn/5XXnkl0qWJHJXGNi9vra3i9ZVVbKtv4/wxg7ls4lBGF2TgnKOivp2Pt9bz8ZZ6Fm+uZ83OJgIOslMTuHJSEdedMoyxQzL3vF9Lp4+Xl1XyzAdbWb2jaa+flZbo4eLxhVw1uYjTR+bh9QdYvaOJTysa+XhrPUs211PZ0H7AWs0gNcHDnPf9AKQkeGj3+vdsH5yRxDUnD+OS8YVMLRt0yDA6kPOPL+D84wvCbqtq6uAvn1Ty1+Xb+c1b6wm4YF05qYkkxceRFB9Hc4ePutYu4gxOKgkGWacvQKfPT3VzJ59sa6ChzbvnPTOT4xmem8ao/PQjqvdQLFJTjprZ7wleCeQBVQR7JiUAOOceDnVz/Q3BBug24Bbn3JLQsV8F/iX0Vvc55353qJ83ZcoUt+9YTKtXr2bs2LEA/NtfV7Jqe1O4Q4/YuKGZ/PgLJxx0n5kzZ/Lyyy8zZswYEhISSE5OJicnhzVr1rBu3TquvPJKtm3bRkdHB3feeSezZs0CPh9bqqWlhUsuuYQzzzyT9957j6KiIl5++WVSUlLC/rxHH32URx55hK6uLkaNGsXTTz9NamoqVVVV3HbbbZSXlwMwe/ZsTj/9dObMmcP999+PmTFhwgSefvrp/d6z+3mU/sfnD9DQ7iUvPemwjgsEHH7nSOj2ZdnY5uXVlTv46/IdvF9ehz/gGJyRRMmgVJZurcc5GJGXRlOHl9qWLiD4ZXzS8GxOKR3EiPx0Xl+5k9dXVtHlD5CRFE+8x4j3xNHS4aPd62fskExumFbC8NxUGtq8NLR7+ayigb9/tpPmTh/ZqQm0dPjwhW7/DM5IYkppDieV5DC+KIsuX4D6ti4a2rxkpsRz3OAMRg1OJ9ETx6a6VpZtbeCzykZy0xIZNzSTcUMzKcxM7tUOGS2dPpZva+DjLfVUN3fS6fPT5QsQ74njzFF5nDM6n5y0xLDHNnd4qWrqIC89iezU8PscDjNb6pybEnbbQJmTuq8GxObNm7nssstYsWIF8+fP59JLL2XFihV7nivYtWsXgwYNor29nVNOOYV33nmH3NzcvQJi1KhRLFmyhEmTJnHttddy+eWXc+ONN4b9eXV1deTm5gJw9913U1BQwB133MF1113Haaedxre//W38fj8tLS1UVFRw1VVX8d5775GXl7enln0pIKJn7c5mFm2opaXDR0unl3avnxOGZnHumHyGZIX/JQGgsd3LO+tqeGt1FfPX1dDQ5mVCcRaXTxzKZROGUpiVfMBjO31+XlhSwcPzN7KjsZ3CzGSKB6WSFB/HB+V1eP2O4bmpXDJ+CBefUMDE4mzi4ozq5g7+/tlO3lxTTV56IpNLcpg8LJsxhRl7hQxAfWsXc5dvZ3NdKz6/wxcIkBTv4QsTh3JSSXbYL+sOr5+31lTz5upqCjKTmFCczYTiLIZk9e6X+0BzsIDo143Uh+NQX+S9ZerUqXs9dPbggw/yl7/8BYBt27axfv36PV/wu5WVlTFp0iQATj75ZDZv3nzA91+xYgV33303DQ0NtLS0cPHFFwPw1ltvMWfOHAA8Hg9ZWVnMmTOHa665hry8PICw4SC9LxBwzF9XzROLNrNoQ+2e9SkJHuI9xjMfbAVgTEEGp44YxJjCTMYUppOfnszCDTW8umIn72+swxdwDEpL5PzjB1OWm8brq6r46d9Wc98rqynMTGZwZjKFmUnkZySRlZJARnICXl+AZz/cys6mDk4qyeaLJxVR2dBOxa52qpo6uOm0Ui6fNJQTi7L2+1IenJHMTaeXctPppYf8O+akJfZov+6SEzzMOHEIM04ccljHyZGLmYDoK9LSPu/BMH/+fN544w3ef/99UlNTOffcc8M+lJaU9PmtAY/HQ3v7ge+13nzzzbz00ktMnDiRJ598kvnz5x/T+qVnfP4AD765no01rfzoC+MoyDzwb+y7Oed4c3U1P391DRuqWyjMTOb708dw9UnFDEoLNtI651hf3cL8tdXMX1vDi0sraO3y7/U+pbmp3HpWGReNK2DSsBw8ccEv8jsuOI7ymhb+vmInm2pbqWrqYFNtK4s319PU7t1zy2Zq2SB+ee1ETh+ph0xjnQIiwjIyMmhubg67rbGxkZycHFJTU1mzZg0ffPDBUf+85uZmhgwZgtfr5dlnn6WoKPgIyQUXXMDs2bP3usV0/vnnc9VVV/Hd736X3NzcA95ikvAqG9r5z1fX8PHWBq6fWsI/njactKR4djS2c8dzn7BkSz0JHuPdjbX8/IsTmD6+8IDv9VlFI/e9sooPyncxIj+NB2ZOYsaJQ/a7NWMW7EI5uiCDWWePJBBwbG9sZ11VM5UNHUwtHcTogvQDfrGPyE/n9vNG7bfeOUe71097l5/cw2yrkIFLARFhubm5nHHGGYwfP56UlBQKCj7v4TB9+nQefvhhxo4dy5gxYzj11FOP+ufde++9TJs2jfz8fKZNm7YnnB544AFmzZrF448/jsfjYfbs2Zx22mn88Ic/5JxzzsHj8TB58mSefPLJo65hIAgEHM0dPjKS44mL2/vLtqnDy6MLynlkQbDB/8SiLH7x6hoeXVjONVOKeWHxNrp8AR6YOYnxRVl8+/ll3PbMUq6dUsyXpw1n7JAMkuI9eP0B3lhVxXMfbWXh+loGpSVyzxUncP3Ukv2C4UDi4ozinFSKc1KP6u9rZqQmxpOaqK8E+VzMNFLLkYu181jT3MnNv/uIldubiDPITk0kPSmeti4fTR0+unwBAK6YNJTvTz+eouwUPt5az6/nrWPh+lqOL8zgoRtOYmSo62GXL8B/vbGO2e9sxDlI9MQxdmgmlfXt1LZ0MjQrmZlTS7j5jFIykzVqrvQuNVKL9NC2XW185fEPqWrq5LsXjt7TZbKl00daUjwZyfFkJidw5qg8Jg77/CHGk0pyePrWaWyobqE4J4XkhM8fBEuMj+P704/nptNL+XhLPcu2NbBsWwMnlWQzc+owzhk9eE87gUhfooDop26//Xbefffdvdbdeeed3HLLLVGqqP9bX9XMVx7/iLYuH898bRonDz/8QYRHDT7wA0sFmclccuIQLlEvHOknBnxAuNAAWwPNQw891Cs/p7/fgvQHHB+W17F6ZzMbqpvZWN1KYnwcQ7KSGZKVTGJ8HJvr2thc28qqHU2kJsbzh2+cttcTviKxakAHRHJy8p4HxwZiSETa7gmDkpMP3UWzL3LO8c9/+pQXl1YAkJOawKjB6bR0+liwvobq5k6cCz6JW5qXxhWTirjtnBEMz+0/g6mJRNKADoji4mIqKiqoqamJdin91u4pR/uj/35rAy8ureC2c0bytbPK9htqwusP4PO7ATM0s8ixNqADIiEhQVNl9mONbV4+rWxg3JDMg/bNr2vp5G+f7WDSsOw9T/i+9Eklv5q3ji9OLuKfp48JewWZ4IkjQdkgckADOiCk/1pf1cxXn1rMtl3Bp8ZH5KUxpTSHC8cVcs7ofBLjg08V//njSn76t1XUh0a4HJGXxvnHD2bO+1s4dcQgfv6lCbq9KHKEFBDS58xfW80dz31CUoKH33x5MhX17SzZvItXV+zkhSUVZKUkMOPEQrbuauPdDXWcVJLNY5eOY31VM3/5pJLHFm1iZH4av71xConxkZx2XWRgU0BIn1HX0snzi7fxy9fXMqYwk8dvmsLQ7NCIpeeMxOsPsGhDLXOXbeflZdvxmHHvleO5YWoJcXHGycNzmDm1hKqmDlISPXroTOQoKSAk4rz+AB+U11Fe08qWuja27moDYNigFIblpJIYH8frq6p4d0Mt/oDjonEF/Pq6SaQl7f3xTPDEcd6YwZw3ZjAdXj/OEbaBuScD44nIoSkgJGK27Wrj+cVbeWFJBTXNnUBwyOqSQcFxg97bWEtbaCTSYYNS+MbZI/jCxKEcX5hxyHaDZLUui0ScAkIi4sE31/PrN9ZhwHljBnPdKcOYVJJNfnrSni9/5xy7WrtobPdSlpemxmSRPkYBIcfcwvU1/GreOi6dMIQfzhj7eTvCPsyM3PQkDS8t0kcpIOSYqmnu5Dt/WM7ognTuv3qiHkIT6ccUEHLMBAKO7/1xOc0dXp792jSFg0g/p07icsw8vmgTC9bV8K+XjWNMYUa0yxGRo6SAkGNi3qoqfvHqGi4+oYAbppVEuxwROQYUEHLUFq2v5fZnP+aEoizuv2aieiOJDBAKCDkqizfv4utzljAiP42nbjmFDD29LDJgqJFajohzjtdWVvH//ricIVnJPH3rNLJTE6NdlogcQwoIOSzOORaur+WXr69leUUjxw1O56mvTiU/Q88yiAw0CgjpscqGdu7606csXF9LUXYK/3H1BL44uYh4j+5UigxECgg5JOccLy2r5EcvrSTgHD+6bBw3nFpCUryecxAZyBQQclCtnT6+/+Kn/O2zHUwZnsOvrp1ESW5qtMsSkV6ggJAD8vkDfOu5j3lnXQ3fnz6Gb5w9Ek+curCKxAoFhITlnOMnf13J22truO+q8dwwbXi0SxKRXqbWRQnrsYWbeOaDrXzj7BEKB5EYpYCQ/by6Yif//vfVzDixkH+efny0yxGRKFFAyF5qWzq568+fMqEoi19dO4k4tTmIxCwFhOzl3v9dRWunj/uvmahpPUViXEQDwsymm9laM9tgZneF2T7czN40s0/NbL6ZFXfb5jezZaE/cyNZpwTNX1vNy8u2881zR3FcgYbrFol1EevFZGYe4CHgQqACWGxmc51zq7rtdj8wxzn3lJmdD/wM+EpoW7tzblKk6pO9tXX5uPulFYzMT+Ob542Mdjki0gdE8gpiKrDBOVfunOsCngeu2GefccBboddvh9kuveTX89ZRUd/Oz744QU9IiwgQ2YAoArZ1W64IretuOfDF0OurgAwzyw0tJ5vZEjP7wMyuDPcDzGxWaJ8lNTU1x7L2mNHlC/Afr67hsUWbuH5qCVPLBkW7JBHpI6L9oNw/Ab8xs5uBBUAl4A9tG+6cqzSzEcBbZvaZc25j94Odc48AjwBMmTLF9V7ZA8OanU185w/LWb2jieumDONfLxsb7ZJEpA+JZEBUAsO6LReH1u3hnNtO6ArCzNKBLznnGkLbKkP/LTez+cBkYK+AkCM3b1UVtz/7MZkp8Tz6j1O4cFxBtEsSkT4mkreYFgPHmVmZmSUCM4G9eiOZWZ6Z7a7hB8ATofU5Zpa0ex/gDKB747YchUDA8fO/r6Y0L5XXvn22wkFEwopYQDjnfMC3gNeA1cALzrmVZnaPmV0e2u1cYK2ZrQMKgPtC68cCS8xsOcHG65/v0/tJjsLba6vZWNPK7eeNIjddE/2ISHgRbYNwzr0CvLLPuh91e/0i8GKY494DToxkbbHskQXlFGWnMOPEIdEuRUT6MD1JHWOWb2vgw027uOWMUhI0E5yIHIS+IWLMowvLyUiOZ+bUkmiXIiJ9nAIihmzb1cYrn+3gy9NKSE+Kdg9nEenrFBAx5PFFm4gz45bTy6Jdioj0AwqIGLGhupnnF2/l8klDKcxKjnY5ItIPKCBiQKfPzx2/X0ZqYjx3aQIgEekhBcQA09zhpaXTt9e6/3h1Lat3NPGfV09gcKauHkSkZ9RSOYDsaGzn6tnv09Tu5eYzSrn1zDKWbWvg8UWbuOm04VwwVk9Mi0jPKSAGiMY2Lzc98RGN7V5OG5nLf7+1gd+9uxlPnDGmIIMfzNBAfCJyeBQQA0CH18/X5ixmc20bT95yCqePymPtzmYefGs9H5bX8eD1kzV9qIgcNgVEP+cPOO74/Scs2VLPf18/mdNH5QEwpjCDh758UpSrE5H+TI3U/dxjC8uZt6qKH102jssmDI12OSIygCgg+rEN1c38ct46LhpXwM2nl0a7HBEZYBQQ/ZTPH+B7f/yUtEQP9111ImYW7ZJEZIBRG0Q/9ejCTSzf1sCD108mP0NzOojIsacriH5ofVUzv563juknFPKFCZrTQUQiQwHRD937t9WkJXm498rxurUkIhGjgOhnVlQ2smBdDV8/e4RuLYlIRCkg+pmH39lIelI8N0wbHu1SRGSAU0D0I1vqWnnlsx3ccGoJWSkJ0S5HRAY4BUQ/8siCcuLj4rj1DE34IyKRp4DoJ2qaO/nj0gq+dHKRhuwWkV6hgOgnfvfuJrz+ALPOHhntUkQkRuhBuT5mZ2MH722s5b2Ndaza3kRrl4/WTh+7Wru4ZHwhZXlp0S5RRGKEAqKPcM7x9TlLeWN1FQDZqQlMGpZNVko6aUnxZCTFc+Op6rkkIr1HAdFHvLuhjjdWV3HTacO59pRhjC3MJC5OD8GJSPQoIPqI3y7YSH5GEv9y6ViS4jW5j4hEnxqp+4BV25tYuL6Wm08vVTiISJ+hgOgDHl1YTmqihxv1dLSI9CEKiCjb3tDOX5dvZ+YpJWSl6uloEek7FBBR9sSiTTjgq2eWRrsUEZG9KCCiqLHdy+8/2sqlJw6hOCc12uWIiOxFARFFTyzaRGuXn1lnj4h2KSIi+1FAREldSyePLSznkvGFjC/KinY5IiL7iWhAmNl0M1trZhvM7K4w24eb2Ztm9qmZzTez4m7bbjKz9aE/N0Wyzmh46O2NtHv9fO+iMdEuRUQkrIgFhJl5gIeAS4BxwPVmNm6f3e4H5jjnJgD3AD8LHTsI+DEwDZgK/NjMciJVa2+rqG/jmQ+2cPXJxYwanB7tckREworkFcRUYINzrtw51wU8D1yxzz7jgLdCr9/utv1iYJ5zbpdzrh6YB0yPYK296oE31oPBnf8wOtqliIgcUCQDogjY1m25IrSuu+XAF0OvrwIyzCy3h8diZrPMbImZLampqTlmhUfS+qpm/vRxBV85dThF2SnRLkdE5ICi3Uj9T8A5ZvYJcA5QCfh7erBz7hHn3BTn3JT8/PxI1XjMbKlr5bsvLCc1MZ5vnqt5HUSkb4vkYH2VwLBuy8WhdXs457YTuoIws3TgS865BjOrBM7d59j5Eaw1opxz/P6jbfz0b6vwmHH/NRPITU+KdlkiIgcVyYBYDBxnZmUEg2Em8OXuO5hZHrDLORcAfgA8Edr0GvDv3RqmLwpt73e8/gD/55mlvLG6mjNG5fKfV09kqG4tiUg/ELGAcM75zOxbBL/sPcATzrmVZnYPsMQ5N5fgVcLPzMwBC4DbQ8fuMrN7CYYMwD3OuV2RqjWS3ttYxxurq/nuhaP51nmjNMeDiPQbEZ0Pwjn3CvDKPut+1O31i8CLBzj2CT6/oui3FqyrITE+jq+fNULhICL9SrQbqQe8BetqmFo6iJREzfMgIv1LjwLCzK4ys6xuy9lmdmXkyhoYtje0s766hbNH50W7FBGRw9bTK4gfO+cady845xoIPuksB7FwffDZjLNH9/0uuCIi++ppQITbT/NZH8KCdbUUZCYxpiAj2qWIiBy2ngbEEjP7lZmNDP35FbA0koX1d/6AY9GGWs46Lh8zNU6LSP/T04C4A+gC/kBwTKUOQl1SJbzlFQ00tnt1e0lE+q0e3SZyzrUC+w3XLQe2YF0NZnDWKDVQi0j/1NNeTPPMLLvbco6ZvRa5svq/BetqmFCURU5aYrRLERE5Ij29xZQX6rkEQGgI7sGRKan/a2zzsmxbg24viUi/1tOACJhZye4FMysFXCQKGgje3VhLwKl7q4j0bz3tqvpDYJGZvQMYcBYwK2JV9XN/+3QHmcnxTBqWfeidRUT6qB5dQTjnXgWmAGuB3wPfA9ojWFe/tbm2lb+v2MGXpw0nwaORTESk/+rRFYSZfQ24k+C8DMuAU4H3gfMjV1r/9MjCcuI9cXz1jNJolyIiclR6+ivuncApwBbn3HnAZKDh4IfEnuqmDl5cUsGXTipmcGZytMsRETkqPQ2IDudcB4CZJTnn1gBjIldW//TEu5vxBQJ84+wR0S5FROSo9bSRuiL0HMRLwDwzqwe2RK6s/qepw8uzH2zhkvFDKM1Li3Y5IiJHradPUl8VevkTM3sbyAJejVhV/dCzH2yludPHbeeMjHYpIiLHxGGPyOqceycShfRnXn+AJ97dxJmj8jixOOvQB4iI9APqh3kMvLuhlprmTm48dXi0SxEROWYUEMfA3OXbyUiO57zj9eS0iAwcCoij1OH18/rKKqafUEhSvOadFpGBQwFxlN5eU01Lp48rJhVFuxQRkWNKAXGUXl62nbz0JE4bmRvtUkREjikFxFFo6vDy1tpqLpswBE+cphUVkYFFAXEUXl9ZRZcvwOWThka7FBGRY04BcRTmLt/OsEEpTNaw3iIyACkgjlBtSyfvbqjl8olDMdPtJREZeBQQR+jvK3biDzgun6jeSyIyMCkgjtDrK3cyIj+NMYUZ0S5FRCQiFBBHoLHdy/sb67hoXGG0SxERiRgFxBGYv7YaX8Bx0QkF0S5FRCRiFBBH4PWVVeRnJDGpWL2XRGTgUkAcpg6vn/lrq7lwXAFxejhORAYwBcRhen9jHa1dfi4ap9tLIjKwRTQgzGy6ma01sw1mdleY7SVm9raZfWJmn5rZjND6UjNrN7NloT8PR7LOw/H6qp2kJ8Vr7CURGfAOe0a5njIzD/AQcCFQASw2s7nOuVXddrsbeME5N9vMxgGvAKWhbRudc5MiVd+R8Acc81ZVcd7xgzW0t4gMeJG8gpgKbHDOlTvnuoDngSv22ccBmaHXWcD2CNZz1D7ZWk9tS5duL4lITIhkQBQB27otV4TWdfcT4EYzqyB49XBHt21loVtP75jZWeF+gJnNMrMlZrakpqbmGJYe3uurqkjwGOeO0cxxIjLwRbuR+nrgSedcMTADeNrM4oAdQIlzbjLwXeA5M8vc92Dn3CPOuSnOuSn5+ZH/0p6/tppTR+SSkZwQ8Z8lIhJtkQyISmBYt+Xi0LrubgVeAHDOvQ8kA3nOuU7nXF1o/VJgIzA6grUeUqfPz8aaVibq2QcRiRGRDIjFwHFmVmZmicBMYO4++2wFLgAws7EEA6LGzPJDjdyY2QjgOKA8grUe0obqFvwBx/FDNPaSiMSGiPVics75zOxbwGuAB3jCObfSzO4Bljjn5gLfAx41s+8QbLC+2TnnzOxs4B4z8wIB4Dbn3K5I1doTa3c2A3C8BucTkRgRsYAAcM69QrDxufu6H3V7vQo4I8xxfwL+FMnaDtfanc0kxsdRmpsW7VJERHpFtBup+43VO5sZlZ9OvEenTERig77temjtzibdXhKRmKKA6IGGti6qmjo1OZCIxBQFRA+sCTVQKyBEJJYoIHrg8x5M+z2rJyIyYCkgemDNzmayUhIoyEyKdikiIr1GAdEDa3c2MaYwAzNNECQisUMBcQjOOdZVtagHk4jEHAXEIVTUt9PS6VMDtYjEHAXEIWiIDRGJVQqIQ1hbFQyI0QUKCBGJLQqIQ1i9o4mi7BTNASEiMUcBcQhrdzbr9pKIxCQFxEF0+vyU17ZqDggRiUkKiIPYWN2KP+AYoyeoRSQGKSAOYlNtKwAj8zUHhIjEHgXEQWyuCwbEcE0SJCIxSAFxEFvqWslLTyI9KaIT74mI9EkKiIPYUtdGaW5qtMsQEYkKBcRBbKlro0QBISIxSgFxAB1ePzubOihV+4OIxCgFxAFs3dUGwHBdQYhIjFJAHMDmWvVgEpHYpoA4gC11wSsINVKLSKxSQBzAll2tZKUkkJ2aGO1SRESiQgFxAFvq2tT+ICIxTQFxAJvrWtX+ICIxTQERRpcvQGV9u9ofRCSmKSDCqMJTRAQAAAjXSURBVGxoJ+CgZJACQkRilwIijN2D9JXm6RaTiMQuBUQYW/Y8A6ErCBGJXQqIMLbsaiM10UN+elK0SxERiRoFRBhb6tooGZSKmUW7FBGRqFFAhLG5rlWD9IlIzItoQJjZdDNba2YbzOyuMNtLzOxtM/vEzD41sxndtv0gdNxaM7s4knV25w84Kna1q/1BRGJexKZKMzMP8BBwIVABLDazuc65Vd12uxt4wTk328zGAa8ApaHXM4ETgKHAG2Y22jnnj1S9u+1obKfLH9BDciIS8yJ5BTEV2OCcK3fOdQHPA1fss48DMkOvs4DtoddXAM875zqdc5uADaH3izgN0iciEhTJgCgCtnVbrgit6+4nwI1mVkHw6uGOwzg2InYHhGaSE5FYF+1G6uuBJ51zxcAM4Gkz63FNZjbLzJaY2ZKamppjUtCWulYSPXEMyUo5Ju8nItJfRTIgKoFh3ZaLQ+u6uxV4AcA59z6QDOT18Ficc48456Y456bk5+cfk6I317VSPCgFT5y6uIpIbItkQCwGjjOzMjNLJNjoPHeffbYCFwCY2ViCAVET2m+mmSWZWRlwHPBRBGvdY1NtKyM0xIaISOR6MTnnfGb2LeA1wAM84ZxbaWb3AEucc3OB7wGPmtl3CDZY3+ycc8BKM3sBWAX4gNt7owdTIODYUtfG2ccdm6sREZH+LGIBAeCce4Vg43P3dT/q9noVcMYBjr0PuC+S9e1rR1MHnb4AZfm6ghARiXYjdZ+yqSY4SF+ZnoEQEVFAdLdJw3yLiOyhgOhmc20ryQlxFGYmR7sUEZGoU0B0s7k2OEhfnLq4iogoILrbVKtRXEVEdlNAhPj8AbbualMPJhGREAVESGVDO76AUw8mEZEQBURIeWgeal1BiIgEKSBCNocCQm0QIiJBCoiQzbWtpCfFk5eeGO1SRET6BAVESHltK2V5aZipi6uICCgg9thc16onqEVEulFAAJ0+P5X17ZRpFjkRkT0UEMC2XW0EnHowiYh0p4AANtUG56FWDyYRkc8pIPi8i2uZ2iBERPZQQBDswZSTmkB2qrq4iojspoAgNIqrrh5ERPaigCDYxVW3l0RE9hbzAdHe5WdHY4cG6RMR2UfMB0Rbl4/LJw5lcklOtEsREelT4qNdQLTlpifx4PWTo12GiEifE/NXECIiEp4CQkREwlJAiIhIWAoIEREJSwEhIiJhKSBERCQsBYSIiISlgBARkbDMORftGo4JM6sBthzGIXlAbYTK6a90Tvam87E3nY/9DYRzMtw5lx9uw4AJiMNlZkucc1OiXUdfonOyN52Pvel87G+gnxPdYhIRkbAUECIiElYsB8Qj0S6gD9I52ZvOx950PvY3oM9JzLZBiIjIwcXyFYSIiByEAkJERMKKyYAws+lmttbMNpjZXdGup7eZ2TAze9vMVpnZSjO7M7R+kJnNM7P1of/G1DR7ZuYxs0/M7H9Dy2Vm9mHoc/IHM0uMdo29ycyyzexFM1tjZqvN7LRY/oyY2XdC/15WmNnvzSx5oH9GYi4gzMwDPARcAowDrjezcdGtqtf5gO8558YBpwK3h87BXcCbzrnjgDdDy7HkTmB1t+VfAL92zo0C6oFbo1JV9DwAvOqcOx6YSPDcxORnxMyKgP8LTHHOjQc8wEwG+Gck5gICmApscM6VO+e6gOeBK6JcU69yzu1wzn0cet1M8B9+EcHz8FRot6eAK6NTYe8zs2LgUuCx0LIB5wMvhnaJtfORBZwNPA7gnOtyzjUQw58RglM0p5hZPJAK7GCAf0ZiMSCKgG3dlitC62KSmZUCk4EPgQLn3I7Qpp1AQZTKiob/Ar4PBELLuUCDc84XWo61z0kZUAP8LnTb7TEzSyNGPyPOuUrgfmArwWBoBJYywD8jsRgQEmJm6cCfgG8755q6b3PB/s8x0QfazC4Dqp1zS6NdSx8SD5wEzHbOTQZa2ed2Uox9RnIIXj2VAUOBNGB6VIvqBbEYEJXAsG7LxaF1McXMEgiGw7POuT+HVleZ2ZDQ9iFAdbTq62VnAJeb2WaCtxzPJ3j/PTt0OwFi73NSAVQ45z4MLb9IMDBi9TPyD8Am51yNc84L/Jng52ZAf0ZiMSAWA8eFeh8kEmxomhvlmnpV6P7648Bq59yvum2aC9wUen0T8HJv1xYNzrkfOOeKnXOlBD8PbznnbgDeBq4O7RYz5wPAObcT2GZmY0KrLgBWEaOfEYK3lk41s9TQv5/d52NAf0Zi8klqM5tB8J6zB3jCOXdflEvqVWZ2JrAQ+IzP77n/C8F2iBeAEoJDp1/rnNsVlSKjxMzOBf7JOXeZmY0geEUxCPgEuNE51xnN+nqTmU0i2GifCJQDtxD8pTImPyNm9m/AdQR7AX4CfI1gm8OA/YzEZECIiMihxeItJhER6QEFhIiIhKWAEBGRsBQQIiISlgJCRETCUkCI9AFmdu7uUWRF+goFhIiIhKWAEDkMZnajmX1kZsvM7LehOSRazOzXobkC3jSz/NC+k8zsAzP71Mz+snvuBDMbZWZvmNlyM/vYzEaG3j692/wLz4ae2BWJGgWESA+Z2ViCT9Ke4ZybBPiBGwgO3LbEOXcC8A7w49Ahc4B/ds5NIPjU+u71zwIPOecmAqcTHB0UgqPqfpvgPCUjCI71IxI18YfeRURCLgBOBhaHfrlPIThYXQD4Q2ifZ4A/h+ZTyHbOvRNa/xTwRzPLAIqcc38BcM51AITe7yPnXEVoeRlQCiyK/F9LJDwFhEjPGfCUc+4He600+9d99jvS8Wu6j+HjR/8+Jcp0i0mk594ErjazwbBnDu/hBP8d7R7R88vAIudcI1BvZmeF1n8FeCc0g1+FmV0Zeo8kM0vt1b+FSA/pNxSRHnLOrTKzu4HXzSwO8AK3E5xMZ2poWzXBdgoIDv/8cCgAdo+GCsGw+K2Z3RN6j2t68a8h0mMazVXkKJlZi3MuPdp1iBxrusUkIiJh6QpCRETC0hWEiIiEpYAQEZGwFBAiIhKWAkJERMJSQIiISFj/H/RHY9NenAn4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV1b338c/vnMwjSQhTwhDmUUAColZttbU4VKyztw7c2lKfarW1E3a89fY+11t7tRMO1NbHWseqVKq0tE5Vq6hhnkeBJAxmICHzuJ4/zgEDhhAgJzs5+/t+vXiRPZxzftmvnXyz19p7LXPOISIi/hXwugAREfGWgkBExOcUBCIiPqcgEBHxOQWBiIjPxXhdwPHq27evGzZsmNdliIj0KsuWLSt1zmW3ty2iQWBms4BfAkHgYefc3UdsnwPcAxSHV/3GOfdwR+85bNgwCgoKIlCtiEj0MrOdR9sWsSAwsyAwH/gMUAS8b2aLnHPrj9j1aefcrZGqQ0REOhbJPoIZwFbn3HbnXCPwFDA7gp8nIiInIJJBkAMUtlkuCq870uVmttrMnjWzwe29kZnNNbMCMysoKSmJRK0iIr7ldWfxX4AnnXMNZvYV4FHg3CN3cs4tABYA5Ofna0wMkSjT1NREUVER9fX1XpfS6yUkJJCbm0tsbGynXxPJICgG2v6Fn8tHncIAOOfK2iw+DPwsgvWISA9VVFREamoqw4YNw8y8LqfXcs5RVlZGUVEReXl5nX5dJJuG3gdGmVmemcUB1wCL2u5gZgPbLF4CbIhgPSLSQ9XX15OVlaUQOElmRlZW1nFfWUXsisA512xmtwJLCN0++nvn3DozuwsocM4tAm4zs0uAZqAcmBOpekSkZ1MIdI0TOY4R7SNwzi0GFh+x7kdtvr4TuDOSNRy0bGc5L2/4kO98doxOOBGRNnwzxMTa4gM88Po29h1o8LoUEZEexTdBMH5QGgDrdld6XImI9DQVFRXcf//9x/26Cy+8kIqKiuN+3Zw5c3j22WeP+3WR4psgGDcwDTNYt/uA16WISA9ztCBobm7u8HWLFy+mT58+kSqr23j9HEG3SYmPYVhWMusVBCI92k/+sq7Lf07HD0rjx5+bcNTt8+bNY9u2bUyZMoXY2FgSEhLIyMhg48aNbN68mUsvvZTCwkLq6+u5/fbbmTt3LvDR2GfV1dVccMEFfOITn+Dtt98mJyeHF154gcTExGPW9sorr/Ctb32L5uZmpk+fzgMPPEB8fDzz5s1j0aJFxMTEcP755/Pzn/+cP/3pT/zkJz8hGAySnp7OG2+80SXHxzdBAKGTYXXR8V/GiUh0u/vuu1m7di0rV67k9ddf56KLLmLt2rWH7sX//e9/T2ZmJnV1dUyfPp3LL7+crKysw95jy5YtPPnkk/z2t7/lqquu4rnnnuO6667r8HPr6+uZM2cOr7zyCqNHj+aGG27ggQce4Prrr2fhwoVs3LgRMzvU/HTXXXexZMkScnJyTqhJ6mj8FQQD03hp9R4q65pIT+z8U3ci0n06+su9u8yYMeOwB7J+9atfsXDhQgAKCwvZsmXLx4IgLy+PKVOmADBt2jR27NhxzM/ZtGkTeXl5jB49GoAbb7yR+fPnc+utt5KQkMBNN93ExRdfzMUXXwzAmWeeyZw5c7jqqqu47LLLuuJbBXzURwAwIdxhrOYhEelIcnLyoa9ff/11Xn75Zd555x1WrVrF1KlT231gKz4+/tDXwWDwmP0LHYmJieG9997jiiuu4MUXX2TWrFkAPPjgg/z0pz+lsLCQadOmUVZWdox36hyfBUE6AOv3KAhE5COpqalUVVW1u62yspKMjAySkpLYuHEjS5cu7bLPHTNmDDt27GDr1q0APPbYY5xzzjlUV1dTWVnJhRdeyH333ceqVasA2LZtG6eddhp33XUX2dnZFBYWdvT2nearpqHs1Hj6pcbrFlIROUxWVhZnnnkmEydOJDExkf79+x/aNmvWLB588EHGjRvHmDFjmDlzZpd9bkJCAo888ghXXnnloc7im2++mfLycmbPnk19fT3OOe69914Avv3tb7Nlyxacc5x33nlMnjy5S+ow53rXYJ75+fnuZGYom/PIe+ytrOdvXz+7C6sSkZOxYcMGxo0b53UZUaO942lmy5xz+e3t76umIQj1E2z5sJr6phavSxER6RF8GATptLQ6tuyr9roUEYlyt9xyC1OmTDns3yOPPOJ1WR/jqz4C+OjOoXW7K5mUm+5xNSJykHMu6gaEnD9/frd/5ok09/vuimBwRhIp8TEaakKkB0lISKCsrOyEfonJRw5OTJOQkHBcr/PdFUEgYIwfmKY7h0R6kNzcXIqKitCc5Cfv4FSVx8N3QQChoSaeKSikpdURDETXpahIbxQbG3tcUytK1/Jd0xCEgqC2sYUdZTVelyIi4jlfBsFHHcbqJxAR8WUQjOqXSlwwwLpi9ROIiPgyCOJiAowZkMpadRiLiPgzCAAm5qSztviAblcTEd/zbRBMykmnsq6JwvI6r0sREfGUr4MAYI36CUTE53wbBKMHpBAbNAWBiPieb4MgPiYY6jBWEIiIz/k2CAAmDkpnTXGlOoxFxNf8HQThDuOi/eowFhH/8nUQqMNYRMTnQTBmQCoxAVM/gYj4mq+DICE2yOj+qboiEBFf83UQQKh5aK06jEXEx3wfBBNz09lf20RxhTqMRcSfIhoEZjbLzDaZ2VYzm9fBfpebmTOz/EjW056DHcbqJxARv4pYEJhZEJgPXACMB641s/Ht7JcK3A68G6laOjJ2QCrBgJ4wFhH/iuQVwQxgq3Nuu3OuEXgKmN3Ofv8J/A9QH8FajiohNsiofimsKdYkNSLiT5EMghygsM1yUXjdIWZ2KjDYOfdSR29kZnPNrMDMCiIxufUpuemsKapQh7GI+JJnncVmFgDuBb55rH2dcwucc/nOufzs7Owur2XK4Az21zaxq7y2y99bRKSni2QQFAOD2yznhtcdlApMBF43sx3ATGCRFx3GUwb3AWDFroru/mgREc9FMgjeB0aZWZ6ZxQHXAIsObnTOVTrn+jrnhjnnhgFLgUuccwURrKldo/unkBQXZGWhgkBE/CdiQeCcawZuBZYAG4BnnHPrzOwuM7skUp97ImKCASblpLNCQSAiPhQTyTd3zi0GFh+x7kdH2feTkazlWKYOyeB3b22nvqmFhNigl6WIiHQr3z9ZfNCUwX1oanGs36PbSEXEXxQEYVOHqMNYRPxJQRDWPy2BQekJ6jAWEd9RELQxdUgGK3bt97oMEZFupSBoY8rgPhTtr6O0usHrUkREuo2CoI2D/QQr1U8gIj6iIGhjYk46MQFjRaGah0TEPxQEbSTEBhk3ME0dxiLiKwqCI0wZ3IdVhZW0tGokUhHxBwXBEaYO6UN1QzPbSqq9LkVEpFsoCI5w6pAMAN7fUe5xJSIi3UNBcIShWUkMSEvgnW1lXpciItItFARHMDNOH5HF0u3lmrFMRHxBQdCOmcMzKa1uUD+BiPiCgqAdpw/vC6DmIRHxBQVBOwZnJjIoPYF3tisIRCT6KQjaYWbMDPcTtOp5AhGJcgqCozh9eBblNY1s+VD9BCIS3RQERzFzeBYA72wr9bgSEZHIUhAcxeDMJHIzEtVPICJRT0HQgdOHZ/HuB+onEJHopiDowMzhWVTUNrFxb5XXpYiIRIyCoAOnjwj3E6h5SESimIKgA4P6JDI0K4m3tpR4XYqISMQoCI7hsxMG8OaWUsprGr0uRUQkIhQEx3DZqTk0tzr+smq316WIiESEguAYxg5IY/zANJ5fXuR1KSIiEaEg6ITLTs1hVVElWz/U3UMiEn0UBJ1wyZRBBAPG88uLvS5FRKTLKQg6oV9qAmeP6svCFcV6uExEoo6CoJMuOzWXPZX1LNUzBSISZRQEnfSZ8f1JjY/hOTUPiUiUiWgQmNksM9tkZlvNbF472282szVmttLM3jKz8ZGs52QkxAa56JSB/HXtHirrmrwuR0Sky0QsCMwsCMwHLgDGA9e284v+CefcJOfcFOBnwL2RqqcrXH/6UBqbW5n33GpNbC8iUSOSVwQzgK3Oue3OuUbgKWB22x2ccwfaLCYDPfq364RB6Xxn1hj+unYvjy3d6XU5IiJdIpJBkAMUtlkuCq87jJndYmbbCF0R3BbBerrElz4xnHPH9uOnL25gTVGl1+WIiJw0zzuLnXPznXMjgO8CP2hvHzOba2YFZlZQUuLtAHCBgPG/V04mKyWOW55YzoF69ReISO8WySAoBga3Wc4Nrzuap4BL29vgnFvgnMt3zuVnZ2d3YYknJiM5jl9fO5Xiijrmv7bV63JERE5KJIPgfWCUmeWZWRxwDbCo7Q5mNqrN4kXAlgjW06Xyh2VyWl4mb2zWnMYi0rtFLAicc83ArcASYAPwjHNunZndZWaXhHe71czWmdlK4A7gxkjVEwlnjMhiw54DGqJaRHq1mEi+uXNuMbD4iHU/avP17ZH8/Eg7fURfYDNLt5dx4aSBXpcjInJCPO8s7s1OyU0nOS7I29vUPCQivZeC4CTEBgPMyMvk7W0af0hEei8FwUk6Y0RftpfUsLey3utSREROiILgJJ0+IguAd7areUhEeicFwUkaPzCN9MRY3t6q5iER6Z0UBCcpEDBOH57F29vKNBCdiPRKCoIucMbILIor6igsr/O6FBGR46Yg6AJnhPsJdBupiPRGCoIuMCI7hezUeN1GKiK9koKgC5gZZ4zI4l9bSzV7mYj0OgqCLnL9zKFU1jVxy+PLaWpp9bocEZFO61QQmNntZpZmIb8zs+Vmdn6ki+tN8odlcvflp/DW1lJ+sHCt7iASkV6js1cEXwxPK3k+kAFcD9wdsap6qSum5XLbuSN5uqCQ+1/f5nU5IiKd0tnRRy38/4XAY+HhpK2jF/jVNz4zmp3ltdyzZBPjB6XxqTH9vC5JRKRDnb0iWGZmfycUBEvMLBVQQ3g7zIyfXXEKeX2Tuedvm9REJCI9XmeD4CZgHjDdOVcLxAL/HrGqern4mCBfO3ck6/cc4O/r93ldjohIhzobBKcDm5xzFWZ2HaFJ5isjV1bvd8nkQeT1TeaXL2/RVYGI9GidDYIHgFozmwx8E9gG/CFiVUWBmGBAVwUi0it0NgiaXejP2tnAb5xz84HUyJUVHXRVICK9QWeDoMrM7iR02+hLZhYg1E8gHdBVgYj0Bp0NgquBBkLPE+wFcoF7IlZVFDl4VXD/a1u9LkVEpF2dCoLwL//HgXQzuxiod86pj6ATYoIBvnDaEFYVVbKtpNrrckREPqazQ0xcBbwHXAlcBbxrZldEsrBocsnkQZjBCyt3e12KiMjHdLZp6PuEniG40Tl3AzAD+GHkyoou/dISOGNEFotWFqvTWER6nM4GQcA592Gb5bLjeK0AsyfnsKOsllVFevxCRHqWzv4y/5uZLTGzOWY2B3gJWBy5sqLPrEkDiIsJ8MLKYq9LERE5TGc7i78NLABOCf9b4Jz7biQLizZpCbGcO6Yff1m1h5ZWNQ+JSM/R2dFHcc49BzwXwVqi3uwpg/jbur28va2Us0Zle12OiAhwjCsCM6syswPt/KsyswPdVWS0+NTYfqTGx+juIRHpUToMAudcqnMurZ1/qc65tO4qMlokxAaZNXEAf1u7l5qGZq/LEREBdOdPt7syfzDVDc189hdvsHjNHt1OKiKeUxB0sxl5mTzx5dNIiY/hq48v55oFS9n6oZ44FhHvKAg8cMaIvrz4tU/w00snsmlfFTf+/j0O1Dd5XZaI+FREg8DMZpnZJjPbambz2tl+h5mtN7PVZvaKmQ2NZD09SUwwwHUzh/K7G6ezp7KO/1i0zuuSRMSnIhYEZhYE5gMXAOOBa81s/BG7rQDynXOnAM8CP4tUPT3VtKEZ3PqpkTy/vJjFa/Z4XY6I+FAkrwhmAFudc9udc43AU4QmtjnEOfdaeA5kgKWEhrf2na+dN4rJuel8b+Ea9h2o97ocEfGZSAZBDlDYZrkovO5obgL+2t4GM5trZgVmVlBSUtKFJfYMscEA9149hfqmFr71p1W6k0hEulWP6Cw2s+uAfI4y2Y1zboFzLt85l5+dHZ1P5I7ITuH7F43nzS2lPPle4bFfICLSRSIZBMXA4DbLueF1hzGzTxMa5voS51xDBOvp8a47bQhnjszi/y7eQHFFndfliIhPRDII3gdGmVmemcUB1wCL2u5gZlOBhwiFwIftvIevmBl3X3YKrc4x77nVaiISkW4RsSBwzjUDtwJLgA3AM865dWZ2l5ldEt7tHiAF+JOZrTSzRUd5O98YnJnEnReO480tpTxToCYiEYk8621/debn57uCggKvy4io1lbHFx5+l7XFlSz5xtkM6pPodUki0suZ2TLnXH5723pEZ7EcLhAwfnbFKTS1tnLPkk1elyMiUU5B0EMNzkzihtOH8cLKYraXaCwiEYkcBUEP9uWzhhMXE+A3r231uhQRiWIKgh4sOzWe604bygsrd7OjtMbrckQkSikIeri55wwnJmC6KhCRiFEQ9HD9UhP4wmlDWbiimJ1luioQka6nIOgFbg5fFfz6VV0ViEjXUxD0Av3SErjh9KE8u6xID5mJSJeL8boA6Zxvf3YsG/ZUcefza8hMiuPT4/t7XZKIRAldEfQScTEBHrx+GhMGpXHLE8tZtrP80LbmllaaWlo9rE5EejMNMdHLlFU3cMWD71Ba3UBe32T2VtZTWt1Aq4PE2CDpibEMz07m19dOJSsl3utyRaSH6GiICTUN9TJZKfH84Ysz+MGf1+KAsQNSGZCWQGwwQGVdE/trm3h+RRGPvr2DO84f43W5ItILKAh6ocGZSTz6xRlH3V5V38Qflu7k/3xyJIlxwW6sTER6I/URRKG5Zw+noraJZ5fpDiMROTYFQRSaNjSDqUP68PBbH9DS2rv6gESk+ykIopCZMfes4ewsq+Uf6/d6XY6I9HAKgih1/oQBDMlMYsEb270uRUR6OAVBlAoGjC+dlcfyXRUU7Cg/9gtExLcUBFHsimm5ZCXHcdOjBTz+7k5a1V8gIu1QEESxpLgYnv7KTMYOSOX7C9fy+fv/xZqiSq/LEpEeRkEQ5Ub2S+WpuTP5xdVTKK6o5/IH3mZlYYXXZYlID6Ig8AEz49KpOfz9G2eTnRrPV/+4jPKaRq/LEpEeQkHgI5nJcTx43TRKaxq57ckVesZARAAFge9Myk3nrksm8NbWUn7x8mavyxGRHkBB4EPXzBjC1fmD+fWrW3lt04delyMiHlMQ+NRPZk9gTP9Uvvvsaiprm7wuR0Q8pCDwqYTYID+/cjJlNY385MV1XpcjIh5SEPjYpNx0vvrJETy/vJiX1+/zuhwR8YiCwOe+du4oxg5I5c6Fa6io1S2lIn6kIPC5uJgAP79yMuU1jfx4kZqIRPxIQSBMzEnna+eO5IWVu3mmQJPZiPiNgkCAUBPR6cOz+NELa9m0t8rrckSkG0U0CMxslpltMrOtZjavne1nm9lyM2s2sysiWYt0LBgwfnntFFLiY/nq48uoaWj2uiQR6SYRCwIzCwLzgQuA8cC1Zjb+iN12AXOAJyJVh3Rev9QEfnXNFD4oreEHf16LcxqCQsQPInlFMAPY6pzb7pxrBJ4CZrfdwTm3wzm3GmiNYB1yHM4Y2ZfbzxvNwhXF3P/6Nq/LEZFuEBPB984B2vY8FgGnncgbmdlcYC7AkCFDTr4y6dDXzh3JB6XV3LNkE/ExAb501nCvSxKRCIpkEHQZ59wCYAFAfn6+2isiLBAwfn7lZBpbWvnpSxuIjwlw/enDvC5LRCIkkkFQDAxus5wbXie9QEwwwC+vmUpj83J++MI6ahpb+OKZecTF6EYzkWgTyZ/q94FRZpZnZnHANcCiCH6edLHYYID5X5jK+eP7c/dfN3L+ff/kpdV71IksEmUiFgTOuWbgVmAJsAF4xjm3zszuMrNLAMxsupkVAVcCD5mZHm3tYeJjgjx0/TQemTOd+JggtzyxnCsefIfKOo1YKhItrLf9dZefn+8KCgq8LsOXWlodzy4r5HsL13LBxAH8+tqpmJnXZYlIJ5jZMudcfnvb1OArnRYMGFdPH8IdnxnNi6v38NxydfmIRAMFgRy3m88ZwWl5mfzohbXsKK3xuhwROUkKAjluwYBx39VTiA0GuO2pFTQ263lAkd5MQSAnZFCfRO6+bBKriyq58qF3+POKYhqaW7wuS0ROgIJATtgFkwZy92WTqKxt5OtPr+SM/36Ve/+xmbpGBYJIb6K7huSktbY6/rWtlEff3snLG/YxNCuJ/75sEmeM6Ot1aSIS1tFdQwoC6VJvbyvlzufXsLOslqvyc5mRl0UwAAEzJuakMyI7xesSRXxJQSDdqq6xhV+8vJnfvrmd1janV3xMgF9cPYULJg30rjgRn1IQiCf21zRSVd9Mi3PUN7Xwgz+vZfmu/XzvgnF86aw8PYwm0o06CoJeMfqo9E4ZyXFkJMcdWn78S6dxxzMr+a/FGyjcX8uPPzeBYEBhIOI13TUk3SYhNshvrj2VuWcP5w/v7OQrjxVQ29jxlJi97YpVpDfSFYF0q0DA+N6F4xickciPF63j6oeW8rs5+fRLTQCgtrGZFbsqeHd7GUs/KGdVYQXjB6Vx3WlDueiUgSTEBj3+DkSij/oIxDOvbNjHrU+sIDM5jlkTB1Cwo5y1uw/Q0uoIGEzMSWdybh/+ta2U7SU19EmKZcawTPbXNlJS1UBtYwvfnTWWy6flev2tiPR46iyWHmtNUSU3Pfo+FXVNTMntQ/6wDKYPyyR/WAapCbFAqHnonW1lPLZ0J5v3VdE3JZ5+aQkUlteysrCC7184ji+frek0RTqiIJAerbmllRbniI85vmafhuYW7nh6FS+t2cNXzhnOvFljdSeSyFHoriHp0WKCgRM6EeNjgvzq2qlkJMfy0D+384/1+0hPjCU+JkB8TJDk+CDJcTEkx8dw3rh+nDUqu8trF4kGCgLp1YIB4z9nT2REdgr/2lpKQ3MrDc2tVNQ2UlzRQm1DMxV1Tfy/t3cwa8IAfvi58eT0SfS6bJEeRU1DEvUamlt4+M0P+PWrWwD4+qdHM/es4QT0DIP4iGYoE1+Ljwlyy6dG8vId53D2qGzu/utGbntqBfVNkR0ltbKuiZfX7+NAveZ3lp5NTUPiG7kZSTx0/TQeemM7d/91I3sr61lwQz6ZbZ5+PlnOOVYUVvDEu7t4cfVu6ptayemTyC+umcL0YZld9jkiXUlNQ+JLL67ezR3PrGJQegKfmzyIhNggSXFBYoMfXSTHxwS4YNJAUuIP/3upqaWV0uoGBqYf3tdQWdfEN59Zxcsb9pEcF+SSKTmcMSKLe5Zsomh/Lbd8aiS3nTfqsM8Q6S66fVSkHct2lnPbkyvZXVnH0X4M+qbE863zR3Nl/mCcc/x55W5+9coWdpXXct7Yfnz3grGM7p/Khj0HuPmPyyjeX8e3PjuG62YOPRQg1Q3N/PiFdTy3vIj8oRk8cN00slPju/E7FVEQiHTIOUdDcyt1jS00tbRCuA95V1kt//3XjSzbuZ+xA1JpbG5le2kNEwalcfbobP74zk5qGps5f/wAXt/8IemJsdz/hVOZNrT9JqAXVhbz3edWk5kUx4Ib8pmYk96N36X4nYJA5AQ553hpzR7u/ftm4mOD3H7eKD47oT9mxv6aRn7z2lYee2cnU4b04Tf/NvXQmElHs7a4ki//oYCK2ib+96rJXKi5GaSbKAhEIuhAfRMpcTGdvh21pKqBm/+4jGU793PN9MHceeE40hNjj7p/aXUDdY0th5qv6ppaKK1uoLS6gar6ZmYOz2Rkv9TDXlNe08ia4kqCZsQGjbiYAAmxQRJjgyTGBUlPjNUAfj6jJ4tFIigt4ei/xNuTnRrPE18+jXv/sZmH3/yAVzd+yH9eOpGzRvVlR2ktH5TWsHlfFWuLK1ldXElJVcMx33PsgFQuPmUgZsarGz9k+a79R+33AEiMDXLp1EFcP3MY4welHVf9En10RSDioTVFlXznudVs2HPgsPUBgxHZKUzKSWdCTvqhKwYD4mMD9E2Jp29KPHHBAK9u3MeLq/dQsHM/AKfkpvOpMf2YOTyLmKDR2NxKY3MrDc0t1DW1UNfYyqrCCl5YVUx9UyvThmYwLCuZ2KAREzQGpidyzuhsxg9M00N3UURNQyI9WFNLK0+9t4vKuiby+qaQ1zeZYX2TSIo7vgv2fQfqMeOY/RQHVdY28adlhTy3vJgDdU00t7bS3OIoq2kEQndMnT2qLyP7pzA0M5mhWUk0trRSWF7LrrJaDtQ3Map/KuMHpjGqf0q7gwY2tbSybOd+UhNiGJKZdGhEWel+CgIR6bSSqgbe2FzC65tLWLq97KhNU3HBAI0trQDEBo1Th2Tw6XH9OW9cP2KDAZ56fxdPv19EafVHr89IimVkvxQm5qRzSm46k3L6MLxv8mFXHlX1TfxzcwkflNQwekAqEwalkdMn8agjy1bVN/XYgGltdVTWNVFR10R1fTPVDc3UNDQzID2BCYPSunW0XAWBiJyw6oZmdpXVsqu8hthggCGZSeRmJBEXE2BnWQ3r9xxgTVEl/9xcwsa9VYdeFzA4d2w/rpiWi3Ows7yWnWW1bN5XxbrdldQ3hUIkOS7IhJx0JgxK44PSGt7eWnYoYA7qkxTLmP6pjBmQyqj+qeAc7+/YT8GOcnZX1jO8bzLnjMnmU2P6MTgziZrwL9xWB6P6p9A3pfue26hrbOGnL61n8Zo9VNQ1HbWvZmB6Ap8e159PjOpLXDBAc6ujpbWVpLgYMpLiyEiOpW9KfJd16isIRKRbFJbX8urGD6luaObzU3MYdJSRXptbWtlaUs3qokrWFleypriS9bsP0D8tgfPH9+f8CQMYPygtHBoHWL+7kk17q9i8r5rqhtA81/1S45mel8mY/qks37Wfd7aV0dDc2u7n9UuNZ9zANKYPy+Cc0f2YMCgy/R+b9lZx6xPL2VpSzezJgxiSmUSfpDj6JMWSmhB7aGj0zfuq+Mf6fby5pZS6Dsa8MoO8rGTGDkxl7IA0PjO+P+MGnljnvoJARHq81lZ3zF/Ozjn2VNbT0urIzc4lLQkAAAd6SURBVDi8uaiusYWl28vYX9tIcnwMKfExtDrHpr1VbNgTugtr077QFUtWchzTh2UyJCuJnD6J5PRJJDs1nszkODKS4zCgrLqRkuoGqhuaGZiewJDMpEN/nVfVN1FYXse+qnoamlppamllV3ktv3plC6kJsdx39eROzX9R39TC+j0HMCA2GCBgRm1jM/trm9hf00hxRR2b9laxce8BdpTV8rPLT+Gq6YNP6Ph6FgRmNgv4JRAEHnbO3X3E9njgD8A0oAy42jm3o6P3VBCIyIkqqWrgra0lvLG5lJWFFRRX1NF4lKuI9vRPiw/Pd9H+iLJnjerLvVdNicgQIjUNzZhx3DcRHOTJcwRmFgTmA58BioD3zWyRc259m91uAvY750aa2TXA/wBXR6omEfG37NR4Pj81l89PzQVCVyGlNQ0U76+jvKaRsppGytvcNZWVEkdKfAy7K+rYVVbLzvJa4mMCDM5MYkhmEv3TEkiIDRyaFe/Iq5SulBwfuce+IvlA2Qxgq3NuO4CZPQXMBtoGwWzgP8JfPwv8xszM9bb2KhHplQIBo19qQqdvuY1WkRwPNwcobLNcFF7X7j7OuWagEsg68o3MbK6ZFZhZQUlJSYTKFRHxp14xMLpzboFzLt85l5+drQnIRUS6UiSDoBho272dG17X7j5mFgOkE+o0FhGRbhLJIHgfGGVmeWYWB1wDLDpin0XAjeGvrwBeVf+AiEj3ilhnsXOu2cxuBZYQun309865dWZ2F1DgnFsE/A54zMy2AuWEwkJERLpRRIehds4tBhYfse5Hbb6uB66MZA0iItKxXtFZLCIikaMgEBHxuV431pCZlQA7j+MlfYHSCJXTG+l4fJyOyeF0PA4XLcdjqHOu3fvve10QHC8zKzja+Bp+pOPxcTomh9PxOJwfjoeahkREfE5BICLic34IggVeF9DD6Hh8nI7J4XQ8Dhf1xyPq+whERKRjfrgiEBGRDigIRER8LmqDwMxmmdkmM9tqZvO8rscLZjbYzF4zs/Vmts7Mbg+vzzSzf5jZlvD/GV7X2p3MLGhmK8zsxfBynpm9Gz5Xng4PkugLZtbHzJ41s41mtsHMTtf5Yd8I/7ysNbMnzSwh2s+RqAyCNtNkXgCMB641s/HeVuWJZuCbzrnxwEzglvBxmAe84pwbBbwSXvaT24ENbZb/B7jPOTcS2E9oClW/+CXwN+fcWGAyoePi2/PDzHKA24B859xEQgNmHpxGN2rPkagMAtpMk+mcawQOTpPpK865Pc655eGvqwj9kOcQOhaPhnd7FLjUmwq7n5nlAhcBD4eXDTiX0FSp4KPjYWbpwNmERgHGOdfonKvAx+dHWAyQGJ4jJQnYQ5SfI9EaBJ2ZJtNXzGwYMBV4F+jvnNsT3rQX6O9RWV74BfAdoDW8nAVUhKdKBX+dK3lACfBIuKnsYTNLxsfnh3OuGPg5sItQAFQCy4jycyRag0DaMLMU4Dng6865A223hScC8sU9xGZ2MfChc26Z17X0EDHAqcADzrmpQA1HNAP56fwACPeHzCYUkoOAZGCWp0V1g2gNgs5Mk+kLZhZLKAQed849H169z8wGhrcPBD70qr5udiZwiZntINRceC6hNvI+4WYA8Ne5UgQUOefeDS8/SygY/Hp+AHwa+MA5V+KcawKeJ3TeRPU5Eq1B0JlpMqNeuP37d8AG59y9bTa1nSL0RuCF7q7NC865O51zuc65YYTOiVedc18AXiM0VSr463jsBQrNbEx41XnAenx6foTtAmaaWVL45+fgMYnqcyRqnyw2swsJtQcfnCbzvzwuqduZ2SeAN4E1fNQm/j1C/QTPAEMIDel9lXOu3JMiPWJmnwS+5Zy72MyGE7pCyARWANc55xq8rK+7mNkUQh3nccB24N8J/YHo2/PDzH4CXE3orrsVwJcI9QlE7TkStUEgIiKdE61NQyIi0kkKAhERn1MQiIj4nIJARMTnFAQiIj6nIBDpRmb2yYOjnor0FAoCERGfUxCItMPMrjOz98xspZk9FJ7DoNrM7guPVf+KmWWH951iZkvNbLWZLTw4fr+ZjTSzl81slZktN7MR4bdPaTMHwOPhJ1hFPKMgEDmCmY0j9GTpmc65KUAL8AVCA5AVOOcmAP8Efhx+yR+A7zrnTiH0FPfB9Y8D851zk4EzCI1mCaFRYL9OaK6M4YTGshHxTMyxdxHxnfOAacD74T/WEwkNvNYKPB3e54/A8+Ex/fs45/4ZXv8o8CczSwVynHMLAZxz9QDh93vPOVcUXl4JDAPeivy3JdI+BYHIxxnwqHPuzsNWmv3wiP1OdHyWtmPUtKCfQ/GYmoZEPu4V4Aoz6weH5ngeSujn5eAIlP8GvOWcqwT2m9lZ4fXXA/8MzwhXZGaXht8j3sySuvW7EOkk/SUicgTn3Hoz+wHwdzMLAE3ALYQmbpkR3vYhoX4ECA1L/GD4F/3BETwhFAoPmdld4fe4shu/DZFO0+ijIp1kZtXOuRSv6xDpamoaEhHxOV0RiIj4nK4IRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5/4/5EnkinOfkeAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plotmodel(history,'efficientnetB0')            \n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "Y_pred = model.predict(valid_data, 240 // 4)\n",
        "#print(Y_pred.shape)\n",
        "#print(type(Y_pred))\n",
        "print(valid_data.classes)  \n",
        "print(Y_pred)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "#print(y_pred)\n",
        "print('Confusion Matrix')\n",
        "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
        "\n",
        "print(confusion_matrix(valid_data.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['non-referable', 'referable']\n",
        "print(classification_report(valid_data.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(matrix,annot=True,fmt='d')\n",
        "plt.xlabel('Predicted value')\n",
        "plt.ylabel('Truth')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDiyJtvhNDuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5508ada7-a3b1-469d-9fdb-c316efdb2fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plot_metric\n",
            "  Downloading plot_metric-0.0.6-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (3.2.2)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (0.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.4.1)\n",
            "Requirement already satisfied: colorlover>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (0.3.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.2->plot_metric) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->plot_metric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->plot_metric) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot_metric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot_metric) (3.1.0)\n",
            "Installing collected packages: plot-metric\n",
            "Successfully installed plot-metric-0.0.6\n"
          ]
        }
      ],
      "source": [
        "pip install plot_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3J5q1SLNMkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "8d2821ef-aa59-447f-9205-b7b0f66efc16"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3RU1drA4d+UJKQnQAooXZoQCCgogtTQCUpHKaICNgSuIKBUKQoIeEFF4cIHBkSkSUeKBbwo6FVIAEGkBEJJgfQ6bX9/xAwEMpkkZOYkM/tZi2XmzCnvnklezz67qYQQAkmSJMkitdIBSJIklXUyUUqSJFkhE6UkSZIVMlFKkiRZIROlJEmSFTJRSpIkWSETZTnXs2dPjh8/rnQYZcbnn3/O1KlTFbn2lClT+OijjxS5dmnbuXMnL730UomOdcTfSZXsR1l6OnbsyK1bt9BoNHh4ePD0008zffp0PD09lQ6tVOh0Oj7++GN27dpFYmIiwcHBDBw4kJdffhmVSmX3eI4fP87bb7/NkSNH7HI9IQTr1q1j06ZNXLt2DR8fH0JDQ3njjTeoX78+U6ZMISgoiH/96192iceSjz/+mCtXrrBo0SKbX6uslNnW5B1lKfv88885ceIE27dv588//2TlypVKh1RsBoOhwO1jx47ll19+YeXKlfzxxx8sXLiQTZs2MW/evFKPQQiByWQq9fM+iHnz5hEREcHUqVP59ddf2b9/P2FhYRw+fLjUr2XpO7AHJa9dZgmp1HTo0EEcPXrU/HrBggVi1KhR5tcnTpwQgwYNEo899pgIDw8Xx44dM7+XlJQkpkyZIlq3bi0ef/xx8dprr5nf+/7770Xv3r3FY489JgYNGiTOnj173zVjY2NFSEiISEpKMr935swZ0bJlS6HT6YQQQmzevFl069ZNPP744+Kll14S165dM+9br149sX79etG5c2fRoUOH+8r2888/i8aNG4sbN27k237y5EnRoEEDER0dLYQQYujQoWLRokWiX79+olmzZuLVV1/NF1Nhn8HQoUPFkiVLxKBBg0RISIiIjo4WW7ZsEd26dROhoaGiY8eO4quvvhJCCJGRkSFCQkJE/fr1RWhoqAgNDRWxsbFi2bJlYsKECUIIIWJiYkS9evXEtm3bRLt27UTLli3F8uXLzdfLysoSkyZNEo8//rjo1q2bWLlypXj66acL/G4vX74sGjRoICIjIwt8XwghJk+eLGbNmiVGjRolQkNDRf/+/cWVK1fM78+ZM0e0bdtWNGvWTPTp00f89ttv5veWLVsm3nzzTTFhwgTRrFkzsWnTJhEZGSkGDhwoHnvsMdG6dWvx3nvviZycHPMx58+fFyNGjBAtWrQQrVq1Ep999pk4fPiwaNSokXj00UdFaGioCA8PF0IIkZqaKt555x3RunVr0aZNG7FkyRJhMBiEEEJs3bpVDBo0SMybN0+0bNlSLFmyRGzdulUMHjxYCCGEyWQS8+bNE08++aRo1qyZ6NWrl/jrr7/Exo0bxaOPPioaNWokQkNDxSuvvCKEyP93YDAYxGeffSY6deokQkNDRZ8+fe77HSoPZKIsRXf/gty8eVP06tVLzJkzRwghRGxsrGjZsqX48ccfhdFoFP/9739Fy5Ytxe3bt4UQQowaNUqMGzdOJCcnC51OJ44fPy6EyE12Tz75pDh58qQwGAxi27ZtokOHDuY/mLuvOWzYMPH111+b45k/f76YPn26EEKIgwcPirCwMHHhwgWh1+vFp59+KgYNGmTet169emLEiBEiKSlJZGVl3Ve2Dz/8UAwZMqTAcrdv396cwIYOHSratGkj/vrrL5GRkSHGjBljTlzWPoOhQ4eKdu3aifPnzwu9Xi90Op344YcfxJUrV4TJZBLHjx8XTZo0EadPnxZCCHHs2LH7EltBiXLq1KkiKytLnD17VjRq1EhcuHAhX5mSk5PN35elRLlhwwbRvn37At/LM3nyZNGyZUsRGRkp9Hq9eOutt8T48ePN72/fvl0kJiYKvV4vVq9eLZ566imRnZ1tjvvRRx8VBw8eFEajUWRlZYlTp06JEydOCL1eL2JiYkS3bt3EmjVrhBBCpKWlidatW4vVq1eL7OxskZaWJk6ePHnfZ5Dn9ddfF9OnTxcZGRni1q1bol+/fubvbOvWraJhw4YiIiJC6PV6kZWVlS9RHjlyRPTp00ekpKQIk8kkLly4IOLi4sxlXrJkSb5r3f07+Z///Ef06tVLXLx4UZhMJnH27FmRmJhY6OdYFsmqdyl74403aNasGe3ataNixYqMHTsWgB07dtC2bVvatWuHWq2mdevWNG7cmMOHDxMfH8+RI0d477338PX1xcXFhZYtWwLw9ddfM2jQIJo2bYpGo6FPnz64uLhw8uTJ+64dHh7O7t27gdyq6969ewkPDwdg48aNjB49mjp16qDVann11Vc5e/Ys169fNx8/evRo/Pz8qFChwn3nTkpKIiAgoMAyBwQEkJSUZH79zDPPUK9ePTw8PBg3bhzffvstRqOx0M8gT58+fahbty5arRYXFxfat29P9erVUalUtGzZktatW/O///2vWN/JmDFjqFChAg0aNKBBgwacO3cOgH379vHKK6/g6+tLcHAww4cPt3iO5ORki+W/W1hYGE2aNEGr1dK7d2/Onj2b73Px9/dHq9Xy0ksvodPpuHz5svn90NBQwsLCUKvVVKhQgcaNGxMaGopWq+Xhhx9m0KBB/PbbbwD8+OOPVK5cmZdeegk3Nze8vLxo2rRpgTHdunWLw4cP8+677+Lh4UGlSpUYMWIEe/bsMe8TGBjIsGHD0Gq1933/Wq2WjIwMLl26hBCCOnXqEBgYaPWzANi8eTPjxo2jdu3aqFQqGjRogL+/f5GOLUu0SgfgaD799FOeeuopfv31VyZMmEBSUhI+Pj7cuHGDb7/9lh9++MG8r8Fg4IknniA2NhZfX198fX3vO9+NGzfYvn0769evN2/T6/XEx8fft2+XLl2YM2cO8fHxREdHo1arefzxx83nef/991mwYIF5fyEEcXFxPPTQQwBUqVLFYrn8/f25cuVKge8lJCTk++W/+zxVq1ZFr9eTlJRU6GdQ0LEAhw8f5tNPPyU6OhqTyUR2djb16tWzGGdBKleubP7Z3d2dzMxMAOLj4/NdLzg42OI5/Pz8SEhIKNa1KlSoYL4WwOrVq9myZQvx8fGoVCrS09Pz/Q/m3utfvnyZ+fPnc/r0abKysjAajTRq1AiAmzdvUr16davxQO53bzAYaNOmjXmbyWQqctlbtWrFkCFDmD17NtevX6dLly5MnjwZLy8vq9eOjY0tcpxlmUyUNtKyZUv69u3LggULWL58OVWqVOGZZ55h7ty59+0bHx9PSkoKqamp+Pj45HuvSpUqvPrqq7z22mtWr+nr60vr1q3Zu3cvly5dokePHubW6Lzz9O7d2+LxhbVcP/XUU3zxxRfcvHkz3x9YZGQkN2/e5MknnzRvu3nzZr6fXVxc8Pf3L/QzKCgGnU7H2LFjWbBgAZ06dcLFxYXXX38d8U9HjQdtaQ8ICCA2NpZHHnkEyP2jtqRVq1bMnj2bU6dOERISUuxr/e9//2PVqlWsXbuWunXrolaradGihbkscH95Zs2axaOPPsrixYvx8vJi7dq17N+/H8j9Pvfu3Vvgte49T3BwMK6urhw7dgyttuA/eWuf5fDhwxk+fDi3b99m/PjxrFq1ivHjx1s9Ljg4mKtXrxb7f25ljax629ALL7zAzz//zLlz5+jduzc//PADP/30E0ajkZycHI4fP05sbCyBgYG0bduW9957j5SUFPR6vbmKNWDAADZu3EhkZCRCCDIzM/nxxx9JT08v8Jrh4eHs2LGD/fv3m6vdAIMHD2blypX8/fffAKSlpbFv374il+Wpp56iVatWvPnmm/z9998YjUZOnjzJ22+/zXPPPUfNmjXN++7cuZMLFy6QlZXF0qVL6dq1KxqNptDPoCA6nQ6dTkfFihXRarUcPnyYo0ePmt+vVKkSycnJpKWlFbkcd+vevTsrVqwgJSWFuLi4fHft96pZsybPP/88EyZM4Pjx4+h0OnJyctizZ0+RejZkZGSg0WioWLEiBoOBTz75xOJ3ePcxnp6eeHp6cvHiRb766ivze+3btychIYG1a9ei0+lIT08nMjISyP1crl+/bu41EBgYSOvWrZk/fz7p6emYTCauXr3Kr7/+WpSPiaioKCIjI9Hr9bi7u+Pq6oparTZf69q1axaPHTBgAEuXLiU6OhohBOfOnct3F11eyERpQxUrVuSZZ57h008/pUqVKixfvpwVK1bQqlUr2rVrx+rVq82/zAsXLkSr1dK9e3fz3RtASEgIc+bMYfbs2bRo0YIuXbqwbds2i9fs2LEj0dHRVK5cmQYNGpi3d+7cmZEjR/LWW2/RvHlzevXqVez+hx9//DFPPPEEI0eOpFmzZrz99tv079+f6dOn59vvmWeeYcqUKbRu3RqdTmfuAG7tM7iXl5cX06ZNY/z48bRo0YLdu3fTsWNH8/t16tShZ8+ehIWF8fjjjxMXF1es8rzxxhsEBwfTqVMnRowYQdeuXXF1dbW4/7Rp08xV0BYtWhAWFsbBgwfp0KGD1Wu1adOGp59+mq5du9KxY0fc3NwKfdQBMHnyZHbv3k3z5s2ZPn06PXr0ML/n5eXF//3f//HDDz/QunVrunbtau7k3a1bNwCeeOIJ+vTpA+T+fun1enr06EGLFi0YO3ZskR4lQG7CnjZtGi1btqRDhw74+fnx8ssvA9C/f38uXLjA448/zuuvv37fsS+++CLdu3fnpZdeonnz5kydOpWcnJwiXbcskR3OpVI1bNgwevfuzYABA5QOpdg2bNjA3r17C72zlJyTvKOUnFZ8fDy///47JpOJS5cusWbNGsLCwpQOSyqDZGOO5LT0ej0zZ87k2rVreHt707NnT55//nmlw5LKIFn1liRJskJWvSVJkqyQiVKSJMmKcveM0mQyYTQW72mBRqMq9jF3i4w8AUDTps1KfI7S8KDlKEtkWcomRylLScrh4qKx+F65e0ap1xtJTs60vuNd/Pw8in3M3YYOHQjA+vWbSnyO0vCg5ShLZFnKJkcpS0nKERDgbfG9cndHqQSlE6QkScqSzyglSZKskIlSkiTJCpkoiyAw0IfAQB/rO0qS5JBkopQkSbJCNuYUQXx8qtIhSJKkIHlHKUmSZIXNEuU777xDq1at6NWrV4HvCyGYO3cunTt3Jjw8nDNnztgqFEmSpAdis0TZt29fVq1aZfH9I0eOEB0dzYEDB5gzZw6zZs2yVSgPbOjQgeZO55IkOR+bPaNs0aJFoVPEf/fddzz77LOoVCpCQ0NJTU0lPj6+yKu72dOBA98qHYIkSRaYTCZu3rzB5cuXuHz5EmmRJ7jt48W48ZPw8bl/wb6SUKwxJy4uLt/Kb8HBwcTFxVlNlBqNCj8/j2JdS6NRF/uYu23b9g3AA52jNDxoOcoSWZayqayWxWAwEBMTw8WLF7h48SIXL17gwoWLXLx4kUuXLpqXl2gL7AE+Bc6EhdG9R89SuX65a/U2GoXdx3q3adMJQPExsI4yDhdkWcoqJcui0+mIibnC5cuXiI6+bL5DvHz5ElevXkGv11s8NiAgkAEVK7HkwnncjEaea9eOCk+0LVZZyuRY76CgoHyr78XGxhIUFKRUOJIk2UF2djZXrkTflQQv/vPfy1y7dtXiQnMAVapUpVat2vn+1axZm1q1auEbF4t/h9aojEaynh9GldWrSE4rvUXMFEuUHTt2ZP369fTs2ZPIyEi8vb3L5PNJgIiINQAMH/6iwpFIUtmXkZGR744wOvrOneGNG9exNGGZSqWievUa1KxZm5o1a+VLiDVq1MTDw/IjAaOnF1kvjkKVmUn6gsX4aSxPmVYSNptm7a233uLXX38lKSmJSpUq8eabb2IwGAB47rnnEEIwe/ZsfvrpJ9zd3Xn//feLtLC8EtOs5Q1fVLrjuazilU3OWJbU1JR8VeO7/8XHW142WKPRUL16jfvuDGvVqkO1atVxc3MrXsB6Pbi45P6cl8pUqvIzzdqSJUsKfV+lUjFz5kxbXb5UDRs2QukQJMmuhBAkJSUWmAijoy9x+/Zti8e6urpSo0bNe6rHuf8efrgaLnmJ7QG5fbMFj48+JHnzTkRQEKhUpXLegpS7xhwlLF68TOkQJKnUCSGIj4+/q3p8kevXYzh//jyXL18mJSXZ4rHu7u75EuDd/6pUqYqmlKu+93L7egPe415HZTLhtusbske+atPryUQpSQ7MZDIRG3vTYjU5MzPD4rFeXt4FJsJatWoTFBSMyoZ3cIWp8GUEXm+9iUoIMiZPtXmSBJkoiyQ29iYAwcFVFI5Eku5nNBq5di3mvi410dG53Wyys7MtHuvv75+vetyoUUMCAx+iVq3aVK5cWbFkaEmFNavwnvwWAOnT3iNr7L/scl2ZKIugSZP6gPKNOZLz0uv15j6G9/6z1sewcuWAAu8Ka9ashb9/xXz7luWGKfeVy/GaNgWA9Nnvk/XqGLtdWybKIggKCra+kyQ9oOzsbK5ezUuGF/Mlw2vXYjAajRaPvbuP4d1da2rWrIW3t2NMOq2Ojwcgbf5isl8aZddry0RZBKdOnVc6BMlBPEgfw2rVqhfYgGKtj6GjyJg6k5xuPTA83tLu15aJUpJKWWpqyn3PC/P+xcXFWjzu7j6G+Ttc16F69RrF72NY3gmB+4pPyXmmL6YqVUGlUiRJgkyUklRs9/YxvHkzhnPnzpvvEG/dumXxWHv1MSz3hMBz9gw8Pl1KhQ3rSPruv3c6litAJsoiCAtrC8ChQ0cUjkSyFyEECQkJ5ueFd1eRi9bHsFaB1eSqVR+yeR/Dck8IPKdPwWPlZwitloy331E0SYJMlEUSFXVS6RAkG7i7j2FBVeWMjHSLx97dx7BBg3pUrVq9TPQxLPdMJrwmT8D9i9UIFxdSV0Wg6146U6U9CJkoi+DgwcNKhyCVkNFo5Pr1awUOw7PWx9DPz6+AKnKd+/oYluUuNeWK0YjXhLG4b1iHcHMjde2X6Dp1UToqQCbKImnatJnSIUiFyO1jePWe6nHuvytXokutj6FkW6779uQmSXd3UiI2om/XQemQzGSilMqFB+ljGBxcxWIydJQ+ho5A1zOcjIlT0Ldpi/6pNkqHk49MlEWwcOH7AEya9K7CkTi2jIyMeyZ1vdPP8Pr1a8XqY5jXvaZGjZp4enrauSRSkel0qJKSzLP/ZJbRvzGbzUdpK3I+yvL9LCwtLfWf/oTXOXPm7F0J8bJ5TH1BNBoN1apVL+DOUPk+ho7wveSxa1lycvAZORzN+b9I2bEPUynOpVBu5qN0JBMnTlE6hHKlsHkMi9rHMP8wvNpUq1Zd9jF0JFlZ+L44BNfvD2Hy90eVkABleNIZmSiLQFa587u/j+HlfA0pycnW+xjWrVuXhx/OP9O17GPoJDIy8B3+HK4//YipUiWSt+zC2Kix0lEVSiZKqUAmk4m4uFiL8xgW1sfQ09Or0HkM1Wq1Q1VXpaJTpafhM2Qgrr8cxRQQSPLWXRgbNFQ6LKtkoiyCyMgTgON1E8rrY2hpHsOsrCyLx/r6+lG7tvU+hpJklpOD78A+uPzvV4zBVUjZthvjI3WVjqpIZKIsgs6d2wHKN+aURGF9DK9evYJOp7N4bOXKlS1O9y/7GErF5uaGrm071LE3Sd66C1Ot2kpHVGQyURZBkyahSodQqJycnH/6GF68LxnGxFwtdh/D3HHKtfDx8bVjKSRnkDl5GlmvvIEoZ/+jlYmyCMrCZBiZmZnExFwkKurPYvcxfPjhavfNVCP7GEr2oIqPx3viWNI/WITpoYdBpSp3SRJkoixT0tJSLc5jWJI+hjVr1qZ69RpUqFDBjqWQpFzq2Jv49gtH+3fuxNepERsVjqjkZKK0s3v7GN6dGG/dSrB4nIuLi/ku8N5kKPsYSmWN+vo1fPv2Qnv5EoaGjUhb/LHSIT0QmSitcNu6iZQ3RvOQyYR4uFrudPT9BlrcXwjBrVu38o1JLmofwwoVKuSrIt/d6fqhhx6mUiVv2aVGKvPUV6/g1zcczdVo9CFNSdm8HVGxktJhPRCZKAvhtnUT3m+9iY/JlLvhWgzeb72JMAmutHnaYjU5PT3N4jmL0sdQksor9eVL+PULR3MtBn2z5qR8/Q3Cz1/psB5YufurjIw8YR57nWfo0IEEBvqwf/8+87aIiDUEBvowYcJY87bY2JsEBvoQElIv3/FhYW0JDPQx95eE3IkwEl8bieqevoSqrCyS3hhF06YNeOaZ7owf/wZLly5m585vOHUqkvT0NHx9/ahUqdI/5+7CsmWfsWvXAT75ZAUZGelUrVqV1asjmDZtFkOGDOfZZ3vQtGmDfEmyoDKtWvWfBy5TYKCPeZKPuz/PvFnc84SE1CMw0Cffs9EJE8YSGOhDRMQa87b9+/cRGOjD0KH577IDA33s9j0pXSZXV63Dlamk35PbgX20vBaDCjgyc445Sdq7TK6u+e8Bi1omS8pdorSn6oVsr1y5Mo8/3pIBAwbj6ekFwJdfbuKvv6L5+++r9OgRDkC3bj0ZPHgITzzxJL6+fvYJXJIUkvXKG5gergaA+OfvwhHI2YMKUbF5IzTXYu6PoepDJJ88W+zzPShHGvYny1I2laQsmjOnET4+mKpZurWwv9KePUjeURYiY+pMhLt7vm3C3Z2s6e8pFJEklS3aqJP49e2JX99eqAtZire8k4myEDn9BpK25GOiAROQGRBI2pKPC231liRnof39N3z7hqNOSsJQvwEmB360JBOlFTn9BtIyIAAN8Me23TJJShKgPfYLvgOeRZ2aQk7P3qT+33pw4IENsntQEeQtTlWpUmWFIykdKSnJjBv3OgCJibf/mfbMn9jYG1SuHMD69ZtL9XqrV6/A3d2D558fVuRjOnd+moMHf7pv+7x5s3jqqTZ06BBW5HOtW7eG3bt3oFarGT/+bZ54olWB5z158g9zw9zUqTOpW7c+QgiWLl3EL78cpUKFCrz77izq129Q5Gs7IpejP+E7ZCCqzAyy+/Qj7ZOViq+7bWsyUVqh1+tJTk5GpVLh71/++4NB7hRpa9duAPInsZs3bzBp0nirxxsMBrTa8vGrc/nyJQ4dOsC6dZu4dSuB8eNf56uvthU4QfDrr4+9LwEfO3aUmJgYNm78hjNnTrNo0Qf85z9f2Cv8MkcdcxXf5/ujysoie8Bg0pYuh3Lyu/AgHL+EDygx8TYAXl5eTjH7tslkYsGCuZw6FUVAQADz5y/Gza0CY8aMpm7d+kRFnSQsrCvNmj3GJ598RGZmJn5+frz77iwqV67M5s0b2bFjKxqNhpo1a/Heex8AEB19iTFjRhMXF8fAgc8xatRLAGzcuJ49e3YCEB7+LAMHPp8vHiEEH320kN9+O05gYDAuLsX7lf3vfw8TFtYFV1dXqlZ9iIcfrsbZs2do3LhJkY7/6afDdOvWA5VKRePGIaSnp3Hr1i0qV3aM2kVxmapVJ/PNf6G+FkP64mXgBH8TIBOlVXlrvKSlWR5t40iuXYth1qx5TJ48jenTp/Djj9/TtWsPIPfuevXqdRgMBsaMGc0HHyzG39+f7747wMqVn/LuuzNZv34tmzfvxNXVNd9ndvXqFZYt+5zMzEyef74fI0YM49y5s+zdu4uVK79ACMHo0SMIDW1OvXp3qrZHjvzA1atXWL9+M0lJiQwdOoCePXvfF/f27VsAePbZ/vm2JyTE06hRiPl1QEAgCQnxBZZ95crlrF27iscea8Grr76Jq6srt24lEBgYbN4nMDCIW7finS9R6nTg6gpA5oTJuducaHJmmSituH07N1E6SrXbmipVqlK3bn0A6tdvwM2bN8zvderUGYCrV6O5dOki//rXGwCYTEbz89s6deoye/Y0nn66PU8/3d58bKtWrXF1dcXV1RV/f39u375NVNRJ2rbtgPs/XbDatetAZOTJfIny5MkThIV1RaPRULlyAM2btygw7nsTZHG98soYKlWqhF6vZ+HCeXz55Re8+OKoBzqno3DdtQPPuTNJ2bIzt6+kEyXIPDJRWpGXKNu0aadwJPZx9yxEarUGozHH/DovoQkBtWrVZsWKNfcd/+GH/yYy8gRHjx4hIuL/+OKLjf+c1/Wu86oLnUy4NAUEBBIfH2d+nZAQT0BA4H375d0hurq60qNHOBs3rv9newDx8Xf6B8bHx1G58v3HOyq3bZvxfmM0KqMRtx3fkDVmnNIhKUJ2D7Iib+ozp6tqFaJ69RokJydx+nQUkNu4c+nSRUwmE/HxcTRv/jivvTaW9PT0Qtfdadq0GT/99CPZ2dlkZWVx5MgPNG2afzb50NBmfP/9QYxGI7du3eKPP/5XrFhbt27LoUMH0Ol03LhxnZiYGBo2bHTffnmPWIQQ/PTTYWrVqgPk/g/y22/3IoTg9OlTeHl5Oc3vgtvGL/F+fRQqo5GMtyaR9Yb1MdGOSt5RWpF3R+koXYNKg4uLC3PnLuDf/15Eeno6RqORgQOfo3r1GsyePZ2MjHSEEPTvPxhvb8vDwurXb0D37r0YNWo4kNuYc3e1G6Bt2w78/vtvDB06gKCgYBo3DinoVBafUdauXYeOHcMYOnQAGo2Gt96aZG6UmzhxLFOmTKdy5QBmz55GcnISQgjq1q3PxInvALmPDH755SiDBj37T/egmSX70MqZCuu/wGvCWFRCkDFlGplvTVI6JEXZdKz3kSNHmDdvHiaTiQEDBjB69Oh879+4cYPJkyeTlpaG0Whk4sSJtGtXeBXXnmO9ASZOHE9ExP8Byi8u5uxjissqRytL9pKleE+ZAED6jDnlsrpd2mO9bXZHaTQamT17NmvWrCEoKIj+/fvTsWNHHnnkEfM+n332Gd27d+f555/nwoULjB49mu+//95WIZVI3h2lJDkL1T/zqabPnU/W6NcVjqZssFmijIqKokaNGlSrljvlUs+ePfnuu+/yJUqVSkV6ejqQ2/0mMLDsPSTPe0a5bdtuhSORJPvIGvsW+rbtMYQ2VzqUMsNmjTlxcXEEB9/pfxYUFERcXFy+fcaMGcOuXcNziqIAACAASURBVLto27Yto0ePZtq0abYKp8Ty7igrVw5QOBJJshEhcF/xKeor0eZNMknmp2hjzp49e+jTpw8vvfQSJ06cYNKkSezevbvQ5RA0GhV+fh7Fuo5Goy72MXnyRubUrl2txOcoLQ9SjrJGlqWMEAL1zBlo5n+A59pViFOny29Z7lLa34nNEmVQUBCxsXf6n8XFxREUFJRvny1btrBq1SoAmjVrRk5ODklJSeZlFApiNAq7NeYYDAYSExMBePHFF/nyy9KdLKK4HK3RQJZFYULg+d50PJYvQ2g0pE2airvWpXyW5R7lZuLekJAQoqOjiYmJQafTsWfPHjp27JhvnypVqvDLL78AcPHiRXJycqhYsewsjp6XJAEOHtyvYCSSVMqEwHPa5NwkqdWSunItOX0ebHSTI7PZHaVWq2XGjBmMHDkSo9FIv379qFu3LkuXLqVx48Z06tSJKVOmMG3aNNauXYtKpWL+/PmoytDwqLyGnKpVH2LBgiUKRyNJpcRkwmvSW7hH/B/C1ZXU1evQde2udFRlmlwzpxA//XSYfv3CadWqNTt27LN+gI2V2ypeAWRZlOPy/UH8BvdDVKhAytov0XfsbH6vvJXFknLTj9IRyFE5kiPSd+xM+vTZGJqGom/bXulwygU51rsQeYny9u1b+dYTlqRyR69HfeO6+WXWm+NlkiwGmSgLkZCQ+4zyl1+OMnFi+RvGJUkA6HT4jBqBX8/OqK9eUTqacklWvQtx+3ZuH8oWLZ6gQYOGCkcjSSWQnY3Py8NwO7gfk68f6qRETNVrKB1VuSMTZSHyqt6jRr3Ks8/2UzgaSSqmrCx8X3gO1x+/x1SxIsmbd2IMKdoSGFJ+MlEWQjbmSOVWRga+wwbh+t8jmCoHkLx1F8aGjyodVbkln1EWIi9RCiGIjb2pcDSSVER6Pb7P9cP1v0cwBgWTvH2vTJIPSN5RFiKvw3n//rmLWSk9H6UkFYmLC7ou3dFcvULKtl0Yaz9i/RipUDJRWmA0GklKSgIgKCjYyt6SVLZkjRlH9rAXEL5+SofiEGTV24LExESEEPj7+3Pq1HlOnTqvdEiSZJHq1i18nu+P+vIl8zaZJEuPvKO0QDbkSOWFKi4OvwG90Z47i0qnJ2XLDqVDcjgyUVogE6VUHqhv3sC3XzjaC39jqN+AtE9XKB2SQ5KJ0oI7y9QGEBbWFoBDh44oGZIk5aO+FoNf315ooi9jaNiI5C07EQFyJn5bkInSgrx1nitVqsyePTsVjkaS8lNficavXziaq1fQhzQlZfN2REXLE15LD0YmSgvurJVTiYMHDyscjSTl53rkx9wk2fwxUjZuQ/j5Kx2SQ5OJ0oK7n1E2bdpM4WgkKb/sYSMQ7u7ounZHePsoHY7Dk4nSgryqt1x9USorNOfOgosWY526AOT0H6RwRM5D9qO04O47yoUL32fhwvcVjkhyZprTp/Dr0wPfvuGoY64qHY7TkYnSgrsT5aJF81m0aL7CEUnOSht5Ar++PVHfvo2x4aOYZC3H7mTV24I7jTmVmThxisLRSM5K+79f8R3cD3VqCjndepD6ny/AzU3psJyOTJQFMBqN5qVqK1asxKRJ7yockeSMtMd+wff5/qjT08jp9Qypn68GV1elw3JKsupdgKSkJEwmE35+fri4uCgdjuSE1HGx+A3uizo9jey+/UlduUYmSQXJO8oC3Dt8MTLyBIDsJiTZjSkomIwpU9GeOU3avz8FjUbpkJyaTJQFuDdRdu7cDpDzUUp2kJNjfgaZ9eoYEAJUKoWDkmTVuwD3JsomTUJp0iRUyZAkJ+C6dzcVn3oMzaULdzbKJFkmFDlRZmVl2TKOMiVvmdq8zuaHDh2RE2JINuW68xt8Rg5HE3MVt+3blA5HuofVRPnHH3/Qo0cPunfvDsC5c+eYNWuWreNS1N3jvCXJ1ty2fI3P6BdRGQxkjn2LzH+9rXRI0j2sJsoPPviA1atX4+eXO1tygwYN+N///mfzwJQk56KU7MXtq/V4vzEalclExsQpZEydKavbZVCRGnOqVKmS77Va7diPNm/fvg3cSZQhIfUA5HIQUqmqELEG74njAMh4dwaZ4ycqHJFkidVEWaVKFf744w9UKhV6vZ6IiAjq1Kljj9gUc+8dZVxcrJLhSI5KrwcgfdY8sl5/U+FgpMJYTZSzZs1i3rx5xMXF0bZtW1q3bs3MmTPtEZti7p7dHCAq6i8lw5EcVPbLo9G3fBJjSBOlQ5GssJooL1++zOLFi/Nt+/3333nsscdsFpTS7kyxlntHGRxcpbDdJanI3FcuR9chDGPd3Mc5MkmWD1YfNs6dO7dI2xyFyWQiKenOOG9JKhVC4LHwfbymTcF3wDOQkaF0RFIxWLyjPHHiBCdOnCAxMZE1a9aYt6enp2M0Gu0SnBKSk5MwGo34+Pji+s/Y2gkTxgKwePEyJUOTyish8Hx/Nh5LFyPU6tyWbU9PpaOSisFiotTr9WRmZmI0Gsm46/9+Xl5eLFvmuAkjr8U7r9oNsG7dWkAmSqkEhMBz5lQ8Pv8EodGQ9tkqcp7tp3RUUjFZTJQtW7akZcuW9OnTh4ceesieMSkqryHn7j6UixYtVSocqTwzmfCaOgn31SsRLi6krlyLrme40lFJJWC1Mcfd3Z0FCxZw4cIFcnJyzNsjIiJsGphS7l6mNs/w4S8qFY5Ujrkc+zk3Sbq6kvp/69B16a50SFIJWW3MmThxIrVr1+batWuMGTOGhx56iJCQEHvEpoi7ZzaXpAehf6oNaR8sIiVio0yS5ZzVRJmcnMyAAQPQarW0bNmSDz74gGPHjtkjNkUUNHxx//597N+/T6mQpPLEYEB99Yr5ZfbLo9F3DFMwIKk0WK16a7W5uwQGBvLjjz8SGBhISkqKzQNTyp3O5ncS5bBhucuCyvkopULp9Xi/NhLXX46SvH2vua+kVP5ZTZSvvfYaaWlpTJ48mTlz5pCRkcG77xZtDZkjR44wb948TCYTAwYMYPTo0ffts3fvXj755BNUKhUNGjS4r3O7vRV0R9mlSzelwpHKi5wcfEaNwO3bPZi8fVClJCsdkVSKrCbKDh06AODt7c26deuA3JE51hiNRmbPns2aNWsICgqif//+dOzYkUceecS8T3R0NCtXruSrr77C19fX3DVHSfdOiAGwfv0mpcKRyoPsbHxeHILboQOY/PxI2bQdQ2hzpaOSSpHFRGk0Gtm3bx9xcXE8/fTT1KtXjx9++IEVK1aQnZ3N9u3bCz1xVFQUNWrUoFq1agD07NmT7777Ll+i3LRpE0OGDMHX1xeASpWUHwlz7/BFSSpUZiaa54ficugQpooVSd68Uw5LdEAWE+XUqVO5efMmTZo0Ye7cuQQGBnL69GkmTpxIWJj1h9NxcXEEBwebXwcFBREVFZVvn+joaAAGDx6MyWRizJgxtG3btoRFKR13Wr3lIvOSFSYTvsMGof7pMKbKASRv3YWx4aNKRyXZgMVEefr0aXbu3IlarSYnJ4fWrVtz8OBB/P39S+3iRqORK1eusG7dOmJjYxk6dCi7du3Cx8fH4jEajQo/P49iXUejURfpGJPJZE6UtWtXw+2fRZ5cXXM/Jp3OUKzrlrailqM8cJSyqAcNRFz8G+O3B/Bu0EDpcB6Yo3wvpV0Oi4nSxcXFPEGvm5sb1apVK1aSDAoKIjb2zjyOcXFxBAUF3bdP06ZNcXFxoVq1atSsWZPo6GiaNLFcdTEaBcnJmUWOA8DPz6NIxyQlJWI0GvH29iEry0hWVv5jinvd0lbUcpQHDlOWgcPwG/wcySYtOEB5HOV7KUk5AgK8Lb5nsR/lpUuXCA8PN/+797U1ISEhREdHExMTg06nY8+ePXTs2DHfPmFhYfz6668AJCYmEh0dbX6mqYQ7DTn5n5XGx6fKrkESAKqkRHwH90Vz7uydjYXUgCTHYPGOcu/evQ92Yq2WGTNmMHLkSIxGI/369aNu3bosXbqUxo0b06lTJ55++mmOHj1Kjx490Gg0TJo0qVSr9sVV0PBFScqjunULv/690f55Gu/0dJJ37Zfr2zgJlRBCKB1Ecej1RptVvXfv3slLLw2lW7ceRERsLGmINuMo1SIof2VRxcXh1z8c7V/nMDxSl5StuzBVqQqUv7IUxlHKUtpV7yItLuYsLK2+OHToQED2p3RW6ps38O3bC+3FCxjqNyB5yy7EPc/bJccmE+VdLCXKAwe+VSIcqQxQX4vBr28vNNGXMTzamOQtOxGyj63TKVKizM7O5saNG9SuXdvW8SjKUqJct+5rJcKRygCX47+gib6MvkkoKZu+QcjlQZyS1UT5/fffs2DBAvR6Pd9//z1nz55l6dKlfP755/aIz64sTbHWtaucIstZ5fQbSIqLC/p2HRC+fkqHIynE6jRrn3zyCVu2bDF3Am/YsCHXr1+3eWBKSEiQrd4SaP4+j+bPM+bXut59ZJJ0ckWaZs3b23JrkCOxdEcZEZG7uJqc6dzxac7+iV+/cECQvPsAxtqPWD1GcnxWE+UjjzzCrl27MBqNREdHs27dOpo1a2aP2OzO0jPKiRPHATJROjrNqSj8BvRGnZiIrl0HjMFVlQ5JKiOsVr2nT5/OhQsXcHV1ZcKECXh5eTF16lR7xGZXQggSE++fYg1g2LARDBs2QoGoJHvRnvwDv369UCcmktO5KynrvgaP8j/mWSodVjucnzlzhkaNGtkrHqts1eE8JSWZunWr4+XlzaVLZfMZrKN0BoayVRbtb8fxHdwPdVoqOd17kfqftfDPmu5FUZbK8qAcpSx273A+f/58bt26RdeuXenRowf16jnm9PZ3lqmV3T+cier2bXOSzH6mL2nL/wMuLkqHJZUxVhPlunXrSEhIYN++fcyYMYOMjAy6d+/O66+/bo/47ObWrdxqd0ET9sbG3gQgOLiKXWOSbE9UqkTGrLm4/HKUtGWfgVaOwZDuZ/UZJUBAQADDhw/nvffeo0GDBixfvtzWcdmdpYYcgCZN6tOkSX17hyTZUlaW+cfsYSNI+3SlTJKSRVYT5cWLF/n4448JDw9n7ty5NGvWjMOHD9sjNrsqbGbzoKBggoKC79sulU+uB/ZR8YnQfH0l5SxAUmGs/i/03XffpXv37qxateq+iXcdyZ1nlPffUZ46dd7e4Ug24rpnFz6jR6DS63HbsZXMR8tOQ6VUdllNlF9/7RzjnAurekuOwW37VrxfG4nKaCTz1TFkTpmudEhSOWExUY4bN46lS5danM18165dNgtKCXcm7ZWt3o7IbdNXeI99DZXJROa4CWS8O0NWt6UiK3QVRsAhJ78oiKXhiwBhYbkrQx46dMSuMUmlo8KGdXj9awwqIch4+x0yJ06RSVIqFouNOYGBgQBs2LCBhx56KN+/DRs22C1Ae8lbL6egxpyoqJNERZ20d0hSKRH/LJKXPnUmmW+/I5OkVGxWn1H+/PPP9207cuQIb7/9tk0CUkphjTkHDzpeK78zyRk8BEOTUIyy4UYqIYuJcsOGDXz11VfExMTke06ZkZFB8+bN7RKcvQghCm3MadrUMScBcWQVVn2O/omnMIbkLn0sk6T0ICwmyvDwcNq2bcuSJUuYMGGCebunpyd+fo41N19aWip6vR4PD0/c3d2VDkd6QB4ffYjnB3MwVa5M4rETCB9fpUOSyjmLiVKlUvHwww8zY8aM+95LTk52qGSZ1+Jd0PNJgIUL3wdg0qR37RaTVAJC4LHwfTwXL0CoVKRPny2TpFQqLCbKCRMmsGLFCvr27YtKpeLuSYZUKhXfffedXQK0hzuJsuCuQYsWzQdkoizThMBz3nt4LFuCUKtJ+2QFOf0HKR2V5CAsJsoVK1YAuWvmODprnc0nTpxiz3Ck4hICzxnv4rHiU4RWS+rnq9H17qN0VJIDsdrq/fvvv9OwYUM8PDzYsWMHf/75Jy+88AJVqzrO7M/WEqW8kyzbtCd+x33lcoSLC6mrItB176l0SJKDsTopxqxZs3B3d+fcuXOsWbOG6tWrM2nSJHvEZjdy+GL5Zmj+OGlLl5P6xQaZJCWbsJootVotKpWKQ4cOMWTIEIYMGUJGRoY9YrMba405kZEniIw8Yc+QJGuMRtSXLppf5gwegi6sq4IBSY7MaqL09PRkxYoV7Ny5k/bt22MymTAYDPaIzW6szW7euXM7OnduZ8+QpMIYDHi/MQr/bh3QnIpSOhrJCVhNlB999BGurq68//77BAQEEBsby8svv2yP2OymsHHeAE2ahNKkSag9Q5Is0enwGf0iFbZtAYMRlYPVbqSyyWqiDAgIIDw8nLS0NH744Qfc3Nx49tln7RGb3eSN87b0jPLQoSNyQoyyICcHn5HDcdu9A5OPLymbt2N4spXSUUlOwGqi3Lt3LwMGDODbb79l37595p8diWzMKQeysvAZ8Txu3+7F5O9PytadGB5roXRUkpOw2j3o888/Z8uWLebnd4mJiYwYMYJu3brZPDh7sDbOWyoDhMB3xPO4/vAdpkqVSN68E2PjEKWjkpyI1TtKIUS+Rg4/Pz+sLAVerqSnp5GTk4OHhweenp4F7hMSUo+QEMdcprdcUKnI7j8IY1Awyd/slUlSsjurd5Rt2rTh5ZdfpmfP3P5pe/fupW3btjYPzF7uzGxu+W4yLi7WXuFIFuQMGExO917g5aV0KJITspooJ0+ezIEDB/j9998BGDRoEJ07d7Z5YPZyp9pteQmIqKi/7BWO9A9VchI+o18kY+pMDHnT3MkkKSnEYqKMjo5mwYIFxMTEUK9ePSZPnuyQqzAWNrN5nuDgKvYKRwJUibfxHfAsLqciUSUlkXzgRzkruaQoi88o3333XTp06MCyZcto1KgRc+bMsWdcdlPYzOaS/akSEvDr0wuXU5EYatUmde2XMklKirN4R5mRkcHAgQMBqF27Nn36OOZsLEVp8Z4wYSwAixcvs0tMzkodF4tvv3C05//CULceKVt3YZJ381IZYDFR5uTk8Oeff5pbuLOzs/O9btTIMabWL0pjzrp1awGZKG1JfeM6vn17ob10EUPDR0nevBPxzwJ3kqQ0i4kyICCADz74wPy6cuXK5tcqlYqIiAjbR2cH1oYvAixatNRe4Tgt7ckTaKIvo2/chJTNOxByfXWpDLGYKNetW2fPOBRTlEQ5fPiL9grHael69CJ17Qb0TzyJ8K+odDiSlI/VDucP4siRI3Tt2pXOnTuzcuVKi/vt37+f+vXrc+rUKVuGU6CiVL0l29Bc/Bvtid/Nr3XdesgkKZVJNkuURqOR2bNns2rVKvbs2cPu3bu5cOHCffulp6cTERFB06ZNbRVKoYrSmLN//z72799nr5Ccw59/4vtMD3wHPIvm7J9KRyNJhbJZooyKiqJGjRpUq1YNV1dXevbsWeCCZEuXLmXUqFG4ubnZKhSLijrOe9iwQQwbJheqKi2aM6fRdu6EJj4OQ5OmGKvXUDokSSpUkcZ679ixg08++QSAGzduEBVlfbLUuLg4goODza+DgoKIi4vLt8+ZM2eIjY2lffv2xQy7dGRkZJCdnY27u7vFcd4AXbp0o0sXx5gERGnaqJP49e2JKiEBXfuOpKzfBIV89pJUFlgdwjhr1izUajXHjh1jzJgxeHp68uabb7J169YHurDJZGL+/Pn5WtaLQqNR4efnUcxj1AUek5SUm7gDAgLw97f8x7p79+5iXc9WLJWjvFD99iua/r1RJScjevREtfFr/CpUUDqsB1bev5e7OUpZSrscVhNlVFQU33zzjXmyXl9fX/R6vdUTBwUFERt7ZzKJuLi4fEMgMzIyOH/+PMOHDwcgISGB1157jc8++4yQEMuzwxiNguTkTKvXv5ufn0eBx1y6dBUAf/9KxT6nEiyVozxQpaZQsVdPVMnJ5PQIR73pa5IzDZBdPstzt/L8vdzLUcpSknIEBHhbfM9qotRqtRiNRlT/DCNLTExErbb+aDMkJITo6GhiYmIICgpiz549LF682Py+t7c3x48fN78eNmwYkyZNKjRJlraiTIghlQ7h40v6B4twPbCPtI9X4OfqCpmOtfaS5LisJsphw4bxxhtvcPv2bT766CO+/fZbxo8fb/3EWi0zZsxg5MiRGI1G+vXrR926dVm6dCmNGzemU6dOpVKAB2FtCYg8gYE+AMTHp9o8JoeTmQkeuVWgnL4DyOnTX47dlsodq4myd+/eNGrUiGPHjiGEYPny5dSpU6dIJ2/Xrh3t2uVfvXDcuHEF7qtEB3dry9RKD8bl+4P4vPkaKeu/xtDssdyNMklK5ZDVRHnjxg3c3d3p0KFDvm1Vq1a1aWD2UNSZg+SdZPG57t+Hz8vDUOl0uO345k6ilKRyyGqifOWVV8w/5+TkcO3aNWrVqsWePXtsGpg9FGX4olR8rrt34jN6BCqDgcxRr5Ix0zGn6JOch9VEuWvXrnyvz5w5w4YNG2wWkD3JRcVKn9s3W/B+fRQqo5HM18fmJklZ3ZbKuWKPzGnUqFGROpyXB0W9oxw6dCBDhw60R0jlmtumr/B+bSQqo5GMf02USVJyGFbvKNesWWP+2WQy8eeffxLoIPMEFrXV+8ABx1rH3FZEhQqgUpExeSqZEyYrHY4klRqriTIjI8P8s0ajoV27dnTt2tWmQdlLXmOOtTvKdeu+tkc45Z6udx+S6jfEWL+B0qFIUqkqNFEajUYyMjKYPNnx7g4yMjLIysrCzc0NT8/CV/fr2rW7naIqfyqsXomhSVMMLZ4AkElSckgWE6XBYECr1fLHH3/YMx67ubshRyWfo5WI+8f/xmvODEy+fiQeOyFnJZcclsVEOWDAAL755hsaNGjAq6++Srdu3fDwuDPIvEuXLnYJ0FbuNORY72weEZH7nFbOdH6Hx+IFeC6Yh1CpyJg5RyZJyaFZfUap0+nw9/fPNy4byn+ivNPZ3Pof+MSJuaOJZKIEhMBjwVw8l3yIUKtJW7qcnEHPKx2VJNmUxUR5+/Zt1qxZQ926dVGpVObVFwGHqKoWtcUbYNiwETaOppwQAs/ZM/D4dClCoyHt05Xk9B2gdFSSZHMWE6XJZMrX4u1oirNWjlymNpfmzzO4r/gUodWSumINuvBnlA5Jkuyi0OVqx4wZY89Y7CrvGWVAgJwQo6iMjRqT+vlqcHVD162H0uFIkt1YTJR3V7UdUXGGL8bG3gQgOLiKTWMqk4xGNJcuYqxbD8jtKylJzsbiEMa1a9faMQz7K+rMQQBNmtSnSZP6tg6p7DEY8B77Gn5d2qP97bj1/SXJQVm8o/Tz87NnHHZXnNnNg4KCre7jcPR6vN8YRYXt2xAenqh0OqUjkiTFWO0e5KiK0+p96tR5W4dTtuh0+Ix+Ebe9uzB5eZPy1VYMTzypdFSSpBinTZR5rd6yMeceOTn4vDwMtwPfYvLxJeXrbRgea6F0VJKkKKdMlJmZmWRmZuDq6oqXl+WV15yOEPiMeiE3Sfr7k7J5B4YmoUpHJUmKK/Z8lI6guOO8w8LaEhbW1tZhKU+lInvQEIxBwSRv3S2TpCT9wynvKIs7s3lU1ElbhqM8IcwT7Op6hpPYoZN55URJkpz8jrKoa+UcPHiYgwcP2zIkxahSU/Ad+CzaY7/c2SiTpCTl45R3lMUZvgjQtGkzW4ajGFVyEr6D+uBy4g/U8XEkfX8UNBqlw5KkMsepE6Uzr76oun0b34HP4nIqEmP1mqSs3ySTpCRZ4JSJsrjPKBcufB+ASZPetVlM9qRKSMCvf2+0Z89gqF2HlG27MVV9SOmwJKnMcupnlEVNlIsWzWfRovm2DMlu1HGx+PXpkZsk69UnZcc+mSQlyQqnvqMsyuzmABMnTrFlOHal+fMMmksXMTRsRPKWnQjZ4V6SrHLqRFnUO0pHqXID6Dt0IuXLzRiahMrlGySpiJyy6p2QkHdH6RyJQn35Ei7Hfja/1nfoJJOkJBWDUybK4t5RRkaeIDLyhC1DshnNhb/xe6Y7voP7oS2nZZAkpTld1Ts7O5uMjHRcXFzw8fEt0jGdO7cDID4+1ZahlTrNX+fw69sLdUI8ulatMdZ5ROmQJKlccrpEWZL1vJuUwzHPmjOn8RvQG/WtW+iebkdKxEbw9FQ6LEkql5wuURZnZvM8hw4dsVU4NqGNOonvgGdQJyWh6xhGypovwd1d6bAkqdxyumeUxX0+We5kZOD7XH/USUnkdO1OyhdfySQpSQ/I6RLlneGLDtrq6+lJ2uJlZPfpR+rqdeDmpnREklTuOV3VO28JiKJ2NgcICcldgbBMLwmRng5eXgDouvWQy8lKUilyujvKklS94+JiiYuLtVVID8zl8A9UahGCyy9HlQ5FkhyS091RlqQxJyrqL1uF88BcvzuAz4ghqHJycN21HX2r1kqHJEkOx+kSZUnuKIODq9gqnAfi+u1efEYOR6XTkTXiZTLmLlA6JElySE5X9b7TmFO+J4Nw3bUdn5eGotLpyHzlddIXLAG1032dkmQXNv3LOnLkCF27dqVz586sXLnyvvfXrFlDjx49CA8P54UXXuD69eu2DAe4e+agord6T5gwlgkTxtoqpGJz27YZn9EvojIYyHzzX2TM/sC85o0kSaXPZonSaDQye/ZsVq1axZ49e9i9ezcXLlzIt0/Dhg3ZunUru3btomvXrnz44Ye2Cscsr9W7OFXvdevWsm7dWhtFVHzCxwfUajImTCZj2iyZJCXJxmz2jDIqKooaNWpQrVo1AHr27Ml3333HI4/cGW/85JNPmn8ODQ1l586dtgoHgJycHNLSUtFqtfj6+hX5uEWLltowquLThXUl6cgxjHXqKh2KJDkFmyXKuLg4goODza+DgoKIioqyuP+WLVto29a2a2fnVbsrVqxU5HHeAMOHv2irkIqswppVqJo2guatAGSSlCQ7KhOt3jt27OD06dOsX7/e6r4ajQo/v+Itp6rRqPHz8+Dy5XQgN2kX9xxKUv/7IzST30Z4l2ZhXAAAIABJREFUeOB39i+oUjZb4Ysj7ztxBLIsZU9pl8NmiTIoKIjY2DudtOPi4ggKCrpvv59//pnPP/+c9evX4+rqavW8RqMgOTmzWLH4+XmQnJxJdPS1f15XLNY59u/fB0DXrt2Ldd3S4L50MV7z3gPAtGAhye6+UMzyl0V534kjkGUpe0pSjoAAb4vv2SxRhoSEEB0dTUxMDEFBQezZs4fFixfn2+fPP/9kxowZrFq1ikp2mHE7r7N5ccd5Dxs2CLDzfJRC4LFoPp4ffoBQqUhf8jEVXnnVIZKkJJU3NkuUWq2WGTNmMHLkSIxGI/369aNu3bosXbqUxo0b06lTJxYuXEhmZibjxo0DoEqVKnz++ee2CqnEMwd16dLNFuFYJgQeH8zB89+LEGo1acs+I2fgc1SwbxSSJP3Dps8o27VrR7t27fJty0uKAGvXrrXl5e9TkgkxANav32SLcCzSXLyAx/JlCI2GtOX/IadPf7teX5Kk/MpEY469lJe5KI2P1CV17ZeQlY0u/Bmlw5Ekp+dUiTJv+GKZTJQmE5q/zmFs+CiQ21dSkqSywakGB99pzCleogwM9CEw0McWIeUyGvF66038u7bH5afDtruOJEkl4lSJskxWvQ0GvN98FfcN63KHIppMSkckSdI9nKrqfacxp3iJ0mbdgvR6vF8fRYUd2xAenqRs2Iz+qTa2uZYkSSXmNIlSp9ORmpqCRqMp1jhvGwaEz+gXcdu7C5O3DylfbcXQ8gmlo5IkqQBOkyjvHuetLgPzNnq/MTo3Sfr6kbLpGwzNHlM6JEmSLFA+Y9jJnQl7i/98cujQgQwdOrBU48l+bijG4CqkbNslk6QklXFOd0dZkpnNDxz4tnSCEMI8d6S+YxiJx0/KNbclqRxwukRZkjHl69Z9/cDXV6Wn4fPiUDLfGIe+fcfcjTJJSlK54ISJsvhV7wedNUiVkozv4H64/P4b6pirJP33N9A6zUcvSeWe0/y1KjUqR5WUiO/APrhEnsBYrTopG7fJJClJ5YzT/MU+yB1lRMQaoPgznatu3cJvwDNoz5zCWKMmydt2Y6pWvdjXlyRJWU6TKB9kmdqJE3NnPCpOolTFxeE3oDfac2cx1HmElG27MVWpWuxrS5KkPKdJlHdavYt/Rzls2IhiH6O9fBFN9GUM9RuQvGUXooDZ3SVJKh+cLlGWpOq9ePGyYh+jf/IpUjZuw1CvAaIEyVmSpLLD6Tqc27IxR30lGpcfvze/1j/VRiZJSXIATpEo9Xo9KSnJqNVq/P39i318bOxNYmNvFrqP+tJF/J7tge+wQWiPHytpqJIklUFOUfXOu5ss6TjvJk3qA5ZnEdL8fR7fvr3QxMWib/EExkcfLXmwkiSVOU6RKBMSSjZhb56goGCL72nO/olf/96oE+LRPdWGlPWbwMurRNdxRkajgaSkBAwGndKhlFhcnAohhNJhlApHKUth5dBqXfH3D0CjKXr6c5JEGQ+U/PnkqVPnC9yuOX0KvwG9Ud++ja5tB1IivgKP8r94vD0lJSVQoYIHnp7BqP4ZB1/eaDRqjEbHmHDZUcpiqRxCCDIyUklKSqBy5SpFPp9TPKNMSLBBQ05ODr5DB6K+fZucTp1JWf+1TJIlYDDo8PT0KbdJUipfVCoVnp4+xa7BOEWiLOlaOYVycyNt2WdkP9OX1LUboIJcdbukZJKU7Kkkv29OUvXOTZQlvaMMC2sLwKFDR1ClpSK8cxca07dtj75t+1KJUVJO27YtqV37EYxGA1WqPMT06bPx9vYG4NKli/z73x+SkBCPEIJu3Xrywgsvm//YfvnlKKtXf052djYuLi40b96CN9/8l5LFuc/58+fYunUT77wzQ+lQCqTT6Zg7dyZ//XUWHx9fZs/+gCoFjGLbtOkrdu36BiGgd+9nGTjweQBSU1OYMeMdYmNvEhxchdmz5+Pv78fRoz9x9uwZRo589YFjdJI7ygerekdFnSQq6iQu/z1CxcdDcPn+YGmGJynMzc2NtWs3sG7dJnx8fNi2bRMAOTnZTJnyFkOHjuCrr7axdu1XnDoVxbZtmwG4dOkCH320kJkz57J+/WZWrVrHww9XK9XYDAbDA58jImIN/fsPtus1i2P37h14e3vz9dfbGTToeT777OP79rl06QK7dn3Df/4Twdq1Gzh69L9cuxYDwPr1a3nssZZs3PgNjz3WkvXr1wLw1FNtOHr0CNnZ2Q8co1Mkyvj43Mackla9Dx48zA8fLML3+f6ok5Jw27O7NMOTypDGjUPMNZCDB78lJKQpLVs+CUCFChV4661JfPnlFwB8+WUEw4e/RM2atQDQaDT06dP/vnNmZmby/vvvMXz4IF54YTA//vgdAJ07P23e54cfDjFv3iwA5s2bxYcfvs+oUS/w2WfL6N8/nLS0NPO+gwf3ITHxNklJSUyd+vb/t3fncVFWbQPHf7Mgmxu4aya4pJIWlKS+qCWIuQwgCu6CJq5RoRZqamlPam4plSK+kpZaVmb6qiiFPCL6WGSPhWKpFbiDooQwKMvMef+YGCWWGRAE8Xw/H/8Y5tznvs4wXJ57uw5BQQEEBQWQmPhzCfvW8scf5+jQ4QkATp8+xZQpE5gwYTRTp77EhQspAERF7WH27BkEB08mJGQ6t2/fZsmSRUyaFMCECaOJjz8EwNWrV5g+PYiXXhrDSy+N4eTJXyr6URsdORLHwIEaAF54wYOffkoodsU6JSUFJ6cuWFlZoVarcXF5hrg4w8Md8fF3tx84UGOMVaFQ4OLyLEePxt93jI/Eoffdc5TlL4gB4Hr9GvUXzkORm8vtcePJXrG6MsOT/jZ6tB8xMd9Wap/9+vXns892mNVWp9Nx/PiPaDQ+ACQn/0nHjp2LtGnV6jFycnLQarNJTv6DkSPHmux38+aN2NrW5dNPDQWgb90yvarn9evXWL/+Y1QqFTqdnsOH/83gwd4kJZ2iWbMW2Ns3YuHCeQwfPoann3YmNTWVWbOC2bat6Fh/++1X2rZtZ3zdpo0Da9f+L2q1mh9//IGIiLUsXrwCgLNnz7BlyxfUrVuPiIi1PPusK2+++TZZWVlMmhRIt27dsbOzZ/XqtVhaWnLx4gUWLpxHZOSWYvFPnx5ETk5OsZ+//PJruLoWXUTv+vVrNG1qqIWgVquxta1LZmYmDRveXQSwbdt2bNiwjszMv7C0tOLYsaN06mT43WRk3DROgho1akRGxk3jdp06OZGYeAIPD0+Tn3lZHolEeT9Xvevs30f9oAAU+fncfmkS2UtWQA1YnEyqPLm5uYwfP5r09Gu0aeNY7A/5fh0/nsCiRUuMr+vXr29ym759+6FSqQDw8PBk06aNDB7szcGD0cY/+uPHE0hJSTZuo9VqycnJweaeuy/S09Np2PDu02jZ2dm8++5CLl26gEKhKHKY7eranQYNGqDT6UlI+J4jR+L4/POtAOTl5ZKWlkrjxk1YvXoZ586dRalUcfHi+RLjX7duo+kPphwcHBwZOzaAGTOCsba2pkOHJ1AqVcXaGc4d371YY2dnZ5wo3Y9HIlEWflDlTZR19uym/pQJLCooIP9ZV0KWrjSueSNVPnNnfpWt8BzlnTt3mDkzmJ07v8LffyQODm35+ef/Fml7+fIlbGxssLWti6NjW86c+ZVOnTpVcM93v0t5eUVvV7G65y6KLl2e4vLli2RkZBAfH0dg4EQAhNATEbEJS0vLMsd2b98bN67nmWe6sXTpSq5evcIrr0wpcZ9CCBYvXs7jjzsU6S8yMgI7u0Zs3vw5er0eDw+3EvdbnhllkyZNuXYtjaZNm1FQUIBWm02DBg2KbavRDEGjGQJARMRamjRpCoCdnT3p6ek0btyY9PT0Io8p5+bmYWl5/3ek1PqpUX5+Pjdv3kShUJT7OW9hbw8WFiwClvz0o0yStZyVlRUhIa+zfftWCgoK6N9/AImJv/Djjz8Ahos7YWErGT16HACjRgWwZcsmLlwwzKr0ej27dhVP9q6u3Y0XgODuobe9vT0pKcno9YZD69IoFAr69OnLRx+9T5s2DsZ16V1de/D113fXczp37kyxbR0cHI0XPcAwo2zSxHAKKipqT6n77N69Jzt2fGE8V3j27G8AaLXZNGrUGKVSSXR0FDqdrsTt163byObNnxX7V9Js3c2tD/v3G877Hzp0kGeecS3xFp7CQ+rU1FTi4mLx9BwAQK9ezxu3379/L717P2/c5uLFCzg6tivWV3nV+kR586bhw7W3tzceypgr3603Nw8d4/XX5/D663OqIjyphnniiU60a9eBmJhoLC2teO+9VXzySSSjRg0lIGAknTo5MWzYCADat+/Aq6/O4q235jJmjB8BASO4cuVysT4DAyeSlXWLceOGExg4ihMnjgMwdWowoaEhTJ36ksmjHQ8PT6Kj9+Ph0d/4s5CQN/jtt18JDBzJ2LH+7Nr1dbHt2rRxQKvNJidHC8CYMQGsX7+WCRNGl5rkAMaPn0hBQcHffQ9n48b1APj6+nPgwF4CA0dx/nwK1pWwQJ5G40NmZiYjRgzhiy+2MXVqMGA4Enz99VeN7ebNC2XsWH9mz57BzJmzjbdwjR0byPHjPzBypC/Hjycwdux44zYnThznf/6n133HqBAP2YOd+fk6/vqr+JS+NKdPJ/HCCz3p2LET8fEJJttbbdmMvmkz8u5zQbGq0LChTbnGXpMVjiU19TzNm7ep7nDuS01/7O+LL7ZhY2OLl9cQk21r+ljMpVIpuX79OosWzScsLLzY+yV975o0qVdqf7V+Rlmegr1WkRHUm/Uq9SeOQ3nxQlWHJkkPxJAhflhYWFR3GA9cWloqwcEhldJXrb+YY26itF73IXUXzgNA+/a/iiwC9ssvJwB4+mmXKopSkqqOpaUlAwYMru4wHrjOnZ+stL5qfaK8e8W7UaltrMNWUXfxIgCyVqzhTuBLRd739DScHC6tHqUkSbXbI5Aoy1h9UQhsVr6H7YqlCIWCrDVryR1V/Abip55yruowJUmqwWp9orxx4wZQ8qG38tJFbNZ+gFAqyfpwPbn+JT8PGxNzuEpjlCSpZnsEEmXpy9TqWz9O5rYvUaZfJ9dn6IMOTZKkh8QjkyiNM0ohUJ06ia7rU4DhXknp0VZWmbX7ERW1h99+O83MmbMrIUqpOtX624OKPL6o11P39RDsBvSlzrf7ze6ja9cn6Nr1iaoKUapmpZVZk6RCj8yMsrGdPfVCXsZq+zaElRXCoo7ZfaSlpVZVeFIN06VLV37//XfAUJIsLGwVeXm5WFpa8eabb/H44w5ERe3hyBFDncMrVy7x/PN9mTbN8ATJvn3/x5Ytm6lXry7t2z9hvH/x6tUrLF36DpmZf9GwoR1z575N8+bNWbx4IZaWlpw9e4aMjAzmzl3AgQP7SEo6iZNTF+bNW1gsxmPHjvDhh6uxsrLmqaee5sqVyyxfvobIyAisrW2Mj1iOGzec5cvX0KJFS6Kjo9ixYzv5+QU4OT3JrFmGJ83ee+9f/PbbaRQKBYMHezN69Di++mo7u3d/jUqlwsHBkUWLlj6AT75mq9JEefjwYRYvXoxer8ff35/JkycXeT8vL4/Q0FCSkpJo2LAhq1ev5rHHHqu0/et0OjIyMlADjm+/idU3OxA2NmRu+YL8e54HNSUxsfgztFLVaNK09Mo6WSvDuBMwAQCrTzdR7/XXSm17vQK3cv2zzFpZJcnOnTvLpk3bsLCwYMyYYQwdOhyVSk1kZASRkVupW7cur746hQ4dDEsdr169goEDNQwcqGHv3t2Eha1g6dJVhnFl3SIiYhNHjsQxZ84swsMjcXRsS1BQAOfOnTH2AYZKRytWLOWjjzbQsmUr3n77TZPjSklJ5uDB7wgP/xi1Ws3Kle/x7bf7cXRsx/Xr19iy5cu/4zDUvNy6dTNfffV/1KlTp0gdzEdZlR1663Q63nnnHTZu3Mi+ffvYu3ev8X/qQl999RX169fnu+++Y/z48axcubJSY7h58yYqIfiqTh2sv9mB3rYumdt3litJAjRv3oLmzc1fsU16uBSWWfPxeZGMjJvGwg3Z2dksWDCHceOG8+GH75Oc/Kdxm27dXKlbty6WlpY4OLQlNTWV06dP4eLyLHZ2dlhYWODufve57KSkRGMRhwEDBhcpsuvm1geFQkHbtu2xt7enXbv2KJVKHB3bcvXq1SKxXriQQsuWrWjZshUAnp4vmhzfTz8lcObMrwQFBTB+/Gh++imBK1cu07JlK65cuczq1cv5/vv/YGtrC0C7dh145535REdHlbs+Qm1VZTPKxMRE2rRpQ+vWhtL4gwcP5uDBg7Rv397YJjY2luBgwwPwL774Iu+88w5CiEpbbCo9/TofA0Py8tDXb0Dm9q8p6PZcpfQtVQ1zZ4J3AiYYZ5f3q7Qya2WVJLv3kUClUolOV/HlEwr7UiqV99WvSqVCiLvPaReWVxNCMHCgxlhs4l6bN39OQsIxdu/+mtjY71iwYBErVqzhl19OcPToYT799GM++WQ7anWtP0tXpiobfVpaGs2bNze+btasGYmJicXatGhhmKmp1Wrq1atHRkYG9vb2pfarUilo2NC8ZWHr1bNiAzDAygq76GjqPtut/AMBpk0zLE4UHr6+QttXFpVKafbYa7rCsaSlKVCpqv+aokqlxNbWhpkzQ5kzZyZ+fsPRarU0a9YMlUrJgQN7je2USgUKRdG4VSolXbt25YMPVpKdfQtbW1sOHYqhffsn/n7vaWJjv2XgQA0HDhzg6aefQaVSolAoUCqVqFRK4+vCfu99r5CDgyNXrlzm2rVUWrRoSWxsjHH/rVq14ujReFQqJWfO/MrVq1dQqZQ891wPQkNnMGrUWOzt7cnMzCQnR4u1tTUWFhZ4eHj+fS5yPnq9nhs3ruPq+hwuLi4cPPjt3+dozT+nX1OU9b1SKMzPI/AQXszR6YTZFXRatXJk0iefk/ns09D0Mahg5Z3ISEO15qVL36/Q9pWlNlYPEkLUiGo1hTG0b/8Ebdt2IDp6P6NHj+PddxeyadP/0rNnL2M7vV4Ui1un02Nn14gJEyYTFDT+74s5HY3tQkLeYMmSRWzb9qnxYo5Op0cIgV6vR6fTG18X9nvve4UsLOowc+ZsQkJexsrKms6dnYzb9OnTl6iovYwa5YeT05O0bv04Op2exx93YNKkabz22nSE0KNSqZk5czaWlpYsXboIvd5QQGzKlJfR63W8/fY8tNpshBAMGzYSGxvbGvE7Kg9TVZCEKJ5HyqoeVGVl1k6cOMFHH31EZGQkABEREQBMmXL38GXixIkEBwfj4uJCQUEBbm5ufP/992Ueepe3zBrcf4L59NNNAARU0qFeRdXGRCnLrJVf4XIPQghWrVpG69atGTFiTKX0XZvKrJU1jvKWWauyGWXXrl1JSUnh4sWLNGvWjH379rFq1aoibdzd3fnmm29wcXEhOjqaHj16VNr5ycpU3QlSku61Z8837N+/j4KCfDp06IiPz7DqDqnWq7JEqVareeuttwgKCkKn0zFs2DA6dOhAWFgYXbp0wcPDAz8/P9544w08PT1p0KABq1fL1Q0lyZQRI8ZU2gxSMk+tr3AO93/IGh1teIrnxWquei4PvWum2nK4CrVnLA/NoXdtMm6cYY0UWY+yalTmLWGSZEpF5oYyUZqhf/8B1R1CraVW10GrvYWtbX2ZLKUqJ4RAq72FWl2+251kojTD1q2ySEJVsbNrQkbGdbKz/6ruUCpMoVBUaJZSE9WWsZQ1DrW6DnZ2JRTyLoNMlFK1UqnUNG78cD8eWhvPHT/sKnsc1f9IhCRJUg0nE6UZmjatT9MyqtpIklS7yUQpSZJkwkN3H6UkSdKDJmeUkiRJJshEKUmSZIJMlJIkSSbIRClJkmSCTJSSJEkmyEQpSZJkQq1KlIcPH+bFF1/E09OTDRs2FHs/Ly+PkJAQPD098ff359KlS9UQpWmmxrFp0yYGDRqEl5cXgYGBXL58uRqiNI+psRSKjo6mY8eOnDx58gFGVz7mjCUqKopBgwYxePBgZs2a9YAjNI+pcVy5coVx48YxZMgQvLy8iIuLq4YozTN37lx69uyJRqMp8X0hBO+++y6enp54eXmRlJRUsR2JWqKgoEB4eHiICxcuiNzcXOHl5SXOnTtXpM3WrVvFggULhBBC7N27V7z22mvVEWqZzBnHsWPHRE5OjhBCiG3bttXIcQhh3liEECIrK0uMHj1a+Pv7i8TExGqI1DRzxpKcnCx8fHzEX3/9JYQQIj09vTpCLZM545g/f77Ytm2bEEKIc+fOib59+1ZHqGZJSEgQp06dEoMHDy7x/UOHDomJEycKvV4vTpw4Ifz8/Cq0n1ozo7x3edw6deoYl8e9V2xsLL6+voBhedxjx47VuEop5oyjR48eWFtbA+Ds7Exqamp1hGqSOWMBCAsLY9KkSVhaWlZDlOYxZyxffvklY8aMoUGDBgA0atSoOkItkznjUCgUZGdnA5CVlUXTpk2rI1SzuLq6Gj/vkhw8eJAhQ4agUChwdnbm1q1bXLt2rdz7qTWJsqTlcdPS0oq1KWl53JrEnHHca8eOHfTp0+dBhFZu5owlKSmJ1NRUXnjhhQccXfmYM5aUlBSSk5MZOXIkw4cP5/Dhww86TJPMGUdwcDB79uyhT58+TJ48mfnz5z/oMCvNP8fbvHnzMv+eSlNrEuWjaPfu3Zw6dYqgoKDqDqVC9Ho97733HrNnz67uUCqFTqfj/PnzbNmyhVWrVrFgwQJu3Xr4quLv27cPX19fDh8+zIYNGwgNDUWvf/iXh7gftSZRNmvWrMghaFpaGs2aNSvW5urVqwAUFBSQlZWFnZ3dA43TFHPGAfCf//yH9evXEx4eTp06NXNxelNj0Wq1nD17loCAANzd3fn555+ZNm1ajbygY+73y93dHQsLC1q3bo2DgwMpKSkPONKymTOOHTt2MHCgYX0oFxcXcnNza9yRl7n+Od7U1NQS/55MqTWJ8t7lcfPy8ti3bx/u7u5F2hQujwvU2OVxzRnH6dOneeuttwgPD6+R58EKmRpLvXr1+OGHH4iNjSU2NhZnZ2fCw8Pp2rVrNUZdMnN+L/369SMhIQGAmzdvkpKSQuvWrasj3FKZM44WLVpw7NgxAP744w9yc3Oxt7evjnDvm7u7O7t27UIIwc8//0y9evUqds614tebap5Dhw6J/v37Cw8PD7Fu3TohhBBr1qwRMTExQggh7ty5I1555RXRr18/MWzYMHHhwoXqDLdUpsYRGBgoevbsKby9vYW3t7eYMmVKdYZbJlNjudfYsWNr7FVvIUyPRa/XiyVLloiBAwcKjUYj9u7dW53hlsrUOM6dOydGjBghvLy8hLe3t4iPj6/OcMs0Y8YM4ebmJpycnETv3r3Fl19+KT777DPx2WefCSEMv5OFCxcKDw8PodFoKvz9kmXWJEmSTKg1h96SJElVRSZKSZIkE2SilCRJMkEmSkmSJBNkopQkSTJBJkrJLJ07d8bHx8f4r6zKSy4uLve9vzlz5uDu7o6Pjw++vr6cOHGi3H3MmzeP33//HYD169cXeW/kyJH3HSPc/Vw0Gg1Tp041+STOr7/+WqOr8UilqLw7mqTazNnZuUralmb27Nli//79Qggh4uPjhUajua/+KiMmU/2GhoYa70sszddffy0WLVpUJbFIVUfOKKUK0Wq1BAYG4uvri5eXFzExMcXaXLt2jTFjxhhnXMePHwfgyJEjjBgxAl9fX1599VW0Wm2Z+3J1deXChQuAoRanRqNBo9GwefNmAHJycpg8eTLe3t5oNBqioqIAGDduHCdPnmTlypXcuXMHHx8fY43IwlnvjBkzOHTokHFfc+bM4cCBA+h0OpYtW8awYcPw8vJi+/btJj8TZ2dnY8GFxMRERowYwZAhQxg5ciR//vkneXl5fPDBB0RFReHj40NUVBQ5OTnMnTsXPz8/hgwZUuLnKNUA1Z2ppYdDp06djE8CTZ8+XeTn54usrCwhhBA3btwQ/fr1E3q9Xghxd5YVGRlpnGEVFBSIrKwscePGDTF69Gih1WqFEEJERESIDz/8sNj+7p1RRkVFCT8/P3Hy5Emh0WiEVqsV2dnZYtCgQSIpKUkcOHBAzJs3z7jtrVu3hBBFn/T554yy8PW3334rQkNDhRBC5Obmij59+ojbt2+L7du3i7Vr1xp/7uvrW+KTXIX9FBQUiFdeeUXExcUJIQw1NvPz84UQQhw9elQEBwcLIYrPKFetWiV27dolhBAiMzNT9O/f3/jZSDWHuroTtfRwsLKyYvfu3cbX+fn5vP/++/z4448olUrS0tJIT0+nSZMmxjZdu3blzTffpKCggH79+tG5c2f+/e9/8/vvvzNq1ChjP87OziXuc/ny5YSHh2Nvb8/ixYs5duwY/fr1w8bGBgBPT0+OHz9O7969WbZsGStWrKBv375069bN7HH16dOHxYsXk5eXx+HDh+nWrRtWVlYcPXqUM2fOEB0dDRjqMp4/f77Ys9uFM9W0tDTatWuHm5ubsf3s2bM5f/48CoWC/Pz8Evd/5MgRYmNj+fjjjwHIzc3l6tWrtGvXzuwxSFVPJkqpQvbs2cPNmzfZuXMnFhYWuLu7k5ubW6SNq6srW7duJS4ujjlz5jBhwgTq16+Pm5sb77//vsl9hIaGMmDAAOPrwkIN/+To6MjOnTuJi4tjzZo19OjRg+DgYLPGYWlpyXPPPUd8fDz79+9n0KBBgGEJgfnz59O7d+8yty/8D+T27dtMnDiRbdu2ERAQQFhYGN27d2ft2rVcunSJgICAUvv44IMPaNu2rVnxStVDnqOUKiQrK4tGjRphYWHB999/X+K6PZcvX6Zx48YMHz4cf39/kpKScHZ25r///S/nz58HDOcXk5OTzdpnt27diImJ4fbt2+Tk5BATE0O3bt1IS0vD2toaHx8fJk6cyOnTp4ttq1arS53VDRo0iJ0H1bf1AAABWUlEQVQ7dxpnpwC9evXi888/N26TnJxMTk5OqbFZW1szf/58Nm3aZCzhV1jOq7BiFYCtrW2Rc7K9evVi69atxkr7JcUuVT85o5QqxMvLi2nTpuHl5UWXLl1KnBElJCQQGRmJWq3GxsaGZcuWYW9vz9KlS5k5cyZ5eXkAhISE4OjoaHKfTz75JEOHDsXf3x8APz8/nJyciI+PZ/ny5SiVStRqNQsXLiy27fDhw/H29sbJyYlVq1YVec/NzY3Q0FA8PDyMtT39/f25fPkyQ4cORQiBnZ0d69atKzM+JycnOnbsyN69ewkKCmLOnDmEh4fz/PPPG9t0796dDRs24OPjw5QpU5g+fTpLlizB29sbvV7PY489RkREhMnPQnqwZPUgSZIkE+ShtyRJkgkyUUqSJJkgE6UkSZIJMlFKkiSZIBOlJEmSCTJRSpIkmSATpSRJkgkyUUqSJJnw/+u53QHQ5p4cAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from plot_metric.functions import BinaryClassification\n",
        "# Visualisation with plot_metric\n",
        "y_true = valid_data.classes\n",
        "y_probas = y_pred\n",
        "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
        "\n",
        "# Figures\n",
        "plt.figure(figsize=(5,5))\n",
        "bc.plot_roc_curve()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FrD-fa4Fql_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "EfficientNetV1+BAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}