{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZmUeX0KMRRE",
        "outputId": "88737892-b65a-48ee-9ec0-f0e85c9fef9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "pip install keras_applications "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YxwC4ylMh4G",
        "outputId": "38b338c4-721d-4de3-91e0-6a54d07e31dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7k4kFe31MptM"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, MaxPool2D\n",
        "from keras.layers.core import Lambda\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models, losses\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import *\n",
        "#from keras.utils import multi_gpu_model\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import load_model\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Lambda\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.inception_v3 import InceptionV3 \n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from keras.applications.resnet50 import ResNet50\n",
        "from keras_applications.resnet import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "import os\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "axHjDrWRMr2D"
      },
      "outputs": [],
      "source": [
        "#iDAAM\n",
        "\n",
        "def self_attention(input_feature, num_channel, base = 'self_attention_base'):\n",
        "    bn_1 = BatchNormalization(axis = -1, name = base + '/bn_1')(input_feature)\n",
        "    dense_1 = Dense(num_channel, name = base + '/dense_1')(bn_1)\n",
        "    act_1 = Activation('relu', name = base + '/act_1')(dense_1)\n",
        "\n",
        "    bn_2 = BatchNormalization(axis = -1, name = base + '/bn_2')(input_feature)\n",
        "    dense_2 = Dense(num_channel, name = base + '/dense_2')(bn_2)\n",
        "    act_2 = Activation('relu', name = base + '/act_2')(dense_2)\n",
        "\n",
        "    bn_3 = BatchNormalization(axis = -1, name = base + '/bn_3')(input_feature)\n",
        "    dense_3 = Dense(num_channel, name = base + '/dense_3')(bn_3)\n",
        "    act_3 = Activation('relu', name = base + '/act_3')(dense_3)\n",
        "\n",
        "    mul_1 = Multiply(name = base + '/mul_1')([act_2, act_3])\n",
        "    mask_part = Activation('softmax', name = base + '/act_4')(mul_1)\n",
        "    mul_2 = Multiply(name = base + '/mul_2')([act_1, mask_part])\n",
        "\n",
        "    output_feature = Add(name = base + '/add_1')([mul_2, input_feature])\n",
        "\n",
        "    return output_feature\n",
        "\n",
        "def CMFA(input_feature, num_channel, base = 'CMFA_base'):\n",
        "    out_1 = self_attention(input_feature, num_channel, base + '/self_att_1')\n",
        "    out_2 = self_attention(input_feature, num_channel, base + '/self_att_2')\n",
        "    out_3 = self_attention(input_feature, num_channel, base + '/self_att_3')\n",
        "    out_4 = self_attention(input_feature, num_channel, base + '/self_att_4')\n",
        "\n",
        "    output_feature = Add(name = base + '/add')([out_1, out_2, out_3, out_4])\n",
        "\n",
        "    return output_feature\n",
        "\n",
        "def SEM(input_feature, num_channel, base = 'SEM_base'):\n",
        "    GAP_output = GlobalAveragePooling2D(name = base + '/gap_layer')(input_feature)\n",
        "\n",
        "    bn_1 = BatchNormalization(axis = -1, name = base + '/bn_1')(GAP_output)\n",
        "    dense_1 = Dense(int(num_channel/4), name = base + '/dense_1')(bn_1)\n",
        "    act_1 = Activation('relu', name = base + '/act_1')(dense_1)\n",
        "\n",
        "    bn_2 = BatchNormalization(axis = -1, name = base + '/bn_2')(act_1)\n",
        "    dense_2 = Dense(num_channel, name = base + '/dense_2')(bn_2)\n",
        "    act_2 = Activation('sigmoid', name = base + '/act_2')(dense_2)\n",
        "\n",
        "    out_channel = Multiply(name = base + '/mul_1')([act_2, input_feature])\n",
        "\n",
        "    strides = (1,1)\n",
        "\n",
        "    bn_3 = BatchNormalization(axis = -1, name = base + '/bn_3')(input_feature)\n",
        "    cn_3 = Conv2D(num_channel, (3,3), strides = strides, padding = 'same', name = base + '/conv_1')(bn_3)\n",
        "    an_3 = Activation('relu', name = base + '/act_3')(cn_3)\n",
        "\n",
        "    bn_4 = BatchNormalization(axis = -1, name = base + '/bn_4')(an_3)\n",
        "    cn_4 = Conv2D(1, (1,1), strides = strides, padding = 'same', name = base + '/conv_2')(bn_4)\n",
        "    an_4 = Activation('sigmoid', name = base + '/act_4')(cn_4)\n",
        "\n",
        "    out_spatial = Multiply(name = base + '/mul_2')([an_4, input_feature])\n",
        "\n",
        "    output_response = Add(name = base + '/add')([input_feature, out_channel, out_spatial])\n",
        "\n",
        "    return output_response\n",
        "\n",
        "def iDAAM(input_feature):\n",
        "  shape=K.int_shape(input_feature)\n",
        "  num_channel = shape[3]\n",
        "  base = 'iDAAM'\n",
        "  sem_feature = SEM(input_feature, num_channel)\n",
        "  print(sem_feature.shape)\n",
        "  cmfa_feature = CMFA(input_feature, num_channel)\n",
        "  print(cmfa_feature.shape)\n",
        "  attend_feature = tf.keras.layers.Add()([sem_feature,cmfa_feature])\n",
        "  return attend_feature"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.6):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points    \n",
        "   \n",
        "def plotmodel(history,name):\n",
        "    \n",
        "    acc = history.history['acc']\n",
        "    #val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    #val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1) \n",
        "    \n",
        "    plt.figure(1)                  \n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    #plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    plt.legend(['train_acc'], loc='upper left')\n",
        "    plt.savefig('acc_'+name+'_idaam.png')\n",
        "    \n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    #plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "    plt.legend(['train_loss'], loc='upper right')\n",
        "    plt.savefig('loss_'+name+'_idaam.png')\n",
        "    \n",
        "def get_base_model(model_name,image_size):\n",
        "    if model_name =='vgg16':\n",
        "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='resnet50':\n",
        "        base_model=ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='xception':\n",
        "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
        "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
        "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
        "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='mobilenetv2':\n",
        "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
        "    if model_name =='inceptionv3':   \n",
        "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name =='inceptionv2':\n",
        "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
        "    if model_name == 'efficientnetv1':\n",
        "      base_model=tf.keras.applications.EfficientNetB0(include_top=False,weights=\"imagenet\",input_shape=(image_size,image_size,3))\n",
        "    return base_model\n",
        "\n",
        "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
        "    \n",
        "    dataParam={'messidor': [960,240,2,'../content/drive/MyDrive/Dataset/Messidor_512_Binary/train',\n",
        "                            '../content/drive/MyDrive/Dataset/Messidor_512_Binary/test'],\n",
        "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
        "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
        "    \n",
        "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
        "    \n",
        "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
        "    valid = ImageDataGenerator()\n",
        "    train_data=train.flow_from_directory(train_dir,\n",
        "                                         target_size=(image_size,image_size),\n",
        "                                         shuffle = True,\n",
        "                                         batch_size=batch_size)\n",
        "    valid_data=valid.flow_from_directory(test_dir,\n",
        "                                         target_size=(image_size,image_size),\n",
        "                                         shuffle = False,\n",
        "                                         batch_size=batch_size)\n",
        "\n",
        "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
        "    \n",
        "    filepath = \"efficientnetv1+iDAAM.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False   \n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
        "    model.fit(train_data,\n",
        "                        steps_per_epoch=train_num/batch_size,\n",
        "                        epochs=Epochs1, \n",
        "                        workers=2,\n",
        "                        callbacks=[lr_decay,checkpoint])   \n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = True\n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
        "    history=model.fit(train_data,\n",
        "                        steps_per_epoch=train_num/batch_size,\n",
        "                        epochs=Epochs2,\n",
        "                        workers=2,\n",
        "                        callbacks=[lr_decay,checkpoint])\n",
        "    \n",
        "    score = model.evaluate(valid_data,batch_size = 64)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    \n",
        "    return history,model,valid_data"
      ],
      "metadata": {
        "id": "E6bJWIrg1d6F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UTUSzdUmMxau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dc087e-0ced-48d9-e564-af060e57b998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 16, 16, 640)\n",
            "(None, 16, 16, 640)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling_1 (Rescaling)        (None, 512, 512, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " normalization_1 (Normalization  (None, 512, 512, 3)  7          ['rescaling_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 513, 513, 3)  0           ['normalization_1[0][0]']        \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 256, 256, 32  864         ['stem_conv_pad[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 256, 256, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 256, 256, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 256, 256, 32  288        ['stem_activation[0][0]']        \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 256, 256, 32  128        ['block1a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 256, 256, 32  0          ['block1a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 256, 256, 32  0           ['block1a_activation[0][0]',     \n",
            "                                )                                 'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 256, 256, 16  512         ['block1a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 256, 256, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 256, 256, 96  1536        ['block1a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 256, 256, 96  384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 256, 256, 96  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 257, 257, 96  0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 128, 128, 96  864        ['block2a_dwconv_pad[0][0]']     \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 128, 128, 96  384        ['block2a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 128, 128, 96  0          ['block2a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 128, 128, 96  0           ['block2a_activation[0][0]',     \n",
            "                                )                                 'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 128, 128, 24  2304        ['block2a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 128, 128, 24  96         ['block2a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 128, 128, 14  3456        ['block2a_project_bn[0][0]']     \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 128, 128, 14  576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                       4)                                                                \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 128, 128, 14  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                       4)                                                                \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 128, 128, 14  1296       ['block2b_expand_activation[0][0]\n",
            " D)                             4)                               ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 128, 128, 14  576        ['block2b_dwconv[0][0]']         \n",
            " )                              4)                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 128, 128, 14  0          ['block2b_bn[0][0]']             \n",
            " )                              4)                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 128, 128, 14  0           ['block2b_activation[0][0]',     \n",
            "                                4)                                'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 128, 128, 24  3456        ['block2b_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 128, 128, 24  96         ['block2b_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 128, 128, 24  0           ['block2b_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 128, 128, 24  0           ['block2b_drop[0][0]',           \n",
            "                                )                                 'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 128, 128, 14  3456        ['block2b_add[0][0]']            \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 128, 128, 14  576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                       4)                                                                \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 128, 128, 14  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                       4)                                                                \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 131, 131, 14  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                           4)                               ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 64, 64, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 64, 64, 144)  576        ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 64, 64, 144)  0          ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 64, 64, 144)  0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 64, 64, 40)   5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 64, 64, 40)  160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 64, 64, 240)  9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 64, 64, 240)  960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 64, 64, 240)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 64, 64, 240)  6000       ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 64, 64, 240)  960        ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 64, 64, 240)  0          ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 64, 64, 240)  0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 64, 64, 40)   9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 64, 64, 40)  160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 64, 64, 40)   0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 64, 64, 40)   0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 64, 64, 240)  9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 64, 64, 240)  960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 64, 64, 240)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 65, 65, 240)  0          ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 32, 32, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 32, 32, 240)  960        ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 32, 32, 240)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 32, 32, 240)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 32, 32, 80)   19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 32, 32, 80)  320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 32, 32, 480)  38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 32, 32, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 32, 32, 480)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 32, 32, 480)  4320       ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 32, 32, 480)  1920       ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 32, 32, 480)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 32, 32, 480)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 32, 32, 80)   38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 32, 32, 80)  320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 32, 32, 80)   0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 32, 32, 80)   0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 32, 32, 480)  38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 32, 32, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 32, 32, 480)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 32, 32, 480)  4320       ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 32, 32, 480)  1920       ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 32, 32, 480)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 32, 32, 480)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 32, 32, 80)   38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 32, 32, 80)  320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 32, 32, 80)   0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 32, 32, 80)   0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 32, 32, 480)  38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 32, 32, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 32, 32, 480)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 32, 32, 480)  12000      ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 32, 32, 480)  1920       ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 32, 32, 480)  0          ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 32, 32, 480)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 32, 32, 112)  53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 32, 32, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 32, 32, 672)  16800      ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 32, 32, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 32, 32, 112)  0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 32, 32, 112)  0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 32, 32, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 32, 32, 672)  16800      ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 32, 32, 672)  2688       ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 32, 32, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 32, 32, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 32, 32, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 32, 32, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 32, 32, 112)  0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 32, 32, 112)  0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 32, 32, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 32, 32, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 32, 32, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 35, 35, 672)  0          ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 16, 16, 672)  16800      ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 16, 16, 672)  2688       ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 16, 16, 672)  0          ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 16, 16, 672)  0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 16, 16, 192)  129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6b_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 16, 16, 1152  0          ['block6b_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 16, 16, 1152  28800      ['block6b_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6b_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 16, 16, 1152  0          ['block6b_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6b_activation[0][0]',     \n",
            "                                )                                 'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 16, 16, 192)  0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 16, 16, 192)  0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6b_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6c_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 16, 16, 1152  0          ['block6c_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 16, 16, 1152  28800      ['block6c_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6c_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 16, 16, 1152  0          ['block6c_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6c_activation[0][0]',     \n",
            "                                )                                 'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 16, 16, 192)  0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 16, 16, 192)  0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6c_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block6d_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 16, 16, 1152  0          ['block6d_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 16, 16, 1152  28800      ['block6d_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block6d_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 16, 16, 1152  0          ['block6d_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block6d_activation[0][0]',     \n",
            "                                )                                 'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 16, 16, 192)  221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 16, 16, 192)  768        ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 16, 16, 192)  0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 16, 16, 192)  0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 16, 16, 1152  221184      ['block6d_add[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 16, 16, 1152  4608       ['block7a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 16, 16, 1152  0          ['block7a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 16, 16, 1152  10368      ['block7a_expand_activation[0][0]\n",
            " D)                             )                                ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 16, 16, 1152  4608       ['block7a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 16, 16, 1152  0          ['block7a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 16, 16, 1152  0           ['block7a_activation[0][0]',     \n",
            "                                )                                 'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 16, 16, 320)  368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 16, 16, 320)  1280       ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 16, 16, 1280  409600      ['block7a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 16, 16, 1280  5120        ['top_conv[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 16, 16, 1280  0           ['top_bn[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 640)  819840      ['top_activation[0][0]']         \n",
            "                                                                                                  \n",
            " SEM_base/gap_layer (GlobalAver  (None, 640)         0           ['conv2d_1[0][0]']               \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " SEM_base/bn_1 (BatchNormalizat  (None, 640)         2560        ['SEM_base/gap_layer[0][0]']     \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " SEM_base/bn_3 (BatchNormalizat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/bn_2 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/bn_3 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " SEM_base/dense_1 (Dense)       (None, 160)          102560      ['SEM_base/bn_1[0][0]']          \n",
            "                                                                                                  \n",
            " SEM_base/conv_1 (Conv2D)       (None, 16, 16, 640)  3687040     ['SEM_base/bn_3[0][0]']          \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_1/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_1/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_2/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_2/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_3/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_3/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/dense_2 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_4/bn_2[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/dense_3 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_4/bn_3[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " SEM_base/act_1 (Activation)    (None, 160)          0           ['SEM_base/dense_1[0][0]']       \n",
            "                                                                                                  \n",
            " SEM_base/act_3 (Activation)    (None, 16, 16, 640)  0           ['SEM_base/conv_1[0][0]']        \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/bn_1 (Bat  (None, 16, 16, 640)  2560       ['conv2d_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_2 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/dense_2[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_3 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/dense_3[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " SEM_base/bn_2 (BatchNormalizat  (None, 160)         640         ['SEM_base/act_1[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " SEM_base/bn_4 (BatchNormalizat  (None, 16, 16, 640)  2560       ['SEM_base/act_3[0][0]']         \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_1/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_1/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_2/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_2/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_3/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_3/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/dense_1 (  (None, 16, 16, 640)  410240     ['CMFA_base/self_att_4/bn_1[0][0]\n",
            " Dense)                                                          ']                               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/mul_1 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/act_2[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_4/act_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " SEM_base/dense_2 (Dense)       (None, 640)          103040      ['SEM_base/bn_2[0][0]']          \n",
            "                                                                                                  \n",
            " SEM_base/conv_2 (Conv2D)       (None, 16, 16, 1)    641         ['SEM_base/bn_4[0][0]']          \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_1 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/dense_1[0]\n",
            " tivation)                                                       [0]']                            \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/act_4 (Ac  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/mul_1[0][0\n",
            " tivation)                                                       ]']                              \n",
            "                                                                                                  \n",
            " SEM_base/act_2 (Activation)    (None, 640)          0           ['SEM_base/dense_2[0][0]']       \n",
            "                                                                                                  \n",
            " SEM_base/act_4 (Activation)    (None, 16, 16, 1)    0           ['SEM_base/conv_2[0][0]']        \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_1/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_2/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_3/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/mul_2 (Mu  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/act_1[0][0\n",
            " ltiply)                                                         ]',                              \n",
            "                                                                  'CMFA_base/self_att_4/act_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " SEM_base/mul_1 (Multiply)      (None, 16, 16, 640)  0           ['SEM_base/act_2[0][0]',         \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " SEM_base/mul_2 (Multiply)      (None, 16, 16, 640)  0           ['SEM_base/act_4[0][0]',         \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_1/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_1/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_2/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_2/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_3/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_3/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " CMFA_base/self_att_4/add_1 (Ad  (None, 16, 16, 640)  0          ['CMFA_base/self_att_4/mul_2[0][0\n",
            " d)                                                              ]',                              \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " SEM_base/add (Add)             (None, 16, 16, 640)  0           ['conv2d_1[0][0]',               \n",
            "                                                                  'SEM_base/mul_1[0][0]',         \n",
            "                                                                  'SEM_base/mul_2[0][0]']         \n",
            "                                                                                                  \n",
            " CMFA_base/add (Add)            (None, 16, 16, 640)  0           ['CMFA_base/self_att_1/add_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'CMFA_base/self_att_2/add_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'CMFA_base/self_att_3/add_1[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'CMFA_base/self_att_4/add_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 640)  0           ['SEM_base/add[0][0]',           \n",
            "                                                                  'CMFA_base/add[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 640)         0           ['add_1[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            1282        ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,725,894\n",
            "Trainable params: 13,664,351\n",
            "Non-trainable params: 61,543\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
        "loss_fun= 'binary_crossentropy'  \n",
        "gpu_num=1\n",
        "k=3\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "batch_size= 16\n",
        "image_size=512\n",
        "classes=2\n",
        "\n",
        "base_model=get_base_model('efficientnetv1',image_size)  \n",
        "base_in=base_model.input\n",
        "base_out=base_model.output\n",
        "\n",
        "shape = K.int_shape(base_out)\n",
        "channel_val = shape[3]/2\n",
        "red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
        "x=iDAAM(red_feat)\n",
        "#base_out=Category_attention_block(x,classes,k)\n",
        "\n",
        "shape=K.int_shape(x)  \n",
        "x=GlobalAveragePooling2D()(x)\n",
        "out=Dense(classes,activation='softmax')(x)\n",
        "\n",
        "parallel_model=keras.Model(base_model.input,out)\n",
        "parallel_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qgw4L6PM6bU",
        "outputId": "c6127a4d-08e8-47e7-9a5c-d7f363bd1adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 960 images belonging to 2 classes.\n",
            "Found 240 images belonging to 2 classes.\n",
            "60/60 [==============================] - ETA: 0s - loss: 5.9908 - acc: 0.5792\n",
            "Epoch 1: acc improved from -inf to 0.57917, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 94s 1s/step - loss: 5.9908 - acc: 0.5792 - lr: 0.0050\n",
            "Epoch 1/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6289 - acc: 0.6573\n",
            "Epoch 1: acc improved from 0.57917 to 0.65729, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 116s 2s/step - loss: 0.6289 - acc: 0.6573 - lr: 1.0000e-04\n",
            "Epoch 2/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4868 - acc: 0.7688\n",
            "Epoch 2: acc improved from 0.65729 to 0.76875, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.4868 - acc: 0.7688 - lr: 1.0000e-04\n",
            "Epoch 3/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3789 - acc: 0.8354\n",
            "Epoch 3: acc improved from 0.76875 to 0.83542, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.3789 - acc: 0.8354 - lr: 1.0000e-04\n",
            "Epoch 4/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3274 - acc: 0.8594\n",
            "Epoch 4: acc improved from 0.83542 to 0.85938, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.3274 - acc: 0.8594 - lr: 1.0000e-04\n",
            "Epoch 5/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3188 - acc: 0.8667\n",
            "Epoch 5: acc improved from 0.85938 to 0.86667, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.3188 - acc: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 6/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2769 - acc: 0.8927\n",
            "Epoch 6: acc improved from 0.86667 to 0.89271, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.2769 - acc: 0.8927 - lr: 1.0000e-04\n",
            "Epoch 7/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2630 - acc: 0.8927\n",
            "Epoch 7: acc did not improve from 0.89271\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.2630 - acc: 0.8927 - lr: 1.0000e-04\n",
            "Epoch 8/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2608 - acc: 0.8896\n",
            "Epoch 8: acc did not improve from 0.89271\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.2608 - acc: 0.8896 - lr: 1.0000e-04\n",
            "Epoch 9/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2275 - acc: 0.9000\n",
            "Epoch 9: acc improved from 0.89271 to 0.90000, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.2275 - acc: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 10/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2260 - acc: 0.9062\n",
            "Epoch 10: acc improved from 0.90000 to 0.90625, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.2260 - acc: 0.9062 - lr: 1.0000e-04\n",
            "Epoch 11/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2132 - acc: 0.9135\n",
            "Epoch 11: acc improved from 0.90625 to 0.91354, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.2132 - acc: 0.9135 - lr: 1.0000e-04\n",
            "Epoch 12/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1895 - acc: 0.9219\n",
            "Epoch 12: acc improved from 0.91354 to 0.92188, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.1895 - acc: 0.9219 - lr: 1.0000e-04\n",
            "Epoch 13/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1879 - acc: 0.9312\n",
            "Epoch 13: acc improved from 0.92188 to 0.93125, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.1879 - acc: 0.9312 - lr: 1.0000e-04\n",
            "Epoch 14/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1545 - acc: 0.9458\n",
            "Epoch 14: acc improved from 0.93125 to 0.94583, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.1545 - acc: 0.9458 - lr: 1.0000e-04\n",
            "Epoch 15/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1694 - acc: 0.9333\n",
            "Epoch 15: acc did not improve from 0.94583\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.1694 - acc: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 16/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1437 - acc: 0.9438\n",
            "Epoch 16: acc did not improve from 0.94583\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.1437 - acc: 0.9438 - lr: 1.0000e-04\n",
            "Epoch 17/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1467 - acc: 0.9375\n",
            "Epoch 17: acc did not improve from 0.94583\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.1467 - acc: 0.9375 - lr: 1.0000e-04\n",
            "Epoch 18/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1384 - acc: 0.9438\n",
            "Epoch 18: acc did not improve from 0.94583\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.1384 - acc: 0.9438 - lr: 1.0000e-04\n",
            "Epoch 19/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1119 - acc: 0.9583\n",
            "Epoch 19: acc improved from 0.94583 to 0.95833, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.1119 - acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 20/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1383 - acc: 0.9448\n",
            "Epoch 20: acc did not improve from 0.95833\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.1383 - acc: 0.9448 - lr: 1.0000e-04\n",
            "Epoch 21/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0764 - acc: 0.9688\n",
            "Epoch 21: acc improved from 0.95833 to 0.96875, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.0764 - acc: 0.9688 - lr: 1.0000e-04\n",
            "Epoch 22/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1040 - acc: 0.9542\n",
            "Epoch 22: acc did not improve from 0.96875\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.1040 - acc: 0.9542 - lr: 1.0000e-04\n",
            "Epoch 23/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0871 - acc: 0.9667\n",
            "Epoch 23: acc did not improve from 0.96875\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0871 - acc: 0.9667 - lr: 1.0000e-04\n",
            "Epoch 24/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0869 - acc: 0.9688\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
            "\n",
            "Epoch 24: acc did not improve from 0.96875\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0869 - acc: 0.9688 - lr: 1.0000e-04\n",
            "Epoch 25/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0784 - acc: 0.9729\n",
            "Epoch 25: acc improved from 0.96875 to 0.97292, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.0784 - acc: 0.9729 - lr: 8.0000e-05\n",
            "Epoch 26/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0760 - acc: 0.9719\n",
            "Epoch 26: acc did not improve from 0.97292\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0760 - acc: 0.9719 - lr: 8.0000e-05\n",
            "Epoch 27/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0573 - acc: 0.9833\n",
            "Epoch 27: acc improved from 0.97292 to 0.98333, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.0573 - acc: 0.9833 - lr: 8.0000e-05\n",
            "Epoch 28/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.9771\n",
            "Epoch 28: acc did not improve from 0.98333\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0604 - acc: 0.9771 - lr: 8.0000e-05\n",
            "Epoch 29/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0640 - acc: 0.9750\n",
            "Epoch 29: acc did not improve from 0.98333\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0640 - acc: 0.9750 - lr: 8.0000e-05\n",
            "Epoch 30/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0820 - acc: 0.9729\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
            "\n",
            "Epoch 30: acc did not improve from 0.98333\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0820 - acc: 0.9729 - lr: 8.0000e-05\n",
            "Epoch 31/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.9865\n",
            "Epoch 31: acc improved from 0.98333 to 0.98646, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0370 - acc: 0.9865 - lr: 6.4000e-05\n",
            "Epoch 32/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.9896\n",
            "Epoch 32: acc improved from 0.98646 to 0.98958, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0308 - acc: 0.9896 - lr: 6.4000e-05\n",
            "Epoch 33/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9844\n",
            "Epoch 33: acc did not improve from 0.98958\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0460 - acc: 0.9844 - lr: 6.4000e-05\n",
            "Epoch 34/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9844\n",
            "Epoch 34: acc did not improve from 0.98958\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0371 - acc: 0.9844 - lr: 6.4000e-05\n",
            "Epoch 35/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0567 - acc: 0.9781\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
            "\n",
            "Epoch 35: acc did not improve from 0.98958\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0567 - acc: 0.9781 - lr: 6.4000e-05\n",
            "Epoch 36/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.9844\n",
            "Epoch 36: acc did not improve from 0.98958\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0439 - acc: 0.9844 - lr: 5.1200e-05\n",
            "Epoch 37/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0461 - acc: 0.9823\n",
            "Epoch 37: acc did not improve from 0.98958\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0461 - acc: 0.9823 - lr: 5.1200e-05\n",
            "Epoch 38/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0298 - acc: 0.9917\n",
            "Epoch 38: acc improved from 0.98958 to 0.99167, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 99s 2s/step - loss: 0.0298 - acc: 0.9917 - lr: 5.1200e-05\n",
            "Epoch 39/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0377 - acc: 0.9896\n",
            "Epoch 39: acc did not improve from 0.99167\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0377 - acc: 0.9896 - lr: 5.1200e-05\n",
            "Epoch 40/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0273 - acc: 0.9906\n",
            "Epoch 40: acc did not improve from 0.99167\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0273 - acc: 0.9906 - lr: 5.1200e-05\n",
            "Epoch 41/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0291 - acc: 0.9885\n",
            "Epoch 41: acc did not improve from 0.99167\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0291 - acc: 0.9885 - lr: 5.1200e-05\n",
            "Epoch 42/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0257 - acc: 0.9896\n",
            "Epoch 42: acc did not improve from 0.99167\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0257 - acc: 0.9896 - lr: 5.1200e-05\n",
            "Epoch 43/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0264 - acc: 0.9885\n",
            "Epoch 43: acc did not improve from 0.99167\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0264 - acc: 0.9885 - lr: 5.1200e-05\n",
            "Epoch 44/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0215 - acc: 0.9927\n",
            "Epoch 44: acc improved from 0.99167 to 0.99271, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0215 - acc: 0.9927 - lr: 5.1200e-05\n",
            "Epoch 45/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9917\n",
            "Epoch 45: acc did not improve from 0.99271\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0204 - acc: 0.9917 - lr: 5.1200e-05\n",
            "Epoch 46/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0287 - acc: 0.9937\n",
            "Epoch 46: acc improved from 0.99271 to 0.99375, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0287 - acc: 0.9937 - lr: 5.1200e-05\n",
            "Epoch 47/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.9917\n",
            "Epoch 47: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0207 - acc: 0.9917 - lr: 5.1200e-05\n",
            "Epoch 48/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9885\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
            "\n",
            "Epoch 48: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0295 - acc: 0.9885 - lr: 5.1200e-05\n",
            "Epoch 49/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0414 - acc: 0.9875\n",
            "Epoch 49: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0414 - acc: 0.9875 - lr: 4.0960e-05\n",
            "Epoch 50/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.9885\n",
            "Epoch 50: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0312 - acc: 0.9885 - lr: 4.0960e-05\n",
            "Epoch 51/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9937\n",
            "Epoch 51: acc did not improve from 0.99375\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0165 - acc: 0.9937 - lr: 4.0960e-05\n",
            "Epoch 52/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9979\n",
            "Epoch 52: acc improved from 0.99375 to 0.99792, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0083 - acc: 0.9979 - lr: 4.0960e-05\n",
            "Epoch 53/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0184 - acc: 0.9917\n",
            "Epoch 53: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0184 - acc: 0.9917 - lr: 4.0960e-05\n",
            "Epoch 54/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9896\n",
            "Epoch 54: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0283 - acc: 0.9896 - lr: 4.0960e-05\n",
            "Epoch 55/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9937\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
            "\n",
            "Epoch 55: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0277 - acc: 0.9937 - lr: 4.0960e-05\n",
            "Epoch 56/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0212 - acc: 0.9917\n",
            "Epoch 56: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0212 - acc: 0.9917 - lr: 3.2768e-05\n",
            "Epoch 57/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9937\n",
            "Epoch 57: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0171 - acc: 0.9937 - lr: 3.2768e-05\n",
            "Epoch 58/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9906\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
            "\n",
            "Epoch 58: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0202 - acc: 0.9906 - lr: 3.2768e-05\n",
            "Epoch 59/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9948\n",
            "Epoch 59: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0124 - acc: 0.9948 - lr: 2.6214e-05\n",
            "Epoch 60/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9969\n",
            "Epoch 60: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0124 - acc: 0.9969 - lr: 2.6214e-05\n",
            "Epoch 61/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.9896\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
            "\n",
            "Epoch 61: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0228 - acc: 0.9896 - lr: 2.6214e-05\n",
            "Epoch 62/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9979\n",
            "Epoch 62: acc did not improve from 0.99792\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0065 - acc: 0.9979 - lr: 2.0972e-05\n",
            "Epoch 63/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0079 - acc: 0.9990\n",
            "Epoch 63: acc improved from 0.99792 to 0.99896, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0079 - acc: 0.9990 - lr: 2.0972e-05\n",
            "Epoch 64/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0168 - acc: 0.9937\n",
            "Epoch 64: acc did not improve from 0.99896\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0168 - acc: 0.9937 - lr: 2.0972e-05\n",
            "Epoch 65/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 65: acc improved from 0.99896 to 1.00000, saving model to efficientnetv1+iDAAM.hdf5\n",
            "60/60 [==============================] - 100s 2s/step - loss: 0.0037 - acc: 1.0000 - lr: 2.0972e-05\n",
            "Epoch 66/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9948\n",
            "Epoch 66: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0132 - acc: 0.9948 - lr: 2.0972e-05\n",
            "Epoch 67/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9948\n",
            "Epoch 67: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0202 - acc: 0.9948 - lr: 2.0972e-05\n",
            "Epoch 68/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0170 - acc: 0.9927\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
            "\n",
            "Epoch 68: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0170 - acc: 0.9927 - lr: 2.0972e-05\n",
            "Epoch 69/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.9969\n",
            "Epoch 69: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0092 - acc: 0.9969 - lr: 1.6777e-05\n",
            "Epoch 70/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9937\n",
            "Epoch 70: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0107 - acc: 0.9937 - lr: 1.6777e-05\n",
            "Epoch 71/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.9969\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
            "\n",
            "Epoch 71: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0089 - acc: 0.9969 - lr: 1.6777e-05\n",
            "Epoch 72/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0099 - acc: 0.9958\n",
            "Epoch 72: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0099 - acc: 0.9958 - lr: 1.3422e-05\n",
            "Epoch 73/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 73: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0042 - acc: 1.0000 - lr: 1.3422e-05\n",
            "Epoch 74/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.9969\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
            "\n",
            "Epoch 74: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0129 - acc: 0.9969 - lr: 1.3422e-05\n",
            "Epoch 75/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9979\n",
            "Epoch 75: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0066 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 76/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9979\n",
            "Epoch 76: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0087 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 77/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9979\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
            "\n",
            "Epoch 77: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0055 - acc: 0.9979 - lr: 1.0737e-05\n",
            "Epoch 78/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0172 - acc: 0.9948\n",
            "Epoch 78: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0172 - acc: 0.9948 - lr: 8.5899e-06\n",
            "Epoch 79/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.9969\n",
            "Epoch 79: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0089 - acc: 0.9969 - lr: 8.5899e-06\n",
            "Epoch 80/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0116 - acc: 0.9948\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
            "\n",
            "Epoch 80: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0116 - acc: 0.9948 - lr: 8.5899e-06\n",
            "Epoch 81/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9958\n",
            "Epoch 81: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0098 - acc: 0.9958 - lr: 6.8719e-06\n",
            "Epoch 82/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9969\n",
            "Epoch 82: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0104 - acc: 0.9969 - lr: 6.8719e-06\n",
            "Epoch 83/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9927\n",
            "Epoch 83: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n",
            "\n",
            "Epoch 83: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0192 - acc: 0.9927 - lr: 6.8719e-06\n",
            "Epoch 84/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0115 - acc: 0.9969\n",
            "Epoch 84: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0115 - acc: 0.9969 - lr: 5.4976e-06\n",
            "Epoch 85/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0069 - acc: 0.9969\n",
            "Epoch 85: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0069 - acc: 0.9969 - lr: 5.4976e-06\n",
            "Epoch 86/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9979\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n",
            "\n",
            "Epoch 86: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0067 - acc: 0.9979 - lr: 5.4976e-06\n",
            "Epoch 87/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0085 - acc: 0.9979\n",
            "Epoch 87: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 96s 2s/step - loss: 0.0085 - acc: 0.9979 - lr: 4.3980e-06\n",
            "Epoch 88/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9948\n",
            "Epoch 88: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0106 - acc: 0.9948 - lr: 4.3980e-06\n",
            "Epoch 89/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9979\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.518437006277964e-06.\n",
            "\n",
            "Epoch 89: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0064 - acc: 0.9979 - lr: 4.3980e-06\n",
            "Epoch 90/90\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 90: acc did not improve from 1.00000\n",
            "60/60 [==============================] - 97s 2s/step - loss: 0.0018 - acc: 1.0000 - lr: 3.5184e-06\n",
            "15/15 [==============================] - 38s 2s/step - loss: 0.5666 - acc: 0.9125\n",
            "Test loss: 0.566644012928009\n",
            "Test accuracy: 0.9125000238418579\n"
          ]
        }
      ],
      "source": [
        "history,model,valid_data=train_model(parallel_model,\n",
        "                                     'messidor',\n",
        "                                     image_size,\n",
        "                                     batch_size,\n",
        "                                     'efficientnetv1',\n",
        "                                     lr1,lr2,1,90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EsEEInLtND3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa76e552-15cc-4e77-cd52-eb521f80217c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[135   8]\n",
            " [ 13  84]]\n",
            "Classification Report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "non-referable       0.91      0.94      0.93       143\n",
            "    referable       0.91      0.87      0.89        97\n",
            "\n",
            "     accuracy                           0.91       240\n",
            "    macro avg       0.91      0.91      0.91       240\n",
            " weighted avg       0.91      0.91      0.91       240\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plotmodel(history,'efficientnetv1')            \n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "Y_pred = model.predict(valid_data, 240 // 4)\n",
        "#print(Y_pred.shape)\n",
        "#print(type(Y_pred))\n",
        "#print(valid_data.classes)  \n",
        "#print(Y_pred)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "#print(y_pred)\n",
        "print('Confusion Matrix')\n",
        "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
        "\n",
        "print(confusion_matrix(valid_data.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['non-referable', 'referable']\n",
        "print(classification_report(valid_data.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(matrix,annot=True,fmt='d')\n",
        "plt.xlabel('Predicted value')\n",
        "plt.ylabel('Truth')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IDiyJtvhNDuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e015361-f826-47a0-eb46-75975c45e8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plot_metric\n",
            "  Downloading plot_metric-0.0.6-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.0.2)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (0.11.2)\n",
            "Requirement already satisfied: colorlover>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (0.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from plot_metric) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot_metric) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.2->plot_metric) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->plot_metric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->plot_metric) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot_metric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot_metric) (3.1.0)\n",
            "Installing collected packages: plot-metric\n",
            "Successfully installed plot-metric-0.0.6\n"
          ]
        }
      ],
      "source": [
        "pip install plot_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c3J5q1SLNMkI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "106a0055-ecd3-4cd8-fb13-e8d37e7751ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from plot_metric.functions import BinaryClassification\n",
        "# Visualisation with plot_metric\n",
        "y_true = valid_data.classes\n",
        "y_probas = y_pred\n",
        "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
        "\n",
        "# Figures\n",
        "plt.figure(figsize=(5,5))\n",
        "bc.plot_roc_curve()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "EfficientNetV1+iDAAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}