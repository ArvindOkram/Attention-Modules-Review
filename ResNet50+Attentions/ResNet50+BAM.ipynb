{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e88bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8fa633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46cd4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bottleneck_Attention_Block(inputs,ratio = 16):\n",
    "    image = tf.zeros([16,16,1024])\n",
    "    shape=K.int_shape(inputs)\n",
    "    ch = shape[3]\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(shape[1],shape[2]))(inputs)\n",
    "    x = Dense(ch//ratio, activation='relu')(x)\n",
    "    F1 = Dense(ch, activation='sigmoid')(x)\n",
    "    con_val = ch//ratio\n",
    "    x1 = Conv2D(con_val,1, padding='same') (inputs)\n",
    "    x=tf.keras.layers.BatchNormalization() (x1)\n",
    "    act1=Activation('relu') (x)\n",
    "\n",
    "    x2 = Conv2D(con_val,3, strides = (1,1), dilation_rate = (4,4), padding='same') (act1)\n",
    "    x=tf.keras.layers.BatchNormalization() (x2)\n",
    "    act2=Activation('relu') (x)\n",
    "\n",
    "    x3 = Conv2D(con_val,3, strides = (1,1), dilation_rate = (4,4), padding='same') (act2)\n",
    "    x=tf.keras.layers.BatchNormalization() (x3)\n",
    "    act3=Activation('relu') (x)\n",
    "\n",
    "    x4 = Conv2D(1,1, padding='same') (x)\n",
    "    x=tf.keras.layers.BatchNormalization() (x4)\n",
    "    F2 = x\n",
    "\n",
    "    add_ele = tf.keras.layers.Add()([F1,F2])\n",
    "    B_A= Activation('sigmoid') (add_ele)\n",
    "\n",
    "    mul_input_BA = tf.keras.layers.Multiply()([B_A,inputs])\n",
    "    out = tf.keras.layers.Add()([mul_input_BA,inputs])\n",
    "\n",
    "    return out\n",
    "\n",
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name,attention):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+attention+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+attention+'.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='efficientnetB0':\n",
    "        base_model = tf.keras.applications.EfficientNetB0 (include_top=False, weights = 'imagenet',input_shape = (image_size,image_size,3))\n",
    "    if model_name =='efficientNetV2B0':\n",
    "        base_model = tf.keras.applications.EfficientNetV2B0 (include_top=False, weights = 'imagenet',input_shape = (image_size,image_size,3))\n",
    "    if model_name =='nasnet':\n",
    "        base_model=tf.keras.applications.NASNetMobile (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+BAM.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ead79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 15:47:31.779901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: GeForce GT 710, pci bus id: 0000:b3:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-05-09 15:47:31.780798: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 15:47:32.448468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30982 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 128)  262272      ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 128)  512        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 16, 16, 128)  0           ['batch_normalization[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 128)  147584      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 128)  147584      ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['conv5_block3_out[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 1, 128)    262272      ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 1)    129         ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 2048)   264192      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 1)   4           ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 2048  0           ['dense_1[0][0]',                \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 16, 16, 2048  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 2048  0           ['activation_3[0][0]',           \n",
      "                                )                                 'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 16, 2048  0           ['multiply[0][0]',               \n",
      "                                )                                 'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['add_1[0][0]']                  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            4098        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,677,383\n",
      "Trainable params: 24,623,493\n",
      "Non-trainable params: 53,890\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "#red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=Bottleneck_Attention_Block(base_out)\n",
    "#base_out=Category_attention_block(x,classes,k)\n",
    "\n",
    "shape=K.int_shape(x)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d69a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 15:47:58.709079: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.7973 - acc: 0.5958\n",
      "Epoch 1: acc improved from -inf to 0.59583, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 42s 578ms/step - loss: 0.7973 - acc: 0.5958 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5521 - acc: 0.7479\n",
      "Epoch 1: acc improved from 0.59583 to 0.74792, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 44s 598ms/step - loss: 0.5521 - acc: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3526 - acc: 0.8490\n",
      "Epoch 2: acc improved from 0.74792 to 0.84896, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 43s 695ms/step - loss: 0.3526 - acc: 0.8490 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3500 - acc: 0.8750\n",
      "Epoch 3: acc improved from 0.84896 to 0.87500, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 38s 610ms/step - loss: 0.3500 - acc: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3150 - acc: 0.8740\n",
      "Epoch 4: acc did not improve from 0.87500\n",
      "60/60 [==============================] - 34s 551ms/step - loss: 0.3150 - acc: 0.8740 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3041 - acc: 0.8875\n",
      "Epoch 5: acc improved from 0.87500 to 0.88750, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 0.3041 - acc: 0.8875 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2613 - acc: 0.9021\n",
      "Epoch 6: acc improved from 0.88750 to 0.90208, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.2613 - acc: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2576 - acc: 0.9010\n",
      "Epoch 7: acc did not improve from 0.90208\n",
      "60/60 [==============================] - 37s 608ms/step - loss: 0.2576 - acc: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2471 - acc: 0.9042\n",
      "Epoch 8: acc improved from 0.90208 to 0.90417, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.2471 - acc: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2735 - acc: 0.8833\n",
      "Epoch 9: acc did not improve from 0.90417\n",
      "60/60 [==============================] - 38s 613ms/step - loss: 0.2735 - acc: 0.8833 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2108 - acc: 0.9104\n",
      "Epoch 10: acc improved from 0.90417 to 0.91042, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 42s 683ms/step - loss: 0.2108 - acc: 0.9104 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2097 - acc: 0.9198\n",
      "Epoch 11: acc improved from 0.91042 to 0.91979, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 41s 677ms/step - loss: 0.2097 - acc: 0.9198 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1898 - acc: 0.9260\n",
      "Epoch 12: acc improved from 0.91979 to 0.92604, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.1898 - acc: 0.9260 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1674 - acc: 0.9271\n",
      "Epoch 13: acc improved from 0.92604 to 0.92708, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.1674 - acc: 0.9271 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1856 - acc: 0.9354\n",
      "Epoch 14: acc improved from 0.92708 to 0.93542, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 661ms/step - loss: 0.1856 - acc: 0.9354 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1514 - acc: 0.9448\n",
      "Epoch 15: acc improved from 0.93542 to 0.94479, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 42s 683ms/step - loss: 0.1514 - acc: 0.9448 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1596 - acc: 0.9438\n",
      "Epoch 16: acc did not improve from 0.94479\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.1596 - acc: 0.9438 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1359 - acc: 0.9490\n",
      "Epoch 17: acc improved from 0.94479 to 0.94896, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 43s 680ms/step - loss: 0.1359 - acc: 0.9490 - lr: 1.0000e-04\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1277 - acc: 0.9490\n",
      "Epoch 18: acc did not improve from 0.94896\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.1277 - acc: 0.9490 - lr: 1.0000e-04\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1519 - acc: 0.9448\n",
      "Epoch 19: acc did not improve from 0.94896\n",
      "60/60 [==============================] - 39s 626ms/step - loss: 0.1519 - acc: 0.9448 - lr: 1.0000e-04\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1161 - acc: 0.9510\n",
      "Epoch 20: acc improved from 0.94896 to 0.95104, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 43s 693ms/step - loss: 0.1161 - acc: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1135 - acc: 0.9531\n",
      "Epoch 21: acc improved from 0.95104 to 0.95312, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.1135 - acc: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1176 - acc: 0.9615\n",
      "Epoch 22: acc improved from 0.95312 to 0.96146, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 0.1176 - acc: 0.9615 - lr: 1.0000e-04\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1050 - acc: 0.9635\n",
      "Epoch 23: acc improved from 0.96146 to 0.96354, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 41s 674ms/step - loss: 0.1050 - acc: 0.9635 - lr: 1.0000e-04\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1202 - acc: 0.9427\n",
      "Epoch 24: acc did not improve from 0.96354\n",
      "60/60 [==============================] - 38s 626ms/step - loss: 0.1202 - acc: 0.9427 - lr: 1.0000e-04\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1462 - acc: 0.9427\n",
      "Epoch 25: acc did not improve from 0.96354\n",
      "60/60 [==============================] - 41s 662ms/step - loss: 0.1462 - acc: 0.9427 - lr: 1.0000e-04\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0729 - acc: 0.9719\n",
      "Epoch 26: acc improved from 0.96354 to 0.97188, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 43s 699ms/step - loss: 0.0729 - acc: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1129 - acc: 0.9594\n",
      "Epoch 27: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.1129 - acc: 0.9594 - lr: 1.0000e-04\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1074 - acc: 0.9604\n",
      "Epoch 28: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 41s 661ms/step - loss: 0.1074 - acc: 0.9604 - lr: 1.0000e-04\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1057 - acc: 0.9583\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 29: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 40s 644ms/step - loss: 0.1057 - acc: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0683 - acc: 0.9708\n",
      "Epoch 30: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 38s 623ms/step - loss: 0.0683 - acc: 0.9708 - lr: 8.0000e-05\n",
      "Epoch 31/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0666 - acc: 0.9812\n",
      "Epoch 31: acc improved from 0.97188 to 0.98125, saving model to resnet50+BAM.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 43s 686ms/step - loss: 0.0666 - acc: 0.9812 - lr: 8.0000e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.9781\n",
      "Epoch 32: acc did not improve from 0.98125\n",
      "60/60 [==============================] - 39s 633ms/step - loss: 0.0609 - acc: 0.9781 - lr: 8.0000e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0387 - acc: 0.9917\n",
      "Epoch 33: acc improved from 0.98125 to 0.99167, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 42s 693ms/step - loss: 0.0387 - acc: 0.9917 - lr: 8.0000e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9844\n",
      "Epoch 34: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0460 - acc: 0.9844 - lr: 8.0000e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0419 - acc: 0.9865\n",
      "Epoch 35: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.0419 - acc: 0.9865 - lr: 8.0000e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0890 - acc: 0.9719\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 36: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 38s 627ms/step - loss: 0.0890 - acc: 0.9719 - lr: 8.0000e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0749 - acc: 0.9698\n",
      "Epoch 37: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0749 - acc: 0.9698 - lr: 6.4000e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0418 - acc: 0.9792\n",
      "Epoch 38: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 39s 639ms/step - loss: 0.0418 - acc: 0.9792 - lr: 6.4000e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9917\n",
      "Epoch 39: acc did not improve from 0.99167\n",
      "60/60 [==============================] - 40s 643ms/step - loss: 0.0236 - acc: 0.9917 - lr: 6.4000e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.9958\n",
      "Epoch 40: acc improved from 0.99167 to 0.99583, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 43s 690ms/step - loss: 0.0232 - acc: 0.9958 - lr: 6.4000e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0279 - acc: 0.9896\n",
      "Epoch 41: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 0.0279 - acc: 0.9896 - lr: 6.4000e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0507 - acc: 0.9802\n",
      "Epoch 42: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.0507 - acc: 0.9802 - lr: 6.4000e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0655 - acc: 0.9781\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 43: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 38s 627ms/step - loss: 0.0655 - acc: 0.9781 - lr: 6.4000e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 44: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 38s 617ms/step - loss: 0.0325 - acc: 0.9917 - lr: 5.1200e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.9958\n",
      "Epoch 45: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 40s 643ms/step - loss: 0.0225 - acc: 0.9958 - lr: 5.1200e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0216 - acc: 0.9958\n",
      "Epoch 46: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 39s 645ms/step - loss: 0.0216 - acc: 0.9958 - lr: 5.1200e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9958\n",
      "Epoch 47: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 37s 603ms/step - loss: 0.0165 - acc: 0.9958 - lr: 5.1200e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9958\n",
      "Epoch 48: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 39s 624ms/step - loss: 0.0132 - acc: 0.9958 - lr: 5.1200e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9917\n",
      "Epoch 49: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.0192 - acc: 0.9917 - lr: 5.1200e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0190 - acc: 0.9948\n",
      "Epoch 50: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.0190 - acc: 0.9948 - lr: 5.1200e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0185 - acc: 0.9937\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 51: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.0185 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0131 - acc: 0.9969\n",
      "Epoch 52: acc improved from 0.99583 to 0.99687, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 0.0131 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9958\n",
      "Epoch 53: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0180 - acc: 0.9958 - lr: 4.0960e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0130 - acc: 0.9969\n",
      "Epoch 54: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.0130 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 55: acc improved from 0.99687 to 1.00000, saving model to resnet50+BAM.hdf5\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0080 - acc: 1.0000 - lr: 4.0960e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 56: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 612ms/step - loss: 0.0077 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 57: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0064 - acc: 0.9979 - lr: 4.0960e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9990\n",
      "Epoch 58: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 624ms/step - loss: 0.0074 - acc: 0.9990 - lr: 4.0960e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 59: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 674ms/step - loss: 0.0096 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.9969\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 60: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0127 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 61: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 664ms/step - loss: 0.0035 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 62: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 632ms/step - loss: 0.0041 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 63: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0071 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9990\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 644ms/step - loss: 0.0074 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 65: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0047 - acc: 1.0000 - lr: 2.6214e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 644ms/step - loss: 0.0033 - acc: 1.0000 - lr: 2.6214e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0018 - acc: 1.0000 - lr: 2.6214e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0088 - acc: 0.9990\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.0088 - acc: 0.9990 - lr: 2.6214e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 654ms/step - loss: 0.0070 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9990\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.0043 - acc: 0.9990 - lr: 2.6214e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 71: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 645ms/step - loss: 0.0058 - acc: 0.9979 - lr: 2.0972e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9990\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 662ms/step - loss: 0.0073 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.0095 - acc: 0.9969 - lr: 2.0972e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 671ms/step - loss: 0.0061 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.0033 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0021 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0066 - acc: 0.9979\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.0066 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 691ms/step - loss: 0.0036 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 0.9979\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 666ms/step - loss: 0.0037 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 672ms/step - loss: 0.0039 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 660ms/step - loss: 0.0028 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0042 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 654ms/step - loss: 0.0036 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0036 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 679ms/step - loss: 0.0015 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9990\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0025 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 668ms/step - loss: 0.0038 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.0025 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000    \n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 639ms/step - loss: 0.0012 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 665ms/step - loss: 0.0010 - acc: 1.0000 - lr: 6.8719e-06\n",
      "15/15 [==============================] - 5s 225ms/step - loss: 0.2577 - acc: 0.9292\n",
      "Test loss: 0.2577410042285919\n",
      "Test accuracy: 0.9291666746139526\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31eec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[7.30683729e-02 9.26931620e-01]\n",
      " [9.99991179e-01 8.79620075e-06]\n",
      " [1.00000000e+00 4.50106308e-09]\n",
      " [1.00000000e+00 1.52232049e-09]\n",
      " [1.00000000e+00 5.68858294e-10]\n",
      " [1.00000000e+00 5.15940658e-11]\n",
      " [1.00000000e+00 9.93183313e-09]\n",
      " [9.89014447e-01 1.09854974e-02]\n",
      " [9.99974251e-01 2.58071159e-05]\n",
      " [9.99939561e-01 6.04602064e-05]\n",
      " [1.00000000e+00 3.45551907e-12]\n",
      " [9.99999166e-01 8.75094941e-07]\n",
      " [1.00000000e+00 2.02229650e-10]\n",
      " [1.00000000e+00 4.87907353e-11]\n",
      " [1.00000000e+00 2.97927237e-14]\n",
      " [9.99999762e-01 2.60140297e-07]\n",
      " [9.99982953e-01 1.70710518e-05]\n",
      " [1.00000000e+00 1.33283819e-13]\n",
      " [1.00000000e+00 1.31978322e-08]\n",
      " [1.00000000e+00 2.83747567e-16]\n",
      " [1.00000000e+00 2.14753059e-11]\n",
      " [1.00000000e+00 8.55299772e-12]\n",
      " [9.99999881e-01 1.09333179e-07]\n",
      " [1.00000000e+00 1.54752155e-12]\n",
      " [9.98897314e-01 1.10261585e-03]\n",
      " [9.99999881e-01 1.31831698e-07]\n",
      " [1.00000000e+00 1.39616063e-09]\n",
      " [9.41662788e-01 5.83371930e-02]\n",
      " [1.00000000e+00 6.32281449e-10]\n",
      " [1.00000000e+00 2.30412889e-09]\n",
      " [9.99998331e-01 1.61199307e-06]\n",
      " [1.00000000e+00 3.57816451e-13]\n",
      " [1.00000000e+00 2.66206683e-08]\n",
      " [1.00000000e+00 3.55287133e-10]\n",
      " [1.00000000e+00 1.75153766e-10]\n",
      " [9.99999881e-01 7.95064636e-08]\n",
      " [9.99999762e-01 1.94185901e-07]\n",
      " [1.00000000e+00 1.05539666e-08]\n",
      " [1.00000000e+00 6.48731957e-09]\n",
      " [1.00000000e+00 9.77893100e-10]\n",
      " [1.00000000e+00 5.80023226e-12]\n",
      " [9.99999881e-01 9.06476529e-08]\n",
      " [1.00000000e+00 3.83637513e-08]\n",
      " [1.00000000e+00 7.07370759e-11]\n",
      " [1.00000000e+00 4.38605596e-10]\n",
      " [1.00000000e+00 4.53709248e-09]\n",
      " [9.99997020e-01 2.96837379e-06]\n",
      " [9.99957204e-01 4.28120911e-05]\n",
      " [1.00000000e+00 5.56504043e-09]\n",
      " [9.96601462e-01 3.39846895e-03]\n",
      " [9.99996901e-01 3.15222633e-06]\n",
      " [1.00000000e+00 4.59852906e-10]\n",
      " [9.99999881e-01 1.64905813e-07]\n",
      " [1.00000000e+00 2.59814251e-13]\n",
      " [1.00000000e+00 2.61292377e-12]\n",
      " [1.00000000e+00 2.56137490e-15]\n",
      " [9.97797847e-01 2.20221723e-03]\n",
      " [9.88481164e-01 1.15188630e-02]\n",
      " [9.96874809e-01 3.12519330e-03]\n",
      " [9.99583185e-01 4.16830677e-04]\n",
      " [9.98126328e-01 1.87361625e-03]\n",
      " [1.00000000e+00 4.49813946e-08]\n",
      " [9.99993920e-01 6.05354671e-06]\n",
      " [9.99995232e-01 4.75216439e-06]\n",
      " [9.99947309e-01 5.26505137e-05]\n",
      " [1.00000000e+00 8.78153193e-12]\n",
      " [9.99993086e-01 6.86526846e-06]\n",
      " [9.99999881e-01 1.77201443e-07]\n",
      " [1.00000000e+00 1.39151603e-13]\n",
      " [1.00000000e+00 4.70129935e-10]\n",
      " [1.00000000e+00 1.83009075e-09]\n",
      " [9.99961972e-01 3.80453384e-05]\n",
      " [1.00000000e+00 4.20519441e-09]\n",
      " [9.85208988e-01 1.47910845e-02]\n",
      " [1.00000000e+00 4.01613356e-08]\n",
      " [9.99999881e-01 8.61334186e-08]\n",
      " [1.00000000e+00 2.55121410e-11]\n",
      " [1.00000000e+00 6.18573974e-15]\n",
      " [1.00000000e+00 7.66134356e-09]\n",
      " [1.00000000e+00 1.10361835e-16]\n",
      " [1.00000000e+00 1.03606665e-14]\n",
      " [1.00000000e+00 2.41726136e-11]\n",
      " [9.99999881e-01 1.43874971e-07]\n",
      " [1.00000000e+00 1.33677748e-12]\n",
      " [1.00000000e+00 1.06581563e-14]\n",
      " [9.98161137e-01 1.83888676e-03]\n",
      " [9.99999762e-01 2.08242270e-07]\n",
      " [1.00000000e+00 1.44407565e-12]\n",
      " [1.00000000e+00 1.07374363e-16]\n",
      " [9.99950767e-01 4.92612053e-05]\n",
      " [1.00000000e+00 9.97187888e-10]\n",
      " [1.00000000e+00 6.68557432e-11]\n",
      " [1.00000000e+00 4.25238837e-12]\n",
      " [9.99961972e-01 3.80693309e-05]\n",
      " [1.00000000e+00 4.65247361e-08]\n",
      " [9.99977708e-01 2.22937579e-05]\n",
      " [1.00000000e+00 1.04796768e-10]\n",
      " [1.00000000e+00 1.36195416e-10]\n",
      " [9.99999166e-01 8.61631349e-07]\n",
      " [1.00000000e+00 5.00964035e-08]\n",
      " [1.00000000e+00 4.24215720e-08]\n",
      " [1.00000000e+00 1.66764380e-11]\n",
      " [9.99999881e-01 1.04541378e-07]\n",
      " [1.00000000e+00 4.66504890e-11]\n",
      " [9.99905229e-01 9.47136359e-05]\n",
      " [9.97916996e-01 2.08299467e-03]\n",
      " [9.94271159e-01 5.72888041e-03]\n",
      " [8.96191239e-01 1.03808768e-01]\n",
      " [9.42667007e-01 5.73330335e-02]\n",
      " [9.99817789e-01 1.82253090e-04]\n",
      " [1.00000000e+00 7.27241574e-12]\n",
      " [6.82388172e-02 9.31761205e-01]\n",
      " [9.99999285e-01 6.74214505e-07]\n",
      " [1.00000000e+00 2.12142630e-11]\n",
      " [1.00000000e+00 8.65349625e-10]\n",
      " [9.99938965e-01 6.09828494e-05]\n",
      " [1.00000000e+00 1.11374972e-12]\n",
      " [1.00000000e+00 2.05593517e-13]\n",
      " [1.00000000e+00 9.02671327e-10]\n",
      " [1.00000000e+00 9.39513178e-09]\n",
      " [9.98000681e-01 1.99932931e-03]\n",
      " [9.99972343e-01 2.76624469e-05]\n",
      " [9.96648848e-01 3.35114333e-03]\n",
      " [1.00000000e+00 1.63447442e-08]\n",
      " [2.56040436e-03 9.97439623e-01]\n",
      " [1.00000000e+00 2.31975120e-10]\n",
      " [7.25134974e-04 9.99274909e-01]\n",
      " [1.00000000e+00 2.37820735e-10]\n",
      " [9.99999881e-01 1.33680885e-07]\n",
      " [1.00000000e+00 5.13068588e-10]\n",
      " [1.00000000e+00 2.68766537e-10]\n",
      " [1.00000000e+00 4.87608478e-12]\n",
      " [1.00000000e+00 4.54273355e-11]\n",
      " [1.00000000e+00 6.38472556e-15]\n",
      " [9.99999762e-01 2.76904188e-07]\n",
      " [1.00000000e+00 5.06419819e-12]\n",
      " [9.99993920e-01 6.13868133e-06]\n",
      " [9.99863625e-01 1.36376359e-04]\n",
      " [1.00000000e+00 1.79681530e-11]\n",
      " [9.99989986e-01 1.00162624e-05]\n",
      " [4.29741522e-06 9.99995708e-01]\n",
      " [1.00000000e+00 3.87823285e-14]\n",
      " [9.57536399e-01 4.24635410e-02]\n",
      " [1.21609716e-18 1.00000000e+00]\n",
      " [9.97753441e-01 2.24655028e-03]\n",
      " [8.30606575e-36 1.00000000e+00]\n",
      " [1.19657365e-23 1.00000000e+00]\n",
      " [5.40073512e-22 1.00000000e+00]\n",
      " [1.32481174e-20 1.00000000e+00]\n",
      " [2.00714452e-14 1.00000000e+00]\n",
      " [3.13240373e-21 1.00000000e+00]\n",
      " [2.05123502e-13 1.00000000e+00]\n",
      " [5.63136619e-29 1.00000000e+00]\n",
      " [2.58371422e-08 1.00000000e+00]\n",
      " [4.20952176e-07 9.99999523e-01]\n",
      " [9.99400139e-01 5.99821331e-04]\n",
      " [4.57959038e-24 1.00000000e+00]\n",
      " [2.30009155e-03 9.97699916e-01]\n",
      " [1.00000000e+00 1.22766453e-09]\n",
      " [1.54788030e-10 1.00000000e+00]\n",
      " [9.99901652e-01 9.82787969e-05]\n",
      " [2.45294362e-16 1.00000000e+00]\n",
      " [1.21748243e-07 9.99999881e-01]\n",
      " [1.96888838e-19 1.00000000e+00]\n",
      " [1.06956069e-10 1.00000000e+00]\n",
      " [2.33288445e-18 1.00000000e+00]\n",
      " [7.30271131e-05 9.99926925e-01]\n",
      " [9.99951720e-01 4.82891555e-05]\n",
      " [1.27432864e-09 1.00000000e+00]\n",
      " [1.45792211e-19 1.00000000e+00]\n",
      " [9.89806534e-15 1.00000000e+00]\n",
      " [3.40656329e-23 1.00000000e+00]\n",
      " [1.32811929e-15 1.00000000e+00]\n",
      " [8.13446465e-14 1.00000000e+00]\n",
      " [7.82138824e-01 2.17861116e-01]\n",
      " [6.12881922e-06 9.99993920e-01]\n",
      " [3.98817051e-35 1.00000000e+00]\n",
      " [8.56227815e-01 1.43772155e-01]\n",
      " [9.99954581e-01 4.54504625e-05]\n",
      " [1.49863993e-03 9.98501420e-01]\n",
      " [1.24803085e-19 1.00000000e+00]\n",
      " [4.76557826e-33 1.00000000e+00]\n",
      " [1.81552426e-08 1.00000000e+00]\n",
      " [5.73158015e-29 1.00000000e+00]\n",
      " [2.05390849e-17 1.00000000e+00]\n",
      " [2.60338495e-25 1.00000000e+00]\n",
      " [2.01462444e-28 1.00000000e+00]\n",
      " [2.33575637e-14 1.00000000e+00]\n",
      " [7.61582971e-01 2.38417000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [2.68005967e-24 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [4.88282448e-30 1.00000000e+00]\n",
      " [7.01770661e-23 1.00000000e+00]\n",
      " [2.90319458e-14 1.00000000e+00]\n",
      " [1.27214798e-06 9.99998689e-01]\n",
      " [5.58940307e-12 1.00000000e+00]\n",
      " [3.45145874e-02 9.65485334e-01]\n",
      " [2.14584745e-30 1.00000000e+00]\n",
      " [1.09594926e-01 8.90405118e-01]\n",
      " [1.26901725e-08 1.00000000e+00]\n",
      " [9.15107365e-11 1.00000000e+00]\n",
      " [2.31506674e-05 9.99976873e-01]\n",
      " [5.41170012e-17 1.00000000e+00]\n",
      " [1.73113330e-27 1.00000000e+00]\n",
      " [1.84240083e-21 1.00000000e+00]\n",
      " [8.26152835e-09 1.00000000e+00]\n",
      " [5.19578345e-02 9.48042154e-01]\n",
      " [1.77095634e-19 1.00000000e+00]\n",
      " [1.76634330e-06 9.99998212e-01]\n",
      " [3.21225616e-06 9.99996781e-01]\n",
      " [9.20699775e-01 7.93002397e-02]\n",
      " [1.77558058e-37 1.00000000e+00]\n",
      " [1.10963018e-30 1.00000000e+00]\n",
      " [1.87897545e-04 9.99812186e-01]\n",
      " [1.85520469e-06 9.99998093e-01]\n",
      " [9.99445856e-01 5.54182450e-04]\n",
      " [3.26585894e-12 1.00000000e+00]\n",
      " [5.47162972e-06 9.99994516e-01]\n",
      " [9.86114383e-01 1.38856489e-02]\n",
      " [3.25405650e-35 1.00000000e+00]\n",
      " [7.79879512e-04 9.99220133e-01]\n",
      " [6.59799203e-02 9.34020102e-01]\n",
      " [8.57717275e-09 1.00000000e+00]\n",
      " [1.05064702e-26 1.00000000e+00]\n",
      " [6.83465839e-19 1.00000000e+00]\n",
      " [6.82346069e-07 9.99999285e-01]\n",
      " [1.54975699e-24 1.00000000e+00]\n",
      " [2.87474061e-21 1.00000000e+00]\n",
      " [2.20188797e-01 7.79811144e-01]\n",
      " [6.66113215e-12 1.00000000e+00]\n",
      " [1.58986230e-27 1.00000000e+00]\n",
      " [2.93728930e-09 1.00000000e+00]\n",
      " [1.04295873e-21 1.00000000e+00]\n",
      " [1.23386051e-15 1.00000000e+00]\n",
      " [5.42573282e-18 1.00000000e+00]\n",
      " [2.39904546e-18 1.00000000e+00]\n",
      " [1.75898733e-17 1.00000000e+00]\n",
      " [1.73801479e-12 1.00000000e+00]\n",
      " [8.41050621e-07 9.99999166e-01]]\n",
      "Confusion Matrix\n",
      "[[138   5]\n",
      " [ 12  85]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.92      0.97      0.94       143\n",
      "    referable       0.94      0.88      0.91        97\n",
      "\n",
      "     accuracy                           0.93       240\n",
      "    macro avg       0.93      0.92      0.93       240\n",
      " weighted avg       0.93      0.93      0.93       240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50','bam')            \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64f21ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot_metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (0.24.2)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot_metric) (3.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (0.10.0)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot_metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot_metric) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot_metric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot_metric) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6920d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aab283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
