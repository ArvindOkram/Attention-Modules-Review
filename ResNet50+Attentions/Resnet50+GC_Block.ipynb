{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "def GC_Block(inputs,ratio = 16):\n",
    "    shape=K.int_shape(inputs)\n",
    "    ch = shape[3]\n",
    "    conv =  Conv2D(1,1, padding='same') (inputs)\n",
    "    print(conv.shape)\n",
    "    d = shape[1]*shape[2]\n",
    "    reshpe = tf.keras.layers.Reshape((1,1,d),input_shape=(1,1,shape[1],shape[2]))(conv)\n",
    "    print(reshpe.shape)\n",
    "    sm = tf.keras.layers.Softmax()(reshpe)\n",
    "    print(sm.shape)\n",
    "\n",
    "\n",
    "    reshpe = tf.keras.layers.Reshape((shape[3],d),input_shape=(shape[1],shape[2],shape[3]))(inputs)\n",
    "    print(reshpe.shape)\n",
    "    mul = tf.keras.layers.Dot(axes=-1)([reshpe,sm])\n",
    "  #mul = tf.keras.layers.Attention(use_scale=False, score_mode=\"dot\")([reshpe,sm])\n",
    "    new_shape = K.int_shape(mul)\n",
    "    print(new_shape)\n",
    "    reshpe = tf.keras.layers.Reshape((1,1,new_shape[1]),input_shape=(new_shape[1],new_shape[2],new_shape[3]))(mul)\n",
    "    print(reshpe.shape)\n",
    "    x = Conv2D(ch//ratio,1)(reshpe)\n",
    "  #print(x.shape)\n",
    "    x = tf.keras.layers.LayerNormalization() (x)\n",
    "  #print(x.shape)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = Conv2D(ch,1, padding='same')(x)\n",
    "  #print(x.shape)\n",
    "    gc_attend = tf.keras.layers.Add()([inputs, x])\n",
    "  #print(gc_attend.shape)\n",
    "    return gc_attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+'gc.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+'gc.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': \n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': \n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+GC_Block.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16, 16, 1)\n",
      "(None, 1, 1, 256)\n",
      "(None, 1, 1, 256)\n",
      "(None, 2048, 256)\n",
      "(None, 2048, 1, 1)\n",
      "(None, 1, 1, 2048)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 1)    2049        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 256)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2048, 256)    0           ['conv5_block3_out[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 1, 1, 256)    0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 2048, 1, 1)   0           ['reshape_1[0][0]',              \n",
      "                                                                  'softmax[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 2048)   0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 1, 1, 128)    262272      ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 1, 1, 128)   256         ['conv2d_1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 1, 1, 128)    0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 1, 1, 2048)   264192      ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 2048  0           ['conv5_block3_out[0][0]',       \n",
      "                                )                                 'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['add[0][0]']                    \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            4098        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,120,579\n",
      "Trainable params: 24,067,459\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "#red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=GC_Block(base_out)\n",
    "\n",
    "\n",
    "shape=K.int_shape(x)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 12:55:09.214708: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 1.2529 - acc: 0.6115\n",
      "Epoch 1: acc improved from -inf to 0.61146, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 38s 526ms/step - loss: 1.2529 - acc: 0.6115 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5115 - acc: 0.7406\n",
      "Epoch 1: acc improved from 0.61146 to 0.74063, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 44s 611ms/step - loss: 0.5115 - acc: 0.7406 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3907 - acc: 0.8260\n",
      "Epoch 2: acc improved from 0.74063 to 0.82604, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 38s 614ms/step - loss: 0.3907 - acc: 0.8260 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3274 - acc: 0.8635\n",
      "Epoch 3: acc improved from 0.82604 to 0.86354, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 36s 593ms/step - loss: 0.3274 - acc: 0.8635 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3062 - acc: 0.8677\n",
      "Epoch 4: acc improved from 0.86354 to 0.86771, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.3062 - acc: 0.8677 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2969 - acc: 0.8771\n",
      "Epoch 5: acc improved from 0.86771 to 0.87708, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 37s 606ms/step - loss: 0.2969 - acc: 0.8771 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2767 - acc: 0.8938\n",
      "Epoch 6: acc improved from 0.87708 to 0.89375, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.2767 - acc: 0.8938 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2453 - acc: 0.9010\n",
      "Epoch 7: acc improved from 0.89375 to 0.90104, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 41s 674ms/step - loss: 0.2453 - acc: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2371 - acc: 0.9104\n",
      "Epoch 8: acc improved from 0.90104 to 0.91042, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 39s 627ms/step - loss: 0.2371 - acc: 0.9104 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2390 - acc: 0.9052\n",
      "Epoch 9: acc did not improve from 0.91042\n",
      "60/60 [==============================] - 36s 577ms/step - loss: 0.2390 - acc: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2397 - acc: 0.9115\n",
      "Epoch 10: acc improved from 0.91042 to 0.91146, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 41s 657ms/step - loss: 0.2397 - acc: 0.9115 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2309 - acc: 0.9094\n",
      "Epoch 11: acc did not improve from 0.91146\n",
      "60/60 [==============================] - 38s 613ms/step - loss: 0.2309 - acc: 0.9094 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2116 - acc: 0.9177\n",
      "Epoch 12: acc improved from 0.91146 to 0.91771, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 41s 673ms/step - loss: 0.2116 - acc: 0.9177 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1789 - acc: 0.9281\n",
      "Epoch 13: acc improved from 0.91771 to 0.92813, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 39s 644ms/step - loss: 0.1789 - acc: 0.9281 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2202 - acc: 0.9135\n",
      "Epoch 14: acc did not improve from 0.92813\n",
      "60/60 [==============================] - 38s 628ms/step - loss: 0.2202 - acc: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1958 - acc: 0.9281\n",
      "Epoch 15: acc did not improve from 0.92813\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.1958 - acc: 0.9281 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1935 - acc: 0.9250\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 16: acc did not improve from 0.92813\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.1935 - acc: 0.9250 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1848 - acc: 0.9271\n",
      "Epoch 17: acc did not improve from 0.92813\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.1848 - acc: 0.9271 - lr: 8.0000e-05\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1378 - acc: 0.9417\n",
      "Epoch 18: acc improved from 0.92813 to 0.94167, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 43s 683ms/step - loss: 0.1378 - acc: 0.9417 - lr: 8.0000e-05\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1704 - acc: 0.9365\n",
      "Epoch 19: acc did not improve from 0.94167\n",
      "60/60 [==============================] - 38s 626ms/step - loss: 0.1704 - acc: 0.9365 - lr: 8.0000e-05\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1637 - acc: 0.9438\n",
      "Epoch 20: acc improved from 0.94167 to 0.94375, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 42s 690ms/step - loss: 0.1637 - acc: 0.9438 - lr: 8.0000e-05\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1013 - acc: 0.9646\n",
      "Epoch 21: acc improved from 0.94375 to 0.96458, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 40s 655ms/step - loss: 0.1013 - acc: 0.9646 - lr: 8.0000e-05\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1304 - acc: 0.9510\n",
      "Epoch 22: acc did not improve from 0.96458\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.1304 - acc: 0.9510 - lr: 8.0000e-05\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1332 - acc: 0.9490\n",
      "Epoch 23: acc did not improve from 0.96458\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.1332 - acc: 0.9490 - lr: 8.0000e-05\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0954 - acc: 0.9688\n",
      "Epoch 24: acc improved from 0.96458 to 0.96875, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 42s 694ms/step - loss: 0.0954 - acc: 0.9688 - lr: 8.0000e-05\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0946 - acc: 0.9615\n",
      "Epoch 25: acc did not improve from 0.96875\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.0946 - acc: 0.9615 - lr: 8.0000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0908 - acc: 0.9677\n",
      "Epoch 26: acc did not improve from 0.96875\n",
      "60/60 [==============================] - 38s 621ms/step - loss: 0.0908 - acc: 0.9677 - lr: 8.0000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0907 - acc: 0.9646\n",
      "Epoch 27: acc did not improve from 0.96875\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0907 - acc: 0.9646 - lr: 8.0000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0847 - acc: 0.9698\n",
      "Epoch 28: acc improved from 0.96875 to 0.96979, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 43s 706ms/step - loss: 0.0847 - acc: 0.9698 - lr: 8.0000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0810 - acc: 0.9729\n",
      "Epoch 29: acc improved from 0.96979 to 0.97292, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 40s 646ms/step - loss: 0.0810 - acc: 0.9729 - lr: 8.0000e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1449 - acc: 0.9615\n",
      "Epoch 30: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 39s 633ms/step - loss: 0.1449 - acc: 0.9615 - lr: 8.0000e-05\n",
      "Epoch 31/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.1133 - acc: 0.9563\n",
      "Epoch 31: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.1133 - acc: 0.9563 - lr: 8.0000e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0772 - acc: 0.9708\n",
      "Epoch 32: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 38s 610ms/step - loss: 0.0772 - acc: 0.9708 - lr: 8.0000e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1038 - acc: 0.9552\n",
      "Epoch 33: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 42s 657ms/step - loss: 0.1038 - acc: 0.9552 - lr: 8.0000e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0742 - acc: 0.9740\n",
      "Epoch 34: acc improved from 0.97292 to 0.97396, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 42s 681ms/step - loss: 0.0742 - acc: 0.9740 - lr: 8.0000e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0584 - acc: 0.9802\n",
      "Epoch 35: acc improved from 0.97396 to 0.98021, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0584 - acc: 0.9802 - lr: 8.0000e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.9875\n",
      "Epoch 36: acc improved from 0.98021 to 0.98750, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 46s 757ms/step - loss: 0.0551 - acc: 0.9875 - lr: 8.0000e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0432 - acc: 0.9896\n",
      "Epoch 37: acc improved from 0.98750 to 0.98958, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.0432 - acc: 0.9896 - lr: 8.0000e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0437 - acc: 0.9802\n",
      "Epoch 38: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 38s 614ms/step - loss: 0.0437 - acc: 0.9802 - lr: 8.0000e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.9760\n",
      "Epoch 39: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 38s 619ms/step - loss: 0.0601 - acc: 0.9760 - lr: 8.0000e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0614 - acc: 0.9760\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 40: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 41s 647ms/step - loss: 0.0614 - acc: 0.9760 - lr: 8.0000e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0817 - acc: 0.9729\n",
      "Epoch 41: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 0.0817 - acc: 0.9729 - lr: 6.4000e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0707 - acc: 0.9771\n",
      "Epoch 42: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0707 - acc: 0.9771 - lr: 6.4000e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.9771\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 43: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 39s 639ms/step - loss: 0.0650 - acc: 0.9771 - lr: 6.4000e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0323 - acc: 0.9906\n",
      "Epoch 44: acc improved from 0.98958 to 0.99063, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 41s 667ms/step - loss: 0.0323 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.9875\n",
      "Epoch 45: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0339 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 46: acc improved from 0.99063 to 0.99271, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 42s 692ms/step - loss: 0.0258 - acc: 0.9927 - lr: 5.1200e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9969\n",
      "Epoch 47: acc improved from 0.99271 to 0.99687, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0140 - acc: 0.9969 - lr: 5.1200e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0195 - acc: 0.9958\n",
      "Epoch 48: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0195 - acc: 0.9958 - lr: 5.1200e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0130 - acc: 0.9969\n",
      "Epoch 49: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.0130 - acc: 0.9969 - lr: 5.1200e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.9906\n",
      "Epoch 50: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 40s 660ms/step - loss: 0.0247 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.9917\n",
      "Epoch 51: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 623ms/step - loss: 0.0208 - acc: 0.9917 - lr: 5.1200e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0169 - acc: 0.9958\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 52: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 41s 645ms/step - loss: 0.0169 - acc: 0.9958 - lr: 5.1200e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0335 - acc: 0.9958\n",
      "Epoch 53: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0335 - acc: 0.9958 - lr: 4.0960e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 54: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 39s 638ms/step - loss: 0.0312 - acc: 0.9917 - lr: 4.0960e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0317 - acc: 0.9927\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 55: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 39s 616ms/step - loss: 0.0317 - acc: 0.9927 - lr: 4.0960e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 56: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 41s 652ms/step - loss: 0.0124 - acc: 0.9958 - lr: 3.2768e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9979\n",
      "Epoch 57: acc improved from 0.99687 to 0.99792, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 41s 665ms/step - loss: 0.0138 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 58: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 611ms/step - loss: 0.0097 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0125 - acc: 0.9979\n",
      "Epoch 59: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0125 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0085 - acc: 0.9979\n",
      "Epoch 60: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 41s 649ms/step - loss: 0.0085 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0062 - acc: 0.9990\n",
      "Epoch 61: acc improved from 0.99792 to 0.99896, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 41s 672ms/step - loss: 0.0062 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.9969\n",
      "Epoch 62: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0127 - acc: 0.9969 - lr: 3.2768e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9979\n",
      "Epoch 63: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0106 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0088 - acc: 0.9979\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 64: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.0088 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9979\n",
      "Epoch 65: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 41s 649ms/step - loss: 0.0087 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9990\n",
      "Epoch 66: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 614ms/step - loss: 0.0177 - acc: 0.9990 - lr: 2.6214e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9990\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 67: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0075 - acc: 0.9990 - lr: 2.6214e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9979\n",
      "Epoch 68: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.0053 - acc: 0.9979 - lr: 2.0972e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9990\n",
      "Epoch 69: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0059 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9979\n",
      "Epoch 70: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 40s 646ms/step - loss: 0.0059 - acc: 0.9979 - lr: 2.0972e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 71: acc improved from 0.99896 to 1.00000, saving model to resnet50+GC_Block.hdf5\n",
      "60/60 [==============================] - 42s 684ms/step - loss: 0.0047 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9990\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 629ms/step - loss: 0.0056 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.0031 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.0074 - acc: 0.9969 - lr: 2.0972e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0103 - acc: 0.9990\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 636ms/step - loss: 0.0103 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 654ms/step - loss: 0.0047 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.0044 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9990\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.0051 - acc: 0.9990 - lr: 1.6777e-05\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9979\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.0044 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.0025 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9979\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0053 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9969\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.0052 - acc: 0.9969 - lr: 1.3422e-05\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0122 - acc: 0.9979\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 639ms/step - loss: 0.0122 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9979\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.0073 - acc: 0.9979 - lr: 1.0737e-05\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9990\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.0052 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0029 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 628ms/step - loss: 0.0033 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 668ms/step - loss: 0.0045 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0030 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 660ms/step - loss: 0.0018 - acc: 1.0000 - lr: 6.8719e-06\n",
      "15/15 [==============================] - 4s 189ms/step - loss: 0.3065 - acc: 0.9083\n",
      "Test loss: 0.30648136138916016\n",
      "Test accuracy: 0.9083333611488342\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.90078211e-01 9.92183201e-03]\n",
      " [9.99999881e-01 9.20642549e-08]\n",
      " [1.00000000e+00 8.12143495e-12]\n",
      " [1.00000000e+00 1.15339194e-09]\n",
      " [1.00000000e+00 9.74065412e-11]\n",
      " [1.00000000e+00 1.29258167e-11]\n",
      " [1.00000000e+00 1.10909246e-08]\n",
      " [7.12238997e-02 9.28776085e-01]\n",
      " [9.99999762e-01 2.09551942e-07]\n",
      " [9.99990106e-01 9.91777961e-06]\n",
      " [1.00000000e+00 4.27919158e-11]\n",
      " [9.99999642e-01 3.19596467e-07]\n",
      " [8.71860623e-01 1.28139317e-01]\n",
      " [1.00000000e+00 2.02048280e-08]\n",
      " [1.00000000e+00 7.60010197e-12]\n",
      " [9.98353362e-01 1.64670730e-03]\n",
      " [9.99487162e-01 5.12859842e-04]\n",
      " [1.00000000e+00 4.89482446e-08]\n",
      " [9.99996066e-01 3.95026200e-06]\n",
      " [1.00000000e+00 3.58299595e-15]\n",
      " [1.00000000e+00 3.38691786e-09]\n",
      " [1.00000000e+00 2.57817989e-09]\n",
      " [1.00000000e+00 3.00348324e-09]\n",
      " [9.99999881e-01 7.80394913e-08]\n",
      " [9.77815509e-01 2.21844930e-02]\n",
      " [9.99967813e-01 3.22038795e-05]\n",
      " [4.47981805e-02 9.55201805e-01]\n",
      " [1.14844907e-02 9.88515556e-01]\n",
      " [1.00000000e+00 9.40344957e-09]\n",
      " [1.00000000e+00 1.62602842e-09]\n",
      " [9.99959588e-01 4.04402927e-05]\n",
      " [9.71580088e-01 2.84199268e-02]\n",
      " [9.99996305e-01 3.65972869e-06]\n",
      " [1.00000000e+00 5.96029302e-12]\n",
      " [1.00000000e+00 5.24112087e-09]\n",
      " [1.00000000e+00 1.99834940e-08]\n",
      " [1.00000000e+00 1.33053781e-08]\n",
      " [9.99967933e-01 3.20471481e-05]\n",
      " [1.00000000e+00 6.65916988e-10]\n",
      " [1.00000000e+00 2.48447307e-08]\n",
      " [1.00000000e+00 1.97574964e-12]\n",
      " [9.99963403e-01 3.65364649e-05]\n",
      " [9.99999762e-01 2.39740729e-07]\n",
      " [1.00000000e+00 4.42332615e-09]\n",
      " [1.00000000e+00 2.01136399e-10]\n",
      " [1.00000000e+00 9.38130817e-09]\n",
      " [9.98664021e-01 1.33593625e-03]\n",
      " [1.36488155e-02 9.86351192e-01]\n",
      " [1.00000000e+00 3.37833868e-08]\n",
      " [6.28624976e-01 3.71375024e-01]\n",
      " [9.97597992e-01 2.40199943e-03]\n",
      " [9.99999642e-01 3.96537928e-07]\n",
      " [9.99999881e-01 9.93212126e-08]\n",
      " [1.00000000e+00 6.07248163e-09]\n",
      " [1.00000000e+00 3.35264749e-09]\n",
      " [1.00000000e+00 2.06507485e-11]\n",
      " [1.65782205e-03 9.98342156e-01]\n",
      " [2.33989861e-02 9.76601005e-01]\n",
      " [8.77546370e-01 1.22453608e-01]\n",
      " [9.99999881e-01 1.08553337e-07]\n",
      " [9.68591332e-01 3.14087346e-02]\n",
      " [9.99927402e-01 7.26149083e-05]\n",
      " [9.99877453e-01 1.22581987e-04]\n",
      " [9.99999404e-01 5.94548737e-07]\n",
      " [9.99994755e-01 5.18634761e-06]\n",
      " [1.00000000e+00 2.09321172e-10]\n",
      " [9.99997377e-01 2.62454296e-06]\n",
      " [9.99999523e-01 4.99984651e-07]\n",
      " [1.00000000e+00 4.64530442e-10]\n",
      " [9.99992490e-01 7.53252880e-06]\n",
      " [1.00000000e+00 9.88187310e-09]\n",
      " [9.99985337e-01 1.46983330e-05]\n",
      " [1.00000000e+00 5.72864707e-08]\n",
      " [9.50393796e-01 4.96061593e-02]\n",
      " [1.00000000e+00 1.78071358e-09]\n",
      " [9.99985456e-01 1.45938993e-05]\n",
      " [1.00000000e+00 5.83421533e-09]\n",
      " [1.00000000e+00 3.71070931e-13]\n",
      " [1.00000000e+00 1.56963580e-08]\n",
      " [1.00000000e+00 3.05974379e-09]\n",
      " [1.00000000e+00 2.27951534e-12]\n",
      " [9.99999046e-01 9.89029331e-07]\n",
      " [9.99795735e-01 2.04293508e-04]\n",
      " [1.00000000e+00 1.59930458e-10]\n",
      " [1.00000000e+00 4.77793206e-13]\n",
      " [9.99709308e-01 2.90687225e-04]\n",
      " [9.99985695e-01 1.43641792e-05]\n",
      " [1.00000000e+00 2.79059371e-08]\n",
      " [1.00000000e+00 6.24914911e-11]\n",
      " [7.25477219e-01 2.74522811e-01]\n",
      " [8.95355791e-02 9.10464466e-01]\n",
      " [1.00000000e+00 8.22705992e-09]\n",
      " [1.00000000e+00 4.44913582e-08]\n",
      " [4.51542586e-01 5.48457444e-01]\n",
      " [9.99999523e-01 4.19971371e-07]\n",
      " [9.99807894e-01 1.92136067e-04]\n",
      " [1.00000000e+00 8.18687295e-14]\n",
      " [1.00000000e+00 2.07159823e-09]\n",
      " [9.99994516e-01 5.52278561e-06]\n",
      " [9.99996662e-01 3.29478917e-06]\n",
      " [9.99999762e-01 1.99212778e-07]\n",
      " [1.00000000e+00 2.06814649e-10]\n",
      " [1.00000000e+00 2.60535984e-08]\n",
      " [1.00000000e+00 2.54036292e-10]\n",
      " [9.99604046e-01 3.95934330e-04]\n",
      " [9.98777688e-01 1.22231781e-03]\n",
      " [9.99591291e-01 4.08762047e-04]\n",
      " [3.39586809e-02 9.66041267e-01]\n",
      " [9.99958158e-01 4.18589370e-05]\n",
      " [1.00000000e+00 4.29321894e-08]\n",
      " [1.00000000e+00 4.39809777e-12]\n",
      " [7.77085405e-03 9.92229164e-01]\n",
      " [9.99677181e-01 3.22880398e-04]\n",
      " [1.00000000e+00 4.73163071e-11]\n",
      " [9.99999523e-01 4.17812174e-07]\n",
      " [9.99807179e-01 1.92892330e-04]\n",
      " [1.00000000e+00 2.95643759e-10]\n",
      " [9.99999881e-01 1.19378043e-07]\n",
      " [9.99995708e-01 4.29886268e-06]\n",
      " [1.00000000e+00 2.92117892e-11]\n",
      " [9.95588183e-01 4.41182638e-03]\n",
      " [9.99979019e-01 2.10332237e-05]\n",
      " [1.00000000e+00 3.88058119e-09]\n",
      " [1.00000000e+00 3.26979226e-08]\n",
      " [5.82317796e-07 9.99999404e-01]\n",
      " [9.99999881e-01 9.31604873e-08]\n",
      " [9.99999285e-01 7.66422488e-07]\n",
      " [1.00000000e+00 8.76788420e-10]\n",
      " [1.00000000e+00 2.16861267e-08]\n",
      " [1.00000000e+00 1.64959446e-09]\n",
      " [9.99998093e-01 1.91421577e-06]\n",
      " [9.99996305e-01 3.67286134e-06]\n",
      " [1.00000000e+00 1.96687444e-10]\n",
      " [1.00000000e+00 2.13448638e-12]\n",
      " [9.99999762e-01 2.22640963e-07]\n",
      " [1.00000000e+00 1.69823657e-08]\n",
      " [1.67529681e-04 9.99832392e-01]\n",
      " [9.99954581e-01 4.53850553e-05]\n",
      " [1.00000000e+00 1.58305946e-09]\n",
      " [9.99988914e-01 1.10406281e-05]\n",
      " [7.93770075e-01 2.06229970e-01]\n",
      " [1.00000000e+00 4.68712742e-13]\n",
      " [1.21706545e-01 8.78293455e-01]\n",
      " [1.11874219e-16 1.00000000e+00]\n",
      " [9.95855749e-01 4.14426764e-03]\n",
      " [3.77519125e-34 1.00000000e+00]\n",
      " [6.17250652e-18 1.00000000e+00]\n",
      " [1.31496931e-11 1.00000000e+00]\n",
      " [3.36936750e-12 1.00000000e+00]\n",
      " [2.66336425e-10 1.00000000e+00]\n",
      " [1.34720652e-18 1.00000000e+00]\n",
      " [1.53683354e-18 1.00000000e+00]\n",
      " [2.38891291e-22 1.00000000e+00]\n",
      " [2.80732289e-02 9.71926808e-01]\n",
      " [1.75215009e-09 1.00000000e+00]\n",
      " [9.99998450e-01 1.53776125e-06]\n",
      " [7.22097146e-23 1.00000000e+00]\n",
      " [9.32977349e-02 9.06702280e-01]\n",
      " [1.00000000e+00 1.72985848e-09]\n",
      " [3.94046219e-11 1.00000000e+00]\n",
      " [9.99890327e-01 1.09698805e-04]\n",
      " [2.18519049e-17 1.00000000e+00]\n",
      " [4.41387649e-10 1.00000000e+00]\n",
      " [6.21246955e-20 1.00000000e+00]\n",
      " [1.34438976e-08 1.00000000e+00]\n",
      " [6.48654357e-19 1.00000000e+00]\n",
      " [6.09964081e-06 9.99993920e-01]\n",
      " [9.91170406e-01 8.82956013e-03]\n",
      " [1.34786067e-04 9.99865174e-01]\n",
      " [2.60405912e-26 1.00000000e+00]\n",
      " [1.18211716e-11 1.00000000e+00]\n",
      " [1.86373834e-17 1.00000000e+00]\n",
      " [2.70490986e-13 1.00000000e+00]\n",
      " [6.80088341e-09 1.00000000e+00]\n",
      " [6.33581638e-01 3.66418332e-01]\n",
      " [3.07946962e-12 1.00000000e+00]\n",
      " [3.44127790e-24 1.00000000e+00]\n",
      " [8.99788260e-01 1.00211725e-01]\n",
      " [9.98882115e-01 1.11786241e-03]\n",
      " [1.62899760e-05 9.99983668e-01]\n",
      " [7.86551271e-13 1.00000000e+00]\n",
      " [8.43484227e-28 1.00000000e+00]\n",
      " [7.89066590e-03 9.92109358e-01]\n",
      " [6.19408288e-20 1.00000000e+00]\n",
      " [2.64911044e-08 1.00000000e+00]\n",
      " [2.83416483e-24 1.00000000e+00]\n",
      " [9.28024237e-12 1.00000000e+00]\n",
      " [1.49650101e-11 1.00000000e+00]\n",
      " [9.99817789e-01 1.82260395e-04]\n",
      " [4.66704256e-26 1.00000000e+00]\n",
      " [2.20695847e-21 1.00000000e+00]\n",
      " [1.12954623e-20 1.00000000e+00]\n",
      " [8.03098227e-27 1.00000000e+00]\n",
      " [4.56809781e-14 1.00000000e+00]\n",
      " [1.02449515e-16 1.00000000e+00]\n",
      " [3.80299811e-04 9.99619722e-01]\n",
      " [5.66736011e-20 1.00000000e+00]\n",
      " [3.81542575e-11 1.00000000e+00]\n",
      " [4.00341640e-26 1.00000000e+00]\n",
      " [3.34734723e-05 9.99966502e-01]\n",
      " [3.47970399e-07 9.99999642e-01]\n",
      " [7.18712763e-12 1.00000000e+00]\n",
      " [2.69852020e-02 9.73014832e-01]\n",
      " [1.44954382e-10 1.00000000e+00]\n",
      " [7.89527777e-23 1.00000000e+00]\n",
      " [2.26295520e-26 1.00000000e+00]\n",
      " [1.76656238e-06 9.99998212e-01]\n",
      " [1.21348612e-05 9.99987841e-01]\n",
      " [3.31049778e-21 1.00000000e+00]\n",
      " [1.57141367e-05 9.99984264e-01]\n",
      " [7.84308504e-05 9.99921560e-01]\n",
      " [1.09025533e-03 9.98909712e-01]\n",
      " [1.27890950e-34 1.00000000e+00]\n",
      " [3.77567210e-31 1.00000000e+00]\n",
      " [6.75743893e-02 9.32425618e-01]\n",
      " [2.50139204e-03 9.97498572e-01]\n",
      " [2.55226979e-07 9.99999762e-01]\n",
      " [3.25736177e-19 1.00000000e+00]\n",
      " [8.89355533e-07 9.99999166e-01]\n",
      " [5.55671332e-03 9.94443238e-01]\n",
      " [1.30580048e-28 1.00000000e+00]\n",
      " [1.54330912e-16 1.00000000e+00]\n",
      " [8.44490433e-09 1.00000000e+00]\n",
      " [4.06853617e-09 1.00000000e+00]\n",
      " [3.67189206e-26 1.00000000e+00]\n",
      " [2.72025266e-15 1.00000000e+00]\n",
      " [2.33214450e-05 9.99976635e-01]\n",
      " [1.35719301e-14 1.00000000e+00]\n",
      " [5.02377979e-13 1.00000000e+00]\n",
      " [9.73187343e-06 9.99990225e-01]\n",
      " [3.47950231e-06 9.99996543e-01]\n",
      " [7.24162679e-17 1.00000000e+00]\n",
      " [2.58267930e-12 1.00000000e+00]\n",
      " [5.03208179e-14 1.00000000e+00]\n",
      " [4.66364967e-12 1.00000000e+00]\n",
      " [1.10234403e-15 1.00000000e+00]\n",
      " [1.06588060e-14 1.00000000e+00]\n",
      " [3.31727849e-33 1.00000000e+00]\n",
      " [3.00163133e-14 1.00000000e+00]\n",
      " [8.74306832e-04 9.99125659e-01]]\n",
      "Confusion Matrix\n",
      "[[130  13]\n",
      " [  9  88]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.94      0.91      0.92       143\n",
      "    referable       0.87      0.91      0.89        97\n",
      "\n",
      "     accuracy                           0.91       240\n",
      "    macro avg       0.90      0.91      0.91       240\n",
      " weighted avg       0.91      0.91      0.91       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGpCAYAAACam6wDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdG0lEQVR4nO3deZgldXkv8O87M4BsJoBCQFCIogiaGMUVNSioLD6ASbgXl4To5I6aKNEkBozmel3Ixavxhhi3cQODoCgaiV5R7xgEjWxxZVMIREQRkEWIQYHpX/7oM9hMZnqGprvPqarPZ556Tp2qOlXv6Yd++uV9f7+qaq0FAKDLlow7AACAe0tCAwB0noQGAOg8CQ0A0HkSGgCg85aNO4D1uePHV5h+BWOw3YP2H3cIMFi3/PSKWszrzeff2k3u96uLGvvaVGgAgM6b2AoNALDAplaPO4J5I6EBgKFqU+OOYN5oOQEAnadCAwBDNdWfCo2EBgAGqmk5AQBMDhUaABgqLScAoPO0nAAAJocKDQAMlRvrAQCdp+UEADA5VGgAYKjMcgIAus6N9QAAJogKDQAMlZYTANB5Wk4AAJNDhQYAhsqN9QCAztNyAgCYHCo0ADBUZjkBAJ2n5QQAMDlUaABgqLScAICua60/07a1nACAzpPQAMBQtan5Wzagqj5QVddV1YUztr2lqi6tqm9V1Ser6pdn7Ht1VV1eVd+pqmdt6PwSGgAYqqmp+Vs27IQkB6y17QtJHtFa+7Uk303y6iSpqj2THJFkr9Fn3llVS2c7uYQGAIZqESs0rbWzkty41rbPt9buHL09J8nOo/VDk3yktfbz1tqVSS5P8rjZzi+hAQDutapaUVUXzFhW3MNTvCjJZ0frD0jy/Rn7rh5tWy+znABgqObx4ZSttZVJVs7ls1X1miR3Jvnwmk3rusRs55DQAMBQTcCdgqvqyCTPTrJfa21N0nJ1kl1mHLZzkh/Odh4tJwBgLKrqgCRHJzmktfYfM3adnuSIqtqsqnZLsnuS82Y7lwoNAAzVIt4puKpOSbJvkvtV1dVJXpfpWU2bJflCVSXJOa21l7TWLqqqU5NcnOlW1B+1DdwFUEIDAEO1iC2n1tpz17H5/bMcf2ySYzf2/FpOAEDnqdAAwFB5OCUA0Hk9Smi0nACAzlOhAYCB2sDEoU6R0ADAUGk5AQBMDhUaABiqCXj0wXyR0ADAUGk5AQBMDhUaABgqLScAoPO0nAAAJocKDQAMlZYTANB5Wk4AAJNDhQYAhqpHFRoJDQAMVY/G0Gg5AQCdp0IDAEOl5QQAdJ6WEwDA5FChAYCh0nICADpPywkAYHKo0ADAUGk5AQCd16OERssJAOg8FRoAGKrWxh3BvJHQAMBQaTkBAEwOFRoAGKoeVWgkNAAwVG6sBwAwOVRoAGCotJwAgM7r0bRtLScAoPNUaABgqLScAIDO61FCo+UEAHSeCg0ADFWP7kMjoQGAgWpTZjkBAEwMFRoAGKoeDQqW0ADAUPVoDI2WEwDQeSo0ADBUPRoULKEBgKEyhgYA6LweJTTG0AAAnadCAwBD1YyhAQC6TssJAGByqNBwj732r96Ws75yXrbd5pfzDye9O0ny9pUfyhe//NUsqSXZdptfyrGv+dNsf//tkiTv/dBH84lPfy5LlyzJq1/50uzz+MeMM3zojXe868054MCn5frrb8gTHntgkuS1f/nKHPTsZ2Rqaio/vv6GvGTFq/KjH1035kiZWD2atq1Cwz122EHPyLvf9qa7bXvh8387n/zQu3Laie/Ib+7z+LzrgycnSf71yu/ls6u+lE+d9O68+21vyhvf+ndZvXr1OMKG3vnwSR/Pbx32wrttO/5v3psnPf6gPPmJz84Zn/1ijn71UWOKjk5oU/O3bEBVfaCqrquqC2ds27aqvlBVl41et5mx79VVdXlVfaeqnrWh80touMf2ftQj80v33fpu27bacsu71m+77Wepml7/4tnn5MD9fjObbrppdt7pV/LAnXfKty/57mKGC731z185PzfdePPdtt1667/ftb7Flluk9WjQJ513QpID1tp2TJJVrbXdk6wavU9V7ZnkiCR7jT7zzqpaOtvJtZyYN8e/54ScfsaqbL3llvnA249Lklx3/Q35tUfscdcxO2x/v1x3/Y/HFSIMwl++7k/z3Oc9J7fccmsOPvD54w6HSbaILafW2llVtetamw9Nsu9o/cQkZyY5erT9I621nye5sqouT/K4JF9d3/kXrEJTVXtU1dFV9bdVdfxo/eEb+MyKqrqgqi5434dOWajQWCB//OLfz6pP/n0OfubTcvJp/5gkafmvvyyVWuzQYFDe+Pq/zp4Pe3JO/ejpefGLf2/c4TDB2tTUvC0z/4aPlhUbEcIOrbVrkmT0uv1o+wOSfH/GcVePtq3XgiQ0VXV0ko8kqSTnJTl/tH5KVR2zvs+11la21vZure39B7/33IUIjUVw8DP3zf8/8ytJkh3uf7/86Nrr79p37XU/zv1Hg4WBhfWxj34qhxy2waEHMC9m/g0fLSvvxenW9X++s5aTFqpCszzJY1trx7XWThotx2W6XLR8ga7JGH3v+z+4a/2fzj4nuz1o5yTJ0578hHx21Zdy++235+of/ihXXf3DPPLhDx1XmNB7D37wrnetH3Tw/vnud64YXzBMvqk2f8vcXFtVOybJ6HXNlLyrk+wy47idk/xwthMt1BiaqSQ7JfneWtt3HO2jw171uuNy/te/lZtvviX7HfaC/OHy383ZXz0//3bV1akllZ1+Zfv8z1e9PEnykF99UJ719KfkkOe/OMuWLs1r/uQPs3TprOO6gI30gROOz5Of8vhst902ueS7X8lfven4PPNZ+2b3h+6WqamW71/1g7ziqNeOO0wm2UbMTlpgpyc5Mslxo9dPzdh+clW9LdP5xO6Z7visVy3ECPiqOiDJ3yW5LL/ogT0wyUOSvKy1dsaGznHHj68wNB/GYLsH7T/uEGCwbvnpFYs6yPCnb3rBvP2t3fK1J80ae1WdkukBwPdLcm2S1yX5hySnZjpHuCrJ4a21G0fHvybJi5LcmeQVrbXPznb+BanQtNbOqKqHZrrF9IBM98KuTnJ+a81NSABgEizuLKf1DY7dbz3HH5vk2I09/4JN226tTSU5Z6HODwDcS57lBAAwOdxYDwCGqkfPcpLQAMBQjX+W07zRcgIAOk+FBgCGSssJAOi6ZpYTAMDkUKEBgKHScgIAOq9HCY2WEwDQeSo0ADBUPboPjYQGAIZKywkAYHKo0ADAQLUeVWgkNAAwVD1KaLScAIDOU6EBgKHq0aMPJDQAMFRaTgAAk0OFBgCGqkcVGgkNAAxUa/1JaLScAIDOU6EBgKHScgIAOq9HCY2WEwDQeSo0ADBQnuUEAHRfjxIaLScAoPNUaABgqPrzKCcJDQAMVZ/G0Gg5AQCdp0IDAEPVowqNhAYAhqpHY2i0nACAzlOhAYCB6tOgYAkNAAyVlhMAwORQoQGAgdJyAgC6r0ctJwkNAAxU61FCYwwNANB5KjQAMFQ9qtBIaABgoLScAAAmiAoNAAxVjyo0EhoAGCgtJwCACaJCAwAD1acKjYQGAAaqTwmNlhMA0HkqNAAwVK3GHcG8kdAAwEBpOQEA3ANV9cqquqiqLqyqU6rqPlW1bVV9oaouG71uM9fzS2gAYKDaVM3bMpuqekCSo5Ls3Vp7RJKlSY5IckySVa213ZOsGr2fEwkNAAxUm5q/ZSMsS7J5VS1LskWSHyY5NMmJo/0nJjlsrt9FQgMALKjW2g+SvDXJVUmuSfKT1trnk+zQWrtmdMw1Sbaf6zUkNAAwUK3VvC1VtaKqLpixrFhzndHYmEOT7JZkpyRbVtUL5vO7mOUEAAM1n7OcWmsrk6xcz+79k1zZWrs+SarqE0melOTaqtqxtXZNVe2Y5Lq5Xl+FBgBYaFcleUJVbVFVlWS/JJckOT3JkaNjjkzyqbleQIUGAAZqQ7OT5u06rZ1bVR9P8rUkdyb5eqarOVslObWqlmc66Tl8rteQ0ADAQLW2mNdqr0vyurU2/zzT1Zp7TcsJAOg8FRoAGKjFajktBgkNAAxUnxIaLScAoPNUaABgoBZzUPBCk9AAwEBpOQEATBAVGgAYqNb6U6GR0ADAQM3ns5zGTcsJAOg8FRoAGKgpLScAoOv6NIZGywkA6DwVGgAYqD7dh0ZCAwAD1ac7BWs5AQCdp0IDAAM1uJZTVT0pya4zj2+tfWiBYgIAFsGgpm1X1d8neXCSbyRZPdrckkhoAICJsDEVmr2T7Nlan4YOAQB9ug/NxiQ0Fyb5lSTXLHAsAMAi6lOpYr0JTVX9Y6ZbS1snubiqzkvy8zX7W2uHLHx4AAAbNluF5q2LFgUAsOgGMSi4tfalJKmqN7fWjp65r6renORLCxwbALCA+jSGZmNurPeMdWw7cL4DAQCYq9nG0Lw0yR8meXBVfWvGrq2T/PNCBwYALKxBDApOcnKSzyb530mOmbH91tbajQsaFQCw4IYyhuYnSX5SVUevtWurqtqqtXbVwoYGALBxNuY+NJ/J9PTtSnKfJLsl+U6SvRYwrmy+01MW8vTAevz48IeNOwRgkfRpUPAGE5rW2iNnvq+qRyd58YJFBAAsij61nDZmltPdtNa+luSxCxALAMCcbMzDKf9kxtslSR6d5PoFiwgAWBQ9muS0UWNotp6xfmemx9SctjDhAACLpU8tp1kTmqpammSr1tqrFikeAGCR9GlQ8HrH0FTVstba6ky3mAAAJtZsFZrzMp3MfKOqTk/ysSQ/XbOztfaJBY4NAFhAU+MOYB5tzBiabZPckOTp+cX9aFoSCQ0AdFhLf1pOsyU0249mOF2YXyQya/RpYDQA0HGzJTRLk2yVrDN9k9AAQMdN9eiv+WwJzTWttTcsWiQAwKKa6lHLabY7BffnWwIAvTZbhWa/RYsCAFh0gxgU3Fq7cTEDAQAWV5+mbd/jh1MCAEyajbkPDQDQQ4NoOQEA/ablBAAwQVRoAGCg+lShkdAAwED1aQyNlhMA0HkqNAAwUFP9KdBIaABgqIbyLCcAgE5QoQGAgWrjDmAeqdAAwEBNzeOyIVX1y1X18aq6tKouqaonVtW2VfWFqrps9LrNXL+LhAYAWAzHJzmjtbZHkl9PckmSY5Ksaq3tnmTV6P2caDkBwEBN1eIMCq6q+yZ5apLfT5LW2u1Jbq+qQ5PsOzrsxCRnJjl6LtdQoQGAgWrzuFTViqq6YMayYsalfjXJ9Uk+WFVfr6r3VdWWSXZorV2TJKPX7ef6XVRoAIB7rbW2MsnK9exeluTRSV7eWju3qo7PvWgvrYsKDQAM1CIOCr46ydWttXNH7z+e6QTn2qraMUlGr9fN9btIaABgoKZq/pbZtNZ+lOT7VfWw0ab9klyc5PQkR462HZnkU3P9LlpOAMBieHmSD1fVpkmuSPLCTBdWTq2q5UmuSnL4XE8uoQGAgVrMRx+01r6RZO917NpvPs4voQGAgXKnYACACaJCAwADtaHBvF0ioQGAgdqYZzB1hZYTANB5KjQAMFB9GhQsoQGAgerTGBotJwCg81RoAGCg+jQoWEIDAAPVp4RGywkA6DwVGgAYqNajQcESGgAYKC0nAIAJokIDAAPVpwqNhAYABqpPdwrWcgIAOk+FBgAGqk+PPpDQAMBA9WkMjZYTANB5KjQAMFB9qtBIaABgoMxyAgCYICo0ADBQZjkBAJ1nDA0A0HnG0AAATBAVGgAYqKke1WgkNAAwUH0aQ6PlBAB0ngoNAAxUfxpOEhoAGCwtJwCACaJCAwAD5U7BAEDn9WnatpYTANB5KjQAMFD9qc9IaABgsMxyAgCYICo0ADBQfRoULKEBgIHqTzqj5QQA9IAKDQAMVJ8GBUtoAGCg+jSGRssJAOg8FRoAGKj+1GckNAAwWH0aQ6PlBAB0ngoNAAxU61HTSUIDAAOl5QQAMEFUaABgoPp0HxoJDQAMVH/SGS0nAKAHJDQAMFBTafO2bIyqWlpVX6+qT4/eb1tVX6iqy0av28z1u0hoAGCgpuZx2Uh/nOSSGe+PSbKqtbZ7klWj93NiDA3z6uUvW57ly5+Xqsr7339y/vbt7xt3SNBbmx3wO9n0aQclrWX196/Mf6x8c5bu9MBs/qJXpjbZNG316tz2weOz+opLxx0qpKp2TnJwkmOT/Mlo86FJ9h2tn5jkzCRHz+X8KjTMm732eliWL39envikg/PoxzwjBx+0fx7ykN3GHRb0Um1zv2z6rOfk1te+JLceszxZsiSbPvHpuc9zX5yffeJDufUvVuRnHz8hmz93xbhDZYK1efxXVSuq6oIZy9r/8f1Nkj/P3Qs6O7TWrkmS0ev2c/0uEhrmzR577J5zz/1abrvtZ1m9enXOOvucHHboAeMOC3qrli5NbbpZsmRJarPNMnXTDUlrqc23mN6/xZaZuvmGMUfJJJvPllNrbWVrbe8Zy8o116mqZye5rrX2Lwv1XbScmDcXXXRp3viGo7Ptttvktttuy4EHPD0X/Ms3xx0W9FK76cf52WdOzX3/9iNpt/88d377gtz57QsydcN12eroN2fz570kqSW59fUvH3eokCT7JDmkqg5Kcp8k962qk5JcW1U7ttauqaodk1w31wsseoWmql44y767ylVTUz9dzLCYB5deenne8pZ35IzPnpL/9+kP55vfujir71w97rCgl2qLrbLJY/bJLa94Xm552eGpze6TTfbZP5vtf0huO+mdueWoI3LbSe/IFv/jz8YdKhNsPltOs16ntVe31nZure2a5IgkX2ytvSDJ6UmOHB12ZJJPzfW7jKPl9Pr17ZhZrlqyZMvFjIl58sETPpLHPf6APG2/385NN92cyy6/ctwhQS8te8RjMnX9NWm3/iRZvTq3n392lu2+VzZ9yjNzx/lnJ0nuOPdLWfbgPcYcKZNsDLOc1nZckmdU1WVJnjF6PycL0nKqqm+tb1eSHRbimkyG+99/u1x//Q3ZZZedcthhB+bJTzlk3CFBL03dcG2WPWTPZNPNktt/nk32enTuvPK7mbrphix7+K/nzku+mWV7/UZW/+gH4w4V7qa1dmamZzOltXZDkv3m47wLNYZmhyTPSnLTWtsryT8v0DWZAB/76Huz7Xbb5I477sxRR70mN9/8k3GHBL20+l8vzR3nfSlbH/ueZPXqrP7e5bn9i5/O6n+7LJv/3stSS5am3XF7bnvfX487VCbYVOvPww8WKqH5dJKtWmvfWHtHVZ25QNdkAuz79N8adwgwGD877cT87LQT77Zt9XcvzL+/9iVjioiu6U86s0AJTWtt+Sz7nrcQ1wQAhsu0bQAYqI19BlMXSGgAYKA2NN26S9wpGADoPBUaABioe3H/mIkjoQGAgerTGBotJwCg81RoAGCg+jQoWEIDAAPVpzE0Wk4AQOep0ADAQDXPcgIAus4sJwCACaJCAwAD1adBwRIaABgo07YBgM4zhgYAYIKo0ADAQJm2DQB0Xp8GBWs5AQCdp0IDAANllhMA0HlmOQEATBAVGgAYKLOcAIDO03ICAJggKjQAMFBmOQEAnTfVozE0Wk4AQOep0ADAQPWnPiOhAYDBMssJAGCCqNAAwED1qUIjoQGAgerTnYK1nACAzlOhAYCB0nICADqvT3cK1nICADpPhQYABqpPg4IlNAAwUH0aQ6PlBAB0ngoNAAyUlhMA0HlaTgAAE0SFBgAGqk/3oZHQAMBATfVoDI2WEwDQeSo0ADBQWk4AQOdpOQEATBAVGgAYKC0nAKDztJwAADZSVe1SVf9UVZdU1UVV9cej7dtW1Req6rLR6zZzvYaEBgAGqs3jvw24M8mfttYenuQJSf6oqvZMckySVa213ZOsGr2fEy0nABioxWo5tdauSXLNaP3WqrokyQOSHJpk39FhJyY5M8nRc7mGCg0AcK9V1YqqumDGsmI9x+2a5DeSnJtkh1Gysybp2X6u11ehAYCBms9ZTq21lUlWznZMVW2V5LQkr2it3VJV83Z9CQ0ADFRrU4t2raraJNPJzIdba58Ybb62qnZsrV1TVTsmuW6u59dyAgAWVE2XYt6f5JLW2ttm7Do9yZGj9SOTfGqu11ChAYCBmlq8G+vtk+R3k3y7qr4x2vYXSY5LcmpVLU9yVZLD53oBCQ0ADFRbvFlOX06yvgEz+83HNbScAIDOU6EBgIFaxJbTgpPQAMBALVbLaTFoOQEAnadCAwAD1aenbUtoAGCg5vNOweOm5QQAdJ4KDQAMVJ8GBUtoAGCgTNsGADqvTxUaY2gAgM5ToQGAgTJtGwDoPC0nAIAJokIDAANllhMA0HlaTgAAE0SFBgAGyiwnAKDzPJwSAGCCqNAAwEBpOQEAnWeWEwDABFGhAYCB6tOgYAkNAAyUlhMAwARRoQGAgepThUZCAwAD1Z90RssJAOiB6lO5iclRVStaayvHHQcMjd89hkqFhoWyYtwBwED53WOQJDQAQOdJaACAzpPQsFD08GE8/O4xSAYFAwCdp0IDAHSehAYA6DwJDfOqqg6oqu9U1eVVdcy444GhqKoPVNV1VXXhuGOBcZDQMG+qammSdyQ5MMmeSZ5bVXuONyoYjBOSHDDuIGBcJDTMp8cluby1dkVr7fYkH0ly6JhjgkForZ2V5MZxxwHjIqFhPj0gyfdnvL96tA0AFpSEhvlU69jmvgAALDgJDfPp6iS7zHi/c5IfjikWAAZEQsN8Oj/J7lW1W1VtmuSIJKePOSYABkBCw7xprd2Z5GVJPpfkkiSnttYuGm9UMAxVdUqSryZ5WFVdXVXLxx0TLCaPPgAAOk+FBgDoPAkNANB5EhoAoPMkNABA50loAIDOk9DAGFXV6qr6RlVdWFUfq6ot7sW5Tqiq3xmtv2+2B4NW1b5V9aQ5XOPfqup+c41xvs8DsIaEBsbrttbao1prj0hye5KXzNw5eoL5PdZa+4PW2sWzHLJvknuc0ABMKgkNTI6zkzxkVD35p6o6Ocm3q2ppVb2lqs6vqm9V1YuTpKb9XVVdXFWfSbL9mhNV1ZlVtfdo/YCq+lpVfbOqVlXVrplOnF45qg49paruX1Wnja5xflXtM/rsdlX1+ar6elW9J+t4XldVvbSq/s+M979fVW8frf9DVf1LVV1UVSvW8dldq+rCGe//rKr+12j9wVV1xujzZ1fVHvf+Rwz01bJxBwAkVbUsyYFJzhhtelySR7TWrhwlAj9prT22qjZL8pWq+nyS30jysCSPTLJDkouTfGCt894/yXuTPHV0rm1bazdW1buT/Htr7a2j405O8n9ba1+uqgdm+m7PD0/yuiRfbq29oaoOTvJfkpIkH8/0HWr/fPT+vyc5drT+otH1Nk9yflWd1lq7YSN/LCuTvKS1dllVPT7JO5M8fSM/CwyMhAbGa/Oq+sZo/ewk7890K+i81tqVo+3PTPJra8bHJPmlJLsneWqSU1prq5P8sKq+uI7zPyHJWWvO1Vq7cT1x7J9kz6q7CjD3raqtR9f4rdFnP1NVN639wdba9VV1RVU9IcllmU6yvjLafVRVPWe0vsso7g0mNFW11ejn8LEZMW22oc8BwyWhgfG6rbX2qJkbRn/AfzpzU5KXt9Y+t9ZxByXZ0LNLaiOOSabbz09srd22jlg25vMfTfLfklya5JOttVZV+2Y6UXpia+0/qurMJPdZ63N35u6t7zX7lyS5ee2fDcD6GEMDk+9zSV5aVZskSVU9tKq2THJWkiNGY2x2TPK0dXz2q0l+s6p2G31229H2W5NsPeO4z2f6waIZHfeo0epZSZ4/2nZgkm3WE+MnkhyW5LmZTm6S6UrSTaNkZo9MV4vWdm2S7UdjdTZL8uwkaa3dkuTKqjp8dO2qql9fz7UBJDTQAe/L9PiYr40G0L4n09XVT2a6xfPtJO9K8qW1P9hauz7T414+UVXfzC+SjX9M8pw1g4KTHJVk79Gg44vzi9lWr0/y1Kr6WqZbX1etK8DW2k2jGB/UWjtvtPmMJMuq6ltJ3pjknHV87o4kb0hybpJPZ7rCs8bzkywfxX1RkkNn/SkBg+Zp2wBA56nQAACdJ6EBADpPQgMAdJ6EBgDoPAkNANB5EhoAoPMkNABA5/0nmMzYXbyf0G4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+GC_Block.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
