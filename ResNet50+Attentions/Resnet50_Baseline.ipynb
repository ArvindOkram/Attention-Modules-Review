{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name,attention):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+attention+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+attention+'.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50          (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50_Baseline.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 17:28:14.004327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: GeForce GT 710, pci bus id: 0000:b3:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-05-04 17:28:14.005381: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-04 17:28:14.627323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30982 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            4098        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "#shape = K.int_shape(base_out)\n",
    "#channel_val = shape[3]/2\n",
    "#red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "#x=GC_Block(red_feat)\n",
    "\n",
    "shape=K.int_shape(base_out)  \n",
    "x=GlobalAveragePooling2D()(base_out)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 17:28:41.234616: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.7779 - acc: 0.5688\n",
      "Epoch 1: acc improved from -inf to 0.56875, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 37s 514ms/step - loss: 0.7779 - acc: 0.5688 - lr: 0.0050\n",
      "Epoch 1/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5426 - acc: 0.7354\n",
      "Epoch 1: acc improved from 0.56875 to 0.73542, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 39s 528ms/step - loss: 0.5426 - acc: 0.7354 - lr: 1.0000e-04\n",
      "Epoch 2/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3882 - acc: 0.8417\n",
      "Epoch 2: acc improved from 0.73542 to 0.84167, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 34s 546ms/step - loss: 0.3882 - acc: 0.8417 - lr: 1.0000e-04\n",
      "Epoch 3/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3234 - acc: 0.8771\n",
      "Epoch 3: acc improved from 0.84167 to 0.87708, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 33s 545ms/step - loss: 0.3234 - acc: 0.8771 - lr: 1.0000e-04\n",
      "Epoch 4/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3440 - acc: 0.8583\n",
      "Epoch 4: acc did not improve from 0.87708\n",
      "60/60 [==============================] - 32s 518ms/step - loss: 0.3440 - acc: 0.8583 - lr: 1.0000e-04\n",
      "Epoch 5/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2910 - acc: 0.8792\n",
      "Epoch 5: acc improved from 0.87708 to 0.87917, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 34s 548ms/step - loss: 0.2910 - acc: 0.8792 - lr: 1.0000e-04\n",
      "Epoch 6/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2925 - acc: 0.8740\n",
      "Epoch 6: acc did not improve from 0.87917\n",
      "60/60 [==============================] - 32s 515ms/step - loss: 0.2925 - acc: 0.8740 - lr: 1.0000e-04\n",
      "Epoch 7/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2448 - acc: 0.9031\n",
      "Epoch 7: acc improved from 0.87917 to 0.90312, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 37s 603ms/step - loss: 0.2448 - acc: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 8/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2943 - acc: 0.8677\n",
      "Epoch 8: acc did not improve from 0.90312\n",
      "60/60 [==============================] - 32s 527ms/step - loss: 0.2943 - acc: 0.8677 - lr: 1.0000e-04\n",
      "Epoch 9/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2318 - acc: 0.9125\n",
      "Epoch 9: acc improved from 0.90312 to 0.91250, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 36s 594ms/step - loss: 0.2318 - acc: 0.9125 - lr: 1.0000e-04\n",
      "Epoch 10/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2261 - acc: 0.9146\n",
      "Epoch 10: acc improved from 0.91250 to 0.91458, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.2261 - acc: 0.9146 - lr: 1.0000e-04\n",
      "Epoch 11/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1628 - acc: 0.9354\n",
      "Epoch 11: acc improved from 0.91458 to 0.93542, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 0.1628 - acc: 0.9354 - lr: 1.0000e-04\n",
      "Epoch 12/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1972 - acc: 0.9219\n",
      "Epoch 12: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.1972 - acc: 0.9219 - lr: 1.0000e-04\n",
      "Epoch 13/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2080 - acc: 0.9135\n",
      "Epoch 13: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 38s 623ms/step - loss: 0.2080 - acc: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 14/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1810 - acc: 0.9333\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 14: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.1810 - acc: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 15/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1777 - acc: 0.9312\n",
      "Epoch 15: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.1777 - acc: 0.9312 - lr: 8.0000e-05\n",
      "Epoch 16/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1605 - acc: 0.9365\n",
      "Epoch 16: acc improved from 0.93542 to 0.93646, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 41s 679ms/step - loss: 0.1605 - acc: 0.9365 - lr: 8.0000e-05\n",
      "Epoch 17/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1538 - acc: 0.9500\n",
      "Epoch 17: acc improved from 0.93646 to 0.95000, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.1538 - acc: 0.9500 - lr: 8.0000e-05\n",
      "Epoch 18/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1208 - acc: 0.9573\n",
      "Epoch 18: acc improved from 0.95000 to 0.95729, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.1208 - acc: 0.9573 - lr: 8.0000e-05\n",
      "Epoch 19/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1136 - acc: 0.9552\n",
      "Epoch 19: acc did not improve from 0.95729\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.1136 - acc: 0.9552 - lr: 8.0000e-05\n",
      "Epoch 20/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1147 - acc: 0.9615\n",
      "Epoch 20: acc improved from 0.95729 to 0.96146, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.1147 - acc: 0.9615 - lr: 8.0000e-05\n",
      "Epoch 21/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1162 - acc: 0.9563\n",
      "Epoch 21: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.1162 - acc: 0.9563 - lr: 8.0000e-05\n",
      "Epoch 22/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.9563\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 22: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.1264 - acc: 0.9563 - lr: 8.0000e-05\n",
      "Epoch 23/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9635\n",
      "Epoch 23: acc improved from 0.96146 to 0.96354, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.1011 - acc: 0.9635 - lr: 6.4000e-05\n",
      "Epoch 24/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0955 - acc: 0.9625\n",
      "Epoch 24: acc did not improve from 0.96354\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.0955 - acc: 0.9625 - lr: 6.4000e-05\n",
      "Epoch 25/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0680 - acc: 0.9802\n",
      "Epoch 25: acc improved from 0.96354 to 0.98021, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 41s 678ms/step - loss: 0.0680 - acc: 0.9802 - lr: 6.4000e-05\n",
      "Epoch 26/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9833\n",
      "Epoch 26: acc improved from 0.98021 to 0.98333, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0593 - acc: 0.9833 - lr: 6.4000e-05\n",
      "Epoch 27/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9708\n",
      "Epoch 27: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0837 - acc: 0.9708 - lr: 6.4000e-05\n",
      "Epoch 28/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0639 - acc: 0.9781\n",
      "Epoch 28: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.0639 - acc: 0.9781 - lr: 6.4000e-05\n",
      "Epoch 29/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0661 - acc: 0.9719\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 29: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 39s 638ms/step - loss: 0.0661 - acc: 0.9719 - lr: 6.4000e-05\n",
      "Epoch 30/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0642 - acc: 0.9823\n",
      "Epoch 30: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0642 - acc: 0.9823 - lr: 5.1200e-05\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0459 - acc: 0.9823\n",
      "Epoch 31: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 0.0459 - acc: 0.9823 - lr: 5.1200e-05\n",
      "Epoch 32/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0351 - acc: 0.9875\n",
      "Epoch 32: acc improved from 0.98333 to 0.98750, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 41s 678ms/step - loss: 0.0351 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 33/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9885\n",
      "Epoch 33: acc improved from 0.98750 to 0.98854, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 41s 667ms/step - loss: 0.0333 - acc: 0.9885 - lr: 5.1200e-05\n",
      "Epoch 34/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.9906\n",
      "Epoch 34: acc improved from 0.98854 to 0.99063, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 40s 660ms/step - loss: 0.0308 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 35/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0282 - acc: 0.9937\n",
      "Epoch 35: acc improved from 0.99063 to 0.99375, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 41s 665ms/step - loss: 0.0282 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 36/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0432 - acc: 0.9812\n",
      "Epoch 36: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.0432 - acc: 0.9812 - lr: 5.1200e-05\n",
      "Epoch 37/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.9854\n",
      "Epoch 37: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.0413 - acc: 0.9854 - lr: 5.1200e-05\n",
      "Epoch 38/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0242 - acc: 0.9896\n",
      "Epoch 38: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 36s 589ms/step - loss: 0.0242 - acc: 0.9896 - lr: 5.1200e-05\n",
      "Epoch 39/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0282 - acc: 0.9896\n",
      "Epoch 39: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 631ms/step - loss: 0.0282 - acc: 0.9896 - lr: 5.1200e-05\n",
      "Epoch 40/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9937\n",
      "Epoch 40: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 630ms/step - loss: 0.0333 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 41/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0264 - acc: 0.9875\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 41: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 659ms/step - loss: 0.0264 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 42/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.9823\n",
      "Epoch 42: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 37s 607ms/step - loss: 0.0382 - acc: 0.9823 - lr: 4.0960e-05\n",
      "Epoch 43/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 43: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 629ms/step - loss: 0.0238 - acc: 0.9927 - lr: 4.0960e-05\n",
      "Epoch 44/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0329 - acc: 0.9906\n",
      "Epoch 44: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 632ms/step - loss: 0.0329 - acc: 0.9906 - lr: 4.0960e-05\n",
      "Epoch 45/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9937\n",
      "Epoch 45: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0272 - acc: 0.9937 - lr: 4.0960e-05\n",
      "Epoch 46/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9937\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 46: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.0283 - acc: 0.9937 - lr: 4.0960e-05\n",
      "Epoch 47/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 47: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 38s 617ms/step - loss: 0.0212 - acc: 0.9937 - lr: 3.2768e-05\n",
      "Epoch 48/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9969\n",
      "Epoch 48: acc improved from 0.99375 to 0.99687, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 42s 669ms/step - loss: 0.0102 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 49/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9969\n",
      "Epoch 49: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0118 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 50/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0123 - acc: 0.9958\n",
      "Epoch 50: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 621ms/step - loss: 0.0123 - acc: 0.9958 - lr: 3.2768e-05\n",
      "Epoch 51/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 51: acc improved from 0.99687 to 1.00000, saving model to resnet50_Baseline.hdf5\n",
      "60/60 [==============================] - 43s 687ms/step - loss: 0.0061 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 52/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0113 - acc: 0.9969\n",
      "Epoch 52: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 603ms/step - loss: 0.0113 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 53/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9979\n",
      "Epoch 53: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 634ms/step - loss: 0.0076 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 54/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9990\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 54: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 628ms/step - loss: 0.0073 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 55/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
      "Epoch 55: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 637ms/step - loss: 0.0060 - acc: 0.9990 - lr: 2.6214e-05\n",
      "Epoch 56/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 56: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.0027 - acc: 1.0000 - lr: 2.6214e-05\n",
      "Epoch 57/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0169 - acc: 0.9937\n",
      "Epoch 57: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.0169 - acc: 0.9937 - lr: 2.6214e-05\n",
      "Epoch 58/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9958\n",
      "Epoch 58: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.0117 - acc: 0.9958 - lr: 2.6214e-05\n",
      "Epoch 59/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9979\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 59: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.0107 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 60/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9958\n",
      "Epoch 60: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 632ms/step - loss: 0.0096 - acc: 0.9958 - lr: 2.0972e-05\n",
      "Epoch 61/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 61: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.0064 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 62/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0121 - acc: 0.9969\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 62: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.0121 - acc: 0.9969 - lr: 2.0972e-05\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 63: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 611ms/step - loss: 0.0049 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 64/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0095 - acc: 0.9958\n",
      "Epoch 64: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0095 - acc: 0.9958 - lr: 1.6777e-05\n",
      "Epoch 65/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 65: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 609ms/step - loss: 0.0037 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 66/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 614ms/step - loss: 0.0060 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 67/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 656ms/step - loss: 0.0026 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 68/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 629ms/step - loss: 0.0026 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 69/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0105 - acc: 0.9969 - lr: 1.0737e-05\n",
      "Epoch 70/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 624ms/step - loss: 0.0034 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 71/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 71: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0032 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 72/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.0022 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 73/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9979\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 641ms/step - loss: 0.0054 - acc: 0.9979 - lr: 8.5899e-06\n",
      "Epoch 74/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 669ms/step - loss: 0.0026 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 75/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.0036 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 76/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0027 - acc: 0.9990\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.0027 - acc: 0.9990 - lr: 6.8719e-06\n",
      "Epoch 77/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9969\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0052 - acc: 0.9969 - lr: 6.8719e-06\n",
      "Epoch 78/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n",
      "\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 637ms/step - loss: 0.0021 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 79/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 0.9990\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 662ms/step - loss: 0.0023 - acc: 0.9990 - lr: 5.4976e-06\n",
      "Epoch 80/80\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.0058 - acc: 0.9979 - lr: 5.4976e-06\n",
      "15/15 [==============================] - 4s 162ms/step - loss: 0.3136 - acc: 0.9292\n",
      "Test loss: 0.3135993778705597\n",
      "Test accuracy: 0.9291666746139526\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn2ElEQVR4nO3deXxV9Z3/8dcnN8vNDtlDWMK+ilEBUVyqthbUilar2LrQZSgdndrO2NY+pjOt1mk787NTbaWidWnrtFqXamlFqWJFrKiABguybyasISEb2ZPv7497wYghBMjh3Nz7fj4eeZB777nJm0Du+57vOef7NeccIiISu+L8DiAiIv5SEYiIxDgVgYhIjFMRiIjEOBWBiEiMi/c7wLHKyclxxcXFfscQEelTVq5cuc85l9vVY32uCIqLi1mxYoXfMURE+hQz236kxzQ0JCIS41QEIiIxTkUgIhLj+twxAhGJPq2trZSXl9PU1OR3lD4vGAwycOBAEhISevwcFYGI+K68vJz09HSKi4sxM7/j9FnOOSorKykvL2fo0KE9fp6GhkTEd01NTWRnZ6sETpCZkZ2dfcx7VioCEYkIKoHecTw/x5gpgvW76/jxC2upa2r1O4qISESJmSIoq2rggSVb2LCn3u8oIiIRJWaKYHRBOgAb99T5nEREIk11dTW//OUvj/l5l1xyCdXV1cf8vNmzZ/P0008f8/O8EjNFUNQvmeSEAOtVBCJymCMVQXt7e7fPW7hwIf369fMo1ckTM6ePxsUZo/LT2KihIZGIdsef1/D+ztpe/ZrjBmTw/c+MP+Ljt99+O5s3b6akpISEhATS0tIoLCyktLSU999/nyuuuIKysjKampq49dZbmTNnDvDh3Gf19fXMmDGDc845hzfeeIOioiL+9Kc/kZycfNRsixcv5rbbbqOtrY3Jkydz//33k5SUxO23386CBQuIj4/n4osv5u677+app57ijjvuIBAIkJmZyWuvvdYrP5+YKQKAUfnpvLqhwu8YIhJhfvKTn7B69WpKS0t59dVXufTSS1m9evWhc/EfeeQRsrKyaGxsZPLkyVx11VVkZ2d/5Gts3LiRxx9/nF/96ldcc801PPPMM1x//fXdft+mpiZmz57N4sWLGTVqFDfeeCP3338/N954I88++yzr1q3DzA4NP915550sWrSIoqKi4xqSOpKYK4KnVpaz/0AL/VMT/Y4jIl3o7p37yTJlypSPXJD185//nGeffRaAsrIyNm7c+LEiGDp0KCUlJQCcccYZbNu27ajfZ/369QwdOpRRo0YBcNNNNzFv3jxuueUWgsEgX/nKV7j00ku57LLLAJg2bRqzZ8/mmmuu4bOf/Wwv/E1DYuYYAcCo8AHjDTpOICLdSE1NPfT5q6++yssvv8yyZctYtWoVp512WpcXbCUlJR36PBAI0NbWdtTv45zr8v74+HjefvttrrrqKp577jmmT58OwPz587nrrrsoKyujpKSEysrKY/2rdSm2iiA/DVARiMhHpaenU1fX9etCTU0N/fv3JyUlhXXr1vHmm2/22vcdM2YM27ZtY9OmTQA89thjnH/++dTX11NTU8Mll1zCPffcQ2lpKQCbN2/mzDPP5M477yQnJ4eysrJeyRFTQ0MFGUHSg/E6c0hEPiI7O5tp06YxYcIEkpOTyc/PP/TY9OnTmT9/PhMnTmT06NFMnTq1175vMBjk0Ucf5XOf+9yhg8Vz586lqqqKmTNn0tTUhHOOn/3sZwB861vfYuPGjTjnuOiiizj11FN7JYcdadckUk2aNMmdyAplV9//BnFxxpNfPasXU4nIiVi7di1jx471O0bU6OrnaWYrnXOTuto+poaGAEbmp7NhT90Rx+ZERGJNzBXB6Pw0qhtaqahr9juKiES5m2++mZKSko98PProo37H+piYOkYAoVNIATbsqScvI+hzGhE5yDkXdTOQzps376R/z+MZ7fB0j8DMppvZejPbZGa3d/H4J8ysxsxKwx//6WUe+PAUUh0wFokcwWCQyspKDdmeoIML0wSDx/Ym17M9AjMLAPOATwHlwHIzW+Cce/+wTZc65y7zKsfhctKSyEpN1ORzIhFk4MCBlJeXU1GhK/9P1MGlKo+Fl0NDU4BNzrktAGb2BDATOLwITrpR+WnaIxCJIAkJCce0tKL0Li+HhoqAzlc7lIfvO9xZZrbKzF4wsy6vLTezOWa2wsxW9MY7htH56WzcU6/dUBERvC2Cro76HP7K+w4wxDl3KvAL4LmuvpBz7kHn3CTn3KTc3NwTDjYyP5365jZ21hzbup4iItHIyyIoBwZ1uj0Q2Nl5A+dcrXOuPvz5QiDBzHI8zAR8uEjNht0aHhIR8bIIlgMjzWyomSUCs4AFnTcwswILny9mZlPCeXpnFqVujMrTmUMiIgd5drDYOddmZrcAi4AA8Ihzbo2ZzQ0/Ph+4GviambUBjcAsdxIG7jNTEsjPSNLkcyIieHxBWXi4Z+Fh983v9Pl9wH1eZjiSUeGpJkREYl3MTTFx0KjwmUPtHTpzSERiWwwXQRrNbR2UVTX4HUVExFcxWwQjw3MObdyrxexFJLbFbhHkabUyERGI4SJIDyZQmBnUnEMiEvNitgjg4CI1GhoSkdgW00UwKi+NzRU6c0hEYltsF0F+us4cEpGYF9NFMDJfB4xFRGK6CEaEzxzSKaQiEstiugjSgwkM0JlDIhLjYroIQGcOiYjEfBGMyteZQyIS22K+CEbmhc4c+kBnDolIjFIRhM8c0nECEYlVKgJNPiciMS7miyAtKZ6ifsm6lkBEYlbMFwGErifQmUMiEqtUBOjMIRGJbSoCQscJWnTmkIjEKBUBocnnQHMOiUhsUhHQac4hFYGIxCAVAR+eOaRTSEUkFqkIwkbmp7F+t/YIRCT2qAjCzhyazbrddXxQqQPGIhJbVARhl5cMAOBPpTt8TiIicnKpCMKK+iUzZWgWz5XuwDldTyAiscPTIjCz6Wa23sw2mdnt3Ww32czazexqL/MczRUlRWyuOMCanbV+xhAROak8KwIzCwDzgBnAOOA6Mxt3hO3+G1jkVZaeuuSUAhICxnPvanhIRGKHl3sEU4BNzrktzrkW4AlgZhfb/QvwDLDXwyw90i8lkQtG57Fg1U5NNyEiMcPLIigCyjrdLg/fd4iZFQFXAvO7+0JmNsfMVpjZioqKil4P2tkVpxWxt66ZZZsrPf0+IiKRwssisC7uO/xt9j3Ad5xz7d19Iefcg865Sc65Sbm5ub2Vr0sXjskjPSme53T2kIjECC+LoBwY1On2QGDnYdtMAp4ws23A1cAvzewKDzMdVTAhwPQJBby4ejdNrd32k4hIVPCyCJYDI81sqJklArOABZ03cM4Ndc4VO+eKgaeBf3bOPedhph658rQi6pvbWLzW98MWIiKe86wInHNtwC2EzgZaCzzpnFtjZnPNbK5X37c3nDksm/yMJBas0vCQiES/eC+/uHNuIbDwsPu6PDDsnJvtZZZjEYgzLhqbz4LSnbS2d5AQ0HV3IhK99Ap3BOeOyKG+uY1VZdV+RxER8ZSK4AjOHp5DnMHSjfv8jiIi4ikVwRFkpiRwysB+vL5JRSAi0U1F0I3zRuZQWlZNbVOr31FERDyjIujGOSNyaO9wuspYRKKaiqAbpw3uT0pigNd1nEBEopiKoBuJ8XFMHZat4wQiEtVUBEdxzogctu47QPl+LWEpItFJRXAU547MAdDwkIhELRXBUYzIS6MgI6jrCUQkaqkIjsLMOGdkDn/fvE+L1YhIVFIR9MC5I3Oobmhlzc4av6OIiPQ6FUEPTBsROk7w2gZvV0cTEfGDiqAHctKSmFKcxeNvl9Ha3uF3HBGRXqUi6KE55w1jR3UjC/+xy+8oIiK9SkXQQxeOyWNEXhrzl2zBOR00FpHooSLoobg4Y855w1i7q5bXdCqpiEQRFcExuKKkiPyMJB5YstnvKCIivUZFcAwS4+P48jlDeWNzJe+VV/sdR0SkV6gIjtF1UwaTnhTPA69t8TuKiEivUBEco/RgAl+YOoQX/rGL7ZUH/I4jInLCVATH4UvTijEz/rC8zO8oIiInTEVwHPIygkwdlsWLa3brVFIR6fNUBMdp+oRCtlQcYNPeer+jiIicEBXBcfr0uHzM4MXVu/2OIiJyQlQExykvI8jpg/vz4hoVgYj0bSqCEzB9fAFrdtbyQaWWsRSRvktFcAKmTygAYJH2CkSkD/O0CMxsupmtN7NNZnZ7F4/PNLP3zKzUzFaY2Tle5ultg7JSGD8gQ8NDItKneVYEZhYA5gEzgHHAdWY27rDNFgOnOudKgC8BD3mVxyvTxxewcvt+9tY2+R1FROS4eLlHMAXY5Jzb4pxrAZ4AZnbewDlX7z48ET8V6HMn5Wt4SET6Oi+LoAjofOltefi+jzCzK81sHfA8ob2CjzGzOeGhoxUVFZG1XOSIvDSG5aZqeEhE+qx4D7+2dXHfx97xO+eeBZ41s/OAHwKf7GKbB4EHASZNmhRRew1mxowJBcxfsoUHX9uMc9DuHBnBBD4/ZTBxcV39GEREIoeXRVAODOp0eyCw80gbO+deM7PhZpbjnOtTK79cfmoRDyzZwo8WrvvI/YWZQS4am+9TKhGRnvGyCJYDI81sKLADmAV8vvMGZjYC2Oycc2Z2OpAIVHqYyROjC9J57wcX09bhiA/vAVx49xJ+/cY2FYGIRLweHSMws1vNLMNCHjazd8zs4u6e45xrA24BFgFrgSedc2vMbK6ZzQ1vdhWw2sxKCZ1hdK3ro7O4pSTGkxFMICUxnpTEeL5w5mCWbtzH5grNRSQika2nB4u/5JyrBS4GcoEvAj852pOccwudc6Occ8Odc/8Vvm++c25++PP/ds6Nd86VOOfOcs69fpx/j4gza8pgEgNxPLZsu99RRES61dMiOHjE8xLgUefcKro+GCxhuelJXDqxkKdXllPf3OZ3HBGRI+ppEaw0s78SKoJFZpYOdHgXKzrceNYQ6pvbePadcr+jiIgcUU+L4MvA7cBk51wDkEBoeEi6UTKoHxMHZvKbZdu1gI2IRKyeFsFZwHrnXLWZXQ98D6jxLlZ0MDNuPKuYTXvrWba5z50MJSIxoqdFcD/QYGanAt8GtgO/9SxVFLlsYiFZqYn8+o1tfkcREelST4ugLXxa50zgXufcvUC6d7GiRzAhwOenDOaltXtYVVbtdxwRkY/paRHUmdl3gRuA58MziyZ4Fyu6zDl/GDlpSXzvudW0d+hYgYhElp4WwbVAM6HrCXYTmjzu/3mWKspkBBP4j8vG8Y8dNfz+LV1XICKRpUdFEH7x/x2QaWaXAU3OOR0jOAafmVjItBHZ/M+i9eyt09oFIhI5ejrFxDXA28DngGuAt8zsai+DRRsz44czJ9Dc2sGPD5ucTkTETz0dGvp3QtcQ3OScu5HQojP/4V2s6DQsN42vnj+MZ9/dwRub+9QEqyISxXpaBHHOub2dblcew3Olk5svGMHgrBR+tHCt31FERICev5i/aGaLzGy2mc0mtJrYQu9iRa9gQoAbpg5h9Y5adlQ3+h1HRKTHB4u/RWiFsInAqcCDzrnveBksml0wJg+AV9btPcqWIiLe6/HCNM65Z4BnPMwSM4bnpjIkO4VX1u7hhqlD/I4jIjGu2yIwszq6WGeY0BTUzjmX4UmqKGdmXDA6j8ff/oDGlnaSEwN+RxKRGNbt0JBzLt05l9HFR7pK4MRcNDaP5rYOnT0kIr7TmT8+mTI0i5TEgI4TiIjvVAQ+SYoPcO7IHF5Zt1drFYiIr1QEPrpwTB67appYt7vO7ygiEsNUBD66YLROIxUR/6kIfJSXEWTiwEwWr93jdxQRiWEqAp9dMDqPd8uqqTrQ4ncUEYlRKgKfXTQ2D+fg1fUaHhIRf6gIfDZhQCa56Uk8+NoWyqoa/I4jIjFIReCzuDjjR1eewo79jVzy86U8/94uvyOJSIxREUSAT43L5/mvn8vw3DRu/v073P7Me6zeUcOGPXVs3XeAvbVa0UxEvGN97WKmSZMmuRUrVvgdwxOt7R3870sbmL9kM4f/s3z5nKF879KxmJk/4USkTzOzlc65SV091uPZR4/zG08H7gUCwEPOuZ8c9vgXgIPTWdcDX3POrfIyUyRLCMTxneljmFkygLKqRlraOmhtD81H9PDrWwkmxPGtT4/xO6aIRBnPisDMAsA84FNAObDczBY4597vtNlW4Hzn3H4zm0FozYMzvcrUV4wpyGBMwYdz+s0sGUAgLo55f9tMckKAWy4c6WM6EYk2Xu4RTAE2Oee2AJjZE8BM4FAROOfe6LT9m8BAD/P0WWbGf10xgebWdu7+6waCCQG+cu4wv2OJSJTwsgiKgLJOt8vp/t3+l4EXunrAzOYAcwAGDx7cW/n6lLg443+unkhTWzt3Pb+WPbVNfHv6GBICOt4vIifGy1eRro5qdnlk2swuIFQEXS5/6Zx70Dk3yTk3KTc3txcj9i3xgTjuufY0bpg6hF8t3co1DyzTuscicsK8LIJyYFCn2wOBnYdvZGYTgYeAmc65Sg/zRIXE+Dh+eMUE5n3+dDbuqeeSe5dqriIROSFeFsFyYKSZDTWzRGAWsKDzBmY2GPgjcINzboOHWaLOpRML+cu/nMPA/sl85bcr+POqj3WsiEiPeFYEzrk24BZgEbAWeNI5t8bM5prZ3PBm/wlkA780s1Izi84LBDxSnJPKM187m8nFWfzrk6W8vlHLXorIsdMFZVGgprGVax9YRllVA3/46llMKMr0O5KIRJjuLijTKSdRIDM5gd98aQr9UhKZ/ejbbNt3wO9IItKHqAiiRH5GkN9+eQrtHY7rH36L7ZUqAxHpGRVBFBmem8ZvvjSF+uY2rrp/GWt21vgdSUT6ABVBlJk4sB9Pzz2LhIAx64E3eWuLzsgVke6pCKLQiLx0nv7a2eRmJHHjI2/rOgMR6ZaKIEoV9Uvm6blnMzI/jW/8oVRrIovIEakIolhWaiI/u6aEA81t/HzxRr/jiEiEUhFEuZH56Vw7eTD/9+Z2tuq0UhHpgoogBnzzUyNJjI/jv19Y53cUEYlAKoIYkJceZO75w3lxzW5WbKvyO46IRBgVQYz4yrlDyc9I4q7n19LXphUREW+pCGJESmI8/3bxaErLqvnLe7v8jiMiEURFEEOuOn0g4wozuOPPa9hb1+R3HBGJECqCGBKIM+6ZVUJ9cxvf/EMp7R0aIhIRFUHMGZWfzg8+M56/b6rk/lc3+R1HRCKAiiAGXTt5EJ85dQA/e3kjy3UWkUjMUxHEIDPjR1dOYGD/ZG59/F32a/oJkZimIohR6cEE7rvudCrqm7n2wWVsrqj3O5KI+ERFEMNOGZjJr784hX31LVz+i9dZ+A+dVioSi1QEMW7aiBye//o5jCpI559/9w53/vl9Glva/Y4lIieRikAozEzmD3POYvbZxTzy962c+aOXuePPa9i0t+7QNi1tHWyuqGfTXg0hiUQb62vTDUyaNMmtWLHC7xhRa/m2Kh5btp0XVu+itd0xfkAGdU1t7KhuPHTdwW0Xj+LmC0ZgZj6nFZGeMrOVzrlJXT0Wf7LDSGSbXJzF5OIs9tWP4+mV5byybi9Dc1KZWTKA4uxUXttYwd1/3cCO6kZ+OHMC8QHtVIr0dSoC6VJOWhJzzx/O3POHf+T+z55exKD+Kdz3t03sqmli3udPJzVJ/41E+jK9nZNjYmbc9unR/OjKU1i6cR9Xz1+mBW9E+jgVgRyXz585mIdvmsSumkYu+/lS/lS6w+9IInKcVARy3D4xOo+FXz+XsYUZ3PpEKd95+j2deirSB3laBGY23czWm9kmM7u9i8fHmNkyM2s2s9u8zCLeGNAvmSfmTOWWC0bw5MoybnzkLc1qKtLHeFYEZhYA5gEzgHHAdWY27rDNqoCvA3d7lUO8Fx+I47ZPj+buq09l+bb9PLR0i9+RROQYeLlHMAXY5Jzb4pxrAZ4AZnbewDm31zm3HGj1MIecJJ89vYhPj8/npy9t+MjFaCIS2bwsgiKgrNPt8vB9x8zM5pjZCjNbUVFR0SvhpPeZGXddcQqpiQH+7an3aGvv8DuSiPSAl0XQ1WWnxzV47Jx70Dk3yTk3KTc39wRjiZdy05P44RUTWFVWzYMaIhLpE7wsgnJgUKfbA4GdHn4/iRCXTRzApacUcs9LG1m/W0NEIpHOyyJYDow0s6FmlgjMAhZ4+P0kgtw5czzpwXhu+f071DXpEJBIJPOsCJxzbcAtwCJgLfCkc26Nmc01s7kAZlZgZuXAvwLfM7NyM8vwKpOcPNlpSfziutPYsu8A3/xDKR06pVQkYmn2UfHUb97YxvcXrOGWC0Zw26dH+x1HJGZ1N/uoriwWT9141hBmTR7EfX/bxF/eCx0ics5Rvr+BNzbvo6lVVyKL+E3TRoqnzIw7Z05g0956bntqFY+//QFrdtZS3RA6bjAsJ5UfffYUpg7L9jmpSOzSHoF4LjE+jvuvP4MJAzKpbWxjxoQC7rpiAvfOKqGtwzHrwTf5ztPvUdOgg8oiftAxAvFVY0s79yzewENLt5KZnMCMCQV8cmw+Zw3PJpgQ8DueSNTo7hiBikAiwpqdNfxi8SZe21hBQ0s7wYQ4zh6ew9nDs5k6LJuxhRkE4rQ0psjx0lKVEvHGD8hk/g1n0NzWzltbqnhl3V6WbKjglXV7AcgIxjNjQiHfv3wcKYn6byvSm/QbJRElKT7AeaNyOW9UaCqRXTWNvLWliqUb9/HkyjLW7Krh4Zsmk58R9DmpSPTQwWKJaIWZyVxxWhE/veZUHrpxElsrDjDzvr+zekeN39FEooaKQPqMi8bm8/TXzibO4HPzl/HS+3v8jiQSFVQE0qeMLczguZunMSo/ja8+toInV5Qd/Uki0i0VgfQ5eRlBfv9PU5k2IodvP/0eDyzZ7HckkT5NRSB9UmpSPA/fNJnLJhby4xfW8eOFa+lrp0KLRAqdNSR9VmJ8HPfOOo3+KYk88NoWtuw7wJ0zx1OYmex3NJE+RXsE0qcF4ow7Z47n3y8Zy9KNFXzyp0t4aOkWLZMpcgxUBNLnmRn/dN4wXvrm+UwZmsVdz6/l8vv+ztKNFRouEukBFYFEjUFZKTwyezLzrz+d/Q0t3PDw23zmvtd5/r1dtB/Dwji1Ta00tLR5mFQksmiuIYlKzW3tPPfuDh5YEjp2UJydwnVTBnPl6UXkpX94VXJlfTMvrN7Nsi2VlFU18EFVA9UNraQnxXPLhSOYPa2YpHhNfid9nyadk5jV3uH465rdPPT6VlZu308gzjh/VC5nD89myYYK3thcSXuHo6hfMsPz0hiclcyg/im8vbWKxev2Mjgrhe/OGMP0CQWYadI76btUBCLA5op6nllZzh/f2cHu2iYGZ6XwmVMLuWziAMYUpH/shX7pxgru+sta1u+pY1BWMqcUZTJ+QCbjBmSQEBdH5YFmKutbqGlsZUh2CiWD+jE0JxUzo6ahlcXr9vDi6t2s31PH+aNymVlSxOmD+33k+7S2d9De4TTltnhORSDSSXuHY2d1IwP7Jx/1XX5bewfPvFPOq+srWLOzlg+qGrrdvl9KAkOyU1mzo4a2DkdBRpCxhem8sbmS5rYOBmUlM7k4i901TXxQ1cDO6kY6HBRkBBmcncKQrBRy0pNISQiQnBggJTGecQMymFiUSZym4ZYToCIQ6SW1Ta2s21WHc47stESyUpNID8azpeIA736wn9KyajZX1HPGkCymTyg49AJe19TKojV7+FPpDtbvrqOofzKDs0Iv/IG4OLZXHeCDyga2VzWw/0ALbYcd3M5JS+T8UXlcNDaPT47NJzFe53nIsVERiPQxre0dNLS0U9/cxvKtofUZXl2/l9qmNoblpPKDy8cfmqpbpCdUBCJRoK29g7+tr+C/nn+fbZUNTB9fwPcuG8vA/il+R5M+QEUgEkWa29p5aOlW7ntlE+3Ocd7IHC4ck8+FY/IoyNSCPdI1LVUpEkWS4gPcfMEIrjytiAdf28LLa/fw8trQkp6j89MZXZDO8Nw0RuSlMX5ABsU5qT4nlkinPQKRPs45x6a99Sxet5dlmyvZXFHPjupGDv5qj85PZ8YpBVx6SiEj89P9DSu+0dCQSIxpbGlny7563t5axQv/2M3y7VU4B6mJAeI6nTLbPzWR4pxUirNTKM5OpTAzSF5GErlpoT97cn1DR4djyYYK3t5WRV1TK3VNbdQ3tdESnvjPzDBCs8UmJwRISQydGlvUL5mhOakMzUmlqH8y1Q2tlFU1UL6/kaoDLYzIS2NCUSZZqYle/ZhiioaGRGJMcmKA8QNCF8B9cdpQ9tY2sWjNbrbu+/A6CIejoq6Z7ZUNvLt9P3XNH59fKSMYT2FmMvmZQQZkBhlTkM74okzGFmbQ3uF4akUZj725ne2VDcTHGRnJCaQH40lLiicxPg7nwAE4R3NbB02t7TS0tB86I6onBmQGGZKdSkNrO/XhokkIxDG2MINxAzIYV5hBUb9kEuKN+Lg4EgNx5KQnkpJ49Je3ptZ2PqhqIDctiX4pCTF79binewRmNh24FwgADznnfnLY4xZ+/BKgAZjtnHunu6+pPQKR3ueco+pAC7trm6ioa6airpm9dc3sqW1iV00Te2qbKKtqYH9DKwBmkBAXR0t7B2cM6c9NZxczfXzBMV3fsP9AC1srD7Cl4gA79jeSlZbIwP6hKT4ykxPYuKeO1TtrWL2jlvL9DaQmxZMRDBXNgZZ21u6qZUtFPUeaT7AgI0hxTgpDc1LJSw+Sk5ZITloSwcQAq8qqeXNLJe98UE1LW2jPJSW8l1KQGSQ7NXSNSFZqAtlpSWSnJpKdlkROWiKGUd3YQnVDKzWNrSQEjIxgwqESjA98+DMwICk+jmBCgGBCAAPqmtqobmxhf0Mrza3t9EtJpH9KAv1SErv8+TW3tbO3tpmd1Y3kpCcxPDetxz/jznwZGjKzALAB+BRQDiwHrnPOvd9pm0uAfyFUBGcC9zrnzuzu66oIRPzhnGNPbTOrd9SwZmctNY2tfPb0IiYUZfqWqbGlnfV76thX10xrewct7R20tHWwp7aJrfsa2FZ5gO2VB6g80ELnlzozGD8gg6lDs5lQlEnlgRZ27G9kR3UDu2uaqGpooaq+hQMt7b2a1wy6e8k9WBrJCQGCCXHUN7ezr7750ONfPX8Y350x9ji/tz9DQ1OATc65LeEQTwAzgfc7bTMT+K0LtdGbZtbPzAqdc7s8zCUix8HMKMgMUpAZ5JPj8v2OA4SGwEoG9Tvqdm3tHVQ1tFBZ30JdUxujC9LJTE446vOaWtupOhB63r4DzeyrC70o909JpF9KApnJCbS2O2qbWqltbKW2qY2OTrsoHZ2GxJpaO2jr6CAzOeHQXkBSfODQ3kV1QyjbwW0bW9tJSQxQmJlMYb8ghZlBRuQd397A0XhZBEVAWafb5YTe9R9tmyLgI0VgZnOAOQCDBw/u9aAiEt3iA3HkpQc/MgV5TwQTAgzol8yAftG9/KmXE5Z0ddTl8J2inmyDc+5B59wk59yk3FxdVi8i0pu8LIJyYFCn2wOBncexjYiIeMjLIlgOjDSzoWaWCMwCFhy2zQLgRguZCtTo+ICIyMnl2TEC51ybmd0CLCJ0+ugjzrk1ZjY3/Ph8YCGhM4Y2ETp99Ite5RERka55ekGZc24hoRf7zvfN7/S5A272MoOIiHRPq1uIiMQ4FYGISIxTEYiIxLg+N/uomVUA24/hKTnAPo/inIhIzQWRmy1Sc0HkZovUXBC52SI1F5xYtiHOuS4vxOpzRXCszGzFkebX8FOk5oLIzRapuSBys0VqLojcbJGaC7zLpqEhEZEYpyIQEYlxsVAED/od4AgiNRdEbrZIzQWRmy1Sc0HkZovUXOBRtqg/RiAiIt2LhT0CERHphopARCTGRW0RmNl0M1tvZpvM7HafszxiZnvNbHWn+7LM7CUz2xj+s78PuQaZ2d/MbK2ZrTGzWyMoW9DM3jazVeFsd0RKtnCOgJm9a2Z/ibBc28zsH2ZWamYrIiVbePXBp81sXfj/21kRkmt0+Gd18KPWzL4RIdm+Gf6/v9rMHg//TniSKyqLILxe8jxgBjAOuM7MxvkY6dfA9MPuux1Y7JwbCSwO3z7Z2oB/c86NBaYCN4d/TpGQrRm40Dl3KlACTA9PVR4J2QBuBdZ2uh0puQAucM6VdDrfPBKy3Qu86JwbA5xK6Gfney7n3Prwz6oEOIPQLMjP+p3NzIqArwOTnHMTCM3gPMuzXM65qPsAzgIWdbr9XeC7PmcqBlZ3ur0eKAx/Xgisj4Cf25+AT0VaNiAFeIfQUqe+ZyO0gNJi4ELgL5H07wlsA3IOu8/XbEAGsJXwySmRkquLnBcDf4+EbHy4jG8WoVmi/xLO50muqNwj4MhrIUeSfBdehCf8Z56fYcysGDgNeIsIyRYefikF9gIvOeciJds9wLeBjk73RUIuCC31+lczWxle6zsSsg0DKoBHw8NpD5lZagTkOtws4PHw575mc87tAO4GPiC0hnuNc+6vXuWK1iLo0VrIEmJmacAzwDecc7V+5znIOdfuQrvsA4EpZjbB50iY2WXAXufcSr+zHME059zphIZFbzaz8/wOROgd7enA/c6504AD+Dt09jHhVRQvB57yOwtAeOx/JjAUGACkmtn1Xn2/aC2CvrAW8h4zKwQI/7nXjxBmlkCoBH7nnPtjJGU7yDlXDbxK6DiL39mmAZeb2TbgCeBCM/u/CMgFgHNuZ/jPvYTGuqdEQLZyoDy8RwfwNKFi8DtXZzOAd5xze8K3/c72SWCrc67COdcK/BE426tc0VoEPVkv2W8LgJvCn99EaHz+pDIzAx4G1jrn/jfCsuWaWb/w58mEfjHW+Z3NOfdd59xA51wxof9Xrzjnrvc7F4CZpZpZ+sHPCY0pr/Y7m3NuN1BmZqPDd10EvO93rsNcx4fDQuB/tg+AqWaWEv49vYjQAXZvcvl5cMbjgy2XABuAzcC/+5zlcULjfK2E3h19GcgmdMBxY/jPLB9ynUNoyOw9oDT8cUmEZJsIvBvOthr4z/D9vmfrlPETfHiw2PdchMbiV4U/1hz8fx8h2UqAFeF/z+eA/pGQK5wtBagEMjvd53s24A5Cb35WA48BSV7l0hQTIiIxLlqHhkREpIdUBCIiMU5FICIS41QEIiIxTkUgIhLjVAQiJ5GZfeLgjKUikUJFICIS41QEIl0ws+vD6yGUmtkD4Qnw6s3sp2b2jpktNrPc8LYlZvammb1nZs8enCPezEaY2csWWlPhHTMbHv7yaZ3m5v9d+MpREd+oCEQOY2ZjgWsJTeBWArQDXwBSCc1HczqwBPh++Cm/Bb7jnJsI/KPT/b8D5rnQmgpnE7q6HEKzvH6D0FoZwwjNXyTim3i/A4hEoIsILVKyPPxmPZnQ5F4dwB/C2/wf8EczywT6OeeWhO//DfBUeM6fIufcswDOuSaA8Nd72zlXHr5dSmititc9/1uJHIGKQOTjDPiNc+67H7nT7D8O2667+Vm6G+5p7vR5O/o9FJ9paEjk4xYDV5tZHhxa83cIod+Xq8PbfB543TlXA+w3s3PD998ALHGhdR3KzeyK8NdIMrOUk/mXEOkpvRMROYxz7n0z+x6hlb7iCM0aezOhBVXGm9lKoIbQcQQITQc8P/xCvwX4Yvj+G4AHzOzO8Nf43En8a4j0mGYfFekhM6t3zqX5nUOkt2loSEQkxmmPQEQkxmmPQEQkxqkIRERinIpARCTGqQhERGKcikBEJMb9f8HpsF9lelM+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50','baseline')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.85990405e-01 1.40095921e-02]\n",
      " [9.99999642e-01 3.11699466e-07]\n",
      " [9.99992967e-01 7.01832005e-06]\n",
      " [1.00000000e+00 3.50577278e-09]\n",
      " [1.00000000e+00 7.62801766e-11]\n",
      " [1.00000000e+00 4.06213122e-13]\n",
      " [1.00000000e+00 2.27620367e-09]\n",
      " [9.96256590e-01 3.74339800e-03]\n",
      " [9.99208748e-01 7.91259343e-04]\n",
      " [1.00000000e+00 5.06758768e-09]\n",
      " [1.00000000e+00 4.03431705e-10]\n",
      " [9.99998569e-01 1.43687134e-06]\n",
      " [9.99998808e-01 1.14387524e-06]\n",
      " [1.00000000e+00 3.66566361e-11]\n",
      " [1.00000000e+00 1.22475315e-12]\n",
      " [9.98340130e-01 1.65984768e-03]\n",
      " [9.98946011e-01 1.05402258e-03]\n",
      " [1.00000000e+00 1.43633683e-09]\n",
      " [9.99999881e-01 1.08128262e-07]\n",
      " [1.00000000e+00 9.21886519e-16]\n",
      " [1.00000000e+00 3.24546640e-12]\n",
      " [1.00000000e+00 5.55333973e-11]\n",
      " [1.00000000e+00 7.80725085e-09]\n",
      " [1.00000000e+00 1.70826180e-08]\n",
      " [9.99873877e-01 1.26096100e-04]\n",
      " [9.99998927e-01 1.05799859e-06]\n",
      " [5.03638876e-04 9.99496341e-01]\n",
      " [5.22757590e-01 4.77242470e-01]\n",
      " [9.99999762e-01 1.92485004e-07]\n",
      " [1.00000000e+00 5.33416367e-10]\n",
      " [9.99940276e-01 5.96697028e-05]\n",
      " [1.00000000e+00 9.93136892e-11]\n",
      " [9.99998331e-01 1.64804067e-06]\n",
      " [9.99999881e-01 1.59941067e-07]\n",
      " [1.00000000e+00 1.43201950e-10]\n",
      " [1.00000000e+00 9.69980971e-11]\n",
      " [1.00000000e+00 2.98308267e-10]\n",
      " [9.99999404e-01 5.40551355e-07]\n",
      " [1.00000000e+00 1.83631013e-10]\n",
      " [1.00000000e+00 4.30712959e-08]\n",
      " [1.00000000e+00 5.08862952e-11]\n",
      " [9.99999762e-01 1.94738746e-07]\n",
      " [9.99972463e-01 2.75055354e-05]\n",
      " [1.00000000e+00 2.79895468e-10]\n",
      " [1.00000000e+00 2.15842817e-12]\n",
      " [1.00000000e+00 5.41151290e-10]\n",
      " [9.99996781e-01 3.24074608e-06]\n",
      " [9.60634053e-01 3.93659398e-02]\n",
      " [1.00000000e+00 1.40650256e-08]\n",
      " [9.97400165e-01 2.59981491e-03]\n",
      " [1.50715074e-04 9.99849319e-01]\n",
      " [9.99999881e-01 1.20692306e-07]\n",
      " [1.00000000e+00 4.23447766e-08]\n",
      " [1.00000000e+00 2.21316312e-10]\n",
      " [1.00000000e+00 7.65869104e-11]\n",
      " [1.00000000e+00 2.10318747e-15]\n",
      " [9.99994874e-01 5.15401325e-06]\n",
      " [9.99944091e-01 5.59464606e-05]\n",
      " [9.18772221e-02 9.08122778e-01]\n",
      " [9.99999881e-01 1.74957535e-07]\n",
      " [9.99974728e-01 2.52264072e-05]\n",
      " [9.99999523e-01 4.58636691e-07]\n",
      " [9.98230040e-01 1.76993816e-03]\n",
      " [1.00000000e+00 4.89230600e-11]\n",
      " [9.97700274e-01 2.29975372e-03]\n",
      " [1.00000000e+00 1.14091202e-12]\n",
      " [1.00000000e+00 3.45001694e-10]\n",
      " [1.00000000e+00 2.51945220e-08]\n",
      " [1.00000000e+00 4.37828631e-16]\n",
      " [1.00000000e+00 3.42864830e-08]\n",
      " [1.00000000e+00 1.39197021e-09]\n",
      " [9.99996424e-01 3.62272908e-06]\n",
      " [1.00000000e+00 8.94996077e-10]\n",
      " [9.97773468e-01 2.22656596e-03]\n",
      " [1.00000000e+00 1.69793211e-08]\n",
      " [9.99999046e-01 9.05999173e-07]\n",
      " [9.99999881e-01 6.73853293e-08]\n",
      " [1.00000000e+00 2.48935231e-13]\n",
      " [9.99999046e-01 9.93600224e-07]\n",
      " [1.00000000e+00 2.30422967e-13]\n",
      " [1.00000000e+00 5.35172153e-14]\n",
      " [9.99999762e-01 2.89148574e-07]\n",
      " [9.99999642e-01 3.32562962e-07]\n",
      " [1.00000000e+00 2.12779083e-09]\n",
      " [1.00000000e+00 2.00016988e-14]\n",
      " [9.80327427e-01 1.96725093e-02]\n",
      " [9.99987721e-01 1.22527290e-05]\n",
      " [1.00000000e+00 1.03200049e-09]\n",
      " [1.00000000e+00 3.75775088e-14]\n",
      " [9.81171370e-01 1.88286193e-02]\n",
      " [9.99971747e-01 2.82171186e-05]\n",
      " [1.00000000e+00 2.55714394e-10]\n",
      " [9.99998450e-01 1.51373854e-06]\n",
      " [9.99590933e-01 4.09105065e-04]\n",
      " [9.99996662e-01 3.34080687e-06]\n",
      " [1.91200778e-01 8.08799207e-01]\n",
      " [1.00000000e+00 1.44829114e-11]\n",
      " [1.00000000e+00 3.57355551e-12]\n",
      " [9.99999881e-01 1.27361659e-07]\n",
      " [9.99999404e-01 6.45978730e-07]\n",
      " [9.99995708e-01 4.24781501e-06]\n",
      " [1.00000000e+00 2.50846175e-12]\n",
      " [9.99997139e-01 2.81270900e-06]\n",
      " [1.00000000e+00 9.33197963e-13]\n",
      " [9.98455048e-01 1.54495356e-03]\n",
      " [9.98868883e-01 1.13106007e-03]\n",
      " [9.91767466e-01 8.23255442e-03]\n",
      " [5.24073482e-01 4.75926548e-01]\n",
      " [9.57928002e-01 4.20720130e-02]\n",
      " [9.99984980e-01 1.50138339e-05]\n",
      " [1.00000000e+00 3.33775636e-16]\n",
      " [2.27790807e-07 9.99999762e-01]\n",
      " [9.99992371e-01 7.59412615e-06]\n",
      " [1.00000000e+00 5.95020344e-13]\n",
      " [1.00000000e+00 5.42129674e-10]\n",
      " [9.99998808e-01 1.22080576e-06]\n",
      " [1.00000000e+00 1.79560238e-11]\n",
      " [9.99999404e-01 5.51784524e-07]\n",
      " [1.00000000e+00 3.71037023e-09]\n",
      " [1.00000000e+00 5.82245718e-08]\n",
      " [9.99945521e-01 5.44806389e-05]\n",
      " [9.99996424e-01 3.57005229e-06]\n",
      " [9.99999881e-01 8.11728427e-08]\n",
      " [9.99994993e-01 4.99049929e-06]\n",
      " [3.57968330e-01 6.42031610e-01]\n",
      " [1.00000000e+00 9.96876137e-10]\n",
      " [9.00882781e-01 9.91172418e-02]\n",
      " [1.00000000e+00 2.10922668e-10]\n",
      " [9.99999881e-01 8.75976909e-08]\n",
      " [1.00000000e+00 2.67646211e-10]\n",
      " [9.99442756e-01 5.57245803e-04]\n",
      " [1.00000000e+00 1.94540686e-13]\n",
      " [9.99830008e-01 1.69941239e-04]\n",
      " [1.00000000e+00 8.09610828e-14]\n",
      " [1.00000000e+00 1.91260718e-09]\n",
      " [1.00000000e+00 1.31852943e-13]\n",
      " [9.99758780e-01 2.41233487e-04]\n",
      " [9.99999523e-01 4.77857327e-07]\n",
      " [1.00000000e+00 1.84849775e-13]\n",
      " [9.99997020e-01 2.92659297e-06]\n",
      " [9.39272523e-01 6.07275292e-02]\n",
      " [1.00000000e+00 4.76354130e-11]\n",
      " [8.19740891e-01 1.80259064e-01]\n",
      " [7.08981400e-17 1.00000000e+00]\n",
      " [9.99994755e-01 5.18560591e-06]\n",
      " [5.23605283e-36 1.00000000e+00]\n",
      " [1.87514358e-22 1.00000000e+00]\n",
      " [2.10310973e-05 9.99979019e-01]\n",
      " [6.47904243e-14 1.00000000e+00]\n",
      " [8.66607479e-08 9.99999881e-01]\n",
      " [5.85387448e-25 1.00000000e+00]\n",
      " [3.53256202e-16 1.00000000e+00]\n",
      " [6.22585127e-27 1.00000000e+00]\n",
      " [3.69341961e-07 9.99999642e-01]\n",
      " [6.30414679e-11 1.00000000e+00]\n",
      " [9.98678148e-01 1.32178236e-03]\n",
      " [1.23025256e-20 1.00000000e+00]\n",
      " [8.35125742e-04 9.99164939e-01]\n",
      " [1.00000000e+00 2.09689710e-09]\n",
      " [8.33815150e-08 9.99999881e-01]\n",
      " [9.99487400e-01 5.12599829e-04]\n",
      " [7.65454755e-10 1.00000000e+00]\n",
      " [1.77901356e-08 1.00000000e+00]\n",
      " [3.79318096e-25 1.00000000e+00]\n",
      " [6.52539311e-09 1.00000000e+00]\n",
      " [6.03716751e-16 1.00000000e+00]\n",
      " [1.79209273e-05 9.99982119e-01]\n",
      " [7.78903604e-01 2.21096411e-01]\n",
      " [1.00329353e-05 9.99989986e-01]\n",
      " [1.86338567e-29 1.00000000e+00]\n",
      " [9.77691948e-17 1.00000000e+00]\n",
      " [1.44943214e-19 1.00000000e+00]\n",
      " [6.83380143e-18 1.00000000e+00]\n",
      " [4.58435928e-10 1.00000000e+00]\n",
      " [1.00000000e+00 1.52323612e-08]\n",
      " [3.19046737e-03 9.96809542e-01]\n",
      " [5.61264096e-30 1.00000000e+00]\n",
      " [6.82696421e-03 9.93173063e-01]\n",
      " [9.99997258e-01 2.78562720e-06]\n",
      " [1.02108866e-09 1.00000000e+00]\n",
      " [2.06036333e-13 1.00000000e+00]\n",
      " [2.98034184e-36 1.00000000e+00]\n",
      " [8.84570691e-05 9.99911547e-01]\n",
      " [8.52233199e-20 1.00000000e+00]\n",
      " [1.20540751e-14 1.00000000e+00]\n",
      " [6.43382657e-28 1.00000000e+00]\n",
      " [8.68161521e-07 9.99999166e-01]\n",
      " [1.54178392e-10 1.00000000e+00]\n",
      " [2.13093966e-01 7.86906064e-01]\n",
      " [4.33589414e-35 1.00000000e+00]\n",
      " [9.16816456e-21 1.00000000e+00]\n",
      " [1.60207629e-33 1.00000000e+00]\n",
      " [8.21063849e-15 1.00000000e+00]\n",
      " [1.04184608e-12 1.00000000e+00]\n",
      " [1.63305941e-16 1.00000000e+00]\n",
      " [1.96987776e-06 9.99997973e-01]\n",
      " [4.19251829e-12 1.00000000e+00]\n",
      " [8.25936125e-11 1.00000000e+00]\n",
      " [1.26800925e-18 1.00000000e+00]\n",
      " [9.71958265e-02 9.02804136e-01]\n",
      " [2.28787670e-04 9.99771178e-01]\n",
      " [2.75756776e-07 9.99999762e-01]\n",
      " [1.49144933e-01 8.50855052e-01]\n",
      " [2.77376483e-13 1.00000000e+00]\n",
      " [4.32951658e-19 1.00000000e+00]\n",
      " [3.19641778e-27 1.00000000e+00]\n",
      " [9.99882221e-01 1.17749871e-04]\n",
      " [1.38720855e-01 8.61279130e-01]\n",
      " [5.20123495e-21 1.00000000e+00]\n",
      " [4.89055121e-04 9.99511003e-01]\n",
      " [3.27775702e-02 9.67222452e-01]\n",
      " [2.06439972e-01 7.93560028e-01]\n",
      " [1.02880356e-30 1.00000000e+00]\n",
      " [9.91955487e-26 1.00000000e+00]\n",
      " [4.08040226e-01 5.91959715e-01]\n",
      " [4.50497027e-03 9.95495081e-01]\n",
      " [6.81193292e-01 3.18806738e-01]\n",
      " [1.27816594e-15 1.00000000e+00]\n",
      " [7.60409832e-01 2.39590168e-01]\n",
      " [9.98275638e-01 1.72433676e-03]\n",
      " [1.05986581e-25 1.00000000e+00]\n",
      " [1.03832694e-08 1.00000000e+00]\n",
      " [2.99359021e-06 9.99997020e-01]\n",
      " [2.80235557e-15 1.00000000e+00]\n",
      " [1.36340240e-28 1.00000000e+00]\n",
      " [1.04077871e-10 1.00000000e+00]\n",
      " [1.77869674e-06 9.99998212e-01]\n",
      " [5.09417279e-23 1.00000000e+00]\n",
      " [6.82672845e-14 1.00000000e+00]\n",
      " [9.64583538e-04 9.99035478e-01]\n",
      " [1.32333993e-08 1.00000000e+00]\n",
      " [1.54463210e-19 1.00000000e+00]\n",
      " [1.08179104e-13 1.00000000e+00]\n",
      " [1.06480424e-09 1.00000000e+00]\n",
      " [3.43994416e-10 1.00000000e+00]\n",
      " [8.79629748e-04 9.99120414e-01]\n",
      " [1.07009072e-11 1.00000000e+00]\n",
      " [1.29337423e-17 1.00000000e+00]\n",
      " [1.41096654e-18 1.00000000e+00]\n",
      " [1.38061878e-04 9.99861956e-01]]\n",
      "Confusion Matrix\n",
      "[[137   6]\n",
      " [ 11  86]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.93      0.96      0.94       143\n",
      "    referable       0.93      0.89      0.91        97\n",
      "\n",
      "     accuracy                           0.93       240\n",
      "    macro avg       0.93      0.92      0.93       240\n",
      " weighted avg       0.93      0.93      0.93       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.savefig('confusion_resnet_baseline.png')\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABfoklEQVR4nO3dd3zM9x/A8deN7MhAhlU1azSEolV7pGjE3rVa2qpaRY2q1l41WjXKj1JR1Kq9VY22qBZRpa0SQiSK7Hnj8/sjchIZdyF3l+Q+z8fDQ+7uO96fu9w7n8/3+xkKIYRAkiRJypHS2gFIkiQVdDJRSpIkGSETpSRJkhEyUUqSJBkhE6UkSZIRMlFKkiQZIRNlIRcYGMiZM2esHUaB8dVXXzFp0iSrnHvChAksWrTIKufOb7t27eKtt956qn2L4u+kQvajzD8tW7bk/v37qFQqnJ2dadKkCZMnT8bFxcXaoeWL1NRUvvzyS3bv3s3Dhw/x9fWlR48eDBo0CIVCYfF4zpw5w4cffsiJEycscj4hBMHBwWzevJnbt2/j5uaGv78/77//Pi+88AITJkzAx8eHDz74wCLx5OTLL7/k5s2bzJ8/3+znKihlNjdZo8xnX331FefPn2fHjh38+eefrFy50toh5ZlWq832+REjRvDLL7+wcuVKfv/9d+bNm8fmzZuZOXNmvscghECv1+f7cZ/FzJkzWbduHZMmTeLs2bMcPHiQ1q1bc/z48Xw/V06fgSVY89wFlpDyTYsWLcRPP/1keDx37lzx9ttvGx6fP39e9OzZU7z00ksiKChInD592vBaVFSUmDBhgmjUqJGoV6+eeO+99wyv/fDDD6JDhw7ipZdeEj179hRXrlzJcs6IiAjh5+cnoqKiDK9dvnxZNGjQQKSmpgohhNiyZYto27atqFevnnjrrbfE7du3DdtWrVpVrF+/XgQEBIgWLVpkKdvPP/8sXnzxRREeHp7p+QsXLohq1aqJ0NBQIYQQffv2FfPnzxddu3YVdevWFUOGDMkUU27vQd++fcXChQtFz549hZ+fnwgNDRVbt24Vbdu2Ff7+/qJly5Zi48aNQgghEhIShJ+fn3jhhReEv7+/8Pf3FxEREWLx4sVizJgxQgghwsLCRNWqVcX27dtFs2bNRIMGDcSyZcsM50tKShLjxo0T9erVE23bthUrV64UTZo0ye6jFTdu3BDVqlUTFy9ezPZ1IYQYP368mDJlinj77beFv7+/6Natm7h586bh9enTp4umTZuKOnXqiM6dO4tff/3V8NrixYvF8OHDxZgxY0SdOnXE5s2bxcWLF0WPHj3ESy+9JBo1aiSmTp0qUlJSDPv8/fffYuDAgaJ+/fqiYcOGYvny5eL48eOiZs2aokaNGsLf318EBQUJIYSIjY0VEydOFI0aNRKNGzcWCxcuFFqtVgghxLZt20TPnj3FzJkzRf369cXChQvFtm3bRK9evYQQQuj1ejFz5kzxyiuviLp164r27duLv/76S2zatEnUqFFD1KxZU/j7+4t3331XCJH5e6DVasXy5ctFq1athL+/v+jcuXOW36HCQCbKfJTxF+Tu3buiffv2Yvr06UIIISIiIkSDBg3Ejz/+KHQ6nTh16pRo0KCBePDggRBCiLfffluMHDlSREdHi9TUVHHmzBkhhBB//PGHeOWVV8SFCxeEVqsV27dvFy1atDB8YTKes1+/fuK7774zxDNnzhwxefJkIYQQhw8fFq1btxbXrl0TGo1GLF26VPTs2dOwbdWqVcXAgQNFVFSUSEpKylK2zz77TLzxxhvZlrt58+aGBNa3b1/RuHFj8ddff4mEhAQxbNgwQ+Iy9h707dtXNGvWTPz9999Co9GI1NRUcezYMXHz5k2h1+vFmTNnRK1atcQff/whhBDi9OnTWRJbdoly0qRJIikpSVy5ckXUrFlTXLt2LVOZoqOjDZ9XTolyw4YNonnz5tm+lm78+PGifv364uLFi0Kj0YjRo0eLUaNGGV7fsWOHePjwodBoNGL16tXi1VdfFcnJyYa4a9SoIQ4fPix0Op1ISkoSly5dEufPnxcajUaEhYWJtm3bijVr1gghhIiLixONGjUSq1evFsnJySIuLk5cuHAhy3uQ7r333hOTJ08WCQkJ4v79+6Jr166Gz2zbtm2ievXqYt26dUKj0YikpKRMifLEiROic+fOIiYmRuj1enHt2jURGRlpKPPChQsznSvj7+T//vc/0b59e/Hvv/8KvV4vrly5Ih4+fJjr+1gQyaZ3Pnv//fepU6cOzZo1o3jx4owYMQKAnTt30rRpU5o1a4ZSqaRRo0a8+OKLHD9+nHv37nHixAmmTp2Ku7s7dnZ2NGjQAIDNmzfTs2dPateujUqlonPnztjZ2XHhwoUs5w4KCmLPnj1AWtN13759BAUFAbBp0ybeeecdKlWqhFqtZsiQIVy5coU7d+4Y9n/nnXfw8PDA0dExy7GjoqLw8vLKtsxeXl5ERUUZHnfs2JGqVavi7OzMyJEjOXDgADqdLtf3IF3nzp2pUqUKarUaOzs7mjdvznPPPYdCoaBBgwY0atSIc+fO5ekzGTZsGI6OjlSrVo1q1apx9epVAPbv38+7776Lu7s7vr6+9O/fP8djREdH51j+jAICAqhVqxZqtZoOHTpw5cqVTO+Lp6cnarWat956i9TUVG7cuGF43d/fn9atW6NUKnF0dOTFF1/E398ftVpN2bJl6dmzJ7/++isAP/74IyVLluStt97CwcEBV1dXateunW1M9+/f58SJE3z00Uc4OztTokQJBg4cyN69ew3beHt7069fP9RqdZbPX61Wk5CQwPXr1xFCUKlSJby9vY2+FwBbtmxh5MiRVKxYEYVCQbVq1fD09DRp34JEbe0AipqlS5fy6quvcvbsWcaMGUNUVBRubm6Eh4dz4MABjh07ZthWq9Xy8ssvExERgbu7O+7u7lmOFx4ezo4dO1i/fr3hOY1Gw71797Js26ZNG6ZPn05kZCQ3b95EoVBQr149w3FmzZrF3LlzDdsLIYiMjKRMmTIAlCpVKsdyeXp6cvPmzWxf+++//zL98mc8TunSpdFoNERFReX6HmS3L8Dx48dZunQpoaGh6PV6kpOTqVq1ao5xZqdkyZKGn52cnEhMTATg3r17mc7n6+ub4zE8PDz477//8nQuR0dHw7kAvv76a7Zs2cK9e/dQKBTEx8dn+gPz5Plv3LjBnDlz+OOPP0hKSkKn01GzZk0A7t69y3PPPWc0Hkj77LVaLY0bNzY8p9frTS57w4YNeeONN5g2bRrh4eEEBAQwfvx4XF1djZ47IiLC5DgLMpkozaRBgwZ06dKFuXPnsmzZMkqVKkXHjh2ZMWNGlm3v3btHTEwMsbGxuLm5ZXqtVKlSDBkyhPfee8/oOd3c3GjUqBH79+/n+vXrBAYGGu5Gpx+nQ4cOOe6f253rV199lW+++Ya7d+9m+oKFhIRw9+5dXnnlFcNzd+/ezfSznZ0dnp6eub4H2cWQmprKiBEjmDt3Lq1atcLOzo6hQ4ciHnXUeNY77V5eXkRERFC5cmUg7Uudk4YNGzJt2jQuXbqEn59fns917tw5/ve//7F27VqqVKmCUqmkfv36hrJA1vJMmTKFGjVqsGDBAlxdXVm7di0HDx4E0j7PjDXCjJ48jq+vL/b29pw+fRq1OvuvvLH3sn///vTv358HDx4watQoVq1axahRo4zu5+vry61bt/L8x62gkU1vMxowYAA///wzV65coUOHDhw7doyTJ0+i0+lISUnhzJkzRERE4O3tTdOmTZk6dSoxMTFoNBpDE6t79+5s2rSJixcvIoQgMTGRH3/8kfj4+GzPGRQUxM6dOzl48KCh2Q3Qq1cvVq5cyT///ANAXFwc+/fvN7ksr776Kg0bNmT48OH8888/6HQ6Lly4wNixY+nduzfPP/+8Ydtdu3Zx7do1kpKS+OKLL2jTpg0qlSrX9yA7qamppKamUrx4cdRqNcePH+enn34yvF6iRAmio6OJi4szuRwZtWvXjhUrVhATE0NkZGSmWvuTnn/+efr06cOYMWM4c+YMqamppKSksHfvXpN6NiQkJKBSqShevDharZYlS5bk+Blm3MfFxQUXFxf+/fdfNm7caHitefPm3L9/n7Vr15Kamkp8fDwXL14E0t6XO3fuGHoNeHt706hRI+bMmUN8fDx6vZ5bt25x9uxZU94mQkJCuHjxIhqNBicnJ+zt7VGpVIZz3b59O8d9u3fvzhdffEFoaChCCK5evZqpFl1YyERpRsWLF6djx46GGuWyZctYsWIFDRs2pFmzZqxevdrwyzxv3jzUajXt2rUz1N4A/Pz8mD59OtOmTaN+/fq89tprbN++PcdztmzZktDQUEqWLEm1atUMzwcEBDB48GBGjx5N3bp1ad++fZ77H3755Ze8/PLLDB48mDp16vDhhx/SrVs3Jk+enGm7jh07MmHCBBo1akRqaqqhA7ix9+BJrq6ufPzxx4waNYr69euzZ88eWrZsaXi9UqVKBAYG0rp1a+rVq0dkZGSeyvP+++/j6+tLq1atGDhwIG3atMHe3j7H7T/++GNDE7R+/fq0bt2aw4cP06JFC6Pnaty4MU2bNqVNmza0bNkSBweHXC91AIwfP549e/ZQt25dJk+ezOuvv254zdXVla+//ppjx47RqFEj2rRpY+jk3bZtWwBefvllOnfuDKT9fmk0Gl5//XXq16/PiBEjTLqUAGkJ++OPP6ZBgwa0aNECDw8PQ2f0bt26ce3aNerVq8fQoUOz7Pvmm2/Srl073nrrLerWrcukSZNISUkx6bwFiexwLuWrfv360aFDB7p3727tUPJsw4YN7Nu3L9eapWSbZI1Ssln37t3jt99+Q6/Xc/36ddasWUPr1q2tHZZUAMmbOZLN0mg0fPrpp9y+fZtixYoRGBhInz59rB2WVADJprckSZIRsuktSZJkhEyUkiRJRhS6a5R6vR6dLm9XC1QqhUn7XLx4HoDates8VWyWYGpZCrqiUg6QZSmo8loWOztVjq8VumuUGo2O6OhE4xtm4OHhbNI+ffv2AGD9+s1PFZslmFqWgq6olANkWQqqvJbFy6tYjq8VuhqlORXkBClJkvXIa5SSJElGyEQpSZJkhEyUGXh7u+Ht7WZ8Q0mSbIpMlJIkSUbImzkZ3LsXa+0QJEkqgGSNUpIkyQizJcqJEyfSsGFD2rdvn+3rQghmzJhBQEAAQUFBXL582VyhSJIkPROzJcouXbqwatWqHF8/ceIEoaGhHDp0iOnTpzNlyhRzhWKyvn17GDqdS5IkpTPbNcr69evnOkX80aNH6dSpEwqFAn9/f2JjY7l3757Jq7uZw6FDB6x2bkmS8k4IwcOHD7lzJ4w7d+5w504YiVevcFehYOLkj3FzK2n8ICaw2s2cyMjITCu/+fr6EhkZaTRRqlQKPDyc83QulUpp0j7bt38PkOfjW5KpZSnoiko5QJbFnBISEggLC+P27TDCwjL+u0VY2G1u3w4jKSnJsH0N4ChwDDj4kj9vD8m6PMXTsFqizG6IuSmr6ul0wmxjvRs3bgVQoMe6FpWxuEWlHCDL8rS0Wi0REXe5ffs24eG3Df/fuXPbUDs0ZSEyNzd3ypQpQxM3dz67cB63lGSaVq+BZ5++hX+st6+vb6bV99JXI5QkqfDLrkmcOSHeISLibo4Ly6Wzt7endOkylClT9tG/MpQpUy7T/8WKuaGIekjxhnVRpiST2rI19mu+xc7NDfIp6VstUbZs2ZL169cTGBjIxYsXKVasmNUT5bp1awDo3/9Nq8YhSQVdQkIC4eF3uH077In/H9cKk5OTcz2GQqHAx8c3Q9LLmghLliyJUmn8nrPwLE7ChxOxP36M2P99Aw4O+VXUtFjNNc3a6NGjOXv2LFFRUZQoUYLhw4ej1WoB6N27N0IIpk2bxsmTJ3FycmLWrFkmLSxvzmnW0ocvFuSO50WlmVdUygFFryz378camsQZa4QZE6HpTeInk19Zw79SpUrnujywSTQasLN7/Fivh0eJtVBMs7Zw4cJcX1coFHz66afmOv1T6ddvoLVDkCSzEkLw4MGDTNcEM/4fERFOeHi4yU3ismXLPfq/LKVLlzX8n94kNie7n05S7INhxHy7BV2VqmlPmlD7fBpyCGMGCxYstnYIkvRM4uPjCQ+/8+iGSMZ/j2uFpjSJfX1LGWqC2SVCU5vE5mJ3/Bju/XuhSErCMXgtCdNmmfV8MlFKUiGh0WiIiLhrSHrZJcLo6Gijx3F398gm+aXVDqtXr4Kzs8ezN4nNyP7IQdze7IsiJYWkN/qT8Ol0s59TJsoMIiLuAuDrW8rKkUi2Jr1JnPGaYNr/j5NhZGSE0Saxg4OD0bvErq45X4sr6Ndb7ffvxW1wfxQaDUkDBxE/Z4HZmtsZyUSZQa1aLwAF+2aOVDilN4mfvEucngTz1iQum2MiLFmypEn9kQsj+907cHv3LRRaLYnvDiVh2mywUFlloszAx8fX+EaS9ASNRkNY2K1srgvmvUn8OPmVzfLP17dUgW4Sm5vy4cO0JDn8AxI+nmKxJAkyUWZy6dLf1g5BKmCEENy/fz+bu8SPa4V5aRKn3yXOmghzbxJLkDzgLbQ1X0T7Un2LJkmQiVKycdk1idObwrdvh3H3brhJTeJSpUrn2l2mKDeJzclh07do/euiq1YdAG29BlaJQyZKqcjSaDTcvRue6wgSU5rEHh4eWe4OZ6wNVqtWiYQEjfkLZGMcV6+k2MSx6L28efjTrwgPT6vFIhNlBq1bNwXgyJETVo5EMubJJnFOd4mNDTxzcHDIlPQy1wrT/nd1dc31GHZ2doBMlPnJafkSXD/9CIDEkaOtmiRBJspMQkIuWDsE6ZH4+LgsiS9jkzg8/A4pKSm5HkOpVBq9S1yiRAnZJC5gnL5YgOvMqQDEzV1I8puDrRyRTJSZHD583Noh2ASNRkNoaChXrvyTw13i28TERBs9joeHR7ZjiDPeJbbLOA5YKtiEwHn+HFw+m41QKIhf+CXJb/S3dlSATJSZ1K5dx9ohFHrpTeKs02s97kRtSpPY0dHx0d3h7BOhKU1iqXBRh1xIS5JKJXGLl5PSo7e1QzKQiVLKk8dN4uxHkJjaJC5Tpgy+vqWz3B1O/182iW2PtnYd4uYtQri7k9K5m7XDyUQmygzmzUsbWD9u3EdWjsQ60u8SZ2wKP9l30JQmsaenpyHppdX+MidCHx9fvLzcC/RQOclChEAZfgd9mbIAJA8cZOWAsicTZQbz588BimaiFELw33//ZdtxOq9N4szJL+tdYhcXFwuVSirU9Hpcx43GYe9OonfsR/dCNWtHlCOZKDMYO3aCtUN4avHxcdnOL5ix47QpTeJSpUrnOJlCmTLlKF68uGwSS89Op8N19HCcNq5HODqiDL8jE2VhUVBrkqmpqYaO0w8f3uPatetZ+g7GxsYYPY6np2emmyOPm8flHl0zLIVaLX8lJDPTaik24j0ct36HcHIiJvg7NE2bWzuqXMlvhZXp9fosd4nTk196rfDevUijTWInJyejd4llk1iyOo2GYkPfxnHndoSzCzEbtqB5tbG1ozJKJsoMLl48D+RvN6G4uFju3LmT4wiS8PA7pKam5noMpVJJ6dJlKF26DBUqPI+Xl2+Wu8SySSwVeELg9u5bOOzZib6YGzEbt6Ft8LK1ozKJTJSPOGzbTOX3BvMcIMqWI2HSp6R07ZHrPulN4uym1cpLk7h48eKZbo6UKVMuy13i9CZxQZ9YVZJypFCQ2rI1dqeOE/Pd92jrvGTtiEwmEyVpSbLY6OEYlkK6HYbr6OHExMRwpU7dHO8Sm9okNnaX2NnZ2exllKSCILnvAFICgxCexa0dSp5Yb3Wgp3Tx4nnDsrLp+vbtgbe3GwcP7jc8t27dGry93RgzZoThuYiIu3h7u+HnVzXT/vEj3kORlJTpOWVSEroJY2jTpgWDBvVj8uSJrFixlN27d/D7778RGRnxqON0WcMwuYEDBzN79mesW7eJwMAgAKZNm83PP//G1q07adeuPfPnz2Hfvt00b96SypWr4OzsjLe3m8llsrdXm1Sm1q2b4u3tZricAGn9RL293Qz9RTO+n+kTgqTz86uKt7ebYXkMgDFjRuDt7WZY/xzg4MH9eHu70bdv5tp3Xspk6udUUMtkb68ucmXKt88pIQG3Qf2Z/+EoQ5nSk2RBLFNOZI0S8NVkP/PLc4C3tw91675EmTJlUSiUrFr1FZUqVWHr1p2GJrGfX1UiIyMYPfpDw3o7hw8fAJDXDSWbpUhIwKNXF+zO/IKDl7e1w3kmCmGs7VjAaDS6PF+jM3Zdr3jdmqhuh2V5Xle2HA9/v5znGM2pqFyjLCrlAFmW7ChionHv1RW7335FV7oMMdt3o6tYOR8iNF1ey+LllfMM84Wu6W0OCZM+JUWlyvSccHIiYdKnVopIkgovRdRD3Lt1TEuS5Z4jeud+iyfJ/CYTJZDStQdfvVSfUEBPWk0ybuGXRu96S5KUmeL+fTy6BGF38Ty68s8TvWMf+vLPWzusZyYT5SMHS5SkArBo/mIe/n5ZJklJegp2p39G9ecfaCtVJnrXAfTlnrN2SPlC3sx5JCEhAYBy5cpZOZL8ERMTzciRQwF4+PABSqUSDw9PIiLCKVnSi/Xrt+Tr+VavXoGTkzN9+vQzeZ+AgCYcPnwyy/MzZ07h1Vcb06JFa5OPFRy8hj17dqJUKhk16kNefrlhtjHu3r0Dj0fLCrz77lAaNmxs8v6ScantOxC34mtSGzZG+PhYO5x8IxPlIwkJ8QC4uBSNyWDd3T1Yu3YDkDmJ3b0bzrhxo4zur9VqC8247xs3rnPkyCGCgzdz//5/jBo1lI0bt6N64rozQI8efbIk87zsL2WlvHMbRVQUuhf9AEjp1NXKEeW/wvFNsID0RPnVV0toUEiGVT0tvV7P3LkzuHQpBC8vL+bMWYCDgyPDhr2Dn19tLl26SKNGTalT5yWWLFlEYmIiHh4efPTRFEqWLMmWLZvYuXMbKpWK55+vwNSpswEIDb3OsGHvEBkZSY8evenevRcAmzatZ+/eXQAEBXWiR48+meIRQrBo0Tx+//0cpUqVNtqJ/0mnTh2ndevXsLe3N3Tkv3LlMi++WMsi+9sy5c1QPLoGoYiPI3rngQI9A9CzkNcoH0lveu/Zs9PKkZjf7dthdOnSnfXrN+PqWowff/zB8FpcXBxLlqyke/defP75Z0yfPpevv15PYGAHVq5cCsD69Wv5+utv+eabTYwd+3jGpVu3brJw4RL+979vWLPmf2i1Wq5evcK+fbtZufIbVqxYy65dO/j776uZ4jlx4hi3bt3km282MX78x/zxR0i2ce/YsZUdO7Zmef6//+7h7f24mefl5c1//93L9hjbt29mwIBezJo1ldjY2DzvLz2mvP4vHp1eR3XrJrrnK6AvQk3tJ8ka5SPx8XEATJ0608qRmF+pUqWpUuUFAF54oRp374YbXmvVKgCAW7dCuX79Xz744H0A9HodJUqUBKBSpSpMm/YxTZo0p0mT5oZ9GzZshL29Pfb29nh6evLw4QNCQi7QtGkLnJycAGjWrAUXL16gQYO6hv0uXDhP69ZtUKlUlCzpRd269bONu1On7JcHyK4Cml1H/86duzFw4GAUCgX/+99ylixZxEcffWry/tJjqn/+xr1Le1SREWjqv0zMpm2IYm7GdyykZKJ8JL1G+eabb1s5EvPLuDKhUqlCp3s8oW96QhMCKlSoyIoVa7Ls/9lnn3Px4nlOnTrO2rWrCA7e/Oi49hmOq0Sn0wGmNaOfJTF5e3tz716k4fF//92jZEmvLNsVL17C8HOHDp0N12pN3V9Ko7ryJx5dg1De/4/UVxsTs34zFPGF3mTTm7RZgFJTU1Gr1Tg4OFg7nALhuefKEx0dZWgGa7Varl//F71ez717kdStW4+hQ0cSHx9P0hPj5DOqXbsuJ0/+SHJyMklJSZw4cYzatf0zbePvX4ejRw+h0+m4f/8+v/9+Lk+xNmrUlCNHDpGamkp4+B3CwsKoXr1mlu3u379v+PnEiWNUrFgpT/tLoIiPw6Nbh7Qk2bQFMRu2FvkkCbJGCTy+kWNv78ChQwdo06adlSOyPjs7O2bMmMvnn88nPj4enU5Hjx69ee658kybNpmEhHiEEPTo0YdixXIe+vXCC9Vo1649b7+dtj5zUFAnqlbNfMG/adMW/PbbrwwY0Ity5Z6jTp262R3KcH3yySZ4xYqVaNmyNX37dkelUjF69DjDHes5c6bTqVNXqlWrwfLlX/DPP3+jUCjw9S3Fhx9OMrq/lJlwLUb85Kk47Pqe2NXB8KgFUtTJsd5AWNgtXnrpRcPje/dinzo+cysq44qLSjnARsqSmgr2jy+tIAQU8Ou4cqx3Pku/Puni4sJrr7W1cjSSVLCoT/9C8YZ1UV3K0BuhgCfJ/CYTJY+b3lWrvsD69ZutHI0kFRx2P53Eo1cXVGG3cFq/1trhWI1MlEB8fFqidHXNueotSbbG7scfcO/TDUViAsk9+xA/6zNrh2Q1MlGSuektSRLYHzmIe7+eKJKSSOo3kLgvloEN3+Aya6I8ceIEbdq0ISAggJUrV2Z5PS4ujiFDhtChQwcCAwPZtm2bOcPJUXpn8wMH9mWZQl6SbI39/r24DeiDIiWFpLfeJv6zz0Fp23Uqs5Vep9Mxbdo0Vq1axd69e9mzZw/Xrl3LtM23335LpUqV2LVrF8HBwcydO9fo0q3mkF6jlCQJFAnxoNWS+O77xM+eb/NJEsyYKENCQihfvjzlypXD3t6ewMBAjh49mmkbhUJBQkICQggSEhJwd3e3yow16dco33tveIHuGiRJlpDSrSfRB4+RMG2Wzd3dzonZEmVkZCS+vr6Gxz4+PkRGRmba5o033uDff/+lSZMmdOjQgUmTJqG0wl+v9LverjYwwkCSsuPw3QbUF343PNb615VJMgOzVd+y68f+5HjeU6dOUb16ddatW8etW7d48803qVevXq4JS6VS4OGRt3WwVSplrvukj3UuWdIzz8e2NGNlKSyKSjmg8JdFsep/qIe/h/D0RPx5BY9Hk58Udvn5uZgtUfr6+hIREWF4HBkZibd35iUrt2/fzjvvvINCoaB8+fKULVuW69evU6tWzvMA6nQi30fmPHgQDcDatd9w9OgPBbovZVEZBVJUygGFuyyOq1dQbOKHACSMGINDiZKFtixPKhQjc/z8/AgNDSUsLIzU1FT27t1Ly5YtM21TqlQpfvnlFyBtwoIbN25QtmxZc4WUo/Sm95Urlzl06IDFzy9J1uC07EtDkoyfOZek90dYOaKCy2w1SrVazSeffMLgwYPR6XR07dqVKlWqsHHjRgB69+7N0KFDmThxIkFBQQghGDt2LMWLFzdXSDlKv5nzwQfjqFv3JYufX5Iszfnz+bjMmgZA3GefkzzgLStHVLDJSTGATp1e5+efT7F9+x4aN276rCGaVWFu5mVUVMoBha8sqqtX8GzeEIQg7vOlpPTua3itsJUlN/nZ9JbTrJFxCKO86y0Vfbpq1YlbvBwUClIerWsk5U72JOXxNcojRw6xbl3WGb0lqdATAuWtm4aHKT16yySZBzJR8nhkzrx5sxg7dqSVo5GkfKbX4/rRh3i2bIw65IK1oymUZNObx03vnj37YJ9xclJJKuz0elw//ACn4DUIBweUcnXJp2LziTJt+GRaoly0aIlVhlBKklnodBT7YBiOm75FODoS881GNC1aWTuqQsnms0JiYiJCCJycnGSSlIoOrZZiw97FcfsWhLMzMes3oyngPToKMpvPDBnnooyIuAuAr28pa4YkSc+s2LB3cNy+Fb2LK7Ebt6J55VVrh1So2fzNnPS5KF1cXKlV6wVq1XrByhFJ0rNLfa0dek9PYrbskEkyH8gapaFG6YqPj6+RrSWpcEjp0p3UVgEIdw9rh1Ik2HyNMmPT+9Klv7l06W8rRyRJTyExEbe3+qH+/ZzhKZkk84+sUSakNb3lqByp0IqPx71fT+x/Oonq6p9EnTxr0+vbmINMlBma3pJU2CjiYnHv3Q27s6fR+fgS+81GmSTNwOYTZcZx3q1bp3WfOHLkhDVDkiSTKGKice/ZGbvff0NXugwx23ejq1jZ2mEVSTafKNM7m7u4uBAih3dJhYTi4QPce3TGLuQCunLPEb19D/ryz1s7rCLL5hPl4xplMQ4fPm7laCTJNOoLv6O+fAnd8xXSkmTZctYOqUiz+USZ8a537dp1rByNJJlG0zKA2K/Xo/Wvg75UaWuHU+TZfPegxx3OXawciSTlTnk3PFP3n9R2gTJJWojNJ8r0GqWrazHmzZvFvHmzrByRJGWlvB2GR8d2uHfvhPrSRWuHY3NkoszQ9J4/fw7z58+xckSSlJnyZigenV5HFXoDXYWK6MpYfgE+W2fz1yjTm96urq6MHTvBytFIUmaq69dw7xKEKvwOmpfqEbNpuxxxYwU2nyjTa5TOzq6MG/eRlaORpMdU//yNe5f2qCIj0LzckJgNWxDF3Kwdlk2y+aa3XFhMKpCSknDv3hFVZASpjZoQvXGbTJJWZPOJMuM1yosXz3Px4nkrRyRJgJMT8dNmkdIqgJhvt4D8Q25VsultmBSjGC+/7A/AvXuxVoxIsmkpKeDgAEBqh86kBnUChcK6MUmyRpmxRlmrlj+1avlbNyDJZql/PUPxBrVR/3rm8ZMySRYIJtcoExMTcXZ2NmcsFqfVaklOTkapVOLk5CQnw5Csxu6Xn3Dr0x1lQjyOG4KJr/+ytUOSMjBao/z99995/fXXef311wG4evUqU6ZMMXdcFvF4QgxXFPIvt2Qldid+xL13V5QJ8SR37UH8Z59bOyTpCUYT5ezZs1m9ejUeHh4AVKtWjXPnzuW+UyGRsdktSdZg98MR3Pv2QJGYSHKvN4hbsgLkaqAFjknXKEuVyrwqoVJZNC5tPtk1yM+vKn5+Va0ZkmRD7A/tx71/LxTJyST1f4u4z5fKSXcLKKN/ukqVKsXvv/+OQqEgNTWV4OBgKlWqZInYzC5j0xsgMjLCmuFItkarA72exMHvkjBznrxxU4AZTZRTpkxh5syZREZG0qxZMxo1asSnn35qidjM7skaZUjIX9YMR7Ixqa+3J+rgj+he9JNJsoAzmihv3LjBggULMj3322+/8dJLL5ktKEt58hqlr2+p3DaXpGfmsPU7dGWfQ/tKQwB0frWsHJFkCqMXG2fMmGHSc4VRxmUgJMncHDcEU+z9d3Dv0w3l3XBrhyPlQY41yvPnz3P+/HkePnzImjVrDM/Hx8ej0+ksEpy5ZVwGAmDMmBEALFiw2GoxSUWT49rVFBv3AQAJI0fLCXcLmRwTpUajITExEZ1OZ2iiQtr1vMWLi0YieTxzUFqNMjh4LSATpZS/nP63HNdJ4wGInzqLpPeGWTkiKa9yTJQNGjSgQYMGdO7cmTJlylgyJovJOBclwPz5X1gzHKkIclryBa7TJgMQN/szkge9a+WIpKdh9GaOk5MTc+fO5dq1a6SkpBieX7dunVkDs4THN3PSEmX//m9aMxypiFFe/xeX2dMAiJv/Bcny96vQMnozZ+zYsVSsWJHbt28zbNgwypQpg5+fnyViMzs5F6VkTvqKlYhduZbYL5bJJFnIGU2U0dHRdO/eHbVaTYMGDZg9ezYXLxaNxY2evOt98OB+Dh7cb82QpMJOCJQ3rhsepgYGkdK7rxUDkvKD0aa3+tG4U29vb3788Ue8vb2JiCgaI1jSE2X6Xe9+/XoCcj5K6SkJgcsnE3EK/oboTdsNfSWlws9oonzvvfeIi4tj/PjxTJ8+nYSEBD76yLS1ZU6cOMHMmTPR6/V0796dd955J8s2Z86cYdasWWi1Wjw9PVm/fn3eS/GUnuxw/tprbS12bqmI0etxnTgWpzWrEHZ2KKMeWjsiKR8ZTZQtWrQAoFixYgQHBwNpI3OM0el0TJs2jTVr1uDj40O3bt1o2bIllStXNmwTGxvL1KlTWbVqFaVLl+bBgwdPW46n8mTTe/36zRY9v1RE6PW4jh2J0/pvEA4OxK5ZT2rrNtaOSspHOSZKnU7H/v37iYyMpEmTJlStWpVjx46xYsUKkpOT2bFjR64HDgkJoXz58pQrVw6AwMBAjh49milR7t69m4CAAEqXTut8W6JEiXwokume7HAuSXmm06F6ezB269chHB2JWbcJTfOW1o5Kymc5JspJkyZx9+5datWqxYwZMyhTpgznz59n7NixtG7d2uiBIyMj8fX1NTz28fEhJCQk0zahoaFotVr69etHQkIC/fv3p1OnTk9fmjyS81FKz6rYB8NQbvoW4exMzPrNaBo3tXZIkhnkmCj/+OMPdu3ahVKpJCUlhVdeeYVDhw7h5eVl0oGFEFmee3IWcZ1Ox+XLl1m7di3Jycn06tWL2rVrU6FChRyPq1Ip8PDI25IUKpUy233Sm95lynjj4eGMvX3a25Gaqs3T8S0pp7IUNkWlHIoe3RCHD6Dbug2XRo2tHc4zKyqfC+RvWXJMlHZ2doYJeh0cHHj++edNTpIAvr6+me6OR0ZG4u3tnWUbT09PnJ2dcXZ2pl69ely9ejXXRKnTCaKjE02OA8DDwznLPkIIQ9Nbq1Vmej2vx7ek7MpSGBWVctC4FR5//UO0Xg1FoDxF5nMh72Xx8sr5ElyO/SivX79OUFCQ4d+Tj43x8/MjNDSUsLAwUlNT2bt3Ly1bZr5206pVK86dO4dWqyUpKYmQkBCLTQqcnJyMTqfDwcEBOzs7IK1bkOwaJOUqKQm3t/ph99PJx8+5uVkvHskicqxR7tu379kOrFbzySefMHjwYHQ6HV27dqVKlSps3LgRgN69e1OpUiWaNGlChw4dUCqVdOvWjapVLbMUg7w+KeVZYiLu/Xtjf+IY6pCLPPzlN3j0R1Yq2hQiu4uJBZhGo8uXpvfNm6HUr1+LcuWe47ff/sjPEM2qqDSNCl054uNx79sD+59PoffyJnrbbnTVqgOFsCy5sOWy5Nb0ttnl3rIb5923bw9A9qeUMlPExeLeqyt2v55B51uKmO170FWuYu2wJAuy2UT55FyUAIcOHbBWOFIBpYiOwr1XF+x+/w1dmbJEb9uNvmLRWFxPMp1JiTI5OZnw8HAqVqxo7ngs5sm5KAGCg7+zVjhSAaX+8zLqPy6he6480dv3oH+uvLVDkqzA6OxBP/zwAx07dmTw4MEAXLlyhSFDhpg9MHN7ci5KgDZt2tGmTTtrhSQVQJpXGxOzbiPRO/fLJGnDjCbKJUuWsHXrVtwedYGoXr06d+7cMXtg5vZ45iA5F6WUmTIyArvTPxsea1oGoC9T1ooRSdZmNFGqVCqKFSt6Y6GzW4Fx3bo1rFu3JqddJBugvBuOe6fXce/ZGfWvZ6wdjlRAGL1GWaVKFXbv3o1OpyM0NJTg4GDq1KljidjMKr3pnXFCjLFjRwJySQhbpQy7hUeX9qhuhqJ5sRa6ipWN7yTZBKM1ysmTJ3Pt2jXs7e0ZM2YMrq6uTJo0yRKxmVV696CMNcp+/QbSr99AK0UkWZMy9AYeHdulJUn/OsRs24Ww8GxWUsFltEZ548YNPvjgAz744ANLxGMx2TW95TK1tkn17z+4dwlCdTccTb0GxGzahnBzt3ZYUgFiNFHOnj2b//77j7Zt2xIYGEiVKkWjo62ci1ICIDUV955dUN0NJ7VhI2K/3YyQvxPSE4w2vYODgwkODqZ48eJMnjyZoKAgli1bZonYzCq7sd4REXeJiLhrrZAka7C3J37OfFJaBRCzYatMklK2jCZKAC8vL/r378/UqVOpVq1akUiU2XU4r1XrBWrVesFaIUmWlJRk+DG1dRtiN2wFOUGKlAOjifLff//lyy+/pH379kyfPp06depw/PhxS8RmVtl1OPfx8cXHxzenXaQiQv37OYo3qI3dyQy/x09MKi1JGRm9Rjlx4kQCAwNZvXo1Pj4+lojJIrKbFOPSpb+tFY5kIeqzZ3Dv1QVlfByOG4LRNGlm7ZCkQsBooty8uWjOpJPdXW+paLP7+RTufbqjSEwguWMX4hYvt3ZIUiGRY6IcOXIkX3zxRY6zme/evdtsQVlCdk1vqeiyO34M9/69UCQlkdytZ1qSVNvs5FlSHuW6CiPAV199ZbFgLOlxjfJxomzdOm0FvSNHTlglJsk87H44jPuAPihSUkjq3Zf4hV+CSmXtsKRCJMebOekLgW3YsIEyZcpk+rdhwwaLBWgOOp2OxMS0mY+dnR+v0hYScoGQkAtWikoyG4UShCBpwCDiFy2RSVLKM6Ntj59//jnLcydOnODDDz80S0CWkJj4uNmdvtIkwOHDhf9uvpSVpkUrog6fSFu6Qd7dlp5Cjolyw4YNbNy4kbCwsEzXKRMSEqhbt65FgjOXnBYWq1278E/2IaVx2LENvbsHmhatANBVr2HliKTCLMdEGRQURNOmTVm4cCFjxowxPO/i4oKHh4clYjOb7LoGSUWHw3cbKDZyKNjb8/DEGfTP57xOvCSZIsdEqVAoKFu2LJ988kmW16Kjowt1sszuRg7AvHmzABg37iOLxyTlD8dv1+E6ejgKIUgYOUYmSSlf5Jgox4wZw4oVK+jSpQsKhYKMq9oqFAqOHj1qkQDN4fFclJkT5fz5cwCZKAsrxzWrKDZ+NADxH08laUTRmvFKsp4cE+WKFSuAtDVzipr0cd5PXqMcO3aCNcKR8oHTymW4fpz2+cVPm0XSkGFWjkgqSoze9f7tt9+oXr06zs7O7Ny5kz///JMBAwZQunRpS8RnFjl1Npc1ycJJeec2LjOmABA3ZwHJb71t3YCkIsfopBhTpkzBycmJq1evsmrVKkqXLs24ceMsEZvZyJs5RYu+TFlivtlI3KIlMklKZmE0UarVahQKBUeOHKF///4MGDDAUCMrrHIa533x4nkuXjxvjZCkvBIC1bV/DA81LVqR/EZ/KwYkFWVGE6WLiwsrVqxg165dNG/eHJ1Oh1artURsZpNTjTIgoBkBAXI2mQJPCFymfYJni1exO1Z4bypKhYfRRLlo0SLs7e2ZNWsWXl5eREZGMmjQIEvEZjbpNWJn58yJslYtf2rV8rdCRJLJhMBl8gScl34BOh2KR3/0JMmcjN7M8fLyIigoiEuXLnHs2DFq1apFp06dLBCa+aQ3vZ+sUcrJMAo4vR7XCWNwWrsaYW9P7Kp1pLZ93dpRSTbAaI1y3759dO/enQMHDrB//37Dz4VZdkvVSgWcTofrmBFpSdLBgZh1G2WSlCzGaI3yq6++YuvWrZR4tMbxw4cPGThwIG3btjV7cOYi56IsfFzHj8Hp23UIJydi1m1C06yFtUOSbIjRGqUQwpAkATw8PDKN0imMcrqZ4+dXFT+/qtYISTIipUMn9CVKELNxm0ySksUZrVE2btyYQYMGERgYCKQ1xZs2bWr2wMwpMTH7pndkZIQ1wpFMoGnanAe/XgLZ91WyAqOJcvz48Rw6dIjffvsNIQQ9e/YkICDAErGZzeMaZeY1nENC/rJGOFJ2UlJwG/o2yX36ktrqtbTnZJKUrCTHRBkaGsrcuXMJCwujatWqjB8/vsiswpjTfJS+vqWsEY70pKQk3Af2wf7YUdTnzvLwzAVwdLR2VJINy/Ea5UcffUSLFi1YvHgxNWvWZPr06ZaMy6zSJ8WQQxgLoIQE3Pv2wP7YUfQlSxKzYatMkpLV5VijTEhIoEePHgBUrFiRzp07Wywoc8vprveYMSMAWLBgscVjkkARH4dbn+7Yn/4ZnbcPMdt2o3uhmrXDkqScE2VKSgp//vmn4Q53cnJypsc1a9a0TIT5LDU1FY1Gg52dHQ4ODpleCw5eC8hEaQ2K2Bjce3XF7txZdKVKE7N9N7pKVawdliQBuSRKLy8vZs+ebXhcsmRJw2OFQsG6devMH50Z5DQXJcD8+V9YOhzpEdU/f6O+fAld2XJEb9uNvkJFa4ckSQY5Jsrg4GBLxmExuXU279//TUuHIz2ifak+MRu2onuuPPpyz1k7HEnKxGiH82dx4sQJ2rRpQ0BAACtXrsxxu5CQEKpXr26RoZFyLsqCQ3HvHnY/Pp5BX9OoiUySUoFktkSp0+mYNm0aq1atYu/evezZs4dr165lu938+fNp3LixuULJJKe5KAEOHtzPwYP7LRKHzQsPx6Pz67j37YHdSbmeulSwGe1w/rRCQkIoX7485cqVAyAwMJCjR49SuXLlTNsFBwfTpk0bLl26ZK5QMnk8IUaxLK/169cTgHv3Yi0Si61S3rmNunsHFNeuoa1eE201uea2VLCZNNZ7586dLFmyBIDw8HBCQkKMHjgyMhJfX1/DYx8fHyIjI7Nsc+TIEXr16pXXuJ9aTp3NAV57rS2vvVZ4J/soDJS3buLR8XUU166hebEW0dv3ILy8rB2WJOXKaI1yypQpKJVKTp8+zbBhw3BxcWH48OFs27Yt1/2ymzhDoVBkejxz5kzGjh2LSqUyOWCVSoGHh7PJ26ftozTsI4QGgOLFPbIcZ8+ePXk6rjVkLEuhc+0a6s6vowgLQ9SvD3v24e7pae2onlmh/kyeIMuSPaOJMiQkhO+//94wWa+7uzsajcbogX19fYmIeDzJRGRkJN7e3pm2+eOPPxg9Om0d5qioKI4fP45araZ169Y5HlenE0RHJxo9f0YeHs6Gfe7dewCAnZ1jno9TEGQsS6Gi1eIZ1B5FWBia+i/Dvn1ECzsojGV5QqH9TLJhy2Xx8sp6OS6d0USpVqvR6XSG2uDDhw9RKo3fA/Lz8yM0NJSwsDB8fHzYu3cvCxYsyLRNxjXDJ0yYQPPmzXNNkvkht6a3ZEZqNfHzv8D5y0XErvoGd3f3IpEkJdtgNFH269eP999/nwcPHrBo0SIOHDjAqFGjjB9YreaTTz5h8ODB6HQ6unbtSpUqVdi4cSMAvXv3fubgn0ZCQs7jvL293QB5MydfJSaCc1rzR9OoCTGvNoYnLsFIUkFnNFF26NCBmjVrcvr0aYQQLFu2jEqVKpl08GbNmtGsWeZVDXNKkHPmzDHpmM9Kzm5uOeqQC7j16U78wsWkvtYu7UmZJKVCyGiiDA8Px8nJiRYtWmR6rnTp0mYNzFxy63Aua5L5R/3br7j37IIyNgbH7zY+TpSSVAgZTZTvvvuu4eeUlBRu375NhQoV2Lt3r1kDM5fcOpxL+UN95jTuvbuijI8jJbADsctXWTskSXomRhPl7t27Mz2+fPky3333ndkCMrf0prccwmgedj+dxP2NHigSE0ju3JW4JSvBzs7aYUnSM8nzEMaaNWtabBSNOTwemZM1Ufbt24O+fXtYOqQiw+74Mdz7dEtLkt17EbdslUySUpFgtEa5Zs0aw896vZ4///yT4sWLmzUoc8qtRnnoUOFer9zahIMjKBQkvdGf+PlfQB4GEkhSQWY0UaYnFgCVSkWzZs1o06aNWYMyp8fzUWZNlMHBhfeSQkGgfaUhUYeOo6tcBUzoaytJhUWuiVKn05GQkMD48eMtFY/Z5dbhvE0beWc2r+x37wCVmtTX2wOgq/qCdQOSJDPIMVFqtVrUajV//vmnJeMxOzkfZf5x2LaZYsPeBaWSqGM/yyQpFVk5Jsru3bvz/fffU716dYYMGULbtm1xdn48wPy1116zSID5Sa/Xk5iYVqN0ds5ao1y3Lu16rJzp3DiHTd9SbORQFEKQMGosuipVrR2SJJmN0WuUMTExeHp6cubMmUzPF8ZEmZSUhBACZ2fnbGcsGjt2JCATpTGOwWtxHTsyLUlOnEziBx9aOyRJMqscE+WDBw9Ys2YNVapUQaFQZJo27cnp0gqL9GZ3drVJgH79BlowmsLJcfVKik0cC0D8J9NJGjbSyhFJkvnlmCj1en2mO95FQfqonJyuT8planOnuHcPl5lTAYifMYekd4ZaOSJJsoxcl6sdNmyYJWMxu8fDF+WNnKchvL2J3bAF1d9/kSwvT0g2JMfObtnNUF7YGZuLMiLiLhERdy0ZUsEnBKq/rhoeal55VSZJyebkmCjXrl1rwTAsI72zeU5N71q1XqBWLdnFxUAInGdPx7PFq9jvK/jLZEiSueTY9Pbw8LBgGJZhbC5KHx/fbJ+3SULgMuVjnJd/iVCpUKQkWzsiSbIasy1XWxAZ62x+6dLflgyn4BICl0njcF61AqFWE7tiDalBHa0dlSRZjU0lSjkXpQn0elzHjcZp3dcIe3tiVweTKod2SjbOxhJl+sxBOa+2ZutcJk9IS5IODsR8swFNywBrhyRJVmdTU7w8nosy+xpl69ZNad26qSVDKnBSOnZFX9KLmG+3yCQpSY/YWI0y90QZEnLBgtEUIEIYFv3SNniZB+cuGVZOlCTJxhLl45s52Te9Dx8+bslwCobUVIoNfZuUjp1JDeqU9pxMkpKUiU0lSmMdzmvXrmPJcKwvORm3wf1xOHQA+59P8qBFa5DTz0lSFjaVKHOb3dzmJCXhPqA39j/+gL54cWK++14mSUnKgU0lSmMdzufNmwXAuHEfWSwmq0hIwL1fT+xPnUBf0ovorbvQ1ahp7agkqcCyyUSZU4fz+fPnAEU7USri43Dr0x370z+j8/ElZttuOTO5JBlhY4ky97veY8dOsGQ4VqEMDUX9xyV0pcsQs303uoqVrR2SJBV4Npkoc7rrXZRrkul0L/oRs/l79CW90D9fwdrhSFKhIDuc2wDF/fvYH9pveKyt10AmSUnKA5tJlBqNhpSUFJRKJY6Ojtluc/HieS5ePG/hyMxLce8eHl0CcRvQB/vDB6wdjiQVSjbT9M7Y7M5pzZ+AgGYA3LsXa7G4zEkZcRf3rkGo//kb7QvV0NSysX6ikpRPbChR5t7ZHKBWLX8LRWN+yju3ce/SHvWN62ir1yR66y6El5e1w5KkQsnmEmVOXYMAjhw5YalwzEp5MxSPrkGobt1EU8ufmM3fI4qXsHZYklRo2cw1ysejcor4jRy9HvcBfdKSZN2XiNm2SyZJSXpGNpMobWYuSqWSuAVfkNIqgJgtOxHuHtaOSJIKPZtpepvSNcjPrypQSJeEiI83jNXWvlSf2I3brByQJBUdNlSjNJ4oIyMjiIyMsFRI+Ub1xyVKvOyPww6ZHCXJHGwmUT6uUebc9A4J+YuQkL8sFVK+UF88j0eXQJT/3cNh+5a0SXglScpXNtP0NqV7kK9vKUuFky/U587i3qsrytgYUtoGEvu/tYaZyiVJyj82VKNMu+udW/egwkR9+hfcu3dKS5JBnYhdvQ4cHKwdliQVSWZNlCdOnKBNmzYEBASwcuXKLK/v2rWLoKAggoKC6NWrF1evXjVbLMbmogQYM2YEY8aMMFsM+cXup5N49OqMMiGe5C7diV3xNdjZWTssSSqyzJYodTod06ZNY9WqVezdu5c9e/Zw7dq1TNuULVuW9evXs3v3bt577z0mT55srnBM6nAeHLyW4OC1ZoshvwhXV4TajuRebxC3dCWobeYKiiRZhdm+YSEhIZQvX55y5coBEBgYyNGjR6lc+fH8h3Xr1jX87O/vT0SE+e44JyQY73A+f/4XZjt/ftLWrkPUoR/TZgBS2szVE0myGrMlysjISHx9fQ2PfXx8CAkJyXH7rVu30rSp+dbUNqXDef/+b5rt/M/Kfu9uFEmJMDgtRn3FSlaOSJJsh9kSpcimm0pOs/acPn2arVu3smHDBqPHVakUeHjkbTlVlUpJcnIiAD4+xfO8v7UptmxBNbg/CIFoUBePWrWtHdIzU6mUhe5zyIksS8GUn2UxW6L09fXN1JSOjIzE29s7y3ZXr17l448/5n//+x+enp5Gj6vTCaKjE/MUi4eHMzExaVOnCaHOcf+DB9Mmt23Tpl2ejm9ODls2UWz4EBR6PYkjRmPnVyvP5S+IPDyci0Q5QJaloMprWby8cm5tmi1R+vn5ERoaSlhYGD4+Puzdu5cFCxZk2iY8PJzhw4czb948KlQw74zb6R3Oc2t69+vXEyg481E6bFxPsVHvoxCChLETSPxwIh6yn6QkWZzZEqVareaTTz5h8ODB6HQ6unbtSpUqVdi4cSMAvXv3ZunSpURHRzN16lQAVCoV27dvN0s8pnQ4f+21tmY599Nw/OZrin04CoCEiZNJ/OBD6wYkSTZMIbK7mFiAaTS6p2p6lyxZgtjYGP755xbuBXxGHUXUQ4q/UgdlVBTxn84g6f3HfTuLStOoqJQDZFkKqkLR9C5IhBAZ5qMs+CNzhGdxYr77HvX530l+c7C1w5Ekm2cTiTI5ORm9Xo+joyPqAtw5W/XnZXQ1agKg9a+L1r+ukT0kSbIEm+itHBdn2uzm3t5ueHu7WSKkzITA+bPZeLZ4FYet31n+/JIk5argVq/y0eMp1gpgs1sIXGZNw/mLBQilUk6TJkkFkE0kysc1ytwTpcW7BQmBy6eTcP5qCUKlIm75KlI6dbVsDJIkGWUTidKU2c0tTghcP/oQp9UrEXZ2xK5cS2pgkLWjkiQpGzaRKB93Ni84TW+X6Z+mJUl7e2K/Dib1tYIzGkiSpMxs5GaOadco+/btQd++PSwREimdu6LzLUXMuk0ySUpSAWcTNcr0prexGuWhQwfMG4gQhqUatH61eXjmAjg5mfeckiQ9M5tIlKZ2DwoONmPXHI2GYu+/TWrLAFJ6vZH2nEySklQo2ESiNGVCDDDjrEEpKbi9PRCHA3ux//EHUtsFIgr4MEpJkh6ziURpao3SLJKTcXurLw5HDqH38CBm8w6ZJCWpkLGJRGnKzEEA69atAfJxpvPERNz798b+xDH0JUoQvXknOr9a+XNsSZIsxiYSZXqN0ljTe+zYkUA+Jcr4eNz79cT+p5PovbyJ3roLXfUaz35cSZIsziYS5eMhjLnXKPv1G5hv51TdDUd95TI6H19itu9BV6Vqvh1bkiTLsolEaWr3oAULFufbOXVVqhKzZSd6F1e5EJgkFXI20uHcMnNRKh4+wH7PLsNjrV9tmSQlqQiwiUQZH59+Myf3RBkRcZeIiLtPdQ7Ff//h0SUIt0H9sN/1/VMdQ5Kkgskmmt6PZzfP/RplrVovAHmfRUgRGYlHtyDUf11FW7kK2vovP12gkiQVSDaSKE0b6+3j45vnYyvvhuPepT3qf6+hfaEa0Vt3I3x8nipOW6PTaYmK+g+tNtXaoTyTyEhFtuvYF0a2UBa12h5PTy9UKtPTn00kysfdg3JPlJcu/Z2n4ypvh+HRpT2q0Btoa/oRvWUnomTJp47T1kRF/YejozMuLr4oCvEyvCqVEp1Ob+0w8kVRL4sQgoSEWKKi/qNkyVImH6vIX6PU6XQkJSWhUChwdnbOvwMLgdugfqhCb6CpXYfo7btlkswjrTYVFxe3Qp0kpcJFoVDg4uKW51ZMkU+UiYmPb+Tk6xdSoSBu4RJSWr9GzNadCM/i+XdsGyKTpGRpT/M7V+Sb3qZ2Ngdo3bopAEeOnMhxG0VcLKJY2gJkupovErthaz5EKVlL06YNqFixMjqdllKlyjB58jSKFUsbwXX9+r98/vln3Lt3DxC0bRvIgAGDDF+0X375iVWrviI5OQkhBK++2oRhw0ZZrzDZ+Pvvq2zfvoUJEyZbO5RspaamMmPGp/z11xXc3NyZNm02pUqVzrLd0aOHWLfua3Q6Pa++2oihQ9NG0W3atJ49e3aiUqnw8PBk4sRP8PUtRVRUFDNmfMKCBV/mS5xFvkaZPs7blNnNQ0IuEBJyIcfXVVf+xLPhSzh+uy6/wpOszMHBgbVrNxAcvBk3Nze2b98MQEpKMhMmjKZv34Fs2rSdtWs3culSCNu3bwHg+vVrLFo0j08+mc6mTdtZt+47Spcuk6+xabXaZz7GunVr6Nq1p0XPmRd79uykWLFifPfdDnr27MPy5VkTW0xMNEuXfsHnny9n/frNPHz4kHPnzgJQtWo1Vq0K5ptvNtG8eSuWLUsbNOLp6UnJkiVz/T7nhQ3UKE3vbH748PEcX1NdCsGjeweUDx/isHsHyb37grLI/52xKS++6Me1a9cAOHz4AH5+tWnQ4BUAHB0dGT16HMOHv0vXrj349tt19O//FuXLPw+AWq2mS5fuWY6ZmJjI559/xtWrf6JQKHjzzbdp3rwVAQFNOHz4JADHjh3h559PMWnSFGbOnIKbmxt///0XVapU5cSJH1mzZoOhltuzZyeWL1+NQqFk/vxZREZGAjBixGhq1fJ/4twJ/PvvP1R5NHz2zz//YPHihaSkJOPg4MhHH33Cc889z759u/n551OkpqaSkpLEnDmLWLRoHtev/4tOp+Wtt96hSZPm3L0bzvTpn5CcnATABx+Mw8+v9jO956dOHeett94BoHnzVixaNA8hRKbmcXj4HcqVK4+npycA9eo14Mcff6BevQbUrVvPsF3Nmi9y6NA+w+OmTVtw6NCBLO/L0yjyiTIvNcratetk+7z6wu+49+iEMjqalIA2xK4Olkkyn/Xp040jRw7l6zFbt36NDSZeGtHpdJw79yvt23cE4MaN67zwQvVM25QpU5bExEQSEuK5ceNfevXqa/S4a9euwsXFlXXr0iaFjo013kc3LOwWn3++DJVKhV4vOHHiGIGBHbh8+Q98fUtTvHgJpkyZRI8eb1C7tj8RERGMGTOMb7/NXNarV69QMcPIsPLln2fJkpWo1Wp+/fUMK1YsZebMzwC4fPkS33yzEU9PT5Yt+5KXXqrPRx99SlxcHG+/PYB69V7G07M4ixYtxcHBgbCwW0yZMonVq4OzxD906GASExOzPP/++yOp/0Qf4//+u4e3d1p3OrVajYuLKzExMXh4eBi2KVOmHLduhXL3bjheXt6cPPkjGk3Wmu+ePTt5+eVXDY+rVavBihVLjb7fpijyiTIv1yizo/71DO69uqKMiyWlXXti/7cW7O3zMULJmlJSUhg4sA8REeG88EJ1wxf5yVpNRnm5GXDu3FmmTp1leOzm5mZ0nxYtWqNSqQBo1SqANWtWERjYgaNHD9KqVYDhuKGhNwz7JCQkkJiYgLPz49/z+/fv4+HhaXgcHx/PjBlTuH37FgqFIlMzu379l3Fzcwfg7NnTnDp1nI0b1wOQmppCZGQEJUt6sWjRXP7552+UShVhYTezjX/ZslVGy5guuy6bT769bm5ujBkzgU8+mYhSqeTFF2sRHn4n0zYHD+7j6tUrLFmy0vBc8eKe3L9/3+RYclPkE2VelqqdNy/tF3rcuI8AUJ/+BffeXVEmxJPcoTNxy1eBnZ35grVhptb88lv6Ncr4+HjGjRvF9u1b6N69FxUqVOLChd8zbXvnzm2cnZ1xdnahQoWK/PXXFUOzNmc5JdzHz6WmZu6q4ujoaPj5xRdrcedOGFFRUZw8eZwBAwalHVXoWbHiaxwcHMmJg4NDpmOvWvUVdevWY/bs+dy9G87w4e9me04hBDNnzuO5557PdLzVq1fg6VmCtWs3otfradWqUbbnzUuN0tvbm3v3IvH29kGr1ZKQEG9I2Bk1btyUxo3Tbrbu3Lkdlepxi+7XX8+wbt3XLFmyEvsMlZiUlFQcHByyjTGvinz78XHTO/e5KAHmz5/D/PlzDI+Fhwc4OpDctQdxX62WSbIIc3V1ZdSosWzcGIxWq+W119oSEnKRX389A6Td3Pnii/n06dMPgN69+xMcvIZbt9JqVXq9nk2b1mc5bv36r7Bt22bD4/Smd/HixQkNvYFer+fEiWM5xqVQKGjatAVLliykfPnncX80O/6Tx/3nn7+y7Pv88xW4fTvM8Dg+Ph4vLy8A9u3bneM5X365IVu3fmcY1fL331eBtEpHiRIlUSqVHDy4D51Ol+3+y5atYu3aDVn+PZkkARo1asr+/XsA+PHHo9StWz/bPyxRUQ+BtPfv+++30r59J0Nsn302izlzFuL5RBe9sLCbVKiQP5PSFPlEmZem99ixExg7doLhsa5adaIOHCNuyQpQF/nKt82rWrUalStX5ciRgzg4ODJnzgK++WY1vXt3oX//XlSrVsNwB7ly5SqMGDGGKVMm0atXF/r378mDBw+yHHPAgEHExcXSr18PBgzozfnz5wAYMmQY48aNYsSIIZQokftAhVatAjh4cD+tWr1meG7UqA+5evUKAwb0om/f7uzYsS3LfuXLP09CQryhL/Ebb/Tnq6+W8t57b6HX5zz6ZuDAQWi1WgYM6EW/fj1YteorADp37s6BA3t4552BhIXdwikfFsdr374jMTEx9OzZie+++5YhQ4ZliKOP4efPP59P377dGTp0EH37DuC558oDsHTpYpKSkpg8eQIDB/Zh/PgPDPv89ts5Xn01+1pvXilEIRvYqdHoiI7OWq3Pyfz5c5g3bxajR49jwoSPjW5vf2g/yrt3SR7w1rOEaTYeHs55Kn9B5eHhzNWrV/D1LW/tUJ5ZQR7299133+Ls7EJQUCeTti/IZcmrYcPeZtasBdleF46IuJnld8/LK+dWpw3VKI3f9bbfuxu3N/tS7MNRqB81uSSpMOvUqRt2NnjJKCoqil69+pp088wURb49aWr3IIcd2/h7yCAUej3V3xuOtl4DS4QnSWbl4OBA27aB1g7D4jw9PWnWrEW+1Y6LfKI0ZS5Khy2bKDZ8CPUfXbe5N2VG1j4KkiTZrCKfKB8vVZt9jdJxQzCuHwxDIQT+Pr7ofXxkkpQkKRMbSJQ5LyymiI/DedY0FEIQP+lTDo0cY+nwJEkqBGwmUWbX9BauxYjZshO7n0+RPOgdS4cmSVIhYQOJMmuHc/Wli2gfDebXVa+BrnoNq8QmWV9u06w9i337dnP16p+MHj0+H6KUrM2Gugel1SidF32GZ6smOH7zdZZt/fyq4udnbEiaVJTkNM2aJGVkAzXKR9coXVxwnjsTlwVzEQoFIpsxoJGREZYOTypAMk6zltuUZKdOnSA5OZnw8Ns0bdqc4cPTRoPs3buL4OC1lCxZknLlnjP0X4yIuMvs2dOIjo56NLnsp/j6+jJz5hQcHBy4eTOUiIgIPvroE/bv38Ply5eoUeNFJk2akiXGX345xZdfLsLd3YMXXqhGePgd5s37nNWrV+Dk5GwYYtmvXw/mzfucUqVKc/DgPrZu3YRGo6VGjZqMGZM2+mzOnOmG6d8CAzvQs+cbbN68ke+/34pKpeL55yswdepsC7zzBZ9ZE+WJEyeYOXMmer2e7t278847ma8Dpg2+n8nx48dxdHRkzpw51KxZM9/OL4Qw1ChLLV6Ey7LFCJWKuCUrSOnaI8v2ISFZx8tKluPlnXPn4Lj5X5Dc/00AHNetodjYkTlu+18elxuGrNOs5TYl2T///M2aNd9iZ2dHnz5d6dGjN6Bk9eoVrF69HldXV0aMeJcqVdKWP164cB5t2wbSrl179uzZyRdffMbs2QvSyhUXy+LFX3Hq1HHGjx/N8uWrqVChIoMH9+eff/4yHAPSZjr67LPZLFmyktKly/Dppx8ZLVdo6A2OHj3M8uVfo1armT9/DocO7adChUr89989goM3P4ojrRtdcPAaNm/ehb29veE5yYyJUqfTMW3aNNasWYOPjw/dunWjZcuWVK5c2bDNiRMnCA0N5dChQ1y8eJEpU6awZcuWfIshNTUVrVbLF0olxZYtRqjVxK74mtQchnP5+pq+KptUNOQ0zVpuU5LVq1ff0Ivi+ecrEhFxl4cPo6hT5yXD5LItW75mmIbs8uUQZs1KS7Jt2wayfPliw7EaNWqKQqGgYsXKFC9enEqV0r4fFSpU5O7du5kS5a1boZQuXcYwk3pAQBt27fo+1/L99ttZ/vrrCoMH939U3mQ8PT1p1Kgp4eF3WLRoHg0bNjZMUFypUhWmTfuYJk2a06RJ86d7U4sgsyXKkJAQypcvT7ly5QAIDAzk6NGjmRLl0aNH6dSpEwqFAn9/f2JjY7l37x7e3t75EkN8fDzTgBF6PcLOjthV60htZ3ujFAoLU2uCyf3fNNQun1VO06zlNiVZxiGBaWOj02bRMXWeyozbpR9LqVRmOq5SqUSnyzw5bW7TMqhUKoR4PAolfXo1IQTt2rXPNNlEurVrN3L27C9s376FH344zEcffcqCBYv5/fffOHXqOGvXriI4eDNqOSGM+RJlZGQkvr6+hsc+Pj6EhITkuo2vry+RkZG5JkqVSoGHh2nLzgqRwiaFgkFqNd5bt+Hc7nVy2/O994YAsHz5VyYd3xpUKqXJ5S/IVColCoUi07yC1ozF3d2N0aPHMX78aLp1605CQgI+Pj6oVEoOHNhj2E6pVGQbt5+fH4sXzyc+PhYXFxd+/PEIlStXRaVS4udXmx9+OES7du05cOAAtWrVMZRfqVSiUimzvB8ZX0tXoUJFwsPvcO9eBKVKleaHH44Y4ipTpgw//XQSlUrJX39d4e7dcFQqJQ0avMK4cR/Qu3dfihcvTkxMDImJCTg5OWFnZ0erVgGUK/ccM2Z8ikKR9p2sX78BderU4fDhg6SmpuDgUHgnqs7p90uhMD2PgBkTZXZ//Z78i2vKNk/S6YTJs+coFA5M+e57/itfBrsKL4CR/VavTpuZefbshSYd3xqK0uxBQogCMVNNegyVK1elUqUqHDx4gD59+jFjxhQ2bgymbt36hu30epFt3J6eJXjzzXcYPHggJUuWpEqVauj1OnQ6PSNHjmX27Gl8++06w80cnU6PEAK9Xo9Opzc8Tj9uxtfS2dnZM3r0eEaNeh93dw9q1Khp2Kdp0xbs27eHfv16Ub16DcqVew6dTs9zzz3P22+/x8iRQxFCj0qlZvTo8Tg4ODB79lT0+rTv4Lvvvo9Go2XKlI+Jj49DCEGPHn1wdnYpEJ/R08htJiQhsuaR3GYPMts0a+fPn2fJkiWsXr0agBUrVgDw7ruPmzCffPIJDRo0oH379gC0adOG4ODgXGuUeZ1mDUxPLuvWrQGgfz4168yhKCVKOc1a3iUmJuLsnPZHZsGCuZQrV46ePd/It+MXpWnWcitLXqdZM1uN0s/Pj9DQUMLCwvDx8WHv3r0sWLAg0zYtW7Zk/fr1BAYGcvHiRYoVK5Zv1yefRkFOkJIEsHv39+zfvxetVkOVKi/QsWNXa4dkE8yWKNVqNZ988gmDBw9Gp9PRtWtXqlSpwsaNGwHo3bs3zZo14/jx4wQEBODk5MSsWbOMHFWSbFvPnm/kaw1SMk2Rn+EcTG+uHjy4H4A2bdo9VWyWIJveBY+tNFcLm0LR9C6M+vVLWw/l3lN0WJaeTm7LwkqSOTxN3VAmygxee62ttUOwKWq1PQkJsbi4uMlkKVmEEIKEhFjU6rx1eZKJMoP16+WECJbk6elFVNR/xMdHWzuUZ6JQKJ6qllIQ2UJZ1Gp7PD298nQsmSglq1Gp1JQsWfiHjRaV68Ygy5IT6w+LkCRJKuBkoszA29sN71xmsJEkyTbJRClJkmREoetHKUmSZGmyRilJkmSETJSSJElGyEQpSZJkhEyUkiRJRshEKUmSZIRMlJIkSUYUqUR54sQJ2rRpQ0BAACtXrszyuhCCGTNmEBAQQFBQEJcvX7ZClMYZK8euXbsICgoiKCiIXr16cfXqVStEaRpjZUkXEhJC9erVOXDggAWjyxtTynLmzBk6duxIYGAgffv2tXCEpjFWjri4OIYMGUKHDh0IDAxk27ZtVojSNBMnTqRhw4aGVRKelG/feVFEaLVa0apVK3Hr1i2RkpIigoKCxD///JNpmx9//FEMGjRI6PV6cf78edGtWzcrRZszU8rx22+/iejoaCFEWpkKYjmEMK0s6dv169dPDB48WOzfv98KkRpnSlliYmJEu3btxJ07d4QQQty/f98aoebKlHIsX75czJs3TwghxIMHD0T9+vVFSkqKNcI16uzZs+KPP/4QgYGB2b6eX9/5IlOjzLg8rr29vWF53IxyWh63IDGlHHXr1sXd3R0Af39/IiIirBGqUaaUBSA4OJg2bdpQokQJK0RpGlPKsnv3bgICAihdujRAgSyPKeVQKBQkJCQ8mpIsAXd39wK7ZG39+vUN34Xs5Nd3vsgkyuyWx42MjMx1m/TlcQsSU8qR0datW2natKklQsszUz+TI0eO0KtXL0uHlyemlCU0NJTY2Fj69etHly5d2LFjh4WjNM6Ucrzxxhv8+++/NGnShA4dOjBp0iSUysKZKvLrO18w/0w8BWGm5XEtLS8xnj59mq1bt7JhwwZzh/VUTCnLzJkzGTt2LCqVylJhPRVTyqLT6bh8+TJr164lOTmZXr16Ubt2bSpUqGCpMI0ypRynTp2ievXqrFu3jlu3bvHmm29Sr149XF1dLRVmvsmv73yRSZS+vr6ZmqCRkZFZVnR8cpuIiAirrvqYHVPKAXD16lU+/vhj/ve//+Hp6WnJEE1mSln++OMPRo8eDUBUVBTHjx9HrVbTunVri8ZqjKm/X56enjg7O+Ps7Ey9evW4evVqgUqUppRj+/btvPPOOygUCsqXL0/ZsmW5fv06tWrVsnS4zyy/vvOFsz6djYzL46amprJ3715atmyZaZuWLVuyY8cOhBBcuHDB6svjZseUcoSHhzN8+HDmzZtXoL6ETzKlLD/88IPhX5s2bfj0008LXJIE08rSqlUrzp07h1arJSkpiZCQECpVqmSliLNnSjlKlSrFL7/8AsD9+/e5ceMGZcuWtUa4zyy/vvNFpkZZVJbHNaUcS5cuJTo6mqlTpwKgUqnYvn27NcPOlillKSxMKUulSpUM1/WUSiXdunWjatWqVo48M1PKMXToUCZOnEhQUBBCCMaOHUvx4sWtHHn2Ro8ezdmzZ4mKiqJp06YMHz4crVYL5O93Xk6zJkmSZESRaXpLkiSZi0yUkiRJRshEKUmSZIRMlJIkSUbIRClJkmSETJSSSapXr07Hjh0N/27fvp3jtnXq1Hnm802YMIGWLVvSsWNHOnfuzPnz5/N8jEmTJnHt2jUAvvrqq0yv5deQyfT3pX379gwZMoTY2Nhct79y5QrHjx/Pl3NLFvRUU2lINsff398s2+Zk/PjxhpmETp48Kdq3b/9Mx8uPmIwdd9y4cWLZsmW5br9t2zYxdepUs8QimY+sUUpPJSEhgQEDBtC5c2eCgoI4cuRIlm3u3bvHG2+8YahxnTt3DkgbS9yzZ086d+7MiBEjSEhIyPVc9evX59atWwCsWbOG9u3b0759e9auXQtAYmIi77zzDh06dKB9+/bs27cPgH79+nHp0iXmz59PcnIyHTt2ZMyYMcDjWu+oUaMy1fAmTJjAwYMH0el0zJ07l65duxIUFMSmTZuMvif+/v6GCRdCQkLo1asXnTp1olevXly/fp3U1FQWL17Mvn376NixI/v27SMxMZGJEyfStWtXOnXqlO37KBUA1s7UUuFQrVo10aFDB9GhQwcxdOhQodFoRFxcnBAibc7C1q1bC71eL4R4XMtavXq1oYal1WpFXFycePDggejTp49ISEgQQgixYsUK8eWXX2Y5X8Ya5b59+0S3bt3EpUuXRPv27UVCQoKIj48Xr7/+urh8+bI4cOCAmDRpkmHf2NhYIYQQffv2FSEhIZliSpf++NChQ2LcuHFCCCFSUlJE06ZNRVJSkti0aZNYunSp4fnOnTuLW7duZYkz/TharVYMHz5cHD9+XAghRFxcnNBoNEIIIX766ScxbNgwIUTWGuWCBQvEjh07hBBp81m+9tprhvdGKjiKzBBGybwcHR3ZuXOn4bFGo2HhwoX8+uuvKJVKIiMjuX//Pl5eXoZt/Pz8+Oijj9BqtbRu3Zrq1atz7Ngxrl27Zhi+qNFo8Pf3z/ac8+bNY/ny5RQvXpyZM2fyyy+/0Lp1a5ydnQEICAjg3LlzNGnShLlz5/LZZ5/RokUL6tWrZ3K5mjZtyowZM0hNTeXEiRPUq1cPR0dHfvrpJ/766y8OHjwIpM36ffPmTcqVK5dp//Sa6p07d6hZsyaNGjUybD9+/Hhu3ryJQqFAo9Fke/5Tp07xww8/8PXXXwOQkpLC3bt3C9wYcVsnE6X0VHbv3s3Dhw/Zvn07dnZ2tGzZkpSUlEzb1K9fn/Xr13P8+HHGjRvHoEGDcHNzo1GjRixcuNDoOcaNG0fbtm0Nj3/++edst6tQoQLbt2/n+PHjLFiwgEaNGjFs2DCTyuHg4ECDBg04efIk+/fvJzAwEEibnuvjjz+mSZMmue6f/gckLi6Od999l2+//Zb+/fvzxRdf8PLLL7N06VJu375N//79czzG4sWLqVixoknxStYhr1FKTyUuLo4SJUpgZ2fH6dOnuXPnTpZt7ty5Q4kSJejRowddu3bl8uXL+Pv78/vvv3Pz5k0AkpKSuHHjhknnrF+/PkeOHCEpKYnExESOHDlCvXr1iIyMxMnJiY4dOzJo0CD+/PPPLPuq1eoca3WBgYFs376dc+fO0bhxYwAaN27Mxo0bDfvcuHGDxMTEHGMrVqwYH3/8MV9//TUajYa4uDh8fHwA+P777w3bubi4ZLom27hxY9avX2+YNzG72CXrkzVK6akEBQXx3nvv0aVLF6pXr55tjejs2bOsXr0atVqNs7Mzc+fOpXjx4syePZvRo0eTmpoKpN1QMWW6uJo1a9KlSxe6d+8OQLdu3ahRowYnT55k3rx5KJVK1Go1U6ZMybJvjx496NChAzVq1GDBggWZXmvUqBHjx4+nZcuW2NvbA9C9e3fu3LlDly5dEELg6enJsmXLco2vRo0aVKtWjb179zJ48GAmTJjAmjVreOWVVwzbvPzyy6xcuZKOHTvy7rvvMnToUGbNmkWHDh0QQlCmTBlWrFhh9L2QLEvOHiRJkmSEbHpLkiQZIROlJEmSETJRSpIkGSETpSRJkhEyUUqSJBkhE6UkSZIRMlFKkiQZIROlJEmSEf8H2kpIAiXim78AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50_Baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
