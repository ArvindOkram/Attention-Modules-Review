{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "def cbam_block(cbam_feature, ratio=8):\n",
    "\tcbam_feature = channel_attention(cbam_feature, ratio)\n",
    "\tcbam_feature = spatial_attention(cbam_feature)\n",
    "\treturn cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\t\n",
    "\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\tchannel = input_feature.shape[channel_axis]\n",
    "\t\n",
    "\tshared_layer_one = Dense(channel//ratio,\n",
    "\t\t\t\t\t\t\t activation='relu',\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\tshared_layer_two = Dense(channel,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\t\n",
    "\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "\tavg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\tavg_pool = shared_layer_one(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tavg_pool = shared_layer_two(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tmax_pool = GlobalMaxPooling2D()(input_feature)\n",
    "\tmax_pool = Reshape((1,1,channel))(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\tmax_pool = shared_layer_one(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tmax_pool = shared_layer_two(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tcbam_feature = Add()([avg_pool,max_pool])\n",
    "\tcbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\n",
    "\treturn multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "\tkernel_size = 7\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tchannel = input_feature.shape[1]\n",
    "\t\tcbam_feature = Permute((2,3,1))(input_feature)\n",
    "\telse:\n",
    "\t\tchannel = input_feature.shape[-1]\n",
    "\t\tcbam_feature = input_feature\n",
    "\t\n",
    "\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert avg_pool.shape[-1] == 1\n",
    "\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert max_pool.shape[-1] == 1\n",
    "\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "\tassert concat.shape[-1] == 2\n",
    "\tcbam_feature = Conv2D(filters = 1,\n",
    "\t\t\t\t\tkernel_size=kernel_size,\n",
    "\t\t\t\t\tstrides=1,\n",
    "\t\t\t\t\tpadding='same',\n",
    "\t\t\t\t\tactivation='sigmoid',\n",
    "\t\t\t\t\tkernel_initializer='he_normal',\n",
    "\t\t\t\t\tuse_bias=False)(concat)\t\n",
    "\tassert cbam_feature.shape[-1] == 1\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\t\n",
    "\treturn multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name,attention):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+attention+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+attention+'.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+cbam_block.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 12:09:56.171890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: GeForce GT 710, pci bus id: 0000:b3:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-05-06 12:09:56.180958: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 12:09:59.293789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30982 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 1024  2098176     ['conv5_block3_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['conv2d[0][0]']                 \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " global_max_pooling2d (GlobalMa  (None, 1024)        0           ['conv2d[0][0]']                 \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 1024)   0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 1024)   0           ['global_max_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 1, 128)    131200      ['reshape[0][0]',                \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 1024)   132096      ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]']                  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1, 1, 1024)   0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, 1, 1024)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 1024  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'activation[0][0]']             \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 16, 16, 1)    0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 16, 16, 1)    0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 2)    0           ['lambda[0][0]',                 \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 1)    98          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 16, 16, 1024  0           ['multiply[0][0]',               \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1024)        0           ['multiply_1[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            2050        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,951,332\n",
      "Trainable params: 25,898,212\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=cbam_block(red_feat)\n",
    "\n",
    "shape=K.int_shape(x)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 12:10:50.442592: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 1.3289 - acc: 0.5354\n",
      "Epoch 1: acc improved from -inf to 0.53542, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 41s 524ms/step - loss: 1.3289 - acc: 0.5354 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6900 - acc: 0.5792\n",
      "Epoch 1: acc improved from 0.53542 to 0.57917, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 44s 595ms/step - loss: 0.6900 - acc: 0.5792 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6657 - acc: 0.6187\n",
      "Epoch 2: acc improved from 0.57917 to 0.61875, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 38s 612ms/step - loss: 0.6657 - acc: 0.6187 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6565 - acc: 0.6031\n",
      "Epoch 3: acc did not improve from 0.61875\n",
      "60/60 [==============================] - 35s 573ms/step - loss: 0.6565 - acc: 0.6031 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6308 - acc: 0.6625\n",
      "Epoch 4: acc improved from 0.61875 to 0.66250, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 43s 707ms/step - loss: 0.6308 - acc: 0.6625 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6243 - acc: 0.6531\n",
      "Epoch 5: acc did not improve from 0.66250\n",
      "60/60 [==============================] - 36s 587ms/step - loss: 0.6243 - acc: 0.6531 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5418 - acc: 0.7427\n",
      "Epoch 6: acc improved from 0.66250 to 0.74271, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 37s 609ms/step - loss: 0.5418 - acc: 0.7427 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4833 - acc: 0.7917\n",
      "Epoch 7: acc improved from 0.74271 to 0.79167, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 37s 610ms/step - loss: 0.4833 - acc: 0.7917 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4530 - acc: 0.8135\n",
      "Epoch 8: acc improved from 0.79167 to 0.81354, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.4530 - acc: 0.8135 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4261 - acc: 0.8260\n",
      "Epoch 9: acc improved from 0.81354 to 0.82604, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 38s 613ms/step - loss: 0.4261 - acc: 0.8260 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4089 - acc: 0.8323\n",
      "Epoch 10: acc improved from 0.82604 to 0.83229, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.4089 - acc: 0.8323 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4155 - acc: 0.8406\n",
      "Epoch 11: acc improved from 0.83229 to 0.84062, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.4155 - acc: 0.8406 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3502 - acc: 0.8396\n",
      "Epoch 12: acc did not improve from 0.84062\n",
      "60/60 [==============================] - 36s 578ms/step - loss: 0.3502 - acc: 0.8396 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3448 - acc: 0.8500\n",
      "Epoch 13: acc improved from 0.84062 to 0.85000, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 639ms/step - loss: 0.3448 - acc: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3822 - acc: 0.8365\n",
      "Epoch 14: acc did not improve from 0.85000\n",
      "60/60 [==============================] - 36s 583ms/step - loss: 0.3822 - acc: 0.8365 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3582 - acc: 0.8458\n",
      "Epoch 15: acc did not improve from 0.85000\n",
      "60/60 [==============================] - 36s 589ms/step - loss: 0.3582 - acc: 0.8458 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3596 - acc: 0.8531\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 16: acc improved from 0.85000 to 0.85312, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.3596 - acc: 0.8531 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3153 - acc: 0.8667\n",
      "Epoch 17: acc improved from 0.85312 to 0.86667, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.3153 - acc: 0.8667 - lr: 8.0000e-05\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3374 - acc: 0.8604\n",
      "Epoch 18: acc did not improve from 0.86667\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.3374 - acc: 0.8604 - lr: 8.0000e-05\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3123 - acc: 0.8802\n",
      "Epoch 19: acc improved from 0.86667 to 0.88021, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.3123 - acc: 0.8802 - lr: 8.0000e-05\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2931 - acc: 0.8875\n",
      "Epoch 20: acc improved from 0.88021 to 0.88750, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.2931 - acc: 0.8875 - lr: 8.0000e-05\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3155 - acc: 0.8708\n",
      "Epoch 21: acc did not improve from 0.88750\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.3155 - acc: 0.8708 - lr: 8.0000e-05\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3184 - acc: 0.8604\n",
      "Epoch 22: acc did not improve from 0.88750\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.3184 - acc: 0.8604 - lr: 8.0000e-05\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3113 - acc: 0.8719\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 23: acc did not improve from 0.88750\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.3113 - acc: 0.8719 - lr: 8.0000e-05\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2769 - acc: 0.8865\n",
      "Epoch 24: acc did not improve from 0.88750\n",
      "60/60 [==============================] - 36s 588ms/step - loss: 0.2769 - acc: 0.8865 - lr: 6.4000e-05\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2551 - acc: 0.9021\n",
      "Epoch 25: acc improved from 0.88750 to 0.90208, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 627ms/step - loss: 0.2551 - acc: 0.9021 - lr: 6.4000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3073 - acc: 0.8771\n",
      "Epoch 26: acc did not improve from 0.90208\n",
      "60/60 [==============================] - 36s 581ms/step - loss: 0.3073 - acc: 0.8771 - lr: 6.4000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2854 - acc: 0.8875\n",
      "Epoch 27: acc did not improve from 0.90208\n",
      "60/60 [==============================] - 36s 580ms/step - loss: 0.2854 - acc: 0.8875 - lr: 6.4000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2863 - acc: 0.8865\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 28: acc did not improve from 0.90208\n",
      "60/60 [==============================] - 38s 609ms/step - loss: 0.2863 - acc: 0.8865 - lr: 6.4000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2626 - acc: 0.8865\n",
      "Epoch 29: acc did not improve from 0.90208\n",
      "60/60 [==============================] - 37s 606ms/step - loss: 0.2626 - acc: 0.8865 - lr: 5.1200e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2375 - acc: 0.9104\n",
      "Epoch 30: acc improved from 0.90208 to 0.91042, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 632ms/step - loss: 0.2375 - acc: 0.9104 - lr: 5.1200e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2274 - acc: 0.9094\n",
      "Epoch 31: acc did not improve from 0.91042\n",
      "60/60 [==============================] - 41s 666ms/step - loss: 0.2274 - acc: 0.9094 - lr: 5.1200e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2570 - acc: 0.8979\n",
      "Epoch 32: acc did not improve from 0.91042\n",
      "60/60 [==============================] - 35s 571ms/step - loss: 0.2570 - acc: 0.8979 - lr: 5.1200e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2342 - acc: 0.9042\n",
      "Epoch 33: acc did not improve from 0.91042\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.2342 - acc: 0.9042 - lr: 5.1200e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2379 - acc: 0.9094\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 34: acc did not improve from 0.91042\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.2379 - acc: 0.9094 - lr: 5.1200e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2285 - acc: 0.9146\n",
      "Epoch 35: acc improved from 0.91042 to 0.91458, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.2285 - acc: 0.9146 - lr: 4.0960e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2333 - acc: 0.9083\n",
      "Epoch 36: acc did not improve from 0.91458\n",
      "60/60 [==============================] - 36s 591ms/step - loss: 0.2333 - acc: 0.9083 - lr: 4.0960e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2045 - acc: 0.9156\n",
      "Epoch 37: acc improved from 0.91458 to 0.91562, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.2045 - acc: 0.9156 - lr: 4.0960e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2172 - acc: 0.9125\n",
      "Epoch 38: acc did not improve from 0.91562\n",
      "60/60 [==============================] - 37s 596ms/step - loss: 0.2172 - acc: 0.9125 - lr: 4.0960e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2199 - acc: 0.9125\n",
      "Epoch 39: acc did not improve from 0.91562\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.2199 - acc: 0.9125 - lr: 4.0960e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1895 - acc: 0.9271\n",
      "Epoch 40: acc improved from 0.91562 to 0.92708, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.1895 - acc: 0.9271 - lr: 4.0960e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1771 - acc: 0.9260\n",
      "Epoch 41: acc did not improve from 0.92708\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.1771 - acc: 0.9260 - lr: 4.0960e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1904 - acc: 0.9250\n",
      "Epoch 42: acc did not improve from 0.92708\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.1904 - acc: 0.9250 - lr: 4.0960e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.9312\n",
      "Epoch 43: acc improved from 0.92708 to 0.93125, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.1665 - acc: 0.9312 - lr: 4.0960e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1687 - acc: 0.9365\n",
      "Epoch 44: acc improved from 0.93125 to 0.93646, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.1687 - acc: 0.9365 - lr: 4.0960e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2017 - acc: 0.9208\n",
      "Epoch 45: acc did not improve from 0.93646\n",
      "60/60 [==============================] - 35s 578ms/step - loss: 0.2017 - acc: 0.9208 - lr: 4.0960e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1790 - acc: 0.9333\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 46: acc did not improve from 0.93646\n",
      "60/60 [==============================] - 37s 608ms/step - loss: 0.1790 - acc: 0.9333 - lr: 4.0960e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1436 - acc: 0.9458\n",
      "Epoch 47: acc improved from 0.93646 to 0.94583, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 639ms/step - loss: 0.1436 - acc: 0.9458 - lr: 3.2768e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1698 - acc: 0.9365\n",
      "Epoch 48: acc did not improve from 0.94583\n",
      "60/60 [==============================] - 35s 578ms/step - loss: 0.1698 - acc: 0.9365 - lr: 3.2768e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1625 - acc: 0.9438\n",
      "Epoch 49: acc did not improve from 0.94583\n",
      "60/60 [==============================] - 37s 607ms/step - loss: 0.1625 - acc: 0.9438 - lr: 3.2768e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1503 - acc: 0.9479\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 50: acc improved from 0.94583 to 0.94792, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 38s 618ms/step - loss: 0.1503 - acc: 0.9479 - lr: 3.2768e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1257 - acc: 0.9521\n",
      "Epoch 51: acc improved from 0.94792 to 0.95208, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.1257 - acc: 0.9521 - lr: 2.6214e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1428 - acc: 0.9448\n",
      "Epoch 52: acc did not improve from 0.95208\n",
      "60/60 [==============================] - 36s 589ms/step - loss: 0.1428 - acc: 0.9448 - lr: 2.6214e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.9479\n",
      "Epoch 53: acc did not improve from 0.95208\n",
      "60/60 [==============================] - 36s 583ms/step - loss: 0.1505 - acc: 0.9479 - lr: 2.6214e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1265 - acc: 0.9583\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 54: acc improved from 0.95208 to 0.95833, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 40s 644ms/step - loss: 0.1265 - acc: 0.9583 - lr: 2.6214e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1189 - acc: 0.9552\n",
      "Epoch 55: acc did not improve from 0.95833\n",
      "60/60 [==============================] - 36s 590ms/step - loss: 0.1189 - acc: 0.9552 - lr: 2.0972e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1112 - acc: 0.9583\n",
      "Epoch 56: acc did not improve from 0.95833\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.1112 - acc: 0.9583 - lr: 2.0972e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1488 - acc: 0.9448\n",
      "Epoch 57: acc did not improve from 0.95833\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.1488 - acc: 0.9448 - lr: 2.0972e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.9531\n",
      "Epoch 58: acc did not improve from 0.95833\n",
      "60/60 [==============================] - 37s 588ms/step - loss: 0.1316 - acc: 0.9531 - lr: 2.0972e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1138 - acc: 0.9542\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 59: acc did not improve from 0.95833\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.1138 - acc: 0.9542 - lr: 2.0972e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.9563\n",
      "Epoch 60: acc did not improve from 0.95833\n",
      "60/60 [==============================] - 36s 593ms/step - loss: 0.1194 - acc: 0.9563 - lr: 1.6777e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1047 - acc: 0.9615\n",
      "Epoch 61: acc improved from 0.95833 to 0.96146, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 629ms/step - loss: 0.1047 - acc: 0.9615 - lr: 1.6777e-05\n",
      "Epoch 62/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.1188 - acc: 0.9583\n",
      "Epoch 62: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.1188 - acc: 0.9583 - lr: 1.6777e-05\n",
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1141 - acc: 0.9583\n",
      "Epoch 63: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 37s 602ms/step - loss: 0.1141 - acc: 0.9583 - lr: 1.6777e-05\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1176 - acc: 0.9542\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 64: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.1176 - acc: 0.9542 - lr: 1.6777e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1131 - acc: 0.9615\n",
      "Epoch 65: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 35s 575ms/step - loss: 0.1131 - acc: 0.9615 - lr: 1.3422e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0853 - acc: 0.9604\n",
      "Epoch 66: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 37s 587ms/step - loss: 0.0853 - acc: 0.9604 - lr: 1.3422e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0991 - acc: 0.9677\n",
      "Epoch 67: acc improved from 0.96146 to 0.96771, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 40s 658ms/step - loss: 0.0991 - acc: 0.9677 - lr: 1.3422e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0851 - acc: 0.9760\n",
      "Epoch 68: acc improved from 0.96771 to 0.97604, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0851 - acc: 0.9760 - lr: 1.3422e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0938 - acc: 0.9583\n",
      "Epoch 69: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 37s 596ms/step - loss: 0.0938 - acc: 0.9583 - lr: 1.3422e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0725 - acc: 0.9760\n",
      "Epoch 70: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0725 - acc: 0.9760 - lr: 1.3422e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0743 - acc: 0.9719\n",
      "Epoch 71: acc did not improve from 0.97604\n",
      "60/60 [==============================] - 36s 584ms/step - loss: 0.0743 - acc: 0.9719 - lr: 1.3422e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0858 - acc: 0.9771\n",
      "Epoch 72: acc improved from 0.97604 to 0.97708, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.0858 - acc: 0.9771 - lr: 1.3422e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0816 - acc: 0.9656\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 73: acc did not improve from 0.97708\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0816 - acc: 0.9656 - lr: 1.3422e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0694 - acc: 0.9792\n",
      "Epoch 74: acc improved from 0.97708 to 0.97917, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 0.0694 - acc: 0.9792 - lr: 1.0737e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0693 - acc: 0.9792\n",
      "Epoch 75: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.0693 - acc: 0.9792 - lr: 1.0737e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0968 - acc: 0.9625\n",
      "Epoch 76: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.0968 - acc: 0.9625 - lr: 1.0737e-05\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0794 - acc: 0.9656\n",
      "Epoch 77: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 37s 607ms/step - loss: 0.0794 - acc: 0.9656 - lr: 1.0737e-05\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0788 - acc: 0.9729\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 78: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.0788 - acc: 0.9729 - lr: 1.0737e-05\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9771\n",
      "Epoch 79: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 38s 611ms/step - loss: 0.0658 - acc: 0.9771 - lr: 8.5899e-06\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0571 - acc: 0.9833\n",
      "Epoch 80: acc improved from 0.97917 to 0.98333, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0571 - acc: 0.9833 - lr: 8.5899e-06\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.9792\n",
      "Epoch 81: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 36s 593ms/step - loss: 0.0612 - acc: 0.9792 - lr: 8.5899e-06\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0602 - acc: 0.9833\n",
      "Epoch 82: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 37s 593ms/step - loss: 0.0602 - acc: 0.9833 - lr: 8.5899e-06\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0610 - acc: 0.9740\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 83: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0610 - acc: 0.9740 - lr: 8.5899e-06\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0707 - acc: 0.9823\n",
      "Epoch 84: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 36s 585ms/step - loss: 0.0707 - acc: 0.9823 - lr: 6.8719e-06\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0578 - acc: 0.9760\n",
      "Epoch 85: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.0578 - acc: 0.9760 - lr: 6.8719e-06\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0557 - acc: 0.9792\n",
      "Epoch 86: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0557 - acc: 0.9792 - lr: 6.8719e-06\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0652 - acc: 0.9771\n",
      "Epoch 87: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.0652 - acc: 0.9771 - lr: 6.8719e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9802\n",
      "Epoch 88: acc did not improve from 0.98333\n",
      "60/60 [==============================] - 38s 626ms/step - loss: 0.0532 - acc: 0.9802 - lr: 6.8719e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.9844\n",
      "Epoch 89: acc improved from 0.98333 to 0.98438, saving model to resnet50+cbam_block.hdf5\n",
      "60/60 [==============================] - 42s 676ms/step - loss: 0.0477 - acc: 0.9844 - lr: 6.8719e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0654 - acc: 0.9771\n",
      "Epoch 90: acc did not improve from 0.98438\n",
      "60/60 [==============================] - 36s 588ms/step - loss: 0.0654 - acc: 0.9771 - lr: 6.8719e-06\n",
      "15/15 [==============================] - 4s 158ms/step - loss: 0.2647 - acc: 0.9083\n",
      "Test loss: 0.26466840505599976\n",
      "Test accuracy: 0.9083333611488342\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50','cbam')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[8.80427539e-01 1.19572431e-01]\n",
      " [9.99997735e-01 2.23141410e-06]\n",
      " [1.00000000e+00 2.32257804e-08]\n",
      " [9.99956608e-01 4.34326321e-05]\n",
      " [1.00000000e+00 6.05180461e-10]\n",
      " [9.99997258e-01 2.72691227e-06]\n",
      " [1.00000000e+00 5.07301312e-09]\n",
      " [9.68253672e-01 3.17463689e-02]\n",
      " [9.99989748e-01 1.02785989e-05]\n",
      " [1.00000000e+00 2.76414269e-09]\n",
      " [1.00000000e+00 4.77852258e-10]\n",
      " [9.96297657e-01 3.70231736e-03]\n",
      " [9.99999881e-01 1.00188828e-07]\n",
      " [9.99999285e-01 7.10293364e-07]\n",
      " [9.99999881e-01 1.11959253e-07]\n",
      " [4.26541865e-01 5.73458076e-01]\n",
      " [1.19480647e-01 8.80519331e-01]\n",
      " [9.99980211e-01 1.97432382e-05]\n",
      " [9.99012709e-01 9.87265958e-04]\n",
      " [1.00000000e+00 1.18675469e-08]\n",
      " [9.99999881e-01 1.39187321e-07]\n",
      " [9.99999881e-01 8.87461411e-08]\n",
      " [9.99997020e-01 2.98103214e-06]\n",
      " [9.99989986e-01 9.99121858e-06]\n",
      " [9.96077836e-01 3.92218633e-03]\n",
      " [9.99634385e-01 3.65608837e-04]\n",
      " [9.99688029e-01 3.12005723e-04]\n",
      " [1.10221333e-06 9.99998927e-01]\n",
      " [9.41202104e-01 5.87978326e-02]\n",
      " [1.00000000e+00 5.57656898e-09]\n",
      " [9.97428119e-01 2.57181446e-03]\n",
      " [9.99999881e-01 1.24319641e-07]\n",
      " [5.75367153e-01 4.24632818e-01]\n",
      " [1.00000000e+00 4.15651763e-10]\n",
      " [9.99984622e-01 1.53789770e-05]\n",
      " [9.99984384e-01 1.55648704e-05]\n",
      " [9.99950528e-01 4.94718261e-05]\n",
      " [9.98791277e-01 1.20877207e-03]\n",
      " [9.99986172e-01 1.38699925e-05]\n",
      " [9.99997735e-01 2.26780139e-06]\n",
      " [1.00000000e+00 2.84286927e-10]\n",
      " [9.99999404e-01 6.17955834e-07]\n",
      " [9.67329621e-01 3.26703303e-02]\n",
      " [9.99997973e-01 2.04025810e-06]\n",
      " [9.99999642e-01 4.01993503e-07]\n",
      " [9.99876380e-01 1.23559163e-04]\n",
      " [9.99689579e-01 3.10460106e-04]\n",
      " [9.86077309e-01 1.39226848e-02]\n",
      " [9.99123991e-01 8.76031350e-04]\n",
      " [8.25711489e-01 1.74288496e-01]\n",
      " [9.89335597e-01 1.06644779e-02]\n",
      " [9.99995589e-01 4.45621208e-06]\n",
      " [9.99999523e-01 5.35454603e-07]\n",
      " [1.00000000e+00 5.90894622e-09]\n",
      " [1.00000000e+00 6.46318643e-09]\n",
      " [9.99996305e-01 3.72936984e-06]\n",
      " [9.30826783e-01 6.91732019e-02]\n",
      " [9.98005688e-01 1.99427782e-03]\n",
      " [9.99995232e-01 4.74823219e-06]\n",
      " [9.99996781e-01 3.21911011e-06]\n",
      " [9.98460293e-01 1.53969880e-03]\n",
      " [9.99196708e-01 8.03356874e-04]\n",
      " [9.99982476e-01 1.75042278e-05]\n",
      " [9.88329887e-01 1.16701415e-02]\n",
      " [9.98055220e-01 1.94485427e-03]\n",
      " [1.00000000e+00 5.75767558e-08]\n",
      " [9.70956981e-01 2.90429983e-02]\n",
      " [9.99954581e-01 4.54412730e-05]\n",
      " [9.99999642e-01 3.27924255e-07]\n",
      " [9.99981284e-01 1.87291935e-05]\n",
      " [1.00000000e+00 6.01361805e-09]\n",
      " [9.99944210e-01 5.58268657e-05]\n",
      " [1.00000000e+00 2.44519924e-08]\n",
      " [9.99945879e-01 5.40754008e-05]\n",
      " [9.99997973e-01 2.03363788e-06]\n",
      " [9.99691606e-01 3.08465707e-04]\n",
      " [3.06947771e-02 9.69305277e-01]\n",
      " [9.99999642e-01 3.08346728e-07]\n",
      " [9.99992847e-01 7.16108525e-06]\n",
      " [1.00000000e+00 1.69147529e-10]\n",
      " [1.00000000e+00 7.22306126e-09]\n",
      " [9.99993801e-01 6.18164268e-06]\n",
      " [9.95403767e-01 4.59623663e-03]\n",
      " [9.89610553e-01 1.03893923e-02]\n",
      " [1.00000000e+00 4.18668485e-12]\n",
      " [6.66311145e-01 3.33688915e-01]\n",
      " [9.99853730e-01 1.46302322e-04]\n",
      " [9.89841878e-01 1.01581151e-02]\n",
      " [1.00000000e+00 7.95168997e-09]\n",
      " [9.99875665e-01 1.24274055e-04]\n",
      " [9.99984384e-01 1.56741753e-05]\n",
      " [9.99995351e-01 4.62510843e-06]\n",
      " [9.99996305e-01 3.64873017e-06]\n",
      " [9.99886751e-01 1.13184069e-04]\n",
      " [9.99999762e-01 1.95146072e-07]\n",
      " [2.59326696e-01 7.40673304e-01]\n",
      " [1.00000000e+00 1.11336641e-10]\n",
      " [9.99977708e-01 2.23464613e-05]\n",
      " [9.99855161e-01 1.44780352e-04]\n",
      " [9.90566671e-01 9.43328161e-03]\n",
      " [9.99999642e-01 3.90673222e-07]\n",
      " [9.99999523e-01 4.99335613e-07]\n",
      " [9.99999881e-01 1.50574039e-07]\n",
      " [1.00000000e+00 7.97249473e-13]\n",
      " [1.00000000e+00 2.71928204e-08]\n",
      " [9.93193984e-01 6.80593261e-03]\n",
      " [9.38203633e-01 6.17963560e-02]\n",
      " [9.97882783e-01 2.11722730e-03]\n",
      " [5.89470387e-01 4.10529643e-01]\n",
      " [1.00000000e+00 7.27404981e-09]\n",
      " [9.99999762e-01 1.89943378e-07]\n",
      " [4.99412343e-02 9.50058699e-01]\n",
      " [9.99997973e-01 2.02779688e-06]\n",
      " [9.99999404e-01 5.85295936e-07]\n",
      " [1.00000000e+00 2.93948504e-10]\n",
      " [9.99998689e-01 1.34547940e-06]\n",
      " [9.99999285e-01 7.72320163e-07]\n",
      " [1.00000000e+00 3.60078655e-12]\n",
      " [9.99414206e-01 5.85811271e-04]\n",
      " [9.99998331e-01 1.64282153e-06]\n",
      " [9.95947659e-01 4.05238196e-03]\n",
      " [9.99996781e-01 3.19251194e-06]\n",
      " [9.99998569e-01 1.43352349e-06]\n",
      " [9.99339283e-01 6.60705904e-04]\n",
      " [4.51794788e-02 9.54820514e-01]\n",
      " [9.99998093e-01 1.93291976e-06]\n",
      " [9.99997139e-01 2.82840961e-06]\n",
      " [9.99880195e-01 1.19791810e-04]\n",
      " [9.99234438e-01 7.65515841e-04]\n",
      " [1.00000000e+00 2.17555821e-10]\n",
      " [1.00000000e+00 9.18872090e-09]\n",
      " [1.00000000e+00 2.27197141e-08]\n",
      " [9.99914169e-01 8.58588974e-05]\n",
      " [9.99999881e-01 1.30420133e-07]\n",
      " [9.99980211e-01 1.97439531e-05]\n",
      " [9.99816239e-01 1.83816112e-04]\n",
      " [5.15737124e-02 9.48426306e-01]\n",
      " [9.99753654e-01 2.46369280e-04]\n",
      " [9.99601305e-01 3.98729288e-04]\n",
      " [9.99992371e-01 7.58303850e-06]\n",
      " [9.99975562e-01 2.44335552e-05]\n",
      " [1.00000000e+00 1.49442025e-09]\n",
      " [5.67938864e-01 4.32061106e-01]\n",
      " [2.92423637e-13 1.00000000e+00]\n",
      " [4.28582216e-03 9.95714128e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.34529955e-07 9.99999881e-01]\n",
      " [1.03035930e-03 9.98969674e-01]\n",
      " [9.49669423e-12 1.00000000e+00]\n",
      " [8.17872817e-04 9.99182165e-01]\n",
      " [4.30694994e-11 1.00000000e+00]\n",
      " [2.60942211e-16 1.00000000e+00]\n",
      " [8.13284599e-19 1.00000000e+00]\n",
      " [1.86422326e-08 1.00000000e+00]\n",
      " [1.24720911e-09 1.00000000e+00]\n",
      " [9.97592509e-01 2.40742136e-03]\n",
      " [2.86881246e-22 1.00000000e+00]\n",
      " [8.64482522e-02 9.13551807e-01]\n",
      " [1.00000000e+00 2.44699883e-09]\n",
      " [5.60093895e-07 9.99999404e-01]\n",
      " [9.99721110e-01 2.78895663e-04]\n",
      " [4.07460732e-10 1.00000000e+00]\n",
      " [2.07670723e-07 9.99999762e-01]\n",
      " [2.01824495e-08 1.00000000e+00]\n",
      " [3.81439701e-02 9.61856008e-01]\n",
      " [4.25978435e-08 1.00000000e+00]\n",
      " [2.16677289e-08 1.00000000e+00]\n",
      " [9.77355480e-01 2.26445515e-02]\n",
      " [4.49370913e-04 9.99550641e-01]\n",
      " [4.39591295e-14 1.00000000e+00]\n",
      " [2.05912585e-07 9.99999762e-01]\n",
      " [2.91488817e-12 1.00000000e+00]\n",
      " [8.00130184e-09 1.00000000e+00]\n",
      " [1.63552230e-08 1.00000000e+00]\n",
      " [7.21917987e-01 2.78082013e-01]\n",
      " [5.27335823e-01 4.72664177e-01]\n",
      " [2.46460330e-15 1.00000000e+00]\n",
      " [9.99092460e-01 9.07497306e-04]\n",
      " [1.00624086e-02 9.89937544e-01]\n",
      " [3.67494076e-02 9.63250518e-01]\n",
      " [1.08371837e-16 1.00000000e+00]\n",
      " [1.03206199e-23 1.00000000e+00]\n",
      " [1.08500346e-04 9.99891520e-01]\n",
      " [1.07232512e-20 1.00000000e+00]\n",
      " [1.16366964e-12 1.00000000e+00]\n",
      " [7.29705649e-18 1.00000000e+00]\n",
      " [1.69608442e-11 1.00000000e+00]\n",
      " [1.01196343e-11 1.00000000e+00]\n",
      " [9.90163326e-01 9.83674545e-03]\n",
      " [5.48688005e-12 1.00000000e+00]\n",
      " [1.67216407e-04 9.99832749e-01]\n",
      " [6.97403971e-25 1.00000000e+00]\n",
      " [5.18924875e-27 1.00000000e+00]\n",
      " [2.27937688e-15 1.00000000e+00]\n",
      " [2.50274512e-09 1.00000000e+00]\n",
      " [4.91494209e-01 5.08505821e-01]\n",
      " [1.06657618e-14 1.00000000e+00]\n",
      " [1.31533560e-11 1.00000000e+00]\n",
      " [2.55997335e-26 1.00000000e+00]\n",
      " [3.63734737e-10 1.00000000e+00]\n",
      " [9.74961400e-01 2.50386037e-02]\n",
      " [5.23033202e-01 4.76966798e-01]\n",
      " [5.60820520e-01 4.39179480e-01]\n",
      " [3.51150071e-13 1.00000000e+00]\n",
      " [5.15943565e-15 1.00000000e+00]\n",
      " [5.65410569e-26 1.00000000e+00]\n",
      " [1.52872488e-01 8.47127497e-01]\n",
      " [9.54967260e-01 4.50327210e-02]\n",
      " [1.53512413e-16 1.00000000e+00]\n",
      " [1.87278737e-03 9.98127162e-01]\n",
      " [9.39631164e-02 9.06036913e-01]\n",
      " [4.90547046e-02 9.50945318e-01]\n",
      " [3.14208657e-28 1.00000000e+00]\n",
      " [2.30508974e-18 1.00000000e+00]\n",
      " [1.26860733e-03 9.98731434e-01]\n",
      " [2.25919997e-03 9.97740865e-01]\n",
      " [2.53685385e-01 7.46314645e-01]\n",
      " [1.40927847e-09 1.00000000e+00]\n",
      " [9.29876987e-04 9.99070108e-01]\n",
      " [9.97361600e-01 2.63835210e-03]\n",
      " [4.02209114e-26 1.00000000e+00]\n",
      " [9.93351758e-01 6.64824108e-03]\n",
      " [4.85812222e-07 9.99999523e-01]\n",
      " [8.94687427e-13 1.00000000e+00]\n",
      " [1.17955161e-15 1.00000000e+00]\n",
      " [6.69330475e-15 1.00000000e+00]\n",
      " [6.06380403e-03 9.93936241e-01]\n",
      " [4.95087509e-21 1.00000000e+00]\n",
      " [1.06342297e-15 1.00000000e+00]\n",
      " [2.38227904e-06 9.99997616e-01]\n",
      " [1.32260736e-09 1.00000000e+00]\n",
      " [7.63257662e-14 1.00000000e+00]\n",
      " [5.76129722e-09 1.00000000e+00]\n",
      " [1.08244167e-16 1.00000000e+00]\n",
      " [9.63556133e-08 9.99999881e-01]\n",
      " [1.03028879e-05 9.99989748e-01]\n",
      " [2.94260771e-15 1.00000000e+00]\n",
      " [2.32394600e-28 1.00000000e+00]\n",
      " [1.77967962e-07 9.99999881e-01]\n",
      " [5.26756607e-03 9.94732380e-01]]\n",
      "Confusion Matrix\n",
      "[[135   8]\n",
      " [ 14  83]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.91      0.94      0.92       143\n",
      "    referable       0.91      0.86      0.88        97\n",
      "\n",
      "     accuracy                           0.91       240\n",
      "    macro avg       0.91      0.90      0.90       240\n",
      " weighted avg       0.91      0.91      0.91       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+CBAM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
