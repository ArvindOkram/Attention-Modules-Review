{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "def SE_Block(inputs,ratio = 16):\n",
    "    shape=K.int_shape(inputs)\n",
    "    ch = shape[3]\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(shape[1],shape[2]))(inputs)\n",
    "    x = Dense(ch//ratio, activation='relu')(x)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    se = tf.keras.layers.Multiply()([inputs, x])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+'se.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+'se.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+SE_Block.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 15:20:50.727148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: GeForce GT 710, pci bus id: 0000:b3:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-05-06 15:20:50.727861: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 15:20:51.371894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30982 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 1024  2098176     ['conv5_block3_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 1024)  0           ['conv2d[0][0]']                 \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense (Dense)                  (None, 1, 1, 64)     65600       ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 1024)   66560       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 1024  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['multiply[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            2050        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,820,098\n",
      "Trainable params: 25,766,978\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=SE_Block(red_feat)\n",
    "\n",
    "\n",
    "shape=K.int_shape(x)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 15:21:30.701664: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 2.0500 - acc: 0.6198\n",
      "Epoch 1: acc improved from -inf to 0.61979, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 39s 534ms/step - loss: 2.0500 - acc: 0.6198 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5955 - acc: 0.7333\n",
      "Epoch 1: acc improved from 0.61979 to 0.73333, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 575ms/step - loss: 0.5955 - acc: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3913 - acc: 0.8385\n",
      "Epoch 2: acc improved from 0.73333 to 0.83854, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.3913 - acc: 0.8385 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3354 - acc: 0.8562\n",
      "Epoch 3: acc improved from 0.83854 to 0.85625, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 36s 586ms/step - loss: 0.3354 - acc: 0.8562 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3624 - acc: 0.8542\n",
      "Epoch 4: acc did not improve from 0.85625\n",
      "60/60 [==============================] - 34s 558ms/step - loss: 0.3624 - acc: 0.8542 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3022 - acc: 0.8781\n",
      "Epoch 5: acc improved from 0.85625 to 0.87813, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 37s 596ms/step - loss: 0.3022 - acc: 0.8781 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2668 - acc: 0.8938\n",
      "Epoch 6: acc improved from 0.87813 to 0.89375, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.2668 - acc: 0.8938 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2479 - acc: 0.8958\n",
      "Epoch 7: acc improved from 0.89375 to 0.89583, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.2479 - acc: 0.8958 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2452 - acc: 0.9052\n",
      "Epoch 8: acc improved from 0.89583 to 0.90521, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 38s 623ms/step - loss: 0.2452 - acc: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2398 - acc: 0.9010\n",
      "Epoch 9: acc did not improve from 0.90521\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.2398 - acc: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2112 - acc: 0.9156\n",
      "Epoch 10: acc improved from 0.90521 to 0.91562, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.2112 - acc: 0.9156 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2223 - acc: 0.9135\n",
      "Epoch 11: acc did not improve from 0.91562\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.2223 - acc: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1889 - acc: 0.9250\n",
      "Epoch 12: acc improved from 0.91562 to 0.92500, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.1889 - acc: 0.9250 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1656 - acc: 0.9396\n",
      "Epoch 13: acc improved from 0.92500 to 0.93958, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.1656 - acc: 0.9396 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1543 - acc: 0.9469\n",
      "Epoch 14: acc improved from 0.93958 to 0.94687, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.1543 - acc: 0.9469 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1779 - acc: 0.9323\n",
      "Epoch 15: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.1779 - acc: 0.9323 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1496 - acc: 0.9406\n",
      "Epoch 16: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.1496 - acc: 0.9406 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1810 - acc: 0.9260\n",
      "Epoch 17: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.1810 - acc: 0.9260 - lr: 1.0000e-04\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1398 - acc: 0.9469\n",
      "Epoch 18: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 40s 637ms/step - loss: 0.1398 - acc: 0.9469 - lr: 1.0000e-04\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1418 - acc: 0.9531\n",
      "Epoch 19: acc improved from 0.94687 to 0.95312, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 687ms/step - loss: 0.1418 - acc: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1249 - acc: 0.9594\n",
      "Epoch 20: acc improved from 0.95312 to 0.95938, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.1249 - acc: 0.9594 - lr: 1.0000e-04\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1018 - acc: 0.9552\n",
      "Epoch 21: acc did not improve from 0.95938\n",
      "60/60 [==============================] - 38s 628ms/step - loss: 0.1018 - acc: 0.9552 - lr: 1.0000e-04\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1537 - acc: 0.9448\n",
      "Epoch 22: acc did not improve from 0.95938\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.1537 - acc: 0.9448 - lr: 1.0000e-04\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1176 - acc: 0.9500\n",
      "Epoch 23: acc did not improve from 0.95938\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.1176 - acc: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1070 - acc: 0.9563\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 24: acc did not improve from 0.95938\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.1070 - acc: 0.9563 - lr: 1.0000e-04\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0727 - acc: 0.9719\n",
      "Epoch 25: acc improved from 0.95938 to 0.97188, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 679ms/step - loss: 0.0727 - acc: 0.9719 - lr: 8.0000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0729 - acc: 0.9740\n",
      "Epoch 26: acc improved from 0.97188 to 0.97396, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0729 - acc: 0.9740 - lr: 8.0000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0783 - acc: 0.9688\n",
      "Epoch 27: acc did not improve from 0.97396\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0783 - acc: 0.9688 - lr: 8.0000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0774 - acc: 0.9771\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 28: acc improved from 0.97396 to 0.97708, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 683ms/step - loss: 0.0774 - acc: 0.9771 - lr: 8.0000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0662 - acc: 0.9771\n",
      "Epoch 29: acc did not improve from 0.97708\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0662 - acc: 0.9771 - lr: 6.4000e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0798 - acc: 0.9740\n",
      "Epoch 30: acc did not improve from 0.97708\n",
      "60/60 [==============================] - 39s 629ms/step - loss: 0.0798 - acc: 0.9740 - lr: 6.4000e-05\n",
      "Epoch 31/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0547 - acc: 0.9865\n",
      "Epoch 31: acc improved from 0.97708 to 0.98646, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 41s 678ms/step - loss: 0.0547 - acc: 0.9865 - lr: 6.4000e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0636 - acc: 0.9750\n",
      "Epoch 32: acc did not improve from 0.98646\n",
      "60/60 [==============================] - 38s 617ms/step - loss: 0.0636 - acc: 0.9750 - lr: 6.4000e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0631 - acc: 0.9792\n",
      "Epoch 33: acc did not improve from 0.98646\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0631 - acc: 0.9792 - lr: 6.4000e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0583 - acc: 0.9812\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 34: acc did not improve from 0.98646\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.0583 - acc: 0.9812 - lr: 6.4000e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0463 - acc: 0.9833\n",
      "Epoch 35: acc did not improve from 0.98646\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0463 - acc: 0.9833 - lr: 5.1200e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0389 - acc: 0.9875\n",
      "Epoch 36: acc improved from 0.98646 to 0.98750, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 683ms/step - loss: 0.0389 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.9906\n",
      "Epoch 37: acc improved from 0.98750 to 0.99063, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.0284 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0401 - acc: 0.9896\n",
      "Epoch 38: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 40s 646ms/step - loss: 0.0401 - acc: 0.9896 - lr: 5.1200e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0326 - acc: 0.9875\n",
      "Epoch 39: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0326 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0174 - acc: 0.9937\n",
      "Epoch 40: acc improved from 0.99063 to 0.99375, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 671ms/step - loss: 0.0174 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0270 - acc: 0.9875\n",
      "Epoch 41: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 39s 635ms/step - loss: 0.0270 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0162 - acc: 0.9948\n",
      "Epoch 42: acc improved from 0.99375 to 0.99479, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.0162 - acc: 0.9948 - lr: 5.1200e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0276 - acc: 0.9885\n",
      "Epoch 43: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0276 - acc: 0.9885 - lr: 5.1200e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0322 - acc: 0.9885\n",
      "Epoch 44: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0322 - acc: 0.9885 - lr: 5.1200e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9865\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 45: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.0333 - acc: 0.9865 - lr: 5.1200e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.9865\n",
      "Epoch 46: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0365 - acc: 0.9865 - lr: 4.0960e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0162 - acc: 0.9969\n",
      "Epoch 47: acc improved from 0.99479 to 0.99687, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 43s 686ms/step - loss: 0.0162 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0264 - acc: 0.9896\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 48: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.0264 - acc: 0.9896 - lr: 4.0960e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0269 - acc: 0.9906\n",
      "Epoch 49: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 40s 639ms/step - loss: 0.0269 - acc: 0.9906 - lr: 3.2768e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9958\n",
      "Epoch 50: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.0158 - acc: 0.9958 - lr: 3.2768e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9948\n",
      "Epoch 51: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.0176 - acc: 0.9948 - lr: 3.2768e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9990\n",
      "Epoch 52: acc improved from 0.99687 to 0.99896, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 42s 684ms/step - loss: 0.0084 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 53: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 643ms/step - loss: 0.0099 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.9927\n",
      "Epoch 54: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.0208 - acc: 0.9927 - lr: 3.2768e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0184 - acc: 0.9937\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 55: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 600ms/step - loss: 0.0184 - acc: 0.9937 - lr: 3.2768e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9948\n",
      "Epoch 56: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 42s 657ms/step - loss: 0.0152 - acc: 0.9948 - lr: 2.6214e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9948\n",
      "Epoch 57: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 617ms/step - loss: 0.0118 - acc: 0.9948 - lr: 2.6214e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9979\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 58: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 41s 652ms/step - loss: 0.0112 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9979\n",
      "Epoch 59: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.0052 - acc: 0.9979 - lr: 2.0972e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9958\n",
      "Epoch 60: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 41s 669ms/step - loss: 0.0070 - acc: 0.9958 - lr: 2.0972e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 61: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 630ms/step - loss: 0.0064 - acc: 0.9979 - lr: 2.0972e-05\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9948\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 62: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 41s 659ms/step - loss: 0.0158 - acc: 0.9948 - lr: 2.0972e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9979\n",
      "Epoch 63: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 42s 681ms/step - loss: 0.0073 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 64: acc improved from 0.99896 to 1.00000, saving model to resnet50+SE_Block.hdf5\n",
      "60/60 [==============================] - 41s 678ms/step - loss: 0.0022 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9948\n",
      "Epoch 65: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 632ms/step - loss: 0.0165 - acc: 0.9948 - lr: 1.6777e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 643ms/step - loss: 0.0048 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.0018 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.0019 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 644ms/step - loss: 0.0015 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 0.9990\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 638ms/step - loss: 0.0021 - acc: 0.9990 - lr: 1.6777e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0063 - acc: 0.9990\n",
      "Epoch 71: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 671ms/step - loss: 0.0063 - acc: 0.9990 - lr: 1.6777e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9990\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 666ms/step - loss: 0.0075 - acc: 0.9990 - lr: 1.6777e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9969\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.0047 - acc: 0.9969 - lr: 1.3422e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.0044 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 643ms/step - loss: 0.0029 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0024 - acc: 0.9990\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.0024 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 0.0075 - acc: 0.9969 - lr: 1.0737e-05\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9990\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 642ms/step - loss: 0.0068 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9979\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 640ms/step - loss: 0.0035 - acc: 0.9979 - lr: 8.5899e-06\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 0.9990\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.0023 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 9.4843e-04 - acc: 1.0000\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 9.4843e-04 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.0011 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 629ms/step - loss: 0.0031 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0016 - acc: 0.9990\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 645ms/step - loss: 0.0016 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0014 - acc: 0.9990\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.0014 - acc: 0.9990 - lr: 6.8719e-06\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 5.0947e-04 - acc: 1.0000\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 5.0947e-04 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 7.5062e-04 - acc: 1.0000\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 7.5062e-04 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 7.2688e-04 - acc: 1.0000\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 629ms/step - loss: 7.2688e-04 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 6.1192e-04 - acc: 1.0000\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n",
      "\n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 6.1192e-04 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - acc: 0.9990\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.0022 - acc: 0.9990 - lr: 5.4976e-06\n",
      "15/15 [==============================] - 4s 196ms/step - loss: 0.4508 - acc: 0.9167\n",
      "Test loss: 0.4508450925350189\n",
      "Test accuracy: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.99999642e-01 3.06941956e-07]\n",
      " [1.00000000e+00 7.47934787e-12]\n",
      " [1.00000000e+00 6.00768768e-10]\n",
      " [1.00000000e+00 4.12843759e-17]\n",
      " [1.00000000e+00 3.37611091e-15]\n",
      " [1.00000000e+00 8.51900591e-15]\n",
      " [1.00000000e+00 2.04180111e-16]\n",
      " [9.99826968e-01 1.73036213e-04]\n",
      " [1.00000000e+00 4.23426322e-10]\n",
      " [1.00000000e+00 1.83026147e-13]\n",
      " [1.00000000e+00 1.68639392e-19]\n",
      " [1.00000000e+00 1.87185337e-10]\n",
      " [1.00000000e+00 1.60694201e-11]\n",
      " [1.00000000e+00 1.81652734e-17]\n",
      " [1.00000000e+00 2.67513167e-20]\n",
      " [1.00000000e+00 4.58983873e-09]\n",
      " [1.00000000e+00 2.69909304e-08]\n",
      " [1.00000000e+00 2.81386039e-15]\n",
      " [1.00000000e+00 3.07965486e-10]\n",
      " [1.00000000e+00 1.16235371e-24]\n",
      " [1.00000000e+00 3.38260622e-16]\n",
      " [1.00000000e+00 1.29253654e-16]\n",
      " [1.00000000e+00 3.44744806e-12]\n",
      " [1.00000000e+00 4.62218534e-13]\n",
      " [9.99973059e-01 2.68857639e-05]\n",
      " [1.00000000e+00 2.96929570e-09]\n",
      " [1.00000000e+00 8.24279772e-13]\n",
      " [9.46770072e-01 5.32298945e-02]\n",
      " [1.00000000e+00 3.66872747e-11]\n",
      " [1.00000000e+00 2.14817134e-17]\n",
      " [1.00000000e+00 1.50519053e-09]\n",
      " [1.00000000e+00 1.88632425e-19]\n",
      " [1.00000000e+00 2.56201425e-08]\n",
      " [1.00000000e+00 1.93119568e-13]\n",
      " [1.00000000e+00 1.01314241e-13]\n",
      " [1.00000000e+00 1.07398230e-14]\n",
      " [1.00000000e+00 1.13839209e-13]\n",
      " [1.00000000e+00 1.43849377e-10]\n",
      " [1.00000000e+00 1.59027102e-13]\n",
      " [1.00000000e+00 2.75066238e-13]\n",
      " [1.00000000e+00 8.05329611e-17]\n",
      " [1.00000000e+00 5.43420343e-11]\n",
      " [9.99998808e-01 1.14382726e-06]\n",
      " [1.00000000e+00 2.69335450e-15]\n",
      " [1.00000000e+00 7.41163676e-16]\n",
      " [1.00000000e+00 2.62828526e-11]\n",
      " [1.00000000e+00 5.13216625e-09]\n",
      " [1.00000000e+00 7.82423015e-09]\n",
      " [1.00000000e+00 1.49841328e-09]\n",
      " [9.99157190e-01 8.42860783e-04]\n",
      " [9.99975681e-01 2.43667964e-05]\n",
      " [1.00000000e+00 9.90045979e-12]\n",
      " [1.00000000e+00 9.10891293e-11]\n",
      " [1.00000000e+00 8.56944804e-18]\n",
      " [1.00000000e+00 3.52335716e-16]\n",
      " [1.00000000e+00 1.59368068e-21]\n",
      " [7.55836768e-03 9.92441654e-01]\n",
      " [9.85232592e-01 1.47674782e-02]\n",
      " [9.99932051e-01 6.79835939e-05]\n",
      " [1.00000000e+00 2.56671212e-10]\n",
      " [9.99999762e-01 2.80765221e-07]\n",
      " [1.00000000e+00 2.11894044e-10]\n",
      " [9.99999881e-01 8.47133350e-08]\n",
      " [1.00000000e+00 2.50044402e-10]\n",
      " [1.00000000e+00 8.29418756e-11]\n",
      " [1.00000000e+00 9.25882119e-18]\n",
      " [1.00000000e+00 1.71588277e-09]\n",
      " [1.00000000e+00 4.90344154e-11]\n",
      " [1.00000000e+00 7.44354078e-16]\n",
      " [1.00000000e+00 2.03130401e-10]\n",
      " [1.00000000e+00 4.58701618e-11]\n",
      " [1.00000000e+00 3.55815932e-11]\n",
      " [1.00000000e+00 6.03458882e-16]\n",
      " [9.99994874e-01 5.08791800e-06]\n",
      " [1.00000000e+00 4.03651085e-10]\n",
      " [9.99998808e-01 1.24939766e-06]\n",
      " [1.00000000e+00 4.49173567e-15]\n",
      " [1.00000000e+00 1.27190964e-17]\n",
      " [1.00000000e+00 4.46269107e-12]\n",
      " [1.00000000e+00 4.59783375e-15]\n",
      " [1.00000000e+00 2.07540112e-18]\n",
      " [9.99999762e-01 2.60176279e-07]\n",
      " [1.00000000e+00 9.45769938e-13]\n",
      " [1.00000000e+00 2.72021822e-10]\n",
      " [1.00000000e+00 3.87842449e-18]\n",
      " [9.99934912e-01 6.51232403e-05]\n",
      " [9.99999881e-01 6.78035690e-08]\n",
      " [1.00000000e+00 1.31256017e-09]\n",
      " [1.00000000e+00 7.06573047e-17]\n",
      " [7.47327387e-01 2.52672553e-01]\n",
      " [1.00000000e+00 1.04243403e-09]\n",
      " [1.00000000e+00 1.55331173e-12]\n",
      " [1.00000000e+00 2.62744323e-11]\n",
      " [1.00000000e+00 1.69986976e-08]\n",
      " [1.00000000e+00 5.50535617e-10]\n",
      " [9.65178967e-01 3.48209962e-02]\n",
      " [1.00000000e+00 5.79751134e-12]\n",
      " [1.00000000e+00 1.30202273e-13]\n",
      " [1.00000000e+00 1.04732338e-08]\n",
      " [1.00000000e+00 1.70862702e-08]\n",
      " [1.00000000e+00 1.02383602e-10]\n",
      " [1.00000000e+00 6.75053749e-15]\n",
      " [1.00000000e+00 4.25800679e-11]\n",
      " [1.00000000e+00 1.44047164e-16]\n",
      " [9.99999881e-01 1.69601023e-07]\n",
      " [9.99967575e-01 3.24487155e-05]\n",
      " [3.86281878e-01 6.13718152e-01]\n",
      " [5.29859168e-03 9.94701385e-01]\n",
      " [9.99999523e-01 5.28599969e-07]\n",
      " [9.99996066e-01 3.90989999e-06]\n",
      " [1.00000000e+00 4.69459772e-17]\n",
      " [3.14244858e-07 9.99999642e-01]\n",
      " [1.00000000e+00 7.37883469e-14]\n",
      " [1.00000000e+00 1.36304145e-16]\n",
      " [1.00000000e+00 3.68447772e-11]\n",
      " [1.00000000e+00 5.20418659e-08]\n",
      " [1.00000000e+00 2.80984465e-18]\n",
      " [1.00000000e+00 6.22908192e-12]\n",
      " [1.00000000e+00 2.17861437e-10]\n",
      " [1.00000000e+00 1.91281959e-08]\n",
      " [9.99938011e-01 6.20134670e-05]\n",
      " [1.00000000e+00 8.06427281e-09]\n",
      " [1.00000000e+00 1.75731744e-13]\n",
      " [9.99994874e-01 5.08808262e-06]\n",
      " [6.21979211e-07 9.99999404e-01]\n",
      " [1.00000000e+00 6.29740367e-15]\n",
      " [9.99986053e-01 1.39999329e-05]\n",
      " [1.00000000e+00 5.05009025e-18]\n",
      " [1.00000000e+00 6.74784534e-12]\n",
      " [1.00000000e+00 4.52560449e-21]\n",
      " [1.00000000e+00 2.05730032e-13]\n",
      " [1.00000000e+00 6.50557544e-19]\n",
      " [1.00000000e+00 1.02852372e-10]\n",
      " [1.00000000e+00 5.10293142e-13]\n",
      " [1.00000000e+00 2.77004197e-10]\n",
      " [1.00000000e+00 7.89335638e-14]\n",
      " [9.99983907e-01 1.60516265e-05]\n",
      " [1.00000000e+00 3.78897447e-09]\n",
      " [1.00000000e+00 5.19359211e-17]\n",
      " [9.99999881e-01 7.00729998e-08]\n",
      " [9.99949574e-01 5.04432428e-05]\n",
      " [1.00000000e+00 8.63169401e-16]\n",
      " [6.28969967e-02 9.37103033e-01]\n",
      " [2.62179196e-18 1.00000000e+00]\n",
      " [1.00000000e+00 3.08706802e-08]\n",
      " [8.97636813e-15 1.00000000e+00]\n",
      " [3.24667496e-15 1.00000000e+00]\n",
      " [5.04234012e-15 1.00000000e+00]\n",
      " [4.29441932e-17 1.00000000e+00]\n",
      " [7.33876959e-07 9.99999285e-01]\n",
      " [5.45821307e-21 1.00000000e+00]\n",
      " [4.34555896e-15 1.00000000e+00]\n",
      " [5.45727753e-28 1.00000000e+00]\n",
      " [1.61569005e-06 9.99998331e-01]\n",
      " [1.51215136e-06 9.99998450e-01]\n",
      " [9.99999881e-01 6.84286121e-08]\n",
      " [3.07255378e-15 1.00000000e+00]\n",
      " [6.69032801e-04 9.99330997e-01]\n",
      " [1.00000000e+00 9.27328296e-17]\n",
      " [4.40418627e-03 9.95595872e-01]\n",
      " [7.43327260e-01 2.56672710e-01]\n",
      " [2.00209200e-08 1.00000000e+00]\n",
      " [2.15953037e-07 9.99999762e-01]\n",
      " [2.63555155e-24 1.00000000e+00]\n",
      " [2.76244680e-08 1.00000000e+00]\n",
      " [6.30520202e-12 1.00000000e+00]\n",
      " [2.01827986e-03 9.97981668e-01]\n",
      " [1.00000000e+00 1.77432613e-09]\n",
      " [5.03210140e-06 9.99994993e-01]\n",
      " [3.52202255e-18 1.00000000e+00]\n",
      " [5.54706769e-09 1.00000000e+00]\n",
      " [7.90291948e-26 1.00000000e+00]\n",
      " [4.34289081e-15 1.00000000e+00]\n",
      " [1.21518325e-11 1.00000000e+00]\n",
      " [9.99999285e-01 7.33094964e-07]\n",
      " [9.88190174e-01 1.18098818e-02]\n",
      " [2.15061830e-21 1.00000000e+00]\n",
      " [9.99999762e-01 2.12301288e-07]\n",
      " [9.99732673e-01 2.67302064e-04]\n",
      " [1.45230771e-07 9.99999881e-01]\n",
      " [1.06130271e-09 1.00000000e+00]\n",
      " [1.61422616e-29 1.00000000e+00]\n",
      " [3.58502575e-07 9.99999642e-01]\n",
      " [6.10207907e-27 1.00000000e+00]\n",
      " [3.00129634e-16 1.00000000e+00]\n",
      " [1.14475669e-24 1.00000000e+00]\n",
      " [5.79997277e-07 9.99999404e-01]\n",
      " [2.13866966e-10 1.00000000e+00]\n",
      " [7.74111104e-05 9.99922633e-01]\n",
      " [1.20282513e-23 1.00000000e+00]\n",
      " [8.83229750e-19 1.00000000e+00]\n",
      " [1.76068342e-27 1.00000000e+00]\n",
      " [3.87377825e-20 1.00000000e+00]\n",
      " [6.51914607e-17 1.00000000e+00]\n",
      " [1.74776738e-13 1.00000000e+00]\n",
      " [4.07413245e-05 9.99959230e-01]\n",
      " [3.51050133e-10 1.00000000e+00]\n",
      " [4.72643757e-10 1.00000000e+00]\n",
      " [2.93349790e-21 1.00000000e+00]\n",
      " [8.30157578e-01 1.69842452e-01]\n",
      " [2.79045075e-01 7.20954955e-01]\n",
      " [2.23597141e-08 1.00000000e+00]\n",
      " [1.44714111e-04 9.99855280e-01]\n",
      " [9.30363208e-13 1.00000000e+00]\n",
      " [7.46335544e-24 1.00000000e+00]\n",
      " [2.87223845e-23 1.00000000e+00]\n",
      " [4.48450446e-03 9.95515525e-01]\n",
      " [9.94622827e-01 5.37718507e-03]\n",
      " [9.11758123e-16 1.00000000e+00]\n",
      " [1.29207356e-05 9.99987125e-01]\n",
      " [2.54528550e-05 9.99974489e-01]\n",
      " [1.23791443e-02 9.87620890e-01]\n",
      " [9.39394400e-25 1.00000000e+00]\n",
      " [1.69598489e-29 1.00000000e+00]\n",
      " [3.91685106e-02 9.60831523e-01]\n",
      " [1.59401861e-06 9.99998450e-01]\n",
      " [9.99999881e-01 1.37878473e-07]\n",
      " [1.17619185e-13 1.00000000e+00]\n",
      " [2.94190645e-03 9.97058153e-01]\n",
      " [9.98289287e-01 1.71072909e-03]\n",
      " [6.37874016e-29 1.00000000e+00]\n",
      " [1.05338076e-17 1.00000000e+00]\n",
      " [1.75173409e-04 9.99824822e-01]\n",
      " [5.51075114e-12 1.00000000e+00]\n",
      " [6.24396710e-22 1.00000000e+00]\n",
      " [2.28709399e-15 1.00000000e+00]\n",
      " [9.40110034e-09 1.00000000e+00]\n",
      " [1.49515990e-15 1.00000000e+00]\n",
      " [1.08977616e-14 1.00000000e+00]\n",
      " [9.64789279e-03 9.90352094e-01]\n",
      " [4.38827146e-06 9.99995589e-01]\n",
      " [2.11478417e-19 1.00000000e+00]\n",
      " [3.02791959e-15 1.00000000e+00]\n",
      " [8.07827347e-11 1.00000000e+00]\n",
      " [4.47051018e-09 1.00000000e+00]\n",
      " [2.51358434e-10 1.00000000e+00]\n",
      " [7.73054794e-18 1.00000000e+00]\n",
      " [1.58294703e-25 1.00000000e+00]\n",
      " [1.45247041e-12 1.00000000e+00]\n",
      " [8.02228570e-01 1.97771460e-01]]\n",
      "Confusion Matrix\n",
      "[[137   6]\n",
      " [ 14  83]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.91      0.96      0.93       143\n",
      "    referable       0.93      0.86      0.89        97\n",
      "\n",
      "     accuracy                           0.92       240\n",
      "    macro avg       0.92      0.91      0.91       240\n",
      " weighted avg       0.92      0.92      0.92       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+SE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
