{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "def Global_attention_block(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    \n",
    "    x=tf.keras.layers.AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('relu') (x)\n",
    "\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    C_A=tf.keras.layers.Multiply()([x,inputs])\n",
    "    \n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True)) (C_A)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    S_A=tf.keras.layers.Multiply()([x,C_A])\n",
    "    return S_A\n",
    "\n",
    "def Category_attention_block(inputs,classes,k):\n",
    "    shape=K.int_shape(inputs)\n",
    "    F=Conv2D(k*classes,1, padding='same') (inputs)\n",
    "    F=tf.keras.layers.BatchNormalization() (F)\n",
    "    F1=Activation('relu') (F)\n",
    "    \n",
    "    F2=F1\n",
    "    x=tf.keras.layers.GlobalMaxPool2D()(F2)\n",
    "    \n",
    "    x=tf.keras.layers.Reshape((classes,k)) (x)\n",
    "    S=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
    "    \n",
    "    x=tf.keras.layers.Reshape((shape[1],shape[2],classes,k)) (F1)\n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))  (x)\n",
    "    x=tf.keras.layers.Multiply()([S,x])\n",
    "    M=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (x)\n",
    "    \n",
    "    semantic=tf.keras.layers.Multiply()([inputs,M])\n",
    "    return semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name,attention):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+attention+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+attention+'.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+CABNet.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 1024  2098176     ['conv5_block3_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 1024)  0           ['conv2d_4[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_5 (Conv2D)              (None, 1, 1, 1024)   1049600     ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1, 1, 1024)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 1, 1, 1024)   1049600     ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 1, 1, 1024)   0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 16, 16, 1024  0           ['activation_5[0][0]',           \n",
      "                                )                                 'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 16, 16, 1)    0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 1)    0           ['lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 16, 16, 1024  0           ['activation_6[0][0]',           \n",
      "                                )                                 'multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 6)    6150        ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 6)   24          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 6)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 6)           0           ['activation_7[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 2, 3)         0           ['global_max_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 16, 16, 2, 3  0           ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 2)            0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 16, 16, 2)    0           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 16, 16, 2)    0           ['lambda_5[0][0]',               \n",
      "                                                                  'lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 16, 16, 1)    0           ['multiply_6[0][0]']             \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 16, 16, 1024  0           ['multiply_5[0][0]',             \n",
      "                                )                                 'lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1024)        0           ['multiply_7[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            2050        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,793,312\n",
      "Trainable params: 27,740,180\n",
      "Non-trainable params: 53,132\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=Global_attention_block(red_feat)\n",
    "base_out=Category_attention_block(x,classes,k)\n",
    "\n",
    "shape=K.int_shape(base_out)  \n",
    "x=GlobalAveragePooling2D()(base_out)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:17:50.673291: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 1.1276 - acc: 0.5031\n",
      "Epoch 1: acc improved from -inf to 0.50313, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 531ms/step - loss: 1.1276 - acc: 0.5031 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6696 - acc: 0.6521\n",
      "Epoch 1: acc improved from 0.50313 to 0.65208, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 44s 596ms/step - loss: 0.6696 - acc: 0.6521 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6044 - acc: 0.7781\n",
      "Epoch 2: acc improved from 0.65208 to 0.77812, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 607ms/step - loss: 0.6044 - acc: 0.7781 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5606 - acc: 0.7990\n",
      "Epoch 3: acc improved from 0.77812 to 0.79896, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 626ms/step - loss: 0.5606 - acc: 0.7990 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4480 - acc: 0.8250\n",
      "Epoch 4: acc improved from 0.79896 to 0.82500, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 40s 660ms/step - loss: 0.4480 - acc: 0.8250 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4250 - acc: 0.8219\n",
      "Epoch 5: acc did not improve from 0.82500\n",
      "60/60 [==============================] - 36s 582ms/step - loss: 0.4250 - acc: 0.8219 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4377 - acc: 0.8281\n",
      "Epoch 6: acc improved from 0.82500 to 0.82812, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.4377 - acc: 0.8281 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3724 - acc: 0.8521\n",
      "Epoch 7: acc improved from 0.82812 to 0.85208, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.3724 - acc: 0.8521 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3524 - acc: 0.8594\n",
      "Epoch 8: acc improved from 0.85208 to 0.85938, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 41s 665ms/step - loss: 0.3524 - acc: 0.8594 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3498 - acc: 0.8740\n",
      "Epoch 9: acc improved from 0.85938 to 0.87396, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 602ms/step - loss: 0.3498 - acc: 0.8740 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3087 - acc: 0.8781\n",
      "Epoch 10: acc improved from 0.87396 to 0.87813, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 607ms/step - loss: 0.3087 - acc: 0.8781 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2790 - acc: 0.8938\n",
      "Epoch 11: acc improved from 0.87813 to 0.89375, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 45s 735ms/step - loss: 0.2790 - acc: 0.8938 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3510 - acc: 0.8667\n",
      "Epoch 12: acc did not improve from 0.89375\n",
      "60/60 [==============================] - 34s 558ms/step - loss: 0.3510 - acc: 0.8667 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2979 - acc: 0.8958\n",
      "Epoch 13: acc improved from 0.89375 to 0.89583, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.2979 - acc: 0.8958 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3048 - acc: 0.8865\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 14: acc did not improve from 0.89583\n",
      "60/60 [==============================] - 36s 585ms/step - loss: 0.3048 - acc: 0.8865 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2682 - acc: 0.8990\n",
      "Epoch 15: acc improved from 0.89583 to 0.89896, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.2682 - acc: 0.8990 - lr: 8.0000e-05\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2227 - acc: 0.9094\n",
      "Epoch 16: acc improved from 0.89896 to 0.90938, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 605ms/step - loss: 0.2227 - acc: 0.9094 - lr: 8.0000e-05\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2041 - acc: 0.9250\n",
      "Epoch 17: acc improved from 0.90938 to 0.92500, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.2041 - acc: 0.9250 - lr: 8.0000e-05\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2078 - acc: 0.9260\n",
      "Epoch 18: acc improved from 0.92500 to 0.92604, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 603ms/step - loss: 0.2078 - acc: 0.9260 - lr: 8.0000e-05\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2203 - acc: 0.9146\n",
      "Epoch 19: acc did not improve from 0.92604\n",
      "60/60 [==============================] - 35s 574ms/step - loss: 0.2203 - acc: 0.9146 - lr: 8.0000e-05\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2099 - acc: 0.9208\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 20: acc did not improve from 0.92604\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.2099 - acc: 0.9208 - lr: 8.0000e-05\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1838 - acc: 0.9271\n",
      "Epoch 21: acc improved from 0.92604 to 0.92708, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.1838 - acc: 0.9271 - lr: 6.4000e-05\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1627 - acc: 0.9469\n",
      "Epoch 22: acc improved from 0.92708 to 0.94687, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 613ms/step - loss: 0.1627 - acc: 0.9469 - lr: 6.4000e-05\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1589 - acc: 0.9438\n",
      "Epoch 23: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 36s 584ms/step - loss: 0.1589 - acc: 0.9438 - lr: 6.4000e-05\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1544 - acc: 0.9396\n",
      "Epoch 24: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 37s 605ms/step - loss: 0.1544 - acc: 0.9396 - lr: 6.4000e-05\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1946 - acc: 0.9198\n",
      "Epoch 25: acc did not improve from 0.94687\n",
      "60/60 [==============================] - 36s 582ms/step - loss: 0.1946 - acc: 0.9198 - lr: 6.4000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1380 - acc: 0.9521\n",
      "Epoch 26: acc improved from 0.94687 to 0.95208, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 629ms/step - loss: 0.1380 - acc: 0.9521 - lr: 6.4000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1198 - acc: 0.9604\n",
      "Epoch 27: acc improved from 0.95208 to 0.96042, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 37s 608ms/step - loss: 0.1198 - acc: 0.9604 - lr: 6.4000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1387 - acc: 0.9490\n",
      "Epoch 28: acc did not improve from 0.96042\n",
      "60/60 [==============================] - 35s 575ms/step - loss: 0.1387 - acc: 0.9490 - lr: 6.4000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1268 - acc: 0.9563\n",
      "Epoch 29: acc did not improve from 0.96042\n",
      "60/60 [==============================] - 37s 593ms/step - loss: 0.1268 - acc: 0.9563 - lr: 6.4000e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1234 - acc: 0.9583\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 30: acc did not improve from 0.96042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 36s 578ms/step - loss: 0.1234 - acc: 0.9583 - lr: 6.4000e-05\n",
      "Epoch 31/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1006 - acc: 0.9615\n",
      "Epoch 31: acc improved from 0.96042 to 0.96146, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 618ms/step - loss: 0.1006 - acc: 0.9615 - lr: 5.1200e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0952 - acc: 0.9656\n",
      "Epoch 32: acc improved from 0.96146 to 0.96562, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0952 - acc: 0.9656 - lr: 5.1200e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0858 - acc: 0.9729\n",
      "Epoch 33: acc improved from 0.96562 to 0.97292, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 627ms/step - loss: 0.0858 - acc: 0.9729 - lr: 5.1200e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0955 - acc: 0.9698\n",
      "Epoch 34: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 35s 562ms/step - loss: 0.0955 - acc: 0.9698 - lr: 5.1200e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1231 - acc: 0.9594\n",
      "Epoch 35: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 37s 591ms/step - loss: 0.1231 - acc: 0.9594 - lr: 5.1200e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0919 - acc: 0.9656\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 36: acc did not improve from 0.97292\n",
      "60/60 [==============================] - 36s 589ms/step - loss: 0.0919 - acc: 0.9656 - lr: 5.1200e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0716 - acc: 0.9792\n",
      "Epoch 37: acc improved from 0.97292 to 0.97917, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.0716 - acc: 0.9792 - lr: 4.0960e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0613 - acc: 0.9771\n",
      "Epoch 38: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0613 - acc: 0.9771 - lr: 4.0960e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0480 - acc: 0.9823\n",
      "Epoch 39: acc improved from 0.97917 to 0.98229, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 633ms/step - loss: 0.0480 - acc: 0.9823 - lr: 4.0960e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0588 - acc: 0.9781\n",
      "Epoch 40: acc did not improve from 0.98229\n",
      "60/60 [==============================] - 36s 584ms/step - loss: 0.0588 - acc: 0.9781 - lr: 4.0960e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9792\n",
      "Epoch 41: acc did not improve from 0.98229\n",
      "60/60 [==============================] - 37s 607ms/step - loss: 0.0751 - acc: 0.9792 - lr: 4.0960e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0527 - acc: 0.9823\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 42: acc did not improve from 0.98229\n",
      "60/60 [==============================] - 37s 602ms/step - loss: 0.0527 - acc: 0.9823 - lr: 4.0960e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0361 - acc: 0.9906\n",
      "Epoch 43: acc improved from 0.98229 to 0.99063, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 40s 655ms/step - loss: 0.0361 - acc: 0.9906 - lr: 3.2768e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9802\n",
      "Epoch 44: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 36s 592ms/step - loss: 0.0501 - acc: 0.9802 - lr: 3.2768e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0428 - acc: 0.9833\n",
      "Epoch 45: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0428 - acc: 0.9833 - lr: 3.2768e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0444 - acc: 0.9823\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 46: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 38s 615ms/step - loss: 0.0444 - acc: 0.9823 - lr: 3.2768e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0396 - acc: 0.9885\n",
      "Epoch 47: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.0396 - acc: 0.9885 - lr: 2.6214e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0426 - acc: 0.9854\n",
      "Epoch 48: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0426 - acc: 0.9854 - lr: 2.6214e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.9885\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 49: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.0439 - acc: 0.9885 - lr: 2.6214e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0270 - acc: 0.9927\n",
      "Epoch 50: acc improved from 0.99063 to 0.99271, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 44s 712ms/step - loss: 0.0270 - acc: 0.9927 - lr: 2.0972e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0388 - acc: 0.9854\n",
      "Epoch 51: acc did not improve from 0.99271\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.0388 - acc: 0.9854 - lr: 2.0972e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 52: acc did not improve from 0.99271\n",
      "60/60 [==============================] - 36s 587ms/step - loss: 0.0298 - acc: 0.9906 - lr: 2.0972e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9937\n",
      "Epoch 53: acc improved from 0.99271 to 0.99375, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 40s 638ms/step - loss: 0.0179 - acc: 0.9937 - lr: 2.0972e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0263 - acc: 0.9896\n",
      "Epoch 54: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.0263 - acc: 0.9896 - lr: 2.0972e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 55: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 38s 618ms/step - loss: 0.0204 - acc: 0.9937 - lr: 2.0972e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0269 - acc: 0.9896\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 56: acc did not improve from 0.99375\n",
      "60/60 [==============================] - 38s 627ms/step - loss: 0.0269 - acc: 0.9896 - lr: 2.0972e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0279 - acc: 0.9948\n",
      "Epoch 57: acc improved from 0.99375 to 0.99479, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.0279 - acc: 0.9948 - lr: 1.6777e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.9969\n",
      "Epoch 58: acc improved from 0.99479 to 0.99687, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 637ms/step - loss: 0.0127 - acc: 0.9969 - lr: 1.6777e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0186 - acc: 0.9958\n",
      "Epoch 59: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 37s 609ms/step - loss: 0.0186 - acc: 0.9958 - lr: 1.6777e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9969\n",
      "Epoch 60: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0137 - acc: 0.9969 - lr: 1.6777e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9948\n",
      "Epoch 61: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 36s 584ms/step - loss: 0.0114 - acc: 0.9948 - lr: 1.6777e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 62: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 39s 607ms/step - loss: 0.0108 - acc: 0.9969 - lr: 1.6777e-05\n",
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0209 - acc: 0.9948\n",
      "Epoch 63: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.0209 - acc: 0.9948 - lr: 1.6777e-05\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0124 - acc: 0.9969\n",
      "Epoch 64: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.0124 - acc: 0.9969 - lr: 1.6777e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9958\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 65: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 619ms/step - loss: 0.0112 - acc: 0.9958 - lr: 1.6777e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 66: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 613ms/step - loss: 0.0250 - acc: 0.9917 - lr: 1.3422e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 67: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 38s 617ms/step - loss: 0.0104 - acc: 0.9969 - lr: 1.3422e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0093 - acc: 0.9979\n",
      "Epoch 68: acc improved from 0.99687 to 0.99792, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0093 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0045 - acc: 0.9990\n",
      "Epoch 69: acc improved from 0.99792 to 0.99896, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 39s 633ms/step - loss: 0.0045 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9979\n",
      "Epoch 70: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0051 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 71: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 614ms/step - loss: 0.0064 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9979\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 72: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0051 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.9958\n",
      "Epoch 73: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 610ms/step - loss: 0.0092 - acc: 0.9958 - lr: 1.0737e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9969\n",
      "Epoch 74: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 619ms/step - loss: 0.0090 - acc: 0.9969 - lr: 1.0737e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9958\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 75: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0104 - acc: 0.9958 - lr: 1.0737e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 76: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 37s 605ms/step - loss: 0.0112 - acc: 0.9969 - lr: 8.5899e-06\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 77: acc improved from 0.99896 to 1.00000, saving model to resnet50+CABNet.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0039 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 610ms/step - loss: 0.0095 - acc: 0.9969 - lr: 8.5899e-06\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9979\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.0108 - acc: 0.9979 - lr: 8.5899e-06\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 648ms/step - loss: 0.0032 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 634ms/step - loss: 0.0058 - acc: 0.9979 - lr: 8.5899e-06\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0030 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9969\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0076 - acc: 0.9969 - lr: 8.5899e-06\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 631ms/step - loss: 0.0034 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.0023 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.0018 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9990\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 579ms/step - loss: 0.0071 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 40s 633ms/step - loss: 0.0023 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 35s 575ms/step - loss: 0.0020 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9969\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 614ms/step - loss: 0.0052 - acc: 0.9969 - lr: 6.8719e-06\n",
      "15/15 [==============================] - 5s 250ms/step - loss: 0.3374 - acc: 0.9208\n",
      "Test loss: 0.33739909529685974\n",
      "Test accuracy: 0.9208333492279053\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50','cabnet')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.9994051e-01 5.9500439e-05]\n",
      " [1.0000000e+00 2.6877180e-09]\n",
      " [1.0000000e+00 7.2007222e-09]\n",
      " [1.0000000e+00 5.8177525e-11]\n",
      " [5.8565795e-01 4.1434205e-01]\n",
      " [1.0000000e+00 2.1315744e-11]\n",
      " [1.0000000e+00 3.4487188e-15]\n",
      " [9.7676063e-01 2.3239393e-02]\n",
      " [9.9999988e-01 6.0282169e-08]\n",
      " [9.9795330e-01 2.0466675e-03]\n",
      " [1.0000000e+00 2.8116393e-15]\n",
      " [9.9999917e-01 8.8008886e-07]\n",
      " [1.0000000e+00 2.8105674e-11]\n",
      " [1.0000000e+00 2.6391106e-11]\n",
      " [1.0000000e+00 1.7929587e-13]\n",
      " [9.9997592e-01 2.4125495e-05]\n",
      " [9.9900788e-01 9.9212048e-04]\n",
      " [1.0000000e+00 2.7698779e-10]\n",
      " [9.9999869e-01 1.2714141e-06]\n",
      " [1.0000000e+00 1.1581791e-18]\n",
      " [9.9999523e-01 4.7720700e-06]\n",
      " [1.0000000e+00 1.7350488e-10]\n",
      " [1.0000000e+00 1.4900832e-12]\n",
      " [1.0000000e+00 2.8625657e-10]\n",
      " [9.9995482e-01 4.5166453e-05]\n",
      " [1.0000000e+00 1.3935128e-10]\n",
      " [4.8583104e-05 9.9995136e-01]\n",
      " [2.3368801e-05 9.9997663e-01]\n",
      " [1.0000000e+00 4.5876533e-08]\n",
      " [1.0000000e+00 5.0611863e-08]\n",
      " [9.9998331e-01 1.6714839e-05]\n",
      " [1.0000000e+00 2.2451123e-12]\n",
      " [9.9979419e-01 2.0581302e-04]\n",
      " [1.0000000e+00 1.4648957e-12]\n",
      " [1.0000000e+00 6.8656254e-11]\n",
      " [1.0000000e+00 2.1683799e-09]\n",
      " [1.0000000e+00 5.5284675e-09]\n",
      " [9.9999714e-01 2.9117075e-06]\n",
      " [9.9999475e-01 5.1927468e-06]\n",
      " [1.0000000e+00 3.3446735e-11]\n",
      " [1.0000000e+00 3.1437001e-16]\n",
      " [9.9999869e-01 1.2535270e-06]\n",
      " [9.9998236e-01 1.7655888e-05]\n",
      " [1.0000000e+00 1.7892258e-08]\n",
      " [1.0000000e+00 2.3206461e-09]\n",
      " [1.0000000e+00 8.6177421e-09]\n",
      " [9.9999928e-01 7.1165078e-07]\n",
      " [3.3694217e-03 9.9663061e-01]\n",
      " [9.9999976e-01 1.8765958e-07]\n",
      " [2.3755620e-01 7.6244378e-01]\n",
      " [9.9491286e-01 5.0871130e-03]\n",
      " [1.0000000e+00 4.8318778e-08]\n",
      " [1.0000000e+00 2.0385942e-09]\n",
      " [1.0000000e+00 1.7632453e-11]\n",
      " [9.9999940e-01 5.8522954e-07]\n",
      " [1.0000000e+00 2.4363969e-11]\n",
      " [9.9996293e-01 3.7042515e-05]\n",
      " [9.9999332e-01 6.7280607e-06]\n",
      " [9.9995852e-01 4.1488151e-05]\n",
      " [1.0000000e+00 7.8904563e-09]\n",
      " [9.9996758e-01 3.2479180e-05]\n",
      " [9.9997103e-01 2.8929420e-05]\n",
      " [9.9999845e-01 1.5894599e-06]\n",
      " [1.0000000e+00 2.1131669e-08]\n",
      " [1.0000000e+00 5.2395588e-10]\n",
      " [1.0000000e+00 1.3969550e-12]\n",
      " [9.9999917e-01 7.8749343e-07]\n",
      " [9.9999857e-01 1.4478675e-06]\n",
      " [1.0000000e+00 4.5669508e-09]\n",
      " [1.0000000e+00 2.0777049e-08]\n",
      " [1.0000000e+00 3.6305219e-09]\n",
      " [1.0000000e+00 4.4540219e-10]\n",
      " [1.0000000e+00 1.9904785e-12]\n",
      " [9.0724677e-01 9.2753254e-02]\n",
      " [9.9999940e-01 5.7156473e-07]\n",
      " [9.9999940e-01 5.4975652e-07]\n",
      " [9.5121133e-01 4.8788738e-02]\n",
      " [1.0000000e+00 1.2196114e-11]\n",
      " [1.0000000e+00 8.0513124e-10]\n",
      " [1.0000000e+00 1.3153059e-18]\n",
      " [1.0000000e+00 4.4460299e-16]\n",
      " [1.0000000e+00 5.7821612e-12]\n",
      " [1.0000000e+00 6.0041372e-10]\n",
      " [1.0000000e+00 2.7246499e-12]\n",
      " [1.0000000e+00 1.0755079e-13]\n",
      " [9.1881579e-01 8.1184246e-02]\n",
      " [9.9999976e-01 2.2886103e-07]\n",
      " [1.0000000e+00 4.5494239e-09]\n",
      " [1.0000000e+00 3.2296916e-14]\n",
      " [9.9999988e-01 1.5178453e-07]\n",
      " [9.9984324e-01 1.5674812e-04]\n",
      " [1.0000000e+00 4.1965272e-08]\n",
      " [1.0000000e+00 2.2283194e-13]\n",
      " [1.0000000e+00 1.3459868e-10]\n",
      " [1.0000000e+00 1.4180476e-08]\n",
      " [1.0000000e+00 1.4088170e-08]\n",
      " [9.9999976e-01 2.6146549e-07]\n",
      " [1.0000000e+00 1.7584148e-12]\n",
      " [9.9999857e-01 1.4301343e-06]\n",
      " [9.9999940e-01 5.9997234e-07]\n",
      " [9.9999869e-01 1.3379660e-06]\n",
      " [1.0000000e+00 3.4227961e-14]\n",
      " [1.0000000e+00 3.9088017e-09]\n",
      " [1.0000000e+00 2.9161076e-11]\n",
      " [9.9758422e-01 2.4157304e-03]\n",
      " [9.9995613e-01 4.3919437e-05]\n",
      " [9.9676263e-01 3.2373799e-03]\n",
      " [4.8741713e-01 5.1258290e-01]\n",
      " [9.9997842e-01 2.1627944e-05]\n",
      " [9.9893099e-01 1.0689619e-03]\n",
      " [1.0000000e+00 4.6455075e-14]\n",
      " [9.9716884e-01 2.8311780e-03]\n",
      " [9.9999964e-01 3.9328134e-07]\n",
      " [1.0000000e+00 2.2438217e-10]\n",
      " [1.0000000e+00 5.6962096e-12]\n",
      " [9.9999857e-01 1.4636804e-06]\n",
      " [1.0000000e+00 6.6032184e-09]\n",
      " [1.0000000e+00 3.1530921e-16]\n",
      " [1.0000000e+00 8.0299302e-11]\n",
      " [9.9999738e-01 2.6044888e-06]\n",
      " [9.9999416e-01 5.7869224e-06]\n",
      " [9.9999988e-01 9.0642118e-08]\n",
      " [1.0000000e+00 1.8852565e-11]\n",
      " [9.9999917e-01 7.9148458e-07]\n",
      " [8.6403852e-05 9.9991357e-01]\n",
      " [1.0000000e+00 2.5401872e-11]\n",
      " [1.0000000e+00 7.9133962e-09]\n",
      " [1.0000000e+00 2.0982193e-11]\n",
      " [1.0000000e+00 3.0187199e-09]\n",
      " [1.0000000e+00 1.5563226e-11]\n",
      " [1.0000000e+00 1.6709928e-08]\n",
      " [1.0000000e+00 2.7814298e-10]\n",
      " [4.8468572e-01 5.1531428e-01]\n",
      " [1.0000000e+00 4.5969530e-09]\n",
      " [1.0000000e+00 2.3317574e-08]\n",
      " [1.0000000e+00 1.8355862e-09]\n",
      " [9.9956363e-01 4.3637957e-04]\n",
      " [9.9999964e-01 3.7351427e-07]\n",
      " [1.0000000e+00 7.4511810e-09]\n",
      " [1.0000000e+00 4.7418011e-12]\n",
      " [7.1276170e-01 2.8723830e-01]\n",
      " [1.0000000e+00 6.8812844e-17]\n",
      " [3.6925585e-03 9.9630749e-01]\n",
      " [9.5632555e-35 1.0000000e+00]\n",
      " [9.9994087e-01 5.9094040e-05]\n",
      " [3.6926272e-17 1.0000000e+00]\n",
      " [1.8695544e-26 1.0000000e+00]\n",
      " [3.1104905e-06 9.9999690e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [5.7865761e-19 1.0000000e+00]\n",
      " [6.5804415e-30 1.0000000e+00]\n",
      " [4.3095565e-29 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [1.5518542e-09 1.0000000e+00]\n",
      " [1.3971801e-14 1.0000000e+00]\n",
      " [1.0000000e+00 1.1008057e-08]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [3.8629159e-01 6.1370838e-01]\n",
      " [1.0000000e+00 4.2738590e-10]\n",
      " [5.9133483e-11 1.0000000e+00]\n",
      " [9.9999881e-01 1.2511337e-06]\n",
      " [2.5254406e-28 1.0000000e+00]\n",
      " [2.1594360e-09 1.0000000e+00]\n",
      " [6.8881965e-23 1.0000000e+00]\n",
      " [2.1286108e-09 1.0000000e+00]\n",
      " [4.3608351e-23 1.0000000e+00]\n",
      " [3.8259550e-08 1.0000000e+00]\n",
      " [9.9550098e-01 4.4990401e-03]\n",
      " [8.8649695e-06 9.9999118e-01]\n",
      " [8.1619325e-35 1.0000000e+00]\n",
      " [1.4449061e-18 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [2.7783413e-23 1.0000000e+00]\n",
      " [2.8003416e-26 1.0000000e+00]\n",
      " [8.7756091e-01 1.2243913e-01]\n",
      " [7.2831614e-04 9.9927169e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [9.3074000e-01 6.9259956e-02]\n",
      " [1.7835309e-01 8.2164699e-01]\n",
      " [3.7482321e-02 9.6251768e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [1.2260712e-31 1.0000000e+00]\n",
      " [4.2840305e-09 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [3.8968476e-16 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [2.4749967e-14 1.0000000e+00]\n",
      " [2.8907590e-31 1.0000000e+00]\n",
      " [9.9998796e-01 1.1996025e-05]\n",
      " [4.6409094e-26 1.0000000e+00]\n",
      " [2.3698872e-38 1.0000000e+00]\n",
      " [1.7625965e-37 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [2.1177378e-20 1.0000000e+00]\n",
      " [6.4649991e-35 1.0000000e+00]\n",
      " [2.4124093e-03 9.9758756e-01]\n",
      " [1.8342694e-10 1.0000000e+00]\n",
      " [1.7413339e-26 1.0000000e+00]\n",
      " [8.8171066e-36 1.0000000e+00]\n",
      " [4.2291601e-11 1.0000000e+00]\n",
      " [3.1481250e-05 9.9996853e-01]\n",
      " [4.0540813e-13 1.0000000e+00]\n",
      " [6.5730840e-01 3.4269154e-01]\n",
      " [8.0866047e-32 1.0000000e+00]\n",
      " [8.8176827e-35 1.0000000e+00]\n",
      " [9.2427628e-26 1.0000000e+00]\n",
      " [6.4198278e-13 1.0000000e+00]\n",
      " [9.9972969e-01 2.7030232e-04]\n",
      " [3.4920140e-34 1.0000000e+00]\n",
      " [2.4845154e-12 1.0000000e+00]\n",
      " [3.4491699e-05 9.9996555e-01]\n",
      " [2.4180496e-05 9.9997580e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [2.6722929e-01 7.3277068e-01]\n",
      " [4.7464798e-08 1.0000000e+00]\n",
      " [9.9995244e-01 4.7524536e-05]\n",
      " [2.4873414e-27 1.0000000e+00]\n",
      " [2.2734937e-11 1.0000000e+00]\n",
      " [2.9863052e-02 9.7013694e-01]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [4.7949613e-23 1.0000000e+00]\n",
      " [2.5184867e-01 7.4815136e-01]\n",
      " [3.0079043e-12 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [1.5393032e-11 1.0000000e+00]\n",
      " [2.4659107e-07 9.9999976e-01]\n",
      " [2.1540488e-30 1.0000000e+00]\n",
      " [7.9230347e-08 9.9999988e-01]\n",
      " [4.8550903e-03 9.9514490e-01]\n",
      " [7.2640930e-17 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [3.0225639e-05 9.9996972e-01]\n",
      " [1.7292689e-23 1.0000000e+00]\n",
      " [2.9714438e-12 1.0000000e+00]\n",
      " [1.0124729e-19 1.0000000e+00]\n",
      " [8.7716197e-20 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00]\n",
      " [3.0454811e-15 1.0000000e+00]\n",
      " [3.5513836e-04 9.9964488e-01]]\n",
      "Confusion Matrix\n",
      "[[135   8]\n",
      " [ 11  86]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.92      0.94      0.93       143\n",
      "    referable       0.91      0.89      0.90        97\n",
      "\n",
      "     accuracy                           0.92       240\n",
      "    macro avg       0.92      0.92      0.92       240\n",
      " weighted avg       0.92      0.92      0.92       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce1970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+CABNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
