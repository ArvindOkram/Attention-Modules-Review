{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "def Global_attention_block(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    \n",
    "    x=tf.keras.layers.AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('relu') (x)\n",
    "\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    C_A=tf.keras.layers.Multiply()([x,inputs])\n",
    "    \n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True)) (C_A)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    S_A=tf.keras.layers.Multiply()([x,C_A])\n",
    "    return S_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name,attention):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+attention+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+attention+'.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+Global_attention_block.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 2048)  0           ['conv5_block3_out[0][0]']       \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 1, 1, 2048)   4196352     ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 1, 1, 2048)   0           ['conv2d_2[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 1, 1, 2048)   4196352     ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1, 1, 2048)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 16, 16, 2048  0           ['activation_4[0][0]',           \n",
      "                                )                                 'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 16, 16, 1)    0           ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 1)    0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 16, 16, 2048  0           ['activation_5[0][0]',           \n",
      "                                )                                 'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['multiply_3[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            4098        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,984,514\n",
      "Trainable params: 31,931,394\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "#red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=Global_attention_block(base_out)\n",
    "\n",
    "shape=K.int_shape(base_out)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 13:13:45.450714: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.7285 - acc: 0.6250\n",
      "Epoch 1: acc improved from -inf to 0.62500, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 553ms/step - loss: 0.7285 - acc: 0.6250 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5165 - acc: 0.7656\n",
      "Epoch 1: acc improved from 0.62500 to 0.76562, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 42s 585ms/step - loss: 0.5165 - acc: 0.7656 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3715 - acc: 0.8406\n",
      "Epoch 2: acc improved from 0.76562 to 0.84062, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 39s 626ms/step - loss: 0.3715 - acc: 0.8406 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3274 - acc: 0.8656\n",
      "Epoch 3: acc improved from 0.84062 to 0.86563, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.3274 - acc: 0.8656 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2876 - acc: 0.8917\n",
      "Epoch 4: acc improved from 0.86563 to 0.89167, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.2876 - acc: 0.8917 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3014 - acc: 0.8792\n",
      "Epoch 5: acc did not improve from 0.89167\n",
      "60/60 [==============================] - 34s 560ms/step - loss: 0.3014 - acc: 0.8792 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3023 - acc: 0.8760\n",
      "Epoch 6: acc did not improve from 0.89167\n",
      "60/60 [==============================] - 34s 559ms/step - loss: 0.3023 - acc: 0.8760 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2690 - acc: 0.8896\n",
      "Epoch 7: acc did not improve from 0.89167\n",
      "60/60 [==============================] - 35s 566ms/step - loss: 0.2690 - acc: 0.8896 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2515 - acc: 0.9042\n",
      "Epoch 8: acc improved from 0.89167 to 0.90417, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 37s 608ms/step - loss: 0.2515 - acc: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2572 - acc: 0.8906\n",
      "Epoch 9: acc did not improve from 0.90417\n",
      "60/60 [==============================] - 35s 566ms/step - loss: 0.2572 - acc: 0.8906 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2242 - acc: 0.9052\n",
      "Epoch 10: acc improved from 0.90417 to 0.90521, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 38s 618ms/step - loss: 0.2242 - acc: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2031 - acc: 0.9271\n",
      "Epoch 11: acc improved from 0.90521 to 0.92708, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 38s 620ms/step - loss: 0.2031 - acc: 0.9271 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2232 - acc: 0.9083\n",
      "Epoch 12: acc did not improve from 0.92708\n",
      "60/60 [==============================] - 35s 573ms/step - loss: 0.2232 - acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1969 - acc: 0.9177\n",
      "Epoch 13: acc did not improve from 0.92708\n",
      "60/60 [==============================] - 35s 574ms/step - loss: 0.1969 - acc: 0.9177 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1929 - acc: 0.9302\n",
      "Epoch 14: acc improved from 0.92708 to 0.93021, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 646ms/step - loss: 0.1929 - acc: 0.9302 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1392 - acc: 0.9563\n",
      "Epoch 15: acc improved from 0.93021 to 0.95625, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 39s 641ms/step - loss: 0.1392 - acc: 0.9563 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1634 - acc: 0.9354\n",
      "Epoch 16: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.1634 - acc: 0.9354 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1233 - acc: 0.9542\n",
      "Epoch 17: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 37s 593ms/step - loss: 0.1233 - acc: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1660 - acc: 0.9365\n",
      "Epoch 18: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 36s 591ms/step - loss: 0.1660 - acc: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2154 - acc: 0.9271\n",
      "Epoch 19: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.2154 - acc: 0.9271 - lr: 1.0000e-04\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1324 - acc: 0.9542\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 20: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 35s 562ms/step - loss: 0.1324 - acc: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1603 - acc: 0.9427\n",
      "Epoch 21: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 38s 605ms/step - loss: 0.1603 - acc: 0.9427 - lr: 8.0000e-05\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1162 - acc: 0.9563\n",
      "Epoch 22: acc did not improve from 0.95625\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.1162 - acc: 0.9563 - lr: 8.0000e-05\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1058 - acc: 0.9615\n",
      "Epoch 23: acc improved from 0.95625 to 0.96146, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.1058 - acc: 0.9615 - lr: 8.0000e-05\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1318 - acc: 0.9521\n",
      "Epoch 24: acc did not improve from 0.96146\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.1318 - acc: 0.9521 - lr: 8.0000e-05\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0865 - acc: 0.9677\n",
      "Epoch 25: acc improved from 0.96146 to 0.96771, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 41s 660ms/step - loss: 0.0865 - acc: 0.9677 - lr: 8.0000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0954 - acc: 0.9646\n",
      "Epoch 26: acc did not improve from 0.96771\n",
      "60/60 [==============================] - 36s 592ms/step - loss: 0.0954 - acc: 0.9646 - lr: 8.0000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0908 - acc: 0.9646\n",
      "Epoch 27: acc did not improve from 0.96771\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.0908 - acc: 0.9646 - lr: 8.0000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0863 - acc: 0.9708\n",
      "Epoch 28: acc improved from 0.96771 to 0.97083, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 650ms/step - loss: 0.0863 - acc: 0.9708 - lr: 8.0000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1186 - acc: 0.9521\n",
      "Epoch 29: acc did not improve from 0.97083\n",
      "60/60 [==============================] - 37s 604ms/step - loss: 0.1186 - acc: 0.9521 - lr: 8.0000e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0948 - acc: 0.9677\n",
      "Epoch 30: acc did not improve from 0.97083\n",
      "60/60 [==============================] - 38s 623ms/step - loss: 0.0948 - acc: 0.9677 - lr: 8.0000e-05\n",
      "Epoch 31/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0694 - acc: 0.9792\n",
      "Epoch 31: acc improved from 0.97083 to 0.97917, saving model to resnet50+Global_attention_block.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0694 - acc: 0.9792 - lr: 8.0000e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0729 - acc: 0.9708\n",
      "Epoch 32: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 37s 605ms/step - loss: 0.0729 - acc: 0.9708 - lr: 8.0000e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0716 - acc: 0.9740\n",
      "Epoch 33: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 38s 614ms/step - loss: 0.0716 - acc: 0.9740 - lr: 8.0000e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0856 - acc: 0.9656\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 34: acc did not improve from 0.97917\n",
      "60/60 [==============================] - 36s 583ms/step - loss: 0.0856 - acc: 0.9656 - lr: 8.0000e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0536 - acc: 0.9844\n",
      "Epoch 35: acc improved from 0.97917 to 0.98438, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 41s 647ms/step - loss: 0.0536 - acc: 0.9844 - lr: 6.4000e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0613 - acc: 0.9792\n",
      "Epoch 36: acc did not improve from 0.98438\n",
      "60/60 [==============================] - 37s 597ms/step - loss: 0.0613 - acc: 0.9792 - lr: 6.4000e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.9865\n",
      "Epoch 37: acc improved from 0.98438 to 0.98646, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.0508 - acc: 0.9865 - lr: 6.4000e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0407 - acc: 0.9885\n",
      "Epoch 38: acc improved from 0.98646 to 0.98854, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 39s 638ms/step - loss: 0.0407 - acc: 0.9885 - lr: 6.4000e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0420 - acc: 0.9865\n",
      "Epoch 39: acc did not improve from 0.98854\n",
      "60/60 [==============================] - 35s 572ms/step - loss: 0.0420 - acc: 0.9865 - lr: 6.4000e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9948\n",
      "Epoch 40: acc improved from 0.98854 to 0.99479, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 0.0277 - acc: 0.9948 - lr: 6.4000e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.9865\n",
      "Epoch 41: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0417 - acc: 0.9865 - lr: 6.4000e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.9875\n",
      "Epoch 42: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 37s 597ms/step - loss: 0.0354 - acc: 0.9875 - lr: 6.4000e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9948\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 43: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 38s 610ms/step - loss: 0.0295 - acc: 0.9948 - lr: 6.4000e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0275 - acc: 0.9927\n",
      "Epoch 44: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 38s 605ms/step - loss: 0.0275 - acc: 0.9927 - lr: 5.1200e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.9906\n",
      "Epoch 45: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 38s 606ms/step - loss: 0.0365 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 46: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 39s 628ms/step - loss: 0.0186 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0212 - acc: 0.9948\n",
      "Epoch 47: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 36s 584ms/step - loss: 0.0212 - acc: 0.9948 - lr: 5.1200e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0183 - acc: 0.9937\n",
      "Epoch 48: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 39s 632ms/step - loss: 0.0183 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9948\n",
      "Epoch 49: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 36s 591ms/step - loss: 0.0178 - acc: 0.9948 - lr: 5.1200e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0272 - acc: 0.9917\n",
      "Epoch 50: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0272 - acc: 0.9917 - lr: 5.1200e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.9927\n",
      "Epoch 51: acc did not improve from 0.99479\n",
      "60/60 [==============================] - 38s 611ms/step - loss: 0.0225 - acc: 0.9927 - lr: 5.1200e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0134 - acc: 0.9979\n",
      "Epoch 52: acc improved from 0.99479 to 0.99792, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 41s 661ms/step - loss: 0.0134 - acc: 0.9979 - lr: 5.1200e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9917\n",
      "Epoch 53: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.0202 - acc: 0.9917 - lr: 5.1200e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.9948\n",
      "Epoch 54: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 603ms/step - loss: 0.0163 - acc: 0.9948 - lr: 5.1200e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0367 - acc: 0.9875\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 55: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.0367 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0235 - acc: 0.9937\n",
      "Epoch 56: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 38s 610ms/step - loss: 0.0235 - acc: 0.9937 - lr: 4.0960e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0195 - acc: 0.9969\n",
      "Epoch 57: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 38s 616ms/step - loss: 0.0195 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9917\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 58: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 35s 573ms/step - loss: 0.0204 - acc: 0.9917 - lr: 4.0960e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9937\n",
      "Epoch 59: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 588ms/step - loss: 0.0143 - acc: 0.9937 - lr: 3.2768e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9979\n",
      "Epoch 60: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 38s 606ms/step - loss: 0.0102 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0192 - acc: 0.9948\n",
      "Epoch 61: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 596ms/step - loss: 0.0192 - acc: 0.9948 - lr: 3.2768e-05\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0233 - acc: 0.9937\n",
      "Epoch 62: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0233 - acc: 0.9937 - lr: 3.2768e-05\n",
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9979\n",
      "Epoch 63: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.0090 - acc: 0.9979 - lr: 3.2768e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0118 - acc: 0.9958\n",
      "Epoch 64: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 36s 588ms/step - loss: 0.0118 - acc: 0.9958 - lr: 3.2768e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 65: acc improved from 0.99792 to 1.00000, saving model to resnet50+Global_attention_block.hdf5\n",
      "60/60 [==============================] - 40s 647ms/step - loss: 0.0055 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9979\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 35s 576ms/step - loss: 0.0090 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.0053 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 611ms/step - loss: 0.0040 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 600ms/step - loss: 0.0034 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9990\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 622ms/step - loss: 0.0054 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 71: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 576ms/step - loss: 0.0037 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 601ms/step - loss: 0.0060 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9979\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 605ms/step - loss: 0.0075 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.9979\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.0111 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 618ms/step - loss: 0.0040 - acc: 0.9990 - lr: 2.6214e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 597ms/step - loss: 0.0141 - acc: 0.9958 - lr: 2.0972e-05\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 592ms/step - loss: 0.0032 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 598ms/step - loss: 0.0026 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 589ms/step - loss: 0.0043 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.9990\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 577ms/step - loss: 0.0044 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 580ms/step - loss: 0.0038 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 586ms/step - loss: 0.0015 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.0041 - acc: 0.9990 - lr: 1.6777e-05\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 577ms/step - loss: 0.0023 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 599ms/step - loss: 0.0026 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 586ms/step - loss: 0.0014 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 37s 594ms/step - loss: 0.0018 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 577ms/step - loss: 0.0022 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 36s 593ms/step - loss: 0.0022 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 38s 614ms/step - loss: 0.0021 - acc: 1.0000 - lr: 1.0737e-05\n",
      "15/15 [==============================] - 5s 259ms/step - loss: 0.3949 - acc: 0.9000\n",
      "Test loss: 0.3949398696422577\n",
      "Test accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50','gab')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.99778807e-01 2.21150520e-04]\n",
      " [9.99999166e-01 8.13577401e-07]\n",
      " [9.99974251e-01 2.57183710e-05]\n",
      " [1.00000000e+00 2.24369091e-12]\n",
      " [1.00000000e+00 4.94054753e-09]\n",
      " [1.00000000e+00 1.20295596e-08]\n",
      " [1.00000000e+00 1.05090523e-08]\n",
      " [9.98407781e-01 1.59229524e-03]\n",
      " [9.99999881e-01 1.32527148e-07]\n",
      " [9.99999762e-01 1.86961302e-07]\n",
      " [1.00000000e+00 5.13946108e-10]\n",
      " [1.00000000e+00 2.26996910e-09]\n",
      " [9.99724805e-01 2.75136903e-04]\n",
      " [1.00000000e+00 1.36484454e-12]\n",
      " [1.00000000e+00 7.88047318e-12]\n",
      " [9.99183238e-01 8.16759537e-04]\n",
      " [6.59675919e-04 9.99340355e-01]\n",
      " [1.00000000e+00 3.23081770e-11]\n",
      " [1.00000000e+00 1.59861675e-12]\n",
      " [1.00000000e+00 1.59548828e-12]\n",
      " [1.00000000e+00 5.58857171e-12]\n",
      " [1.00000000e+00 1.83567028e-09]\n",
      " [1.00000000e+00 5.15983957e-11]\n",
      " [1.00000000e+00 4.21265440e-08]\n",
      " [9.98555124e-01 1.44487899e-03]\n",
      " [9.87456620e-01 1.25433495e-02]\n",
      " [9.99993443e-01 6.61279000e-06]\n",
      " [9.29279745e-01 7.07202777e-02]\n",
      " [1.00000000e+00 7.93903610e-09]\n",
      " [1.00000000e+00 3.79860019e-08]\n",
      " [9.99994755e-01 5.23650988e-06]\n",
      " [1.00000000e+00 1.27400165e-11]\n",
      " [9.99997973e-01 2.04534285e-06]\n",
      " [9.99997616e-01 2.41046610e-06]\n",
      " [1.00000000e+00 1.44817380e-09]\n",
      " [1.00000000e+00 3.27890562e-11]\n",
      " [1.00000000e+00 8.18021206e-09]\n",
      " [9.99999881e-01 1.17330273e-07]\n",
      " [9.99999642e-01 3.21465734e-07]\n",
      " [1.00000000e+00 5.96726357e-09]\n",
      " [1.00000000e+00 1.83606667e-12]\n",
      " [1.00000000e+00 1.41882142e-08]\n",
      " [9.98281121e-01 1.71888852e-03]\n",
      " [9.99999881e-01 1.24833122e-07]\n",
      " [1.00000000e+00 3.22089067e-09]\n",
      " [1.00000000e+00 6.54540866e-10]\n",
      " [9.99999285e-01 6.81427196e-07]\n",
      " [9.93498921e-01 6.50104368e-03]\n",
      " [1.00000000e+00 4.74027084e-09]\n",
      " [9.18777227e-01 8.12227950e-02]\n",
      " [1.53231539e-07 9.99999881e-01]\n",
      " [9.99999881e-01 1.43236036e-07]\n",
      " [9.99999762e-01 2.44601864e-07]\n",
      " [1.00000000e+00 3.57668256e-10]\n",
      " [1.00000000e+00 1.84335498e-08]\n",
      " [1.00000000e+00 6.32450581e-13]\n",
      " [1.72330777e-03 9.98276711e-01]\n",
      " [9.59245861e-01 4.07541618e-02]\n",
      " [9.98338103e-01 1.66188588e-03]\n",
      " [1.00000000e+00 5.49603492e-08]\n",
      " [9.98883188e-01 1.11678580e-03]\n",
      " [9.99853492e-01 1.46508668e-04]\n",
      " [9.99990702e-01 9.25812947e-06]\n",
      " [1.00000000e+00 5.35145190e-08]\n",
      " [9.99995470e-01 4.51475944e-06]\n",
      " [1.00000000e+00 8.67309696e-13]\n",
      " [9.99969959e-01 3.00390311e-05]\n",
      " [9.99999046e-01 9.18399166e-07]\n",
      " [1.00000000e+00 5.67511749e-12]\n",
      " [9.99935269e-01 6.46807239e-05]\n",
      " [1.00000000e+00 5.07599651e-08]\n",
      " [9.99997616e-01 2.37983318e-06]\n",
      " [1.00000000e+00 1.65883748e-11]\n",
      " [9.99917269e-01 8.27826734e-05]\n",
      " [1.00000000e+00 2.86436819e-10]\n",
      " [1.00000000e+00 3.66179833e-08]\n",
      " [1.00000000e+00 4.13130596e-09]\n",
      " [1.00000000e+00 1.49290025e-11]\n",
      " [1.00000000e+00 6.55584744e-12]\n",
      " [1.00000000e+00 2.62992510e-11]\n",
      " [1.00000000e+00 3.72849217e-11]\n",
      " [9.99988675e-01 1.13111810e-05]\n",
      " [9.99974608e-01 2.53831186e-05]\n",
      " [1.00000000e+00 1.44626561e-10]\n",
      " [1.00000000e+00 1.89567979e-12]\n",
      " [9.92445171e-01 7.55485613e-03]\n",
      " [9.99999642e-01 3.56682222e-07]\n",
      " [1.00000000e+00 4.10543710e-10]\n",
      " [1.00000000e+00 2.69986008e-12]\n",
      " [7.09551394e-01 2.90448636e-01]\n",
      " [1.32291699e-02 9.86770868e-01]\n",
      " [1.00000000e+00 1.63673852e-09]\n",
      " [1.00000000e+00 1.33789105e-10]\n",
      " [9.99992609e-01 7.42300790e-06]\n",
      " [1.00000000e+00 8.26969515e-09]\n",
      " [9.99991298e-01 8.72621786e-06]\n",
      " [9.99999881e-01 1.26728835e-07]\n",
      " [1.00000000e+00 4.60593542e-11]\n",
      " [1.00000000e+00 3.74929110e-09]\n",
      " [9.99999881e-01 8.51403215e-08]\n",
      " [1.00000000e+00 3.62300279e-09]\n",
      " [1.00000000e+00 6.79336307e-13]\n",
      " [1.00000000e+00 1.44123463e-10]\n",
      " [1.00000000e+00 3.33076611e-13]\n",
      " [9.59778190e-01 4.02218401e-02]\n",
      " [9.99998689e-01 1.29915043e-06]\n",
      " [9.98929441e-01 1.07057020e-03]\n",
      " [1.33655006e-02 9.86634493e-01]\n",
      " [9.90155101e-01 9.84482933e-03]\n",
      " [9.99719679e-01 2.80255859e-04]\n",
      " [1.00000000e+00 5.76219020e-12]\n",
      " [4.36970964e-03 9.95630264e-01]\n",
      " [9.99999523e-01 4.84488965e-07]\n",
      " [1.00000000e+00 6.96580380e-12]\n",
      " [1.00000000e+00 1.94429806e-09]\n",
      " [1.00000000e+00 1.62527272e-08]\n",
      " [1.00000000e+00 4.84361379e-12]\n",
      " [1.00000000e+00 4.45564696e-09]\n",
      " [1.00000000e+00 3.03490921e-08]\n",
      " [1.00000000e+00 4.39369235e-10]\n",
      " [9.99956012e-01 4.40443873e-05]\n",
      " [9.99964356e-01 3.56097953e-05]\n",
      " [1.00000000e+00 1.48648951e-08]\n",
      " [1.00000000e+00 1.85441307e-09]\n",
      " [2.66452283e-01 7.33547688e-01]\n",
      " [1.00000000e+00 6.29215473e-12]\n",
      " [8.34547937e-01 1.65452078e-01]\n",
      " [1.00000000e+00 2.24099891e-10]\n",
      " [9.99983311e-01 1.66388782e-05]\n",
      " [1.00000000e+00 6.68294131e-09]\n",
      " [9.99999881e-01 1.03235777e-07]\n",
      " [9.99999881e-01 1.65751857e-07]\n",
      " [9.99999881e-01 6.50720011e-08]\n",
      " [1.00000000e+00 4.38035652e-09]\n",
      " [1.00000000e+00 1.46137602e-09]\n",
      " [1.00000000e+00 1.61246439e-12]\n",
      " [9.99652267e-01 3.47685855e-04]\n",
      " [9.99999523e-01 4.67798031e-07]\n",
      " [1.00000000e+00 1.99428256e-12]\n",
      " [9.99987006e-01 1.29580249e-05]\n",
      " [8.26067030e-01 1.73932940e-01]\n",
      " [1.00000000e+00 1.85219187e-14]\n",
      " [2.00502992e-01 7.99497008e-01]\n",
      " [3.31613476e-21 1.00000000e+00]\n",
      " [9.99373496e-01 6.26586727e-04]\n",
      " [1.02390407e-33 1.00000000e+00]\n",
      " [2.04485991e-13 1.00000000e+00]\n",
      " [1.01518165e-12 1.00000000e+00]\n",
      " [3.33468765e-17 1.00000000e+00]\n",
      " [2.46707668e-08 1.00000000e+00]\n",
      " [4.09054384e-19 1.00000000e+00]\n",
      " [4.80314102e-17 1.00000000e+00]\n",
      " [8.80294026e-25 1.00000000e+00]\n",
      " [2.86126579e-03 9.97138739e-01]\n",
      " [1.24876271e-06 9.99998808e-01]\n",
      " [9.99742568e-01 2.57436855e-04]\n",
      " [1.90967534e-25 1.00000000e+00]\n",
      " [4.43562232e-02 9.55643833e-01]\n",
      " [1.00000000e+00 9.40265643e-10]\n",
      " [1.73923436e-05 9.99982595e-01]\n",
      " [9.99997497e-01 2.52369045e-06]\n",
      " [2.20365326e-09 1.00000000e+00]\n",
      " [1.55133312e-05 9.99984503e-01]\n",
      " [2.41707758e-18 1.00000000e+00]\n",
      " [1.38923029e-09 1.00000000e+00]\n",
      " [6.73810119e-18 1.00000000e+00]\n",
      " [4.47062682e-03 9.95529354e-01]\n",
      " [9.99990463e-01 9.51589755e-06]\n",
      " [4.36253274e-08 1.00000000e+00]\n",
      " [6.12179058e-24 1.00000000e+00]\n",
      " [5.21402033e-09 1.00000000e+00]\n",
      " [4.22685447e-18 1.00000000e+00]\n",
      " [9.32753615e-23 1.00000000e+00]\n",
      " [2.25348140e-09 1.00000000e+00]\n",
      " [9.99606192e-01 3.93851456e-04]\n",
      " [3.30203067e-04 9.99669790e-01]\n",
      " [3.14456286e-24 1.00000000e+00]\n",
      " [9.60954368e-01 3.90456058e-02]\n",
      " [9.99707162e-01 2.92850018e-04]\n",
      " [2.92247608e-02 9.70775306e-01]\n",
      " [4.90533874e-23 1.00000000e+00]\n",
      " [1.57745344e-35 1.00000000e+00]\n",
      " [3.07968584e-09 1.00000000e+00]\n",
      " [7.99516543e-25 1.00000000e+00]\n",
      " [1.16128217e-15 1.00000000e+00]\n",
      " [5.72238564e-28 1.00000000e+00]\n",
      " [6.47298366e-05 9.99935269e-01]\n",
      " [3.92167124e-07 9.99999642e-01]\n",
      " [1.09003037e-01 8.90996933e-01]\n",
      " [1.94131629e-34 1.00000000e+00]\n",
      " [6.11087705e-22 1.00000000e+00]\n",
      " [1.36561671e-25 1.00000000e+00]\n",
      " [5.00228216e-14 1.00000000e+00]\n",
      " [1.24118999e-18 1.00000000e+00]\n",
      " [4.66557076e-16 1.00000000e+00]\n",
      " [1.91743220e-05 9.99980807e-01]\n",
      " [7.20860142e-19 1.00000000e+00]\n",
      " [2.53315950e-13 1.00000000e+00]\n",
      " [1.29255225e-22 1.00000000e+00]\n",
      " [9.99204338e-01 7.95706816e-04]\n",
      " [9.41710591e-01 5.82894087e-02]\n",
      " [1.08950235e-05 9.99989152e-01]\n",
      " [1.01523288e-01 8.98476720e-01]\n",
      " [1.58598476e-13 1.00000000e+00]\n",
      " [1.86400372e-22 1.00000000e+00]\n",
      " [1.16211821e-25 1.00000000e+00]\n",
      " [9.92597699e-01 7.40227848e-03]\n",
      " [9.99501348e-01 4.98640642e-04]\n",
      " [1.15984652e-17 1.00000000e+00]\n",
      " [1.68258157e-05 9.99983191e-01]\n",
      " [2.53758657e-07 9.99999762e-01]\n",
      " [1.25962577e-03 9.98740375e-01]\n",
      " [9.67947376e-31 1.00000000e+00]\n",
      " [2.00125942e-27 1.00000000e+00]\n",
      " [9.98911977e-01 1.08800852e-03]\n",
      " [1.33243964e-06 9.99998689e-01]\n",
      " [9.99999881e-01 8.03654530e-08]\n",
      " [8.79403643e-08 9.99999881e-01]\n",
      " [8.20990622e-01 1.79009348e-01]\n",
      " [9.26449537e-01 7.35504404e-02]\n",
      " [1.58465072e-25 1.00000000e+00]\n",
      " [1.50849644e-08 1.00000000e+00]\n",
      " [1.00672960e-05 9.99989986e-01]\n",
      " [1.10730737e-10 1.00000000e+00]\n",
      " [5.51081116e-28 1.00000000e+00]\n",
      " [5.34294053e-10 1.00000000e+00]\n",
      " [2.14205222e-08 1.00000000e+00]\n",
      " [7.89539993e-15 1.00000000e+00]\n",
      " [1.16424509e-15 1.00000000e+00]\n",
      " [7.53196855e-06 9.99992490e-01]\n",
      " [5.23057757e-08 1.00000000e+00]\n",
      " [1.74589613e-19 1.00000000e+00]\n",
      " [4.04839411e-13 1.00000000e+00]\n",
      " [1.06548059e-17 1.00000000e+00]\n",
      " [3.11570714e-10 1.00000000e+00]\n",
      " [2.41936669e-01 7.58063316e-01]\n",
      " [1.77525147e-19 1.00000000e+00]\n",
      " [2.04896548e-22 1.00000000e+00]\n",
      " [2.83320992e-19 1.00000000e+00]\n",
      " [5.03809019e-07 9.99999523e-01]]\n",
      "Confusion Matrix\n",
      "[[135   8]\n",
      " [ 16  81]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.89      0.94      0.92       143\n",
      "    referable       0.91      0.84      0.87        97\n",
      "\n",
      "     accuracy                           0.90       240\n",
      "    macro avg       0.90      0.89      0.89       240\n",
      " weighted avg       0.90      0.90      0.90       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+GAB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
