{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "def self_attention(input_feature, num_channel, base = 'self_attention_base'):\n",
    "    bn_1 = BatchNormalization(axis = -1, name = base + '/bn_1')(input_feature)\n",
    "    dense_1 = Dense(num_channel, name = base + '/dense_1')(bn_1)\n",
    "    act_1 = Activation('relu', name = base + '/act_1')(dense_1)\n",
    "\n",
    "    bn_2 = BatchNormalization(axis = -1, name = base + '/bn_2')(input_feature)\n",
    "    dense_2 = Dense(num_channel, name = base + '/dense_2')(bn_2)\n",
    "    act_2 = Activation('relu', name = base + '/act_2')(dense_2)\n",
    "\n",
    "    bn_3 = BatchNormalization(axis = -1, name = base + '/bn_3')(input_feature)\n",
    "    dense_3 = Dense(num_channel, name = base + '/dense_3')(bn_3)\n",
    "    act_3 = Activation('relu', name = base + '/act_3')(dense_3)\n",
    "\n",
    "    mul_1 = Multiply(name = base + '/mul_1')([act_2, act_3])\n",
    "    mask_part = Activation('softmax', name = base + '/act_4')(mul_1)\n",
    "    mul_2 = Multiply(name = base + '/mul_2')([act_1, mask_part])\n",
    "\n",
    "    output_feature = Add(name = base + '/add_1')([mul_2, input_feature])\n",
    "\n",
    "    return output_feature\n",
    "\n",
    "def CMFA(input_feature, num_channel, base = 'CMFA_base'):\n",
    "    out_1 = self_attention(input_feature, num_channel, base + '/self_att_1')\n",
    "    out_2 = self_attention(input_feature, num_channel, base + '/self_att_2')\n",
    "    out_3 = self_attention(input_feature, num_channel, base + '/self_att_3')\n",
    "    out_4 = self_attention(input_feature, num_channel, base + '/self_att_4')\n",
    "\n",
    "    output_feature = Add(name = base + '/add')([out_1, out_2, out_3, out_4])\n",
    "\n",
    "    return output_feature\n",
    "\n",
    "def SEM(input_feature, num_channel, base = 'SEM_base'):\n",
    "    GAP_output = GlobalAveragePooling2D(name = base + '/gap_layer')(input_feature)\n",
    "\n",
    "    bn_1 = BatchNormalization(axis = -1, name = base + '/bn_1')(GAP_output)\n",
    "    dense_1 = Dense(int(num_channel/4), name = base + '/dense_1')(bn_1)\n",
    "    act_1 = Activation('relu', name = base + '/act_1')(dense_1)\n",
    "\n",
    "    bn_2 = BatchNormalization(axis = -1, name = base + '/bn_2')(act_1)\n",
    "    dense_2 = Dense(num_channel, name = base + '/dense_2')(bn_2)\n",
    "    act_2 = Activation('sigmoid', name = base + '/act_2')(dense_2)\n",
    "\n",
    "    out_channel = Multiply(name = base + '/mul_1')([act_2, input_feature])\n",
    "\n",
    "    strides = (1,1)\n",
    "\n",
    "    bn_3 = BatchNormalization(axis = -1, name = base + '/bn_3')(input_feature)\n",
    "    cn_3 = Conv2D(num_channel, (3,3), strides = strides, padding = 'same', name = base + '/conv_1')(bn_3)\n",
    "    an_3 = Activation('relu', name = base + '/act_3')(cn_3)\n",
    "\n",
    "    bn_4 = BatchNormalization(axis = -1, name = base + '/bn_4')(an_3)\n",
    "    cn_4 = Conv2D(1, (1,1), strides = strides, padding = 'same', name = base + '/conv_2')(bn_4)\n",
    "    an_4 = Activation('sigmoid', name = base + '/act_4')(cn_4)\n",
    "    out_spatial = Multiply(name = base + '/mul_2')([an_4, input_feature])\n",
    "\n",
    "    output_response = Add(name = base + '/add')([input_feature, out_channel, out_spatial])\n",
    "\n",
    "    return output_response\n",
    "\n",
    "def iDAAM(input_feature):\n",
    "    shape=K.int_shape(input_feature)\n",
    "    num_channel = shape[3]\n",
    "    base = 'iDAAM'\n",
    "    sem_feature = SEM(input_feature, num_channel)\n",
    "    print(sem_feature.shape)\n",
    "    cmfa_feature = CMFA(input_feature, num_channel)\n",
    "    print(cmfa_feature.shape)\n",
    "    attend_feature = tf.keras.layers.Add()([sem_feature,cmfa_feature])\n",
    "    return attend_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+'idaam.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+'idaam.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+iDAAM.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 14:02:58.699746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: GeForce GT 710, pci bus id: 0000:b3:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-05-09 14:02:58.700206: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 14:02:59.374777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30677 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16, 16, 2048)\n",
      "(None, 16, 16, 2048)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " SEM_base/gap_layer (GlobalAver  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " SEM_base/bn_1 (BatchNormalizat  (None, 2048)        8192        ['SEM_base/gap_layer[0][0]']     \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SEM_base/bn_3 (BatchNormalizat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/bn_2 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/bn_3 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/bn_2 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/bn_3 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/bn_2 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/bn_3 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/bn_2 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/bn_3 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " SEM_base/dense_1 (Dense)       (None, 512)          1049088     ['SEM_base/bn_1[0][0]']          \n",
      "                                                                                                  \n",
      " SEM_base/conv_1 (Conv2D)       (None, 16, 16, 2048  37750784    ['SEM_base/bn_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/dense_2 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_1/bn_2[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/dense_3 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_1/bn_3[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/dense_2 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_2/bn_2[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/dense_3 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_2/bn_3[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/dense_2 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_3/bn_2[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/dense_3 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_3/bn_3[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/dense_2 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_4/bn_2[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/dense_3 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_4/bn_3[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " SEM_base/act_1 (Activation)    (None, 512)          0           ['SEM_base/dense_1[0][0]']       \n",
      "                                                                                                  \n",
      " SEM_base/act_3 (Activation)    (None, 16, 16, 2048  0           ['SEM_base/conv_1[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/bn_1 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/act_2 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/dense_2[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/act_3 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/dense_3[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/bn_1 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/act_2 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/dense_2[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/act_3 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/dense_3[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/bn_1 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/act_2 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/dense_2[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/act_3 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/dense_3[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/bn_1 (Bat  (None, 16, 16, 2048  8192       ['conv5_block3_out[0][0]']       \n",
      " chNormalization)               )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/act_2 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/dense_2[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/act_3 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/dense_3[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " SEM_base/bn_2 (BatchNormalizat  (None, 512)         2048        ['SEM_base/act_1[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " SEM_base/bn_4 (BatchNormalizat  (None, 16, 16, 2048  8192       ['SEM_base/act_3[0][0]']         \n",
      " ion)                           )                                                                 \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/dense_1 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_1/bn_1[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/mul_1 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/act_2[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_1/act_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/dense_1 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_2/bn_1[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/mul_1 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/act_2[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_2/act_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/dense_1 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_3/bn_1[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/mul_1 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/act_2[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_3/act_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/dense_1 (  (None, 16, 16, 2048  4196352    ['CMFA_base/self_att_4/bn_1[0][0]\n",
      " Dense)                         )                                ']                               \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/mul_1 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/act_2[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_4/act_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " SEM_base/dense_2 (Dense)       (None, 2048)         1050624     ['SEM_base/bn_2[0][0]']          \n",
      "                                                                                                  \n",
      " SEM_base/conv_2 (Conv2D)       (None, 16, 16, 1)    2049        ['SEM_base/bn_4[0][0]']          \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/act_1 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/dense_1[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/act_4 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/mul_1[0][0\n",
      " tivation)                      )                                ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/act_1 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/dense_1[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/act_4 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/mul_1[0][0\n",
      " tivation)                      )                                ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/act_1 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/dense_1[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/act_4 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/mul_1[0][0\n",
      " tivation)                      )                                ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/act_1 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/dense_1[0]\n",
      " tivation)                      )                                [0]']                            \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/act_4 (Ac  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/mul_1[0][0\n",
      " tivation)                      )                                ]']                              \n",
      "                                                                                                  \n",
      " SEM_base/act_2 (Activation)    (None, 2048)         0           ['SEM_base/dense_2[0][0]']       \n",
      "                                                                                                  \n",
      " SEM_base/act_4 (Activation)    (None, 16, 16, 1)    0           ['SEM_base/conv_2[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " CMFA_base/self_att_1/mul_2 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/act_1[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_1/act_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/mul_2 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/act_1[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_2/act_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/mul_2 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/act_1[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_3/act_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/mul_2 (Mu  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/act_1[0][0\n",
      " ltiply)                        )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_4/act_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " SEM_base/mul_1 (Multiply)      (None, 16, 16, 2048  0           ['SEM_base/act_2[0][0]',         \n",
      "                                )                                 'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " SEM_base/mul_2 (Multiply)      (None, 16, 16, 2048  0           ['SEM_base/act_4[0][0]',         \n",
      "                                )                                 'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_1/add_1 (Ad  (None, 16, 16, 2048  0          ['CMFA_base/self_att_1/mul_2[0][0\n",
      " d)                             )                                ]',                              \n",
      "                                                                  'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_2/add_1 (Ad  (None, 16, 16, 2048  0          ['CMFA_base/self_att_2/mul_2[0][0\n",
      " d)                             )                                ]',                              \n",
      "                                                                  'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_3/add_1 (Ad  (None, 16, 16, 2048  0          ['CMFA_base/self_att_3/mul_2[0][0\n",
      " d)                             )                                ]',                              \n",
      "                                                                  'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " CMFA_base/self_att_4/add_1 (Ad  (None, 16, 16, 2048  0          ['CMFA_base/self_att_4/mul_2[0][0\n",
      " d)                             )                                ]',                              \n",
      "                                                                  'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " SEM_base/add (Add)             (None, 16, 16, 2048  0           ['conv5_block3_out[0][0]',       \n",
      "                                )                                 'SEM_base/mul_1[0][0]',         \n",
      "                                                                  'SEM_base/mul_2[0][0]']         \n",
      "                                                                                                  \n",
      " CMFA_base/add (Add)            (None, 16, 16, 2048  0           ['CMFA_base/self_att_1/add_1[0][0\n",
      "                                )                                ]',                              \n",
      "                                                                  'CMFA_base/self_att_2/add_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'CMFA_base/self_att_3/add_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'CMFA_base/self_att_4/add_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 16, 2048  0           ['SEM_base/add[0][0]',           \n",
      "                                )                                 'CMFA_base/add[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['add[0][0]']                    \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            4098        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 113,925,507\n",
      "Trainable params: 113,809,923\n",
      "Non-trainable params: 115,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "#red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=iDAAM(base_out)\n",
    "\n",
    "\n",
    "shape=K.int_shape(x)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 14:03:34.338208: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 1.9608 - acc: 0.6562\n",
      "Epoch 1: acc improved from -inf to 0.65625, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 45s 589ms/step - loss: 1.9608 - acc: 0.6562 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9662 - acc: 0.6854\n",
      "Epoch 1: acc improved from 0.65625 to 0.68542, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 52s 694ms/step - loss: 0.9662 - acc: 0.6854 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6407 - acc: 0.7854\n",
      "Epoch 2: acc improved from 0.68542 to 0.78542, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 47s 763ms/step - loss: 0.6407 - acc: 0.7854 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4931 - acc: 0.8240\n",
      "Epoch 3: acc improved from 0.78542 to 0.82396, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 56s 929ms/step - loss: 0.4931 - acc: 0.8240 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4415 - acc: 0.8510\n",
      "Epoch 4: acc improved from 0.82396 to 0.85104, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.4415 - acc: 0.8510 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3527 - acc: 0.8667\n",
      "Epoch 5: acc improved from 0.85104 to 0.86667, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.3527 - acc: 0.8667 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2972 - acc: 0.8948\n",
      "Epoch 6: acc improved from 0.86667 to 0.89479, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.2972 - acc: 0.8948 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2503 - acc: 0.9052\n",
      "Epoch 7: acc improved from 0.89479 to 0.90521, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.2503 - acc: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2580 - acc: 0.9031\n",
      "Epoch 8: acc did not improve from 0.90521\n",
      "60/60 [==============================] - 59s 973ms/step - loss: 0.2580 - acc: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2584 - acc: 0.9031\n",
      "Epoch 9: acc did not improve from 0.90521\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.2584 - acc: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2631 - acc: 0.9021\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 10: acc did not improve from 0.90521\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.2631 - acc: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1916 - acc: 0.9271\n",
      "Epoch 11: acc improved from 0.90521 to 0.92708, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 73s 1s/step - loss: 0.1916 - acc: 0.9271 - lr: 8.0000e-05\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1655 - acc: 0.9323\n",
      "Epoch 12: acc improved from 0.92708 to 0.93229, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.1655 - acc: 0.9323 - lr: 8.0000e-05\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1525 - acc: 0.9417\n",
      "Epoch 13: acc improved from 0.93229 to 0.94167, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.1525 - acc: 0.9417 - lr: 8.0000e-05\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1308 - acc: 0.9521\n",
      "Epoch 14: acc improved from 0.94167 to 0.95208, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.1308 - acc: 0.9521 - lr: 8.0000e-05\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1371 - acc: 0.9469\n",
      "Epoch 15: acc did not improve from 0.95208\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.1371 - acc: 0.9469 - lr: 8.0000e-05\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1738 - acc: 0.9302\n",
      "Epoch 16: acc did not improve from 0.95208\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.1738 - acc: 0.9302 - lr: 8.0000e-05\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1919 - acc: 0.9312\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 17: acc did not improve from 0.95208\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.1919 - acc: 0.9312 - lr: 8.0000e-05\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1383 - acc: 0.9490\n",
      "Epoch 18: acc did not improve from 0.95208\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.1383 - acc: 0.9490 - lr: 6.4000e-05\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1013 - acc: 0.9552\n",
      "Epoch 19: acc improved from 0.95208 to 0.95521, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 75s 1s/step - loss: 0.1013 - acc: 0.9552 - lr: 6.4000e-05\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1013 - acc: 0.9646\n",
      "Epoch 20: acc improved from 0.95521 to 0.96458, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 72s 1s/step - loss: 0.1013 - acc: 0.9646 - lr: 6.4000e-05\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1425 - acc: 0.9563\n",
      "Epoch 21: acc did not improve from 0.96458\n",
      "60/60 [==============================] - 61s 1s/step - loss: 0.1425 - acc: 0.9563 - lr: 6.4000e-05\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.9688\n",
      "Epoch 22: acc improved from 0.96458 to 0.96875, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.0950 - acc: 0.9688 - lr: 6.4000e-05\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0789 - acc: 0.9667\n",
      "Epoch 23: acc did not improve from 0.96875\n",
      "60/60 [==============================] - 61s 1s/step - loss: 0.0789 - acc: 0.9667 - lr: 6.4000e-05\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0854 - acc: 0.9677\n",
      "Epoch 24: acc did not improve from 0.96875\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0854 - acc: 0.9677 - lr: 6.4000e-05\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.9708\n",
      "Epoch 25: acc improved from 0.96875 to 0.97083, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 73s 1s/step - loss: 0.0770 - acc: 0.9708 - lr: 6.4000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0803 - acc: 0.9729\n",
      "Epoch 26: acc improved from 0.97083 to 0.97292, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 70s 1s/step - loss: 0.0803 - acc: 0.9729 - lr: 6.4000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0791 - acc: 0.9771\n",
      "Epoch 27: acc improved from 0.97292 to 0.97708, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.0791 - acc: 0.9771 - lr: 6.4000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0843 - acc: 0.9729\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 28: acc did not improve from 0.97708\n",
      "60/60 [==============================] - 61s 1s/step - loss: 0.0843 - acc: 0.9729 - lr: 6.4000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0340 - acc: 0.9906\n",
      "Epoch 29: acc improved from 0.97708 to 0.99063, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.0340 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0400 - acc: 0.9833\n",
      "Epoch 30: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 61s 1s/step - loss: 0.0400 - acc: 0.9833 - lr: 5.1200e-05\n",
      "Epoch 31/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0237 - acc: 0.9906\n",
      "Epoch 31: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0237 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.9885\n",
      "Epoch 32: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0374 - acc: 0.9885 - lr: 5.1200e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9875\n",
      "Epoch 33: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0458 - acc: 0.9875 - lr: 5.1200e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0331 - acc: 0.9906\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 34: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0331 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0315 - acc: 0.9865\n",
      "Epoch 35: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0315 - acc: 0.9865 - lr: 4.0960e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.9896\n",
      "Epoch 36: acc did not improve from 0.99063\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0304 - acc: 0.9896 - lr: 4.0960e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0204 - acc: 0.9958\n",
      "Epoch 37: acc improved from 0.99063 to 0.99583, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 75s 1s/step - loss: 0.0204 - acc: 0.9958 - lr: 4.0960e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9948\n",
      "Epoch 38: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.0161 - acc: 0.9948 - lr: 4.0960e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0235 - acc: 0.9906\n",
      "Epoch 39: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0235 - acc: 0.9906 - lr: 4.0960e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0201 - acc: 0.9927\n",
      "Epoch 40: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.0201 - acc: 0.9927 - lr: 4.0960e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0225 - acc: 0.9927\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 41: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0225 - acc: 0.9927 - lr: 4.0960e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9948\n",
      "Epoch 42: acc did not improve from 0.99583\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0164 - acc: 0.9948 - lr: 3.2768e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.9969\n",
      "Epoch 43: acc improved from 0.99583 to 0.99687, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.0100 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9958\n",
      "Epoch 44: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.0107 - acc: 0.9958 - lr: 3.2768e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0301 - acc: 0.9937\n",
      "Epoch 45: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0301 - acc: 0.9937 - lr: 3.2768e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.9927\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 46: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0297 - acc: 0.9927 - lr: 3.2768e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0332 - acc: 0.9885\n",
      "Epoch 47: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 68s 1s/step - loss: 0.0332 - acc: 0.9885 - lr: 2.6214e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0135 - acc: 0.9969\n",
      "Epoch 48: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0135 - acc: 0.9969 - lr: 2.6214e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0134 - acc: 0.9969\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 49: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 67s 1s/step - loss: 0.0134 - acc: 0.9969 - lr: 2.6214e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 50: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.0106 - acc: 0.9969 - lr: 2.0972e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0072 - acc: 0.9990\n",
      "Epoch 51: acc improved from 0.99687 to 0.99896, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 74s 1s/step - loss: 0.0072 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9990\n",
      "Epoch 52: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 58s 958ms/step - loss: 0.0055 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 53: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0075 - acc: 0.9969 - lr: 2.0972e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9958\n",
      "Epoch 54: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0074 - acc: 0.9958 - lr: 2.0972e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 55: acc improved from 0.99896 to 1.00000, saving model to resnet50+iDAAM.hdf5\n",
      "60/60 [==============================] - 73s 1s/step - loss: 0.0062 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 56: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 60s 993ms/step - loss: 0.0026 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9948\n",
      "Epoch 57: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0157 - acc: 0.9948 - lr: 1.6777e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9990\n",
      "Epoch 58: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0076 - acc: 0.9990 - lr: 1.6777e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 59: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0069 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9990\n",
      "Epoch 60: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.0083 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 61: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0023 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0090 - acc: 0.9969\n",
      "Epoch 62: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.0090 - acc: 0.9969 - lr: 1.3422e-05\n",
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9990\n",
      "Epoch 63: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0053 - acc: 0.9990 - lr: 1.3422e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 64: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.0061 - acc: 0.9979 - lr: 1.3422e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9990\n",
      "Epoch 65: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0087 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0018 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0017 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0065 - acc: 0.9979 - lr: 1.0737e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0023 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0061 - acc: 0.9979 - lr: 1.0737e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 71: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.0036 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0052 - acc: 0.9979\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0052 - acc: 0.9979 - lr: 8.5899e-06\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0013 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0024 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0029 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 0.9990\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0026 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0030 - acc: 0.9990\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0030 - acc: 0.9990 - lr: 6.8719e-06\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.9979\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0043 - acc: 0.9979 - lr: 6.8719e-06\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9990\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n",
      "\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 65s 1s/step - loss: 0.0054 - acc: 0.9990 - lr: 6.8719e-06\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9990\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0084 - acc: 0.9990 - lr: 5.4976e-06\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.0014 - acc: 1.0000 - lr: 5.4976e-06\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n",
      "\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.0017 - acc: 1.0000 - lr: 5.4976e-06\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0017 - acc: 1.0000 - lr: 4.3980e-06\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 0.9990\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0026 - acc: 0.9990 - lr: 4.3980e-06\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0022 - acc: 0.9990\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.518437006277964e-06.\n",
      "\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0022 - acc: 0.9990 - lr: 4.3980e-06\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0014 - acc: 0.9990\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0014 - acc: 0.9990 - lr: 3.5184e-06\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 63s 1s/step - loss: 0.0017 - acc: 1.0000 - lr: 3.5184e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.814749677781947e-06.\n",
      "\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0012 - acc: 1.0000 - lr: 3.5184e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0015 - acc: 1.0000 - lr: 2.8147e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 64s 1s/step - loss: 0.0016 - acc: 1.0000 - lr: 2.8147e-06\n",
      "15/15 [==============================] - 6s 313ms/step - loss: 0.3290 - acc: 0.9292\n",
      "Test loss: 0.328961044549942\n",
      "Test accuracy: 0.9291666746139526\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.98714447e-01 1.28552213e-03]\n",
      " [9.99999762e-01 1.81940720e-07]\n",
      " [1.00000000e+00 8.31278868e-09]\n",
      " [1.00000000e+00 5.58936057e-12]\n",
      " [1.00000000e+00 7.16441462e-10]\n",
      " [1.00000000e+00 1.09799001e-11]\n",
      " [1.00000000e+00 3.08153154e-16]\n",
      " [7.18617055e-04 9.99281347e-01]\n",
      " [1.00000000e+00 3.42095987e-08]\n",
      " [9.99989390e-01 1.06518828e-05]\n",
      " [1.00000000e+00 2.70729041e-16]\n",
      " [1.00000000e+00 1.14250666e-11]\n",
      " [9.99999881e-01 1.66689659e-07]\n",
      " [1.00000000e+00 3.31637604e-13]\n",
      " [1.00000000e+00 1.46331856e-15]\n",
      " [9.97672737e-01 2.32726661e-03]\n",
      " [9.99245524e-01 7.54479726e-04]\n",
      " [1.00000000e+00 8.24900287e-11]\n",
      " [9.99846458e-01 1.53517292e-04]\n",
      " [1.00000000e+00 4.26835572e-16]\n",
      " [1.00000000e+00 4.02234973e-12]\n",
      " [1.00000000e+00 1.28057938e-11]\n",
      " [1.00000000e+00 2.36287310e-08]\n",
      " [1.00000000e+00 7.31656541e-11]\n",
      " [7.16572344e-01 2.83427656e-01]\n",
      " [9.81600285e-01 1.83996521e-02]\n",
      " [9.99995351e-01 4.63971355e-06]\n",
      " [2.68477452e-05 9.99973178e-01]\n",
      " [1.00000000e+00 7.91862617e-11]\n",
      " [1.00000000e+00 3.40209735e-11]\n",
      " [9.99892712e-01 1.07326639e-04]\n",
      " [1.00000000e+00 2.08675078e-13]\n",
      " [9.98272657e-01 1.72739127e-03]\n",
      " [1.00000000e+00 6.55249035e-14]\n",
      " [1.00000000e+00 1.29515687e-09]\n",
      " [1.00000000e+00 1.69352599e-09]\n",
      " [1.00000000e+00 5.86554305e-10]\n",
      " [1.00000000e+00 1.17154011e-08]\n",
      " [9.99999881e-01 1.69011670e-07]\n",
      " [9.99999404e-01 5.48631476e-07]\n",
      " [1.00000000e+00 1.92544522e-11]\n",
      " [9.99999881e-01 8.42839754e-08]\n",
      " [9.98594463e-01 1.40549801e-03]\n",
      " [1.00000000e+00 2.76903966e-09]\n",
      " [1.00000000e+00 5.89578164e-14]\n",
      " [1.00000000e+00 1.05716091e-09]\n",
      " [9.99999881e-01 6.54159535e-08]\n",
      " [7.64788389e-01 2.35211611e-01]\n",
      " [9.99996901e-01 3.08632298e-06]\n",
      " [9.48318779e-01 5.16812354e-02]\n",
      " [5.16540408e-01 4.83459592e-01]\n",
      " [1.00000000e+00 1.99557548e-09]\n",
      " [1.00000000e+00 2.10857598e-09]\n",
      " [1.00000000e+00 2.48049787e-14]\n",
      " [1.00000000e+00 1.31792344e-09]\n",
      " [1.00000000e+00 1.91844609e-12]\n",
      " [1.43936621e-02 9.85606372e-01]\n",
      " [9.99846578e-01 1.53373621e-04]\n",
      " [9.99920964e-01 7.90722697e-05]\n",
      " [9.99996305e-01 3.66959466e-06]\n",
      " [9.98943150e-01 1.05685298e-03]\n",
      " [9.99998331e-01 1.62593813e-06]\n",
      " [9.54201400e-01 4.57985438e-02]\n",
      " [9.99998331e-01 1.61593971e-06]\n",
      " [1.00000000e+00 4.94493113e-09]\n",
      " [1.00000000e+00 1.76994785e-14]\n",
      " [9.99878168e-01 1.21872072e-04]\n",
      " [9.99999642e-01 3.02165688e-07]\n",
      " [1.00000000e+00 4.71647287e-12]\n",
      " [1.00000000e+00 6.78127243e-09]\n",
      " [9.99998569e-01 1.42810632e-06]\n",
      " [9.99999881e-01 6.60974848e-08]\n",
      " [1.00000000e+00 8.48673798e-10]\n",
      " [9.97397065e-01 2.60289293e-03]\n",
      " [9.99997735e-01 2.24035716e-06]\n",
      " [1.00000000e+00 1.82673663e-08]\n",
      " [1.00000000e+00 1.31674260e-09]\n",
      " [1.00000000e+00 7.58228065e-15]\n",
      " [1.00000000e+00 4.21488582e-13]\n",
      " [1.00000000e+00 5.87580456e-16]\n",
      " [1.00000000e+00 1.60223071e-16]\n",
      " [1.00000000e+00 3.82380759e-13]\n",
      " [9.99925613e-01 7.44329809e-05]\n",
      " [1.00000000e+00 1.06963940e-08]\n",
      " [1.00000000e+00 1.05671719e-17]\n",
      " [6.53136253e-01 3.46863687e-01]\n",
      " [9.98429120e-01 1.57082651e-03]\n",
      " [1.00000000e+00 1.21183366e-08]\n",
      " [1.00000000e+00 4.02538115e-16]\n",
      " [9.96631205e-01 3.36880051e-03]\n",
      " [9.93141949e-01 6.85810158e-03]\n",
      " [1.00000000e+00 8.89864831e-12]\n",
      " [1.00000000e+00 6.38394629e-15]\n",
      " [1.00000000e+00 3.18407203e-08]\n",
      " [9.99999404e-01 5.80138305e-07]\n",
      " [9.83473599e-01 1.65263321e-02]\n",
      " [1.00000000e+00 1.95615552e-10]\n",
      " [1.00000000e+00 1.54764410e-10]\n",
      " [1.00000000e+00 1.37746330e-08]\n",
      " [1.00000000e+00 1.96658551e-10]\n",
      " [9.99986768e-01 1.31974257e-05]\n",
      " [1.00000000e+00 1.05830072e-13]\n",
      " [1.00000000e+00 2.53222243e-09]\n",
      " [1.00000000e+00 6.04931957e-15]\n",
      " [9.07591641e-01 9.24083516e-02]\n",
      " [7.44548678e-01 2.55451292e-01]\n",
      " [5.64404726e-01 4.35595274e-01]\n",
      " [9.96445119e-01 3.55491717e-03]\n",
      " [9.99998569e-01 1.40806151e-06]\n",
      " [3.71454209e-01 6.28545761e-01]\n",
      " [1.00000000e+00 1.38253515e-12]\n",
      " [4.10856082e-05 9.99958873e-01]\n",
      " [1.00000000e+00 5.35122773e-08]\n",
      " [1.00000000e+00 4.55662380e-16]\n",
      " [1.00000000e+00 4.11265937e-08]\n",
      " [9.99995112e-01 4.86615318e-06]\n",
      " [1.00000000e+00 1.79358525e-16]\n",
      " [1.00000000e+00 5.21455434e-10]\n",
      " [9.99998569e-01 1.39153224e-06]\n",
      " [9.99996066e-01 3.95465668e-06]\n",
      " [8.98886085e-01 1.01113923e-01]\n",
      " [1.00000000e+00 2.32250734e-08]\n",
      " [1.00000000e+00 1.48785930e-16]\n",
      " [1.00000000e+00 4.43570736e-11]\n",
      " [3.09447827e-08 1.00000000e+00]\n",
      " [1.00000000e+00 4.64423422e-13]\n",
      " [9.89169002e-01 1.08310506e-02]\n",
      " [1.00000000e+00 5.69810189e-19]\n",
      " [1.00000000e+00 1.02007647e-09]\n",
      " [1.00000000e+00 9.88600044e-13]\n",
      " [1.00000000e+00 1.88846236e-08]\n",
      " [1.00000000e+00 2.63918568e-15]\n",
      " [1.00000000e+00 1.49900630e-11]\n",
      " [1.00000000e+00 3.97178210e-12]\n",
      " [9.99997735e-01 2.26606971e-06]\n",
      " [1.00000000e+00 6.77218481e-13]\n",
      " [4.09452990e-03 9.95905399e-01]\n",
      " [9.99999404e-01 5.73350007e-07]\n",
      " [1.00000000e+00 3.29912226e-12]\n",
      " [1.00000000e+00 3.31744875e-11]\n",
      " [6.58092082e-01 3.41907859e-01]\n",
      " [1.00000000e+00 6.10802870e-16]\n",
      " [9.99997616e-01 2.33469586e-06]\n",
      " [5.41374792e-23 1.00000000e+00]\n",
      " [9.99989510e-01 1.04737383e-05]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.41144285e-25 1.00000000e+00]\n",
      " [1.27199771e-16 1.00000000e+00]\n",
      " [1.10705282e-12 1.00000000e+00]\n",
      " [3.74019078e-17 1.00000000e+00]\n",
      " [1.71963133e-16 1.00000000e+00]\n",
      " [3.84913415e-35 1.00000000e+00]\n",
      " [7.25977600e-07 9.99999285e-01]\n",
      " [6.28629102e-15 1.00000000e+00]\n",
      " [9.99999762e-01 2.54484945e-07]\n",
      " [3.25689150e-33 1.00000000e+00]\n",
      " [3.27805287e-06 9.99996781e-01]\n",
      " [1.00000000e+00 1.86104430e-11]\n",
      " [3.71952367e-04 9.99628067e-01]\n",
      " [9.97600019e-01 2.39996635e-03]\n",
      " [1.13063112e-15 1.00000000e+00]\n",
      " [1.25699655e-08 1.00000000e+00]\n",
      " [6.28811251e-23 1.00000000e+00]\n",
      " [1.46812634e-16 1.00000000e+00]\n",
      " [5.29059054e-11 1.00000000e+00]\n",
      " [3.69851927e-10 1.00000000e+00]\n",
      " [5.21066226e-02 9.47893381e-01]\n",
      " [5.75723647e-08 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [4.58857591e-10 1.00000000e+00]\n",
      " [4.81464807e-30 1.00000000e+00]\n",
      " [2.40781397e-15 1.00000000e+00]\n",
      " [1.48103942e-11 1.00000000e+00]\n",
      " [9.99834538e-01 1.65465550e-04]\n",
      " [1.12482511e-01 8.87517512e-01]\n",
      " [4.77997788e-34 1.00000000e+00]\n",
      " [1.31571378e-05 9.99986887e-01]\n",
      " [9.14906681e-01 8.50933716e-02]\n",
      " [7.57828653e-01 2.42171347e-01]\n",
      " [6.33112288e-16 1.00000000e+00]\n",
      " [4.84891121e-23 1.00000000e+00]\n",
      " [6.81451340e-10 1.00000000e+00]\n",
      " [7.61641691e-26 1.00000000e+00]\n",
      " [3.26048710e-16 1.00000000e+00]\n",
      " [3.75425345e-26 1.00000000e+00]\n",
      " [1.22389334e-24 1.00000000e+00]\n",
      " [5.60521797e-22 1.00000000e+00]\n",
      " [3.37239020e-02 9.66276109e-01]\n",
      " [6.84656941e-38 1.00000000e+00]\n",
      " [1.49667393e-35 1.00000000e+00]\n",
      " [2.00524026e-35 1.00000000e+00]\n",
      " [5.11212262e-30 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [5.43714605e-19 1.00000000e+00]\n",
      " [2.31862143e-02 9.76813793e-01]\n",
      " [1.86321499e-14 1.00000000e+00]\n",
      " [2.54885141e-10 1.00000000e+00]\n",
      " [1.48535041e-34 1.00000000e+00]\n",
      " [3.46395718e-05 9.99965310e-01]\n",
      " [5.52455366e-01 4.47544694e-01]\n",
      " [4.70421424e-10 1.00000000e+00]\n",
      " [8.75521437e-07 9.99999166e-01]\n",
      " [2.91623260e-24 1.00000000e+00]\n",
      " [5.43942562e-35 1.00000000e+00]\n",
      " [1.12074630e-22 1.00000000e+00]\n",
      " [2.47126250e-20 1.00000000e+00]\n",
      " [3.00480030e-03 9.96995211e-01]\n",
      " [1.32133963e-12 1.00000000e+00]\n",
      " [1.11366689e-05 9.99988914e-01]\n",
      " [1.50177002e-05 9.99984980e-01]\n",
      " [2.05250217e-06 9.99997973e-01]\n",
      " [6.46213142e-30 1.00000000e+00]\n",
      " [4.99495909e-37 1.00000000e+00]\n",
      " [3.39626538e-04 9.99660373e-01]\n",
      " [1.10314945e-02 9.88968492e-01]\n",
      " [9.99362648e-01 6.37319346e-04]\n",
      " [5.13171865e-38 1.00000000e+00]\n",
      " [4.28767862e-07 9.99999523e-01]\n",
      " [9.98402894e-01 1.59710390e-03]\n",
      " [3.92280144e-30 1.00000000e+00]\n",
      " [1.74933661e-11 1.00000000e+00]\n",
      " [5.06738570e-06 9.99994874e-01]\n",
      " [7.47478168e-09 1.00000000e+00]\n",
      " [1.02795646e-37 1.00000000e+00]\n",
      " [9.98268347e-26 1.00000000e+00]\n",
      " [2.14410579e-06 9.99997854e-01]\n",
      " [3.69407025e-29 1.00000000e+00]\n",
      " [3.39882200e-26 1.00000000e+00]\n",
      " [8.05200852e-06 9.99991894e-01]\n",
      " [1.69129937e-08 1.00000000e+00]\n",
      " [3.87750872e-25 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [5.47395449e-14 1.00000000e+00]\n",
      " [2.45382837e-12 1.00000000e+00]\n",
      " [3.80242071e-34 1.00000000e+00]\n",
      " [2.43573467e-28 1.00000000e+00]\n",
      " [4.58518028e-33 1.00000000e+00]\n",
      " [9.25382461e-22 1.00000000e+00]\n",
      " [3.50432856e-06 9.99996543e-01]]\n",
      "Confusion Matrix\n",
      "[[136   7]\n",
      " [ 10  87]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.93      0.95      0.94       143\n",
      "    referable       0.93      0.90      0.91        97\n",
      "\n",
      "     accuracy                           0.93       240\n",
      "    macro avg       0.93      0.92      0.93       240\n",
      " weighted avg       0.93      0.93      0.93       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+iDAAM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
