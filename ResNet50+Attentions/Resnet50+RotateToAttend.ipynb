{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08feba7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08feba7a",
    "outputId": "d1f9ec9f-b31f-4241-bb7c-76e43301fe95",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_applications in /home/deepak1010/anaconda3/lib/python3.9/site-packages (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (1.20.3)\n",
      "Requirement already satisfied: h5py in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from keras_applications) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d22802",
   "metadata": {
    "id": "f4d22802"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "#from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import os\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sFWh0aLxf5ZH",
   "metadata": {
    "id": "sFWh0aLxf5ZH"
   },
   "outputs": [],
   "source": [
    "#Rotate to Attend\n",
    "\n",
    "def rotateToAttend(input_feature):\n",
    "    shape = K.int_shape(input_feature)\n",
    "\n",
    "    permute_1 =tf.keras.layers.Permute((3,2,1),input_shape=(shape[1],shape[2],shape[3]))(input_feature)  \n",
    "    print(permute_1.shape)\n",
    "    x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_1)\n",
    "    x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_1)\n",
    "    x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "    x = Conv2D(1,7, padding='same', dilation_rate=(1, 1)) (x3)\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n",
    "    x = tf.keras.activations.sigmoid(x)  \n",
    "    x = tf.keras.layers.Multiply()([x,permute_1])\n",
    "    F1 = tf.keras.layers.Permute((3,2,1),input_shape=(shape[1],shape[2],shape[3]))(x)\n",
    "\n",
    "    permute_2 = tf.keras.layers.Permute((1,3,2),input_shape=(shape[1],shape[2],shape[3]))(input_feature) \n",
    "    x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_2)\n",
    "    x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_2)\n",
    "    x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "    x = Conv2D(1,7, padding='same', dilation_rate=(1, 1)) (x3)\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n",
    "    x = tf.keras.activations.sigmoid(x)  \n",
    "    x = tf.keras.layers.Multiply()([x,permute_2])\n",
    "    F2 = tf.keras.layers.Permute((1,3,2),input_shape=(shape[1],shape[2],shape[3]))(x)\n",
    "\n",
    "\n",
    "    permute_3 = input_feature\n",
    "    x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_3)\n",
    "    x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_3)\n",
    "    x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "    x = Conv2D(1,7, padding='same', dilation_rate=(1, 1)) (x3)\n",
    "    x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n",
    "    x = tf.keras.activations.sigmoid(x)  \n",
    "    F3 = tf.keras.layers.Multiply()([x,permute_3])\n",
    "\n",
    "    attend_feature = tf.keras.layers.Average()([F1, F2, F3])\n",
    "    return attend_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2630422e",
   "metadata": {
    "id": "2630422e"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    \n",
    "   \n",
    "def plotmodel(history,name):\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    #val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    #plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.legend(['train_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+'rta.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    #plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.legend(['train_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+'rta.png')\n",
    "    \n",
    "def get_base_model(model_name,image_size):\n",
    "    if model_name =='vgg16':\n",
    "        base_model=VGG16              (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='resnet50':\n",
    "        base_model=tf.keras.applications.ResNet50           (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='xception':\n",
    "        base_model=Xception           (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='densenet121':    #done acc = 55% epochs:30\n",
    "        base_model=DenseNet121       (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet0.75': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=0.75,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenet1.0': #acc = 60.41% loss = 1.21 epochs:70\n",
    "        base_model=MobileNet         (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='mobilenetv2':\n",
    "        base_model=MobileNetV2      (include_top=False,weights='imagenet',alpha=1.0,input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv3':   \n",
    "        base_model=InceptionV3       (include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if model_name =='inceptionv2':\n",
    "        base_model=tf.keras.applications.InceptionResNetV2 (include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    return base_model\n",
    "\n",
    "def train_model(model,dataset,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "    \n",
    "    dataParam={'messidor': [960,240,2,'Messidor_Binary_512/train',\n",
    "                            'Messidor_Binary_512/test'],\n",
    "               'kaggle': [30000,5126,5,'./data/kaggle/train','./data/kaggle/valid'],\n",
    "               'DDR':   [9851,2503,5,'./data/DDR/train','./data/DDR/valid']} \n",
    "    \n",
    "    train_num,valid_num,classes,train_dir,test_dir = dataParam[dataset]\n",
    "    \n",
    "    train=ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=90)          \n",
    "    valid = ImageDataGenerator()\n",
    "    train_data=train.flow_from_directory(train_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = True,\n",
    "                                         batch_size=batch_size)\n",
    "    valid_data=valid.flow_from_directory(test_dir,\n",
    "                                         target_size=(image_size,image_size),\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "    #save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',period=10)\n",
    "    \n",
    "    filepath = \"resnet50+rotateToAttend.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False   \n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr1,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs1, \n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])   \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n",
    "    history=model.fit(train_data,\n",
    "                        steps_per_epoch=train_num/batch_size,\n",
    "                        epochs=Epochs2,\n",
    "                        workers=2,\n",
    "                        callbacks=[lr_decay,checkpoint])\n",
    "    \n",
    "    score = model.evaluate(valid_data,batch_size = 64)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return history,model,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db0ac5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4db0ac5c",
    "outputId": "67094294-b4da-4173-b8ea-63bb694071ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 11:36:37.334900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: GeForce GT 710, pci bus id: 0000:b3:00.0, compute capability: 3.5) with core count: 1. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2022-05-09 11:36:37.340133: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 11:36:41.069779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30982 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:65:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2048, 16, 16)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
      "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       6)                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
      "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 16, 16, 512)  524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 16, 16, 2048  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 16, 16, 2048  0           ['conv5_block1_out[0][0]',       \n",
      "                                )                                 'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 16, 16, 512)  1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 16, 16, 512)  2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 16, 16, 2048  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 16, 16, 2048  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 16, 16, 2048  0           ['conv5_block2_out[0][0]',       \n",
      "                                )                                 'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 16, 16, 2048  0           ['conv5_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 2048, 16, 16  0           ['conv5_block3_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " permute_2 (Permute)            (None, 16, 2048, 16  0           ['conv5_block3_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda (Lambda)                (None, 2048, 16, 1)  0           ['permute[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 2048, 16, 1)  0           ['permute[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 16, 2048, 1)  0           ['permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 16, 2048, 1)  0           ['permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2048, 16, 2)  0           ['lambda[0][0]',                 \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 2048, 2)  0           ['lambda_2[0][0]',               \n",
      "                                                                  'lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 16, 16, 1)    0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 16, 16, 1)    0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 2048, 16, 1)  99          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 2048, 1)  99          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 16, 16, 2)    0           ['lambda_4[0][0]',               \n",
      "                                                                  'lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2048, 16, 1)  4          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 2048, 1)  4          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 1)    99          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambda)   (None, 2048, 16, 1)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_1 (TFOpLambda)  (None, 16, 2048, 1)  0          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 1)   4           ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 2048, 16, 16  0           ['tf.math.sigmoid[0][0]',        \n",
      "                                )                                 'permute[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 16, 2048, 16  0           ['tf.math.sigmoid_1[0][0]',      \n",
      "                                )                                 'permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_2 (TFOpLambda)  (None, 16, 16, 1)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " permute_1 (Permute)            (None, 16, 16, 2048  0           ['multiply[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " permute_3 (Permute)            (None, 16, 16, 2048  0           ['multiply_1[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 16, 16, 2048  0           ['tf.math.sigmoid_2[0][0]',      \n",
      "                                )                                 'conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " average (Average)              (None, 16, 16, 2048  0           ['permute_1[0][0]',              \n",
      "                                )                                 'permute_3[0][0]',              \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['average[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            4098        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,592,119\n",
      "Trainable params: 23,538,993\n",
      "Non-trainable params: 53,126\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"    \n",
    "loss_fun= 'binary_crossentropy'  \n",
    "gpu_num=1\n",
    "k=3\n",
    "lr1=0.005\n",
    "lr2=0.0001\n",
    "batch_size= 16\n",
    "image_size=512\n",
    "classes=2\n",
    "\n",
    "base_model=get_base_model('resnet50',image_size)  \n",
    "base_in=base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "shape = K.int_shape(base_out)\n",
    "channel_val = shape[3]/2\n",
    "#red_feat = tf.keras.layers.Conv2D(channel_val,1,padding='same')(base_out)\n",
    "x=rotateToAttend(base_out)\n",
    "\n",
    "\n",
    "shape=K.int_shape(x)  \n",
    "x=GlobalAveragePooling2D()(x)\n",
    "out=Dense(classes,activation='softmax')(x)\n",
    "\n",
    "parallel_model=keras.Model(base_model.input,out)\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bcac75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89bcac75",
    "outputId": "1f4dbeb4-9638-4269-d4b2-83b0f055f7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 images belonging to 2 classes.\n",
      "Found 240 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 11:37:14.370500: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.6681 - acc: 0.5990\n",
      "Epoch 1: acc improved from -inf to 0.59896, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 39s 492ms/step - loss: 0.6681 - acc: 0.5990 - lr: 0.0050\n",
      "Epoch 1/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5071 - acc: 0.7479\n",
      "Epoch 1: acc improved from 0.59896 to 0.74792, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 42s 573ms/step - loss: 0.5071 - acc: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3760 - acc: 0.8427\n",
      "Epoch 2: acc improved from 0.74792 to 0.84271, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 35s 564ms/step - loss: 0.3760 - acc: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3451 - acc: 0.8531\n",
      "Epoch 3: acc improved from 0.84271 to 0.85312, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 37s 610ms/step - loss: 0.3451 - acc: 0.8531 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3057 - acc: 0.8823\n",
      "Epoch 4: acc improved from 0.85312 to 0.88229, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 40s 652ms/step - loss: 0.3057 - acc: 0.8823 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2736 - acc: 0.8969\n",
      "Epoch 5: acc improved from 0.88229 to 0.89688, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 39s 633ms/step - loss: 0.2736 - acc: 0.8969 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3212 - acc: 0.8698\n",
      "Epoch 6: acc did not improve from 0.89688\n",
      "60/60 [==============================] - 36s 582ms/step - loss: 0.3212 - acc: 0.8698 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2290 - acc: 0.9083\n",
      "Epoch 7: acc improved from 0.89688 to 0.90833, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 38s 625ms/step - loss: 0.2290 - acc: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2740 - acc: 0.8969\n",
      "Epoch 8: acc did not improve from 0.90833\n",
      "60/60 [==============================] - 37s 595ms/step - loss: 0.2740 - acc: 0.8969 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2274 - acc: 0.9135\n",
      "Epoch 9: acc improved from 0.90833 to 0.91354, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 39s 636ms/step - loss: 0.2274 - acc: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2575 - acc: 0.9052\n",
      "Epoch 10: acc did not improve from 0.91354\n",
      "60/60 [==============================] - 36s 592ms/step - loss: 0.2575 - acc: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2219 - acc: 0.9125\n",
      "Epoch 11: acc did not improve from 0.91354\n",
      "60/60 [==============================] - 39s 638ms/step - loss: 0.2219 - acc: 0.9125 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1935 - acc: 0.9354\n",
      "Epoch 12: acc improved from 0.91354 to 0.93542, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 41s 671ms/step - loss: 0.1935 - acc: 0.9354 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1902 - acc: 0.9292\n",
      "Epoch 13: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 37s 597ms/step - loss: 0.1902 - acc: 0.9292 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1862 - acc: 0.9177\n",
      "Epoch 14: acc did not improve from 0.93542\n",
      "60/60 [==============================] - 38s 600ms/step - loss: 0.1862 - acc: 0.9177 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1521 - acc: 0.9417\n",
      "Epoch 15: acc improved from 0.93542 to 0.94167, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 44s 690ms/step - loss: 0.1521 - acc: 0.9417 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1803 - acc: 0.9365\n",
      "Epoch 16: acc did not improve from 0.94167\n",
      "60/60 [==============================] - 40s 654ms/step - loss: 0.1803 - acc: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1699 - acc: 0.9250\n",
      "Epoch 17: acc did not improve from 0.94167\n",
      "60/60 [==============================] - 40s 653ms/step - loss: 0.1699 - acc: 0.9250 - lr: 1.0000e-04\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1499 - acc: 0.9344\n",
      "Epoch 18: acc did not improve from 0.94167\n",
      "60/60 [==============================] - 40s 651ms/step - loss: 0.1499 - acc: 0.9344 - lr: 1.0000e-04\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1472 - acc: 0.9458\n",
      "Epoch 19: acc improved from 0.94167 to 0.94583, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 43s 699ms/step - loss: 0.1472 - acc: 0.9458 - lr: 1.0000e-04\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1542 - acc: 0.9375\n",
      "Epoch 20: acc did not improve from 0.94583\n",
      "60/60 [==============================] - 39s 639ms/step - loss: 0.1542 - acc: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1157 - acc: 0.9531\n",
      "Epoch 21: acc improved from 0.94583 to 0.95312, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 43s 708ms/step - loss: 0.1157 - acc: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1229 - acc: 0.9500\n",
      "Epoch 22: acc did not improve from 0.95312\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.1229 - acc: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.9531\n",
      "Epoch 23: acc did not improve from 0.95312\n",
      "60/60 [==============================] - 41s 673ms/step - loss: 0.1177 - acc: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1178 - acc: 0.9573\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 24: acc improved from 0.95312 to 0.95729, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 44s 712ms/step - loss: 0.1178 - acc: 0.9573 - lr: 1.0000e-04\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1072 - acc: 0.9583\n",
      "Epoch 25: acc improved from 0.95729 to 0.95833, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 43s 697ms/step - loss: 0.1072 - acc: 0.9583 - lr: 8.0000e-05\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0808 - acc: 0.9719\n",
      "Epoch 26: acc improved from 0.95833 to 0.97188, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 43s 700ms/step - loss: 0.0808 - acc: 0.9719 - lr: 8.0000e-05\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0889 - acc: 0.9625\n",
      "Epoch 27: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 41s 667ms/step - loss: 0.0889 - acc: 0.9625 - lr: 8.0000e-05\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1002 - acc: 0.9625\n",
      "Epoch 28: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 42s 688ms/step - loss: 0.1002 - acc: 0.9625 - lr: 8.0000e-05\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0795 - acc: 0.9708\n",
      "Epoch 29: acc did not improve from 0.97188\n",
      "60/60 [==============================] - 42s 680ms/step - loss: 0.0795 - acc: 0.9708 - lr: 8.0000e-05\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.9771\n",
      "Epoch 30: acc improved from 0.97188 to 0.97708, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 44s 695ms/step - loss: 0.0649 - acc: 0.9771 - lr: 8.0000e-05\n",
      "Epoch 31/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0820 - acc: 0.9656\n",
      "Epoch 31: acc did not improve from 0.97708\n",
      "60/60 [==============================] - 40s 649ms/step - loss: 0.0820 - acc: 0.9656 - lr: 8.0000e-05\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0608 - acc: 0.9781\n",
      "Epoch 32: acc improved from 0.97708 to 0.97812, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 44s 722ms/step - loss: 0.0608 - acc: 0.9781 - lr: 8.0000e-05\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0482 - acc: 0.9875\n",
      "Epoch 33: acc improved from 0.97812 to 0.98750, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 42s 693ms/step - loss: 0.0482 - acc: 0.9875 - lr: 8.0000e-05\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0761 - acc: 0.9708\n",
      "Epoch 34: acc did not improve from 0.98750\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0761 - acc: 0.9708 - lr: 8.0000e-05\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0643 - acc: 0.9812\n",
      "Epoch 35: acc did not improve from 0.98750\n",
      "60/60 [==============================] - 41s 666ms/step - loss: 0.0643 - acc: 0.9812 - lr: 8.0000e-05\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0551 - acc: 0.9802\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 36: acc did not improve from 0.98750\n",
      "60/60 [==============================] - 42s 689ms/step - loss: 0.0551 - acc: 0.9802 - lr: 8.0000e-05\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0531 - acc: 0.9812\n",
      "Epoch 37: acc did not improve from 0.98750\n",
      "60/60 [==============================] - 41s 672ms/step - loss: 0.0531 - acc: 0.9812 - lr: 6.4000e-05\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0589 - acc: 0.9781\n",
      "Epoch 38: acc did not improve from 0.98750\n",
      "60/60 [==============================] - 43s 699ms/step - loss: 0.0589 - acc: 0.9781 - lr: 6.4000e-05\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0490 - acc: 0.9865\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 39: acc did not improve from 0.98750\n",
      "60/60 [==============================] - 42s 676ms/step - loss: 0.0490 - acc: 0.9865 - lr: 6.4000e-05\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0293 - acc: 0.9896\n",
      "Epoch 40: acc improved from 0.98750 to 0.98958, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 42s 689ms/step - loss: 0.0293 - acc: 0.9896 - lr: 5.1200e-05\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0329 - acc: 0.9865\n",
      "Epoch 41: acc did not improve from 0.98958\n",
      "60/60 [==============================] - 41s 677ms/step - loss: 0.0329 - acc: 0.9865 - lr: 5.1200e-05\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0380 - acc: 0.9927\n",
      "Epoch 42: acc improved from 0.98958 to 0.99271, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 45s 730ms/step - loss: 0.0380 - acc: 0.9927 - lr: 5.1200e-05\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0151 - acc: 0.9969\n",
      "Epoch 43: acc improved from 0.99271 to 0.99687, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 43s 709ms/step - loss: 0.0151 - acc: 0.9969 - lr: 5.1200e-05\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9969\n",
      "Epoch 44: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 41s 676ms/step - loss: 0.0156 - acc: 0.9969 - lr: 5.1200e-05\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0280 - acc: 0.9906\n",
      "Epoch 45: acc did not improve from 0.99687\n",
      "60/60 [==============================] - 43s 695ms/step - loss: 0.0280 - acc: 0.9906 - lr: 5.1200e-05\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0133 - acc: 0.9979\n",
      "Epoch 46: acc improved from 0.99687 to 0.99792, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 45s 735ms/step - loss: 0.0133 - acc: 0.9979 - lr: 5.1200e-05\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9885\n",
      "Epoch 47: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 39s 644ms/step - loss: 0.0250 - acc: 0.9885 - lr: 5.1200e-05\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0278 - acc: 0.9927\n",
      "Epoch 48: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 43s 694ms/step - loss: 0.0278 - acc: 0.9927 - lr: 5.1200e-05\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0234 - acc: 0.9937\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 49: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 41s 671ms/step - loss: 0.0234 - acc: 0.9937 - lr: 5.1200e-05\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9979\n",
      "Epoch 50: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0145 - acc: 0.9979 - lr: 4.0960e-05\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9969\n",
      "Epoch 51: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 42s 661ms/step - loss: 0.0156 - acc: 0.9969 - lr: 4.0960e-05\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.9854\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 52: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 40s 655ms/step - loss: 0.0457 - acc: 0.9854 - lr: 4.0960e-05\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9969\n",
      "Epoch 53: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 41s 670ms/step - loss: 0.0158 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9937\n",
      "Epoch 54: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 41s 664ms/step - loss: 0.0177 - acc: 0.9937 - lr: 3.2768e-05\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9979\n",
      "Epoch 55: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 40s 657ms/step - loss: 0.0112 - acc: 0.9979 - lr: 3.2768e-05\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0123 - acc: 0.9969\n",
      "Epoch 56: acc did not improve from 0.99792\n",
      "60/60 [==============================] - 40s 648ms/step - loss: 0.0123 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9990\n",
      "Epoch 57: acc improved from 0.99792 to 0.99896, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 44s 694ms/step - loss: 0.0106 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 58: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 40s 656ms/step - loss: 0.0084 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9990\n",
      "Epoch 59: acc did not improve from 0.99896\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0074 - acc: 0.9990 - lr: 3.2768e-05\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 60: acc improved from 0.99896 to 1.00000, saving model to resnet50+rotateToAttend.hdf5\n",
      "60/60 [==============================] - 44s 694ms/step - loss: 0.0055 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 61: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 667ms/step - loss: 0.0046 - acc: 1.0000 - lr: 3.2768e-05\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0057 - acc: 0.9990\n",
      "Epoch 62: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 682ms/step - loss: 0.0057 - acc: 0.9990 - lr: 3.2768e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0104 - acc: 0.9958\n",
      "Epoch 63: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 0.0104 - acc: 0.9958 - lr: 3.2768e-05\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.9969\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 64: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 697ms/step - loss: 0.0129 - acc: 0.9969 - lr: 3.2768e-05\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9979\n",
      "Epoch 65: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 685ms/step - loss: 0.0087 - acc: 0.9979 - lr: 2.6214e-05\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 688ms/step - loss: 0.0081 - acc: 0.9969 - lr: 2.6214e-05\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9948\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0102 - acc: 0.9948 - lr: 2.6214e-05\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 688ms/step - loss: 0.0042 - acc: 1.0000 - lr: 2.0972e-05\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9990\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 693ms/step - loss: 0.0067 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9979\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 686ms/step - loss: 0.0060 - acc: 0.9979 - lr: 2.0972e-05\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0054 - acc: 0.9990\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 71: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 687ms/step - loss: 0.0054 - acc: 0.9990 - lr: 2.0972e-05\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 72: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 672ms/step - loss: 0.0040 - acc: 1.0000 - lr: 1.6777e-05\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 73: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 683ms/step - loss: 0.0070 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9979\n",
      "Epoch 74: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 688ms/step - loss: 0.0055 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 75: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0058 - acc: 0.9979 - lr: 1.6777e-05\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0206 - acc: 0.9927\n",
      "Epoch 76: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 663ms/step - loss: 0.0206 - acc: 0.9927 - lr: 1.3422e-05\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 77: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 45s 708ms/step - loss: 0.0036 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 78: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 679ms/step - loss: 0.0026 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 79: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 664ms/step - loss: 0.0021 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 80: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 684ms/step - loss: 0.0037 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 81: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 670ms/step - loss: 0.0030 - acc: 1.0000 - lr: 1.3422e-05\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9990\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 82: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 675ms/step - loss: 0.0025 - acc: 0.9990 - lr: 1.3422e-05\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 83: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 41s 668ms/step - loss: 0.0024 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 84: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 45s 705ms/step - loss: 0.0025 - acc: 1.0000 - lr: 1.0737e-05\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0069 - acc: 0.9990\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 85: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 696ms/step - loss: 0.0069 - acc: 0.9990 - lr: 1.0737e-05\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 86: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 690ms/step - loss: 0.0038 - acc: 1.0000 - lr: 8.5899e-06\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 87: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 684ms/step - loss: 0.0038 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0050 - acc: 0.9990\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 88: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 43s 699ms/step - loss: 0.0050 - acc: 0.9990 - lr: 8.5899e-06\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 89: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 42s 682ms/step - loss: 0.0037 - acc: 1.0000 - lr: 6.8719e-06\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0050 - acc: 0.9990\n",
      "Epoch 90: acc did not improve from 1.00000\n",
      "60/60 [==============================] - 44s 722ms/step - loss: 0.0050 - acc: 0.9990 - lr: 6.8719e-06\n",
      "15/15 [==============================] - 4s 181ms/step - loss: 0.2839 - acc: 0.9167\n",
      "Test loss: 0.2839406728744507\n",
      "Test accuracy: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "history,model,valid_data=train_model(parallel_model,\n",
    "                                     'messidor',\n",
    "                                     image_size,\n",
    "                                     batch_size,\n",
    "                                     'resnet50',\n",
    "                                     lr1,lr2,1,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9161dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "f9161dca",
    "outputId": "504d67dd-b3ed-4322-a3fc-1e062db663a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotmodel(history,'resnet50')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6uGQ0vXAjlWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uGQ0vXAjlWI",
    "outputId": "ba11ef0a-e272-40d7-d4e0-5823ff8d8b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[9.78704572e-01 2.12953798e-02]\n",
      " [1.00000000e+00 1.73506400e-08]\n",
      " [9.99999404e-01 6.45326054e-07]\n",
      " [1.00000000e+00 7.34859326e-11]\n",
      " [1.00000000e+00 1.14411002e-10]\n",
      " [1.00000000e+00 7.44358741e-11]\n",
      " [1.00000000e+00 3.23201362e-11]\n",
      " [9.82040286e-01 1.79596320e-02]\n",
      " [9.99967575e-01 3.24301218e-05]\n",
      " [9.99999642e-01 4.04035944e-07]\n",
      " [1.00000000e+00 7.86995080e-10]\n",
      " [1.00000000e+00 5.56752759e-08]\n",
      " [1.00000000e+00 1.39618461e-09]\n",
      " [1.00000000e+00 1.55135757e-12]\n",
      " [1.00000000e+00 4.46757279e-15]\n",
      " [8.86828840e-01 1.13171212e-01]\n",
      " [9.99431670e-01 5.68280288e-04]\n",
      " [1.00000000e+00 8.91731755e-09]\n",
      " [1.00000000e+00 4.77773199e-09]\n",
      " [1.00000000e+00 6.00920036e-10]\n",
      " [1.00000000e+00 2.03861750e-09]\n",
      " [1.00000000e+00 2.25030081e-11]\n",
      " [9.99999881e-01 7.26925435e-08]\n",
      " [1.00000000e+00 4.78158846e-09]\n",
      " [9.99768794e-01 2.31230923e-04]\n",
      " [9.99999762e-01 2.02073977e-07]\n",
      " [1.00000000e+00 3.79114251e-09]\n",
      " [3.76637705e-04 9.99623299e-01]\n",
      " [1.00000000e+00 3.69597721e-08]\n",
      " [1.00000000e+00 2.35124475e-10]\n",
      " [9.99938726e-01 6.12803415e-05]\n",
      " [1.00000000e+00 7.09193190e-11]\n",
      " [9.99993563e-01 6.37783705e-06]\n",
      " [1.00000000e+00 1.01140249e-10]\n",
      " [1.00000000e+00 3.52574396e-08]\n",
      " [1.00000000e+00 1.83000086e-08]\n",
      " [1.00000000e+00 1.13234599e-09]\n",
      " [9.99999285e-01 6.66993571e-07]\n",
      " [1.00000000e+00 2.57382293e-08]\n",
      " [1.00000000e+00 5.49550516e-10]\n",
      " [1.00000000e+00 1.98574135e-13]\n",
      " [9.99999166e-01 8.07747426e-07]\n",
      " [3.17592104e-03 9.96824145e-01]\n",
      " [1.00000000e+00 3.76927795e-11]\n",
      " [1.00000000e+00 8.06115417e-12]\n",
      " [1.00000000e+00 4.81520639e-12]\n",
      " [9.99995828e-01 4.12788449e-06]\n",
      " [9.99991179e-01 8.84220572e-06]\n",
      " [9.99999881e-01 1.24939604e-07]\n",
      " [7.18372166e-01 2.81627804e-01]\n",
      " [1.63061870e-03 9.98369396e-01]\n",
      " [1.00000000e+00 5.90260418e-09]\n",
      " [1.00000000e+00 7.04898673e-09]\n",
      " [1.00000000e+00 6.04258588e-11]\n",
      " [1.00000000e+00 2.19067853e-09]\n",
      " [1.00000000e+00 4.56443161e-10]\n",
      " [5.35435200e-01 4.64564741e-01]\n",
      " [9.99949098e-01 5.08695448e-05]\n",
      " [9.99892473e-01 1.07495216e-04]\n",
      " [9.99999881e-01 1.44297772e-07]\n",
      " [9.99473393e-01 5.26581192e-04]\n",
      " [9.99997854e-01 2.15333102e-06]\n",
      " [1.00000000e+00 2.54041872e-08]\n",
      " [1.00000000e+00 6.19146845e-10]\n",
      " [9.99998927e-01 1.11961970e-06]\n",
      " [1.00000000e+00 3.60535305e-14]\n",
      " [1.00000000e+00 4.58289318e-09]\n",
      " [1.00000000e+00 1.96239451e-08]\n",
      " [1.00000000e+00 9.53058596e-13]\n",
      " [9.99999881e-01 8.29133597e-08]\n",
      " [1.00000000e+00 4.38565912e-08]\n",
      " [9.99997735e-01 2.22436029e-06]\n",
      " [1.00000000e+00 8.20185011e-13]\n",
      " [9.82521236e-01 1.74787659e-02]\n",
      " [1.00000000e+00 9.04832931e-10]\n",
      " [1.00000000e+00 3.83433951e-09]\n",
      " [1.00000000e+00 1.20777015e-08]\n",
      " [1.00000000e+00 1.24821455e-11]\n",
      " [1.00000000e+00 1.88747107e-09]\n",
      " [1.00000000e+00 1.01079296e-14]\n",
      " [1.00000000e+00 4.10534481e-13]\n",
      " [1.00000000e+00 1.55781006e-08]\n",
      " [9.99998093e-01 1.93523624e-06]\n",
      " [1.00000000e+00 5.85950177e-11]\n",
      " [1.00000000e+00 4.15631226e-17]\n",
      " [9.65604842e-01 3.43951769e-02]\n",
      " [9.99997497e-01 2.47583876e-06]\n",
      " [9.99999762e-01 1.93669734e-07]\n",
      " [1.00000000e+00 1.96358945e-15]\n",
      " [9.99888062e-01 1.11915731e-04]\n",
      " [9.99999881e-01 1.45752196e-07]\n",
      " [1.00000000e+00 5.71676213e-11]\n",
      " [1.00000000e+00 1.89826502e-10]\n",
      " [9.99354422e-01 6.45526801e-04]\n",
      " [9.99893308e-01 1.06655119e-04]\n",
      " [1.38484603e-02 9.86151516e-01]\n",
      " [1.00000000e+00 1.21156951e-09]\n",
      " [1.00000000e+00 1.01230318e-11]\n",
      " [9.99667406e-01 3.32628057e-04]\n",
      " [1.00000000e+00 1.27175053e-08]\n",
      " [1.00000000e+00 1.54795488e-09]\n",
      " [1.00000000e+00 2.92384457e-14]\n",
      " [9.99999642e-01 3.46096186e-07]\n",
      " [1.00000000e+00 4.08661034e-13]\n",
      " [9.98868883e-01 1.13108708e-03]\n",
      " [9.99962926e-01 3.71145034e-05]\n",
      " [9.99492407e-01 5.07535704e-04]\n",
      " [9.90525186e-01 9.47481953e-03]\n",
      " [9.86003220e-01 1.39967017e-02]\n",
      " [9.98403609e-01 1.59646024e-03]\n",
      " [1.00000000e+00 3.02108954e-15]\n",
      " [2.69947555e-02 9.73005235e-01]\n",
      " [9.99999642e-01 3.60097971e-07]\n",
      " [1.00000000e+00 4.75080001e-12]\n",
      " [1.00000000e+00 2.10196555e-10]\n",
      " [9.99951601e-01 4.83647345e-05]\n",
      " [1.00000000e+00 4.16450818e-10]\n",
      " [1.00000000e+00 6.80329237e-10]\n",
      " [9.99999881e-01 1.14680006e-07]\n",
      " [9.99999166e-01 8.23417338e-07]\n",
      " [9.99119222e-01 8.80802982e-04]\n",
      " [9.99999046e-01 1.00097111e-06]\n",
      " [9.99993682e-01 6.28142016e-06]\n",
      " [1.00000000e+00 4.93786479e-12]\n",
      " [4.86403750e-03 9.95135963e-01]\n",
      " [1.00000000e+00 2.90395347e-10]\n",
      " [9.80625510e-01 1.93744991e-02]\n",
      " [1.00000000e+00 8.92991473e-16]\n",
      " [1.00000000e+00 2.97458690e-11]\n",
      " [1.00000000e+00 8.74379805e-11]\n",
      " [1.00000000e+00 2.09640127e-09]\n",
      " [1.00000000e+00 5.96610816e-11]\n",
      " [1.00000000e+00 8.87695403e-11]\n",
      " [1.00000000e+00 3.79978124e-12]\n",
      " [1.00000000e+00 2.85376855e-09]\n",
      " [1.00000000e+00 3.26222296e-12]\n",
      " [4.97087717e-01 5.02912283e-01]\n",
      " [9.99953508e-01 4.64537479e-05]\n",
      " [1.00000000e+00 4.19924484e-10]\n",
      " [1.00000000e+00 1.62243677e-10]\n",
      " [9.99803126e-01 1.96942652e-04]\n",
      " [1.00000000e+00 3.91882470e-14]\n",
      " [9.99172986e-01 8.27042561e-04]\n",
      " [4.21560979e-13 1.00000000e+00]\n",
      " [1.00000000e+00 3.48533757e-09]\n",
      " [1.18220967e-22 1.00000000e+00]\n",
      " [7.32364143e-08 9.99999881e-01]\n",
      " [1.97162805e-03 9.98028338e-01]\n",
      " [3.94310834e-11 1.00000000e+00]\n",
      " [2.10304691e-07 9.99999762e-01]\n",
      " [1.07997226e-14 1.00000000e+00]\n",
      " [6.16276405e-11 1.00000000e+00]\n",
      " [2.99767834e-25 1.00000000e+00]\n",
      " [2.59273648e-02 9.74072576e-01]\n",
      " [9.87898648e-01 1.21013895e-02]\n",
      " [8.23272407e-01 1.76727593e-01]\n",
      " [2.03276344e-23 1.00000000e+00]\n",
      " [2.35256478e-02 9.76474345e-01]\n",
      " [1.00000000e+00 1.86941803e-12]\n",
      " [1.57570862e-03 9.98424292e-01]\n",
      " [9.51133013e-01 4.88670245e-02]\n",
      " [8.48516975e-17 1.00000000e+00]\n",
      " [6.22666703e-05 9.99937773e-01]\n",
      " [2.44305114e-11 1.00000000e+00]\n",
      " [3.46889574e-05 9.99965310e-01]\n",
      " [1.25764911e-15 1.00000000e+00]\n",
      " [4.43893168e-06 9.99995589e-01]\n",
      " [9.93400991e-01 6.59896154e-03]\n",
      " [1.19848599e-04 9.99880195e-01]\n",
      " [3.69376377e-27 1.00000000e+00]\n",
      " [1.27859963e-08 1.00000000e+00]\n",
      " [5.27920398e-17 1.00000000e+00]\n",
      " [1.60564650e-14 1.00000000e+00]\n",
      " [8.18133969e-08 9.99999881e-01]\n",
      " [9.99926686e-01 7.33235429e-05]\n",
      " [9.86679375e-01 1.33206742e-02]\n",
      " [5.36745040e-19 1.00000000e+00]\n",
      " [7.44540870e-01 2.55459130e-01]\n",
      " [9.85535264e-01 1.44648040e-02]\n",
      " [1.70002691e-04 9.99830008e-01]\n",
      " [3.65386597e-07 9.99999642e-01]\n",
      " [2.41496595e-19 1.00000000e+00]\n",
      " [1.12575875e-03 9.98874247e-01]\n",
      " [3.59246112e-18 1.00000000e+00]\n",
      " [4.70806449e-10 1.00000000e+00]\n",
      " [1.76510083e-28 1.00000000e+00]\n",
      " [1.29176794e-08 1.00000000e+00]\n",
      " [1.02741744e-07 9.99999881e-01]\n",
      " [8.42642605e-01 1.57357424e-01]\n",
      " [2.10663691e-18 1.00000000e+00]\n",
      " [5.61613507e-14 1.00000000e+00]\n",
      " [9.99041445e-34 1.00000000e+00]\n",
      " [9.43982089e-13 1.00000000e+00]\n",
      " [6.25318552e-09 1.00000000e+00]\n",
      " [5.74266459e-18 1.00000000e+00]\n",
      " [5.61220527e-01 4.38779503e-01]\n",
      " [4.03671208e-07 9.99999642e-01]\n",
      " [4.90109286e-08 1.00000000e+00]\n",
      " [5.85528399e-17 1.00000000e+00]\n",
      " [1.05473939e-02 9.89452600e-01]\n",
      " [4.07998974e-04 9.99592006e-01]\n",
      " [4.86768804e-05 9.99951363e-01]\n",
      " [4.23175609e-03 9.95768309e-01]\n",
      " [1.61879624e-13 1.00000000e+00]\n",
      " [4.37835993e-13 1.00000000e+00]\n",
      " [4.84881875e-23 1.00000000e+00]\n",
      " [5.90652274e-03 9.94093478e-01]\n",
      " [5.89065291e-02 9.41093504e-01]\n",
      " [1.11491518e-18 1.00000000e+00]\n",
      " [1.21089921e-04 9.99878883e-01]\n",
      " [1.25080743e-03 9.98749137e-01]\n",
      " [1.94364544e-02 9.80563521e-01]\n",
      " [9.78897103e-25 1.00000000e+00]\n",
      " [1.02358439e-17 1.00000000e+00]\n",
      " [2.39560351e-01 7.60439634e-01]\n",
      " [9.62569728e-04 9.99037504e-01]\n",
      " [4.55240637e-01 5.44759393e-01]\n",
      " [1.95917096e-08 1.00000000e+00]\n",
      " [6.50432994e-05 9.99934912e-01]\n",
      " [9.72229838e-01 2.77702268e-02]\n",
      " [8.63652298e-19 1.00000000e+00]\n",
      " [9.10300580e-19 1.00000000e+00]\n",
      " [2.90387106e-05 9.99970913e-01]\n",
      " [3.83739041e-09 1.00000000e+00]\n",
      " [4.80215172e-17 1.00000000e+00]\n",
      " [2.15118839e-10 1.00000000e+00]\n",
      " [1.47061003e-02 9.85293925e-01]\n",
      " [1.26537168e-13 1.00000000e+00]\n",
      " [1.56680235e-09 1.00000000e+00]\n",
      " [2.73497868e-02 9.72650170e-01]\n",
      " [1.82456949e-06 9.99998212e-01]\n",
      " [3.98159252e-18 1.00000000e+00]\n",
      " [8.36552710e-14 1.00000000e+00]\n",
      " [1.36523110e-14 1.00000000e+00]\n",
      " [1.45677011e-04 9.99854326e-01]\n",
      " [8.42065583e-06 9.99991536e-01]\n",
      " [1.85505597e-10 1.00000000e+00]\n",
      " [1.59725648e-17 1.00000000e+00]\n",
      " [2.45219638e-15 1.00000000e+00]\n",
      " [1.11067129e-04 9.99888897e-01]]\n",
      "Confusion Matrix\n",
      "[[136   7]\n",
      " [ 13  84]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.91      0.95      0.93       143\n",
      "    referable       0.92      0.87      0.89        97\n",
      "\n",
      "     accuracy                           0.92       240\n",
      "    macro avg       0.92      0.91      0.91       240\n",
      " weighted avg       0.92      0.92      0.92       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "Y_pred = model.predict(valid_data, 240 // 4)\n",
    "#print(Y_pred.shape)\n",
    "#print(type(Y_pred))\n",
    "print(valid_data.classes)  \n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(valid_data.classes, y_pred)\n",
    "\n",
    "print(confusion_matrix(valid_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(valid_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "p6dDyf2Wjqyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "p6dDyf2Wjqyx",
    "outputId": "760ff374-0953-4399-a575-5f4fd829a46d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vRxJ0IrEJh9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRxJ0IrEJh9a",
    "outputId": "e19ae8e1-a35f-4841-eb2c-045a34fa7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VEilAGF6jvLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VEilAGF6jvLZ",
    "outputId": "58118e19-6849-48b0-d0d3-a6cde1cc6db1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABfQUlEQVR4nO3dd3zM9x/A8deN7MhAIvbeDaFo1SqSohF776rSqlXULDVq1mhVKT9KRVGralNqddBqEVXaGrETRfa+u8/vj8jJutyF3F2S+zwfDw+5u+94f+5y73y+n+9nKIQQAkmSJMkgpbUDkCRJyu9kopQkSTJCJkpJkiQjZKKUJEkyQiZKSZIkI2SilCRJMkImygIuMDCQM2fOWDuMfOOLL75g6tSpVjn3pEmTWLp0qVXOndd2797N4MGDn2nfwvg7qZD9KPNOq1atePjwISqVCmdnZ5o1a8a0adNwcXGxdmh5Ijk5mc8++4w9e/bw+PFjfHx86NGjB2+++SYKhcLi8Zw5c4b333+fkydPWuR8QgiCg4PZunUrd+7cwc3NDT8/P959912qV6/OpEmTKFGiBO+9955F4jHks88+4+bNmyxatMjs58ovZTY3WaPMY1988QXnzp1j165d/PXXX6xevdraIeWaRqPJ9vlRo0bxyy+/sHr1av744w8WLlzI1q1bmTNnTp7HIIRAp9Pl+XGfx5w5c9iwYQNTp07l119/5dChQ/j7+3PixIk8P5ehz8ASrHnufEtIeaZly5bip59+0j9esGCBeOutt/SPz507J3r27ClefPFFERQUJE6fPq1/LSIiQkyaNEk0adJENGjQQLzzzjv613744QfRoUMH8eKLL4qePXuKy5cvZzlnWFiY8PX1FREREfrXLl26JBo1aiSSk5OFEEJs27ZNtG3bVjRo0EAMHjxY3LlzR79ttWrVxMaNG0VAQIBo2bJllrL9/PPP4oUXXhD37t3L8Pz58+dFjRo1RGhoqBBCiH79+olFixaJrl27ivr164u33347Q0w5vQf9+vUTS5YsET179hS+vr4iNDRUbN++XbRt21b4+fmJVq1aic2bNwshhIiLixO+vr6ievXqws/PT/j5+YmwsDCxbNkyMW7cOCGEELdv3xbVqlUTO3fuFC1atBCNGjUSK1as0J8vISFBTJgwQTRo0EC0bdtWrF69WjRr1iy7j1bcuHFD1KhRQ1y4cCHb14UQYuLEiWLGjBnirbfeEn5+fqJbt27i5s2b+tdnz54tmjdvLurVqyc6d+4sfvvtN/1ry5YtEyNHjhTjxo0T9erVE1u3bhUXLlwQPXr0EC+++KJo0qSJmDlzpkhKStLv888//4hBgwaJhg0bisaNG4uVK1eKEydOiNq1a4tatWoJPz8/ERQUJIQQIjo6WkyePFk0adJENG3aVCxZskRoNBohhBA7duwQPXv2FHPmzBENGzYUS5YsETt27BC9evUSQgih0+nEnDlzxMsvvyzq168v2rdvL/7++2+xZcsWUatWLVG7dm3h5+cnhg0bJoTI+D3QaDRi5cqVonXr1sLPz0907tw5y+9QQSATZR5K/wty//590b59ezF79mwhhBBhYWGiUaNG4vjx40Kr1Yoff/xRNGrUSDx69EgIIcRbb70lRo8eLSIjI0VycrI4c+aMEEKIP//8U7z88svi/PnzQqPRiJ07d4qWLVvqvzDpz9m/f3/xzTff6OOZP3++mDZtmhBCiO+//174+/uLq1evipSUFPH555+Lnj176retVq2aGDRokIiIiBAJCQlZyvbxxx+Lvn37ZlvuV199VZ/A+vXrJ5o2bSr+/vtvERcXJ0aMGKFPXMbeg379+okWLVqIf/75R6SkpIjk5GRx7NgxcfPmTaHT6cSZM2dEnTp1xJ9//imEEOL06dNZElt2iXLq1KkiISFBXL58WdSuXVtcvXo1Q5kiIyP1n5ehRLlp0ybx6quvZvtamokTJ4qGDRuKCxcuiJSUFDF27FgxZswY/eu7du0Sjx8/FikpKWLt2rXilVdeEYmJifq4a9WqJb7//nuh1WpFQkKCuHjxojh37pxISUkRt2/fFm3bthXr1q0TQggRExMjmjRpItauXSsSExNFTEyMOH/+fJb3IM0777wjpk2bJuLi4sTDhw9F165d9Z/Zjh07RM2aNcWGDRtESkqKSEhIyJAoT548KTp37iyioqKETqcTV69eFeHh4foyL1myJMO50v9O/u9//xPt27cX165dEzqdTly+fFk8fvw4x/cxP5KX3nns3XffpV69erRo0YKiRYsyatQoAL777juaN29OixYtUCqVNGnShBdeeIETJ07w4MEDTp48ycyZM3F3d8fOzo5GjRoBsHXrVnr27EndunVRqVR07twZOzs7zp8/n+XcQUFB7N27F0i9dN2/fz9BQUEAbNmyhaFDh1K5cmXUajVvv/02ly9f5u7du/r9hw4dioeHB46OjlmOHRERgZeXV7Zl9vLyIiIiQv+4Y8eOVKtWDWdnZ0aPHs3BgwfRarU5vgdpOnfuTNWqVVGr1djZ2fHqq69Srlw5FAoFjRo1okmTJpw9ezZXn8mIESNwdHSkRo0a1KhRgytXrgBw4MABhg0bhru7Oz4+PgwYMMDgMSIjIw2WP72AgADq1KmDWq2mQ4cOXL58OcP74unpiVqtZvDgwSQnJ3Pjxg39635+fvj7+6NUKnF0dOSFF17Az88PtVpNmTJl6NmzJ7/99hsAx48fp3jx4gwePBgHBwdcXV2pW7dutjE9fPiQkydPMmXKFJydnSlWrBiDBg1i3759+m28vb3p378/arU6y+evVquJi4vj+vXrCCGoXLky3t7eRt8LgG3btjF69GgqVaqEQqGgRo0aeHp6mrRvfqK2dgCFzeeff84rr7zCr7/+yrhx44iIiMDNzY179+5x8OBBjh07pt9Wo9Hw0ksvERYWhru7O+7u7lmOd+/ePXbt2sXGjRv1z6WkpPDgwYMs27Zp04bZs2cTHh7OzZs3USgUNGjQQH+cuXPnsmDBAv32QgjCw8MpXbo0ACVLljRYLk9PT27evJnta//991+GX/70xylVqhQpKSlERETk+B5kty/AiRMn+PzzzwkNDUWn05GYmEi1atUMxpmd4sWL6392cnIiPj4egAcPHmQ4n4+Pj8FjeHh48N9//+XqXI6OjvpzAXz55Zds27aNBw8eoFAoiI2NzfAHJvP5b9y4wfz58/nzzz9JSEhAq9VSu3ZtAO7fv0+5cuWMxgOpn71Go6Fp06b653Q6ncllb9y4MX379mXWrFncu3ePgIAAJk6ciKurq9Fzh4WFmRxnfiYTpZk0atSILl26sGDBAlasWEHJkiXp2LEjH330UZZtHzx4QFRUFNHR0bi5uWV4rWTJkrz99tu88847Rs/p5uZGkyZNOHDgANevXycwMFB/NzrtOB06dDC4f053rl955RW++uor7t+/n+ELFhISwv3793n55Zf1z92/fz/Dz3Z2dnh6eub4HmQXQ3JyMqNGjWLBggW0bt0aOzs7hg8fjnjSUeN577R7eXkRFhZGlSpVgNQvtSGNGzdm1qxZXLx4EV9f31yf6+zZs/zvf/9j/fr1VK1aFaVSScOGDfVlgazlmTFjBrVq1WLx4sW4urqyfv16Dh06BKR+nulrhOllPo6Pjw/29vacPn0atTr7r7yx93LAgAEMGDCAR48eMWbMGNasWcOYMWOM7ufj48OtW7dy/cctv5GX3mY0cOBAfv75Zy5fvkyHDh04duwYp06dQqvVkpSUxJkzZwgLC8Pb25vmzZszc+ZMoqKiSElJ0V9ide/enS1btnDhwgWEEMTHx3P8+HFiY2OzPWdQUBDfffcdhw4d0l92A/Tq1YvVq1fz77//AhATE8OBAwdMLssrr7xC48aNGTlyJP/++y9arZbz588zfvx4evfuTYUKFfTb7t69m6tXr5KQkMCnn35KmzZtUKlUOb4H2UlOTiY5OZmiRYuiVqs5ceIEP/30k/71YsWKERkZSUxMjMnlSK9du3asWrWKqKgowsPDM9TaM6tQoQJ9+vRh3LhxnDlzhuTkZJKSkti3b59JPRvi4uJQqVQULVoUjUbD8uXLDX6G6fdxcXHBxcWFa9eusXnzZv1rr776Kg8fPmT9+vUkJycTGxvLhQsXgNT35e7du/peA97e3jRp0oT58+cTGxuLTqfj1q1b/Prrr6a8TYSEhHDhwgVSUlJwcnLC3t4elUqlP9edO3cM7tu9e3c+/fRTQkNDEUJw5cqVDLXogkImSjMqWrQoHTt21NcoV6xYwapVq2jcuDEtWrRg7dq1+l/mhQsXolaradeunb72BuDr68vs2bOZNWsWDRs25LXXXmPnzp0Gz9mqVStCQ0MpXrw4NWrU0D8fEBDAkCFDGDt2LPXr16d9+/a57n/42Wef8dJLLzFkyBDq1avH+++/T7du3Zg2bVqG7Tp27MikSZNo0qQJycnJ+g7gxt6DzFxdXfnggw8YM2YMDRs2ZO/evbRq1Ur/euXKlQkMDMTf358GDRoQHh6eq/K8++67+Pj40Lp1awYNGkSbNm2wt7c3uP0HH3ygvwRt2LAh/v7+fP/997Rs2dLouZo2bUrz5s1p06YNrVq1wsHBIcemDoCJEyeyd+9e6tevz7Rp03j99df1r7m6uvLll19y7NgxmjRpQps2bfSdvNu2bQvASy+9ROfOnYHU36+UlBRef/11GjZsyKhRo0xqSoDUhP3BBx/QqFEjWrZsiYeHh74zerdu3bh69SoNGjRg+PDhWfZ94403aNeuHYMHD6Z+/fpMnTqVpKQkk86bn8gO51Ke6t+/Px06dKB79+7WDiXXNm3axP79+3OsWUq2SdYoJZv14MEDfv/9d3Q6HdevX2fdunX4+/tbOywpH5I3cySblZKSwocffsidO3coUqQIgYGB9OnTx9phSfmQvPSWJEkyQl56S5IkGSETpSRJkhEFro1Sp9Oh1eautUClUpi8z4UL5wCoW7dermOzhNyUJT8rLOUAWZb8KrdlsbNTGXytwLVRpqRoiYyMN75hOh4ezibv069fDwA2btya69gsITdlyc8KSzlAliW/ym1ZvLyKGHytwNUozS2/JkhJkqxHtlFKkiQZIROlJEmSETJRZuLt7Ya3t5vxDSVJshkyUUqSJBkhb+Zk8uBBtLVDkCQpn5E1SkmSJCPMlignT55M48aNad++fbavCyH46KOPCAgIICgoiEuXLpkrFEmSpOditkTZpUsX1qxZY/D1kydPEhoayuHDh5k9ezYzZswwVyi50q9fD32nc0mSJDBjG2XDhg1znCL+6NGjdOrUCYVCgZ+fH9HR0Tx48MDk1d3M5fDhg1Y9vyRJuaPT6QgLu09o6A1CQ28QGXKBOzotk6d9QJEixfLkHFa7mRMeHp5h5TcfHx/Cw8ONJkqVSoGHh3OuzqVSKU3eZ+fObwFyfQ5LyU1Z8rPCUg6QZbGE5ORkbt68ybVrV7l+/TrXr1/j2rXrXL9+nRs3rpOYmAhALeAocAw4WL8ub72ddXmKZ2G1RJndEHNTVtXTaoVZx3o3bdoaIN+Ody0sY3ELSzlAliWvxMbGEhp6gxs3rutrh6GhN7h58wZ37tw2uLYSpC4T7O9Vgi+uXcU9OYnmNWrh2adfwR/r7ePjk2H1vbTVCCVJKpyEEDx8+JDQ0OtZkmFo6A0ePjS82JlSqaRs2XJUqFDxyb9K6X6ugJtGQ9HG9VEmJ5Hcyh/7dV9j5+YGeZT0rZYoW7VqxcaNGwkMDOTChQsUKVIkXyTKDRvWATBgwBtWjkSSCh6tVsvdu3eyTYShoTeIizO8RK+DgwPly1fQJ8CKFZ8mw7Jly+e4QqYA4t6fjP2JY0T/7ytwcMjTcpltmrWxY8fy66+/EhERQbFixRg5ciQajQaA3r17I4Rg1qxZnDp1CicnJ+bOnWvSwvLmnmYtbfhifu14Xlgu8wpLOcD2ypKQkMCtWzefXCZfy5AIb9++RUpKisF93d090tUEMyZDH5+SKJW57IiTkgJ2dk8f63Tw5BgFYpq1JUuW5Pi6QqHgww8/NNfpn1n//oOsHYIkWV1kZIQ++WWuHd6/fy/HfX18ShpMhp6eRfMsRrufTlHkvRFEfb0NbdVqqU/mNtGaSA5hzGTx4mXWDkGSzE6n0xEeHpYpGV7n9u1bXLt2lcjISIP7qtXqLO2FacmwXLnyODub/6653YljuA/ohSIhAcfg9cTNmmvW88lEKUmFVHJyMnfu3HqSCG8QGno93Z3kUH2Xmuw4O7tkqBWmrxmWLl0Gtdp6qcP+yCHc3uiHIimJhL4DiPtwttnPKRNlJmFh94HUywdJyu/SutSk/3fjxnWTu9SUL58xGdapU4tixUrh5eVlUnc9S7M/sA+3IQNQpKSQMOhNYucvNtvldnoyUWZSp051IP/ezJFsS/ouNZmTYW671JQvX5GKFZ8mxSJFss67mp9vTNnv2YXbsMEoNBrihw0nbtY8sFAyl4kykxIlfIxvJEl5KK1LTXY1w9x2qUnfbli2bDkc8ribjDUpHz9OTZIj3yPugxkWS5IgE2UWFy/+Y+0QpEIoMTGRmzdDnyTB6xmSobEuNW5u7hnuHKdvM3ymLjUFVOLAwWhqv4DmxYYWTZIgE6Uk5Zn0XWoy1wxz26Um/T9Pz6L5sr3QEhy2fI3Grz7aGjUB0DRoZJU4ZKKUJBNl7lKTVjO8ffsmV6/mvkvN07bDChbpUlPQOK5dTZHJ49F5efP4p98QHp5Wi0Umykz8/ZsDcOTISStHIllDSkoKt2/fTNelJnVShrQuNQkJCQb3dXZ2zjQG+em/MmXKWrVLTUHjtHI5rh9OASB+9FirJkmQiTKLkJDz1g5BMrPsutSk/bt79zZardbgvsWKFcuSDH19a1KsWCm8vb1t9hI5Lzl9uhjXOTMBiFmwhMQ3hlg5Ipkos/j++xPWDkF6TkIIHj16lGUcctq///57YHBfhUJBmTJl9TdPCnqXmgJFCJwXzcfl43kIhYLYJZ+R2HeAtaMCZKLMom7detYOQTKBVqvl3r27BmepiY2NMbivg4MD5cqVz+ZOcuHrUlOQqEPOpyZJpZKYZStJ6tHb2iHpyUQp5VuJiYncunVTPw45fSK8deum0S412U3KUKFCRUqWLGUzXWoKEk3desQsXIpwdyepczdrh5OBTJSZLFyYOrh+woQpVo7ENkRFReY4S01OswCWKOFjMBnacpeaAkUIlPfuoitdBoDEQW9aOaDsmW0+SnOR81EWrPYwIUSmWWqu6bvUXLt2jYiICIP7qtVqypQpmy4ZVs6XXWoK2meSE4uWRafDdcJYHPZ9R+SuA2ir18jTwxeI+SgLqvHjJ1k7hAIntUvNrSyTMpjapSb9xAzpa4ayS00hptXiOnYkTps3IhwdUd67m+eJMi/J38JM5CV39uLi4rIdh2x6l5qK+oRYsWIl2aXGlmk0FBn1Do7bv0E4OREV/A0pzV+1dlQ5kolSAp52qck8Djk3XWqym7uwfPkKuLm5Z9mnMF2uSrmQkkKR4W/h+N1OhLMLUZu2kfJKU2tHZZRMlJlcuHAOKJzdhNK61BiqGebUpcbe3j7LLDWpyVB2qZFMJARuwwbjsPc7dEXciNq8A02jl6wdlUlkoswkIKAFkH9v5hiT1qUmu5rh7du3SE5ONrhv+i41mWuGskuN9NwUCpJb+WP34wmivvkWTb0XrR2RyWSizKROHT9rh2BU+i412c1SY2qXmswJUXapkcwtsd9AkgKDEHm4yJglyESZSX6YDCNzl5rMna0fP35scF+VSpXjLDUuLi4WLIlk8+LicBv1DnFjJ6Ct/QJAgUuSIBOl1WTuUvN00afU/3PTpSbzLDV26dc5liQrUcRE496nO3ZnfkF1/RoRR09ZZH0bc5CJ0owyd6lJXzu8cyd3XWrSaod169bC0dFNXiJL+ZoiKhL3Xl2x+/03tKVKE732qwKbJEEmygwcdmwl6t2hlNbpEGXKEjf1Q5K69jC4fXZdatL/e/Ag3OC+2XWpSf8vuy41ILvVSPmfIuIx7j06Y3fhHNqy5YjcuRdd+QrWDuu5yET5hMOOrRQZOxK3tOU979ymyNiR6HQ6rr/8isH5C2NiDN8dz65LTVrNsFy58rJLjVToKB4+xKN7R9SXLqItXyE1SZYtZ+2wnluBqwtfuHBOPx47Tb9+PfD2duPQoQP65zZsWIe3txvjxo3SPxcWdh9vbzd8fatl2N/fvzmP3xmCIlO7oCIhgah3h/Liiy/QtWsQ48aN4rPPlrJnzy4uXrxATEw0RYq46YfZDR48lCVLPmPnzr107tyN5ORkhg17l6+/3sacOQspV64Cffv2YObMDzIkSW9vN5PLZG+vNrlM3t5u+n6hkDrhh7e3m37ij/TvZ9rM7ml8favh7e2mX+ccYNy4UXh7u7Fhwzr9c4cOHcDb241+/TLWvHNTptx8TvmxTPb26kJXpmf9nOxO/8xLly6iAI7PX6RPkgWlTIYUuERpLob+5pUFvL1L8NJLjQkIaJv6XNlyHDhwlMuXb3D16m2KFSsOwJgx4+jXbyBNmzbH1dXVMoFLUj6S3L4D2nLlARDFvawcTd6Rswc9UbR+bVR3bmd5XlO6DBHn/srV+cypsLRRFpZygCyL8u4dFBERaF/wNVNUzyYvZw+SNcon4qZ+iHByyvCccHIi/oMZ1glIkgoA5c1QPDq2w6NbEKq/r1g7HLORifKJpK49iFnyGaGADkjyKUnMks9yvOstSbZMef0aHp1eR3XrJtoKFdGVKGHtkMxGJsp0krr2oIaDIyrg1snTMklKkgGqf//Bo2M7VHfvkNLwJaK2fWf1JWXNSXYPSken05GcnASQ7Wp7BVFUVCSjRw8H4PHjRyiVSjw8PAkLu0fx4l5s3LgtT8+3du0qnJyc6dOnv8n7BAQ04/vvT2V5fs6cGbzySlNatvQ3+VjBwevYu/c7lEolY8a8z0svNc42xj17duHx5Is9bNhwGjduavL+tk51+S88ugahfPgfya80JWrjVijkNy9lokwnLi4WIQQuLq6oVCprh5Mn3N09WL9+E5Axid2/f48JE8YY3V+j0RSYWcZv3LjOkSOHCQ7eysOH/zFmzHA2b96Z7WfZo0efLMk8N/vbKkVsDB7dOqQmyeYtidqwGfLJkhzmVDC+ARYSHZ3aedxWxkrrdDoWLPiIixdD8PLyYv78xTg4ODJixFB8fety8eIFmjRpTr16L7J8+VLi4+Px8PBgypQZFC9enG3btvDddztQqVRUqFCRmTPnARAaep0RI4YSHh5Ojx696d69FwBbtmxk377dAPTo0YOgoIwr7QkhWLp0IX/8cZaSJUvlOAtSdn788QT+/q9hb29PqVKlKVOmLJcvX+KFF+pYZH9bIFyLEDttJg67vyV6bTBkugFaWMlEmU5aooyMNLzgVWFy585tZsyYw8SJHzBt2iSOH/+BNm1eByAmJobly1ej0WgYMWIo8+YtxtPTk6NHD7N69edMmfIhGzeuZ9u23djb2xMT83TS31u3brJs2RfEx8fTp09XOnfuxtWr/7J//x5Wr/4KIQTvvPMG1au/QLVqT9dJOXnyGLdu3eSrr7YQEfGYfv26ExjYIUvcu3ZtB6BTp4yJ9r//HlC79tMuKl5e3gZnZt+5cyuHDu2jevWajBjxHm5ubrna3+YkJ4O9PQBJvfqS1LMP2NB8A/JmTjppidLdPftx1oVNyZKlqFq1OgDVq9fg/v17+tdatw4A4NatUK5fv8Z7773LoEF9+OqrtfrkUblyVWbN+oBDh/ZnuDxt3LgJ9vb2eHh44OnpyePHjwgJOU/z5i1xcnLC2dkZf/8ALlw4nyGe8+fP4e/fBpVKRfHiXtSv3zDbuDt16pYlSQJkVwHNbvKQzp278c03u1i3bhPFihVn+fKludrf1qhP/0LRxvVRXQx5+qSNvS+yRplOTEwUAPXrN7ByJJaRvolBqVSh1SbpHzs9uaQSAipWrMSqVeuy7P/xx59w4cI5fvzxBOvXryE4eOuT49qnO67yySxJpl1GP09i8vb2zjARyX//PaB4NqNDihYtpv+5Q4fO+rZaU/e3JXY/ncK9bw8U8XE4bVxP7IIl1g7JKmSNMp20GqWhmXtsUbly5YmMjODPP1NrExqNhuvXr6HT6XjwIJz69RswfPhoYmNjc5xDs27d+pw6dZzExEQSEhI4evQIdev6ZdjGz68eR48eRqvV8vDhQ/7442yuYm3SpDlHjhwmOTmZe/fucvv2bWrWrJ1lu4cPH+p/PnnyGJUqVc7V/rbC7vgPuPfphiI+jsSefYid+7G1Q7IaWaNM52miLBxdg/KCnZ0dH320gE8+WURsbCxarZYePXpTrlx5Zs2apu8p0KNHH4oUMTwErHr1GrRr15633hoApN7MSd8+CdC8eUt+//03Bg7sRdmy5ahXr362xzLURlmpUmVatfKnX7/uqFQqxo6doG8SmD9/Np06daVGjVqsXPkp//77DwqFAh+fkrz//lSj+9sa+yOHcHujH4qkJBL6DyL2408K9HySz8usY71PnjzJnDlz0Ol0dO/enaFDh2Z4PSYmhvfff5979+6h1WoZPHgwXbt2zfGY5hrrDfDZZ58we/Z0IP8uLlZYxhUXlnJA4StL/OZtuA0ZgCIlhYTBb6XWJAtgkiwQY721Wi2zZs1izZo17Nu3j71793L16tUM23z99ddUrlyZ3bt3ExwczIIFC3JcJdDccppbUpJshSIuFjQa4oe9S+y8RQUySeY1s116h4SEUL58ecqWLQtAYGAgR48epUqVKvptFAoFcXFxCCGIi4vD3d3dqp2bo6NTb+bMmbPAajFIkrUldeuJtkpVNHXr2dzdbUPM9qciPDwcHx8f/eMSJUoQHp5xaYS+ffty7do1mjVrRocOHZg6dapV145Oa6MsLMMXJclUDt9sQn3+D/1jjV99mSTTMVv1Lbumz8xdP3788Udq1qzJhg0buHXrFm+88QYNGjTIcdJblUqBh0fuhkypVEqT9klIiAOgZEnvXJ/DUkwtS35XWMoBBb8sijX/Qz3yHYSnJ+Kvy3g8mYi6oMvLz8VsidLHx4ewsDD94/DwcLy9vTNss3PnToYOHYpCoaB8+fKUKVOG69evU6eO4SFjWq0w282cx49TR+QsWDCfFi0CcnUOSyksNw4KSzmgYJfFce0qikx+H4C4UeNwKFa8wJYlswJxM8fX15fQ0FBu375NcnIy+/bto1WrVhm2KVmyJL/88guQ2rftxo0blClTxlwhGZV26X327G9Wi0GSLMVpxWf6JBk7ZwEJ7xpfO8ZWma1GqVarmT59OkOGDEGr1dK1a1eqVq3K5s2bAejduzfDhw9n8uTJBAUFIYRg/PjxFC1a1FwhGZU2XnnRok+tFoMkWYLzJ4twmTsLgJiPPyFx4GArR5S/yTVz0qlevTwRERH89dd1ihfPn+00BfkyL73CUg4oeGVRXbmM56uNQQhiPvmcpN799K8VtLLkJC8vveXInCeEEHJkjmQTtDVqErNsJSgUJD2ZAk/KmexJ+kR8fDxarRa1Ws2WLV9bOxxJyltCoLx1U/8wqUdvmSRzQSbKJ9JG5Wg0GsaPH23laCQpD+l0uE55H89WTVGHnLd2NAWSvPR+In1n806dulg5GknKIzodru+/h1PwOoSDA0o5EfEzkYnyibThi1WqVGHx4mVWjkaS8oBWS5H3RuC45WuEoyNRX20mpWVra0dVIMlE+URa16AiReRclFIhoNFQZMQwHHduQzg7E7VxKylNm1s7qgJLtlE+kdZGaWdnR1jYfStHI0nPp8iIoTju3IbOxZWoLTtlknxOMlE+kdZGefToYerUqW7laCTp+SS/1g6dpydR23aR8vIr1g6nwJOX3k+kJUpnZ2c5e5BU4CV16U5y6wCEu4e1QykUZI3yibSbOcOHj+LixX+sHI0k5VJ8PG6D+6NOt86QTJJ5R9Yon0hro5SjcqQCJzYW9/49sf/pFKorfxFx6lew0bV+zEUmyifkCoxSQaSIica9dzfsfj2NtoQP0V9tlknSDOSl9xNp3YOWLv0Yf395h1DK/xRRkbh375iaJEuVJuq7/WirVrN2WIWSrFE+kXbpffNmqHUDkSQTKB4/wr1HZ+xCzqMtW47InXvRla9g7bAKLZkon0i79P7ssy+oUaOmlaORpJypz/+B+tJFtBUqpibJMmWtHVKhJhPlE2l3vV98sSFVqlS1cjSSlLOUVgFEf7kRjV89dCVLWTucQk+2UT6Rdukt+1BK+ZXy/r0M3X+S2wXKJGkhMlE+kXbpvXbtKhYunGvlaCQpI+Wd23h0bId7906oL16wdjg2RyZKIDExkeTkZOzs7Pjkk0UsWjTf2iFJkp7yZigenV5HFXoDbcVKaEtbbwE+WyXbKHnaNcjNzY033njLytFI0lOq61dx7xKE6t5dUl5sQNSWnXLEjRXIRAnExKTeyHF1LcKECVOsHI0kpVL9+w/uXdqjCg8j5aXGRG3ahpBt6FYhL72Ro3KkfCghAffuHVGFh5HcpBmRm3fIJGlFMlFChtUXL1w4x4UL56wckWTznJyInTWXpNYBRH29DVxdrR2RTZOX3mRcLycgoAUADx5EWzMkyVYlJYGDAwDJHTqTHNQJFArrxiTJGiVknDmoTh0/6tTxs25Akk1S/3aGoo3qov7tzNMnZZLMF0yuUcbHx+Ps7GzOWKwmbVSOm5sbR46ctHI0ki2y++Un3Pp0RxkXi+OmYGIbvmTtkKR0jNYo//jjD15//XVef/11AK5cucKMGTPMHZdFpe8eJEmWZnfyOO69u6KMiyWxaw9iP/7E2iFJmRhNlPPmzWPt2rV4eHgAUKNGDc6ePZvzTgXM0zZKeddbsiy7H47g3q8Hivh4Env1JWb5KlDLWwf5jUltlCVLlsy4k7JwNW0+HeddBF/favj6yjn9JPOzP3wA9wG9UCQmkjBgMDGffC4n3c2njP7pKlmyJH/88QcKhYLk5GSCg4OpXLmyJWKzmPTdg8LDw6wcjWQzNFrQ6YgfMoy4OQvljZt8zGiinDFjBnPmzCE8PJwWLVrQpEkTPvzwQ0vEZjHpb+aEhPxt5WgkW5H8ensiDh1H+4KvTJL5nNFEeePGDRYvXpzhud9//50XX3zRbEFZWvop1nx8ShrZWpKencP2b9CWKYfm5cYAaH3rWDkiyRRGGxs/+ugjk54ryOQQRskSHDcFU+Tdobj36Yby/j1rhyPlgsEa5blz5zh37hyPHz9m3bp1+udjY2PRarUWCc5S0ncPGjduFACLFy+zZkhSIeO4fi1FJrwHQNzosXLC3QLGYKJMSUkhPj4erVZLXFyc/nlXV1eWLStcSST9pXdw8HpAJkop7zj9byWuUycCEDtzLgnvjLByRFJuGUyUjRo1olGjRnTu3JnSpUtbMiaLSvuDoFQqcXFxYdGiT60dklSIOC3/FNdZ0wCImfcxiW8Os3JE0rMwejPHycmJBQsWcPXqVZKSkvTPb9iwwayBWUr62qRCoWDAgDesHJFUWCivX8Nl3iwAYhZ9SqL83SqwjN7MGT9+PJUqVeLOnTuMGDGC0qVL4+vra4nYLCJ9H0pJyku6SpWJXr2e6E9XyCRZwBlNlJGRkXTv3h21Wk2jRo2YN28eFy4UnsWNMq++eOjQAQ4dOmDNkKSCTAiUN67rHyYHBpHUu58VA5LygtFLb/WTcafe3t4cP34cb29vwsIKz+iVzDXK/v17AnI+SukZCIHL9Mk4BX9F5Jad+r6SUsFnNFG+8847xMTEMHHiRGbPnk1cXBxTppi2rszJkyeZM2cOOp2O7t27M3To0CzbnDlzhrlz56LRaPD09GTjxo25L8VzyDxz0GuvtbXo+aVCQqfDdfJ4nNatQdjZoYx4bO2IpDxkNFG2bNkSSJ0wIjg4GEgdmWOMVqtl1qxZrFu3jhIlStCtWzdatWpFlSpV9NtER0czc+ZM1qxZQ6lSpXj06NGzluOZpQ1fTLv03rhxq8VjkAo4nQ7X8aNx2vgVwsGB6HUbSfZvY+2opDxkMFFqtVoOHDhAeHg4zZo1o1q1ahw7doxVq1aRmJjIrl27cjxwSEgI5cuXp2zZsgAEBgZy9OjRDIlyz549BAQEUKpUaufbYsWK5UGRcif9zEGSlGtaLaq3hmC3cQPC0ZGoDVtIebWVtaOS8pjBRDl16lTu379PnTp1+OijjyhdujTnzp1j/Pjx+Pv7Gz1weHg4Pj4++sclSpQgJCQkwzahoaFoNBr69+9PXFwcAwYMoFOnTs9emmcghy9Kz6PIeyNQbvka4exM1MatpDRtbu2QJDMwmCj//PNPdu/ejVKpJCkpiZdffpnDhw/j5eVl0oGFEFmeU2SaIUWr1XLp0iXWr19PYmIivXr1om7dulSsWNHgcVUqBR4euVuSQqVSGtwnKSkeAG/vYnh4OGNvn/qWJCdrcnUOS8mpLAVJYSmHokc3xPcH0W7fgUuTptYO57kVls8F8rYsBhOlnZ2dfoJeBwcHKlSoYHKSBPDx8clwdzw8PBxvb+8s23h6euLs7IyzszMNGjTgypUrOSZKrVYQGRlvchwAHh7OBvf577/URnc7O6cM2+T2HJaSU1kKksJSDpq2xuPvf4nUqaEQlKfQfC7kvixeXoab3wz2o7x+/TpBQUH6f5kfG+Pr60toaCi3b98mOTmZffv20apVxrab1q1bc/bsWTQaDQkJCYSEhFh8UuCYmKdzUUJqtyDZNUgyKCEBt8H9sfvp1NPn5GCFQs9gjXL//v3Pd2C1munTpzNkyBC0Wi1du3alatWqbN68GYDevXtTuXJlmjVrRocOHVAqlXTr1o1q1Sy7DINcWEwyWXw87gN6Y3/yGOqQCzz+5Xews7N2VJIFGEyUeTERRosWLWjRokWG53r37p3h8ZAhQxgyZMhzn+tZyYXFJJPExuLerwf2P/+IzsubqI3fyCRpQ2x+ubfM3YP69esByP6U0lOKmGjce3XF7rczaH1KErVzL9oqVa0dlmRBNp8oMw9hPHz4oDXDkfIZRWQE7r26YPfH72hLlyFyxx50lQrX4nqScSYlysTERO7du0elSpXMHY/FZU6UwcHfWDMcKZ9R/3UJ9Z8X0ZYrT+TOvejKlbd2SJIVGJ096IcffqBjx476dsTLly/z9ttvmz0wS9BqtcTGpt7McXVNvfRu06Ydbdq0s2ZYUj6S8kpTojZsJvK7AzJJ2jCjiXL58uVs375dX+OqWbMmd+/eNXtglpA+SarkwvPSE8rwMOxO/6x/nNIqAF3pMlaMSLI2o4lSpVIV2nHQ2XUN2rBhHRs2rDO0i1TIKe/fw73T67j37Iz6tzPWDkfKJ4y2UVatWpU9e/ag1WoJDQ0lODiYevXqWSI2s8tudvPx40cDyCUhbJDy9i08urRHdTOUlBfqoK1UxfhOkk0wWqOcNm0aV69exd7ennHjxuHq6srUqVMtEZvZpSXKtPZJgP79B9G//yArRSRZizL0Bh4d26UmSb96RO3YjbDCbFZS/mS0Rnnjxg3ee+893nvvPUvEY1GZhy+CXKbWFqmu/Yt7lyBU9++R0qARUVt2IORsUlI6RhPlvHnz+O+//2jbti2BgYFUrVp4OtrKhcUkkpNx79kF1f17JDduQvTXWxGuhbNNXnp2Ri+9g4ODCQ4OpmjRokybNo2goCBWrFhhidjMLrvhi2Fh9wkLu2+tkCRLs7cndv4ikloHELVpu0ySUraMJkoALy8vBgwYwMyZM6lRo0ahSZRpwxfT1yjr1KlOnTrVrRWSZCkJCfofk/3bEL1pO7i4WDEgKT8zmiivXbvGZ599Rvv27Zk9ezb16tXjxIkTlojN7LLrHlSihA8lSvgY2kUqBNR/nKVoo7rYnUr3e5xpUmlJSs9oG+XkyZMJDAxk7dq1lChRwhIxWUzawmLpE+XFi/9YKxzJAtS/nsG9VxeUsTE4bgompVkL4ztJNs9ooty6tfDOopNd9yCp8LL7+Ufc+3RHER9HYscuxCxbae2QpALCYKIcPXo0n376qcHZzPfs2WO2oCzlaRul7ApS2NmdOIb7gF4oEhJI7NYzNUmqbX7yLMlEOa7CCPDFF19YLBhLy657kL9/6ip6R46ctEpMUt6z++F73Af2QZGURELvfsQu+Qzk2H4pFwzezElbCGzTpk2ULl06w79NmzZZLEBzyi5RhoScJyTkvJUiksxCoQQhSBj4JrFLl8skKeWa0WuPn3/+OctzJ0+e5P333zdLQJb0dHbzp4ny++8Lxx196amUlq2J+P4k2ho15d1t6ZkYTJSbNm1i8+bN3L59O0M7ZVxcHPXr17dIcOaWXT/KunULx4Qfts5h1w507h6ktGwNgLZmLStHJBVkBhNlUFAQzZs3Z8mSJYwbN07/vIuLCx4eHpaIzayEEPp+lOlrlFLB5/DNJoqMHg729jw+eQZdBcPrxEuSKQwmSoVCQZkyZZg+fXqW1yIjIwt8soyLi0Or1eLk5IRdutX0Fi6cC8CECVOsFZr0HBy/3oDr2JEohCBu9DiZJKU8YTBRjhs3jlWrVtGlSxcUCgVCCP1rCoWCo0ePWiRAc8mufRJg0aL5gEyUBZHjujUUmTgWgNgPZpIwqvDNeCVZh8FEuWrVKiB1zZzCyNDMQePHT7JGONJzclq9AtcPUj+72FlzSXh7hJUjkgoTo3e9f//9d2rWrImzszPfffcdf/31FwMHDqRUqVKWiM9sshu+CLImWRAp797B5aMZAMTMX0zi4LesG5BU6BidFGPGjBk4OTlx5coV1qxZQ6lSpZgwYYIlYjMrQ5feUsGjK12GqK82E7N0uUySklkYTZRqtRqFQsGRI0cYMGAAAwcOJC4uzhKxmdXTmYMyDl+8cOEcFy6cs0ZIUm4Igerqv/qHKS1bk9h3gBUDkgozo4nSxcWFVatWsXv3bl599VW0Wi0ajcYSsZmVoTbKgIAWBATIGWXyNSFwmTUdz5avYHesYN9UlAoGo4ly6dKl2NvbM3fuXLy8vAgPD+fNN9+0RGxmZWjmoDp1/KhTx88KEUkmEQKXaZNw/vxT0GpRxMZaOyLJBhi9mePl5UVQUBAXL17k2LFj1KlTh06dOlkgNPPKbmExkJNh5Gs6Ha6TxuG0fi3C3p7oNRtIbvu6taOSbIDRGuX+/fvp3r07Bw8e5MCBA/qfCzq5sFgBo9XiOm5UapJ0cCBqw2aZJCWLMVqj/OKLL9i+fTvFnqxx/PjxYwYNGkTbtm3NHpw5PU2Uci7KgsB14jicvt6AcHIiasMWUlq0tHZIkg0xWqMUQuiTJICHh0eGUToF1dMVGDPWKH19q+HrW80aIUk5SOrQCV2xYkRt3iGTpGRxRmuUTZs25c033yQwMBBIvRRv3ry52QMzt9jYrAuLAYSHh1kjHMmIlOav8ui3i+Dqau1QJBtkNFFOnDiRw4cP8/vvvyOEoGfPngQEBFgiNrMy1EYZEvK3NcKRMktKwm34WyT26Udy69dSn5NJUrISg4kyNDSUBQsWcPv2bapVq8bEiRML1SqMaUMYixTJ2D3Ix6ekNcKR0ktIwH1QH+yPHUV99lcenzkPjo7WjkqyYQbbKKdMmULLli1ZtmwZtWvXZvbs2ZaMy+yeDmGUN3Pylbg43Pv1wP7YUXTFixO1abtMkpLVGaxRxsXF0aNHDwAqVapE586dLRaUuQkhDF56jxs3CoDFi5dZPC5bp4iNwa1Pd+xP/4zWuwRRO/agrV7D2mFJkuFEmZSUxF9//aW/w52YmJjhce3atS0ToRkkJiaSkpKCvb09jplqK8HB6wGZKC1NER2Fe6+u2J39FW3JUkTt3IO2clVrhyVJQA6J0svLi3nz5ukfFy9eXP9YoVCwYcMG80dnJjl1Nl+06FNLhyMBqn//QX3pItoyZYncsQddxUrWDkmS9AwmyuDgYEvGYVGxsYanWBsw4A1LhyMBmhcbErVpO9py5dGVLWftcCQpA6Mdzp/HyZMnadOmDQEBAaxevdrgdiEhIdSsWdNiQyPlqJz8QfHgAXbHn86gn9KkmUySUr5ktkSp1WqZNWsWa9asYd++fezdu5erV69mu92iRYto2rSpuULJ4umonCJZXjt06ACHDh2wWCw26949PDq/jnu/HtidkmupS/mb0Q7nzyokJITy5ctTtmxZAAIDAzl69ChVqlTJsF1wcDBt2rTh4sWL5golC0PDFwH69+8JwIMH0RaLx9Yo795B3b0DiqtX0dSsjaaGXHNbyt9MGuv93XffsXz5cgDu3btHSEiI0QOHh4fj4+Ojf1yiRAnCw8OzbHPkyBF69eqV27ifS1ofyuxu5rz2Wltee61gT/iRnylv3cSj4+sorl4l5YU6RO7ci/DysnZYkpQjozXKGTNmoFQqOX36NCNGjMDFxYWRI0eyY8eOHPfLbuIMhUKR4fGcOXMYP348KpXK5IBVKgUeHs4mb5+6jzLDPikpCQB4eRXLcqy9e/fm6tiWlrksBcrVq6g7v47i9m1Ew4awdz/unp7Wjuq5FejPJBNZluwZTZQhISF8++23+sl63d3dSUlJMXpgHx8fwsKeTjARHh6Ot7d3hm3+/PNPxo5NXYc5IiKCEydOoFar8ff3N3hcrVYQGRlv9PzpeXg4Z9gnPPwhAPb2Trk+lrVlLkuBodHgGdQexe3bpDR8CfbvJ1LYQUEsSyYF9jPJhi2Xxcsr6z2LNEYTpVqtRqvV6muDjx8/Rqk0fg/I19eX0NBQbt++TYkSJdi3bx+LFy/OsE36NcMnTZrEq6++mmOSzCuGFhaTzEitJnbRpzh/tpToNV/h7u5eKJKkZBuMJsr+/fvz7rvv8ujRI5YuXcrBgwcZM2aM8QOr1UyfPp0hQ4ag1Wrp2rUrVatWZfPmzQD07t37uYN/Vjm1UXp7pz4nb+bkkfh4cE69/Elp0oyoV5pCpiYYScrvjCbKDh06ULt2bU6fPo0QghUrVlC5cmWTDt6iRQtatMi4oqGhBDl//nyTjpkXcuoeJOUddch53Pp0J3bJMpJfa5f6pEySUgFkNFHeu3cPJycnWrZsmeG5UqVKmTUwc8qpe5CsSeYN9e+/4d6zC8roKBy/2fw0UUpSAWQ0UQ4bNkz/c1JSEnfu3KFixYrs27fPrIGZk6EVGKW8oT5zGvfeXVHGxpAU2IHolWusHZIkPRejiXLPnj0ZHl+6dIlvvvnGbAFZghzCaD52P53CvW8PFPFxJHbuSszy1WBnZ+2wJOm55HoIY+3atS06isYccpo9qF+/HvTr18PSIRUKdieO4d6nW2qS7N6LmBVrZJKUCgWjNcp169bpf9bpdPz1118ULVrUrEGZW9rCYtm1UR4+XPDXLLcW4eAICgUJfQcQu+hTyMVAAknKz4wmyri4OP3PKpWKFi1a0KZNG7MGZU4pKSkkJCSgUqlwds7aaz84uGA3K1iT5uXGRBw+gbZKVTChr60kFRQ5JkqtVktcXBwTJ060VDxml75rUOYhlQBt2si7s7lhv2cXqNQkv94eAG216tYNSJLMwGCi1Gg0qNVq/vrrL0vGY3Zpqy/KGznPz2HHVoqMGAZKJRHHfpZJUiq0DCbK7t278+2331KzZk3efvtt2rZtm+FS9bXXXrNIgHnt6eqL2XcN2rAhtU1WznSeM4ctX1Nk9HAUQhA3ZjzaqtWsHZIkmY3RNsqoqCg8PT05c+ZMhucLaqLM6Y43wPjxowGZKHPiGLwe1/GjU5Pk5GnEv/e+tUOSJLMymCgfPXrEunXrqFq1KgqFIsO0adm17RUUTyfEyD5R9u8/yILRFDyOa1dTZPJ4AGKnzyZhxGgrRyRJ5mcwUep0ugx3vAuLtDZKQ5fecplawxQPHuAyZyYAsR/NJ2HocCtHJEmWkeNytSNGjLBkLBaR08xBUs6EtzfRm7ah+udvEmXThGRDDHZ2y26G8sIgpwkxAMLC7hMWdt+SIeVvQqD6+4r+YcrLr8gkKdkcg4ly/fr1FgzDcowlyjp1qlOnjuzmAoAQOM+bjWfLV7Dfn7+XyJAkczJ46e3h4WHBMCzH2KV3iRI+2T5vc4TAZcYHOK/8DKFSoUhKtHZEkmQ1ZluuNr8y1j3o4sV/LBlO/iQELlMn4LxmFUKtJnrVOpKDOlo7KkmyGptLlPJmjhE6Ha4TxuK04UuEvT3Ra4NJlsM6JRtnc4nyaRulHMKYHZdpk1KTpIMDUV9tIqVVgLVDkiSrs7kpXozVKP39m+Pv39ySIeUrSR27oivuRdTX22SSlKQnbLhGmf3CYiEh5y0YTT4hhH7RL02jl3h09qJ+5URJkmw4URqqUX7//QlLhmN9yckUGf4WSR07kxzUKfU5mSQlKQObSpSp82vGolAocHXNvkZZt249C0dlRYmJuA0ZgMPhg9j/fIpHLf3B1dXaUUlSvmNTiTKtfdLVtQhKW5+BOyEB94G9sT/+A7qiRYn65luZJCXJABtLlDnPHASwcOFcACZMmGKRmKwiLg73/j2x//EkuuJeRG7fjbZWbWtHJUn5lk0lSmPtkwCLFs0HCm+iVMTG4NanO/anf0ZbwoeoHXvkzOSSZIRNJUpjs5sDjB8/yVLhWIUyNBT1nxfRlipN1M49aCtVsXZIkpTv2VSifDoXZfY3cqDw1iTTaF/wJWrrt+iKe6GrUNHa4UhSgWBTdzRMufQujBQPH2J/+ID+saZBI5kkJSkXbDJR5jR88cKFc1y4cM5SIZmd4sEDPLoE4jawD/bfH7R2OJJUINnUpbcpE2IEBLQA4MGDaIvEZE7KsPu4dw1C/e8/aKrXIKWODfURlaQ8ZGOJ0nj3oDp1/CwUjXkp797BvUt71Deuo6lZm8jtuxFeXtYOS5IKJJtKlMYWFgM4cuSkpcIxG+XNUDy6BqG6dZOUOn5Ebf0WUbSYtcOSpALLJtsoC/XNHJ0O94F9UpNk/ReJ2rFbJklJek42lShN6UdZ4CmVxCz+lKTWAURt+w7h7mHtiCSpwLOxS2/jNUpf32pAAVwSIjZWP1Zb82JDojfvsHJAklR42FSN0tgKjADh4WGEh4dZKqQ8ofrzIsVe8sNhl0yOkmQONpUoTekeFBLyNyEhf1sqpOemvnAOjy6BKP97gMPObamT8EqSlKds6tLblO5BPj4lLRXOc1Of/RX3Xl1RRkeR1DaQ6P+t189ULklS3rGZGqUQolDdzFGf/gX37p1Sk2RQJ6LXbgAHB2uHJUmFklkT5cmTJ2nTpg0BAQGsXr06y+u7d+8mKCiIoKAgevXqxZUrV8wWS1xcLDqdDmdnF9RqwxXpceNGMW7cKLPFkRfsfjqFR6/OKONiSezSnehVX4KdnbXDkqRCy2yJUqvVMmvWLNasWcO+ffvYu3cvV69ezbBNmTJl2LhxI3v27OGdd95h2rRp5grH6KJiaYKD1xMcvN5sceQF4eqKUNuR2KsvMZ+vhhwSvyRJz89s37CQkBDKly9P2bJlAQgMDOTo0aNUqfJ0/sP69evrf/bz8yMszHx3m03tbL5o0admiyGvaOrWI+Lw8dQZgGx9SQtJsgCzJcrw8HB8fHz0j0uUKEFISIjB7bdv307z5uZbT9vURDlgwBtmi+F52O/bgyIhHoakxqerVNnKEUmS7TBbohTZdFNRGLgje/r0abZv386mTZuMHlelUuDhkbvlVFUqJTpdIgBFi3rmen9rU2zbhmrIABAC0ag+HnXqWjuk56ZSKQvc52CILEv+lJdlMVui9PHxyXApHR4ejre3d5btrly5wgcffMD//vc/PD09jR5XqxVERsbnKhYPD2fCwh4C4OTkmuP+hw6lTnDbpk27XJ3DXBy2baHIyLdR6HTEjxqLnW+dXJc/P/LwcC4U5QBZlvwqt2Xx8jJ8/8JsidLX15fQ0FBu375NiRIl2LdvH4sXL86wzb179xg5ciQLFy6kYkXzzrht6qV3//49gfwxH6XD5o0UGfMuCiGIGz+J+Pcn4yH7SUqSxZktUarVaqZPn86QIUPQarV07dqVqlWrsnnzZgB69+7N559/TmRkJDNnzgRApVKxc+dOs8RjyvBFgNdea2uW8+eW41dfUuT9MQDETZ5G/HvvWzcgSbJhZu1X0qJFC1q0aJHhud69e+t/njNnDnPmzDFnCHoxMcYXFgPYuHGrJcLJkSLiMS5zU/94xH74EQnv5u9+nZJU2NlMB7yCNBel8CxK1Dffoj73B4lvDLF2OJJk82wwURpeWMzaVH9dQlurNgAav/po/Oob2UOSJEuwmd7Kpo7z9vZ2w9vbwrVOIXD+eB6eLV/BYfs3lj23JElG2UyN0pSZg6xCCFzmzsL508UIpVJOkyZJ+ZDNJEpT2ygt2i1ICFw+nIrzF8sRKhUxK9eQ1Kmr5c4vSZJJbChRGl+B0aKEwHXK+zitXY2wsyN69XqSA4OsHZUkSdmwmUSZ3+aidJn9YWqStLcn+stgkl/LHyOBJEnKyiZu5gghTL707tevB/369TB7TEmdu6L1KUnUhi0ySUpSPmcTNcqEhAQ0Gg0ODg44GJkF/PDhg+YLRAj9Ug0a37o8PnMenJzMdz5JkvKETSTKqCjT2yeDg83UPSclhSLvvkVyqwCSevVNfU4mSUkqEGwiUeZmVI5ZZg1KSsLtrUE4HNyH/fEfSG4XiHD3yPvzSJJkFjaSKFNrlFbpQ5mYiNvgfjgcOYzOw4OorbtkkpSkAsYmEuXTS2/jwxc3bFgH5NFM5/HxuA/ojf3JY+iKFSNy63dofes8/3ElSbIoG0mUpi0sBjB+/GggDxJlbCzu/Xti/9MpdF7eRG7fjbZmrec7piRJVmETiTI3l979+w/Kk3Oq7t9DffkS2hI+RO3ci7ZqtTw5riRJlmcTiTLt0tuURLl48bI8Oae2ajWitn2HzsVVLgQmSQWcTXQ4z033oOehePwI+7279Y81vnVlkpSkQsAmEmXa8EVT5qIMC7tPWNj9XJ9D8d9/eHQJwu3N/tjv/jbX+0uSlH/ZyKW36f0o69SpDuRuFiFFeDge3YJQ/30FTZWqaBq+9GyBSpKUL9lIojS9jbJECZ9cHVt5/x7uXdqjvnYVTfUaRG7fgyhR4pnitDVarYaIiP/QaJKtHcpzCQ9XZLuOfUFkC2VRq+3x9PRCpTI9/dlEoky76+3qarx70MWL/5h8XOWd23h0aY8q9Aaa2r5EbvsOUbz4M8dpayIi/sPR0RkXFx8UBXgZXpVKiVars3YYeaKwl0UIQVxcNBER/1G8eEmTj2UTbZS5ufQ2mRC4vdkfVegNUurWI3LnHpkkc0mjScbFxa1AJ0mpYFEoFLi4uOX6KsZGEmXapXceLiymUBCzZDlJ/q8Rtf07hGfRvDu2DZFJUrK0Z/mds4lEmZsO5/7+zfH3b27wdUXM05s82tovEL1puxy7XYA1b96IQYP60L9/DyZMeE+/thLA9evXGDXqbXr16kKvXp1Zv35NhjavX375iTff7E+vXl3o06cry5d/YoUS5Oyff64wf/5sa4dhUHJyMtOnT6Znz0689dZA7t+/l+12R48eZuDAXvTr14MVKz7VP3/+/B8MHtyXFi1e4tixI/rnIyIiGDPm3TyL00YSpemzm4eEnCck5Hy2r6ku/4Vn4xdx/HpDXoYnWZGDgwPr128iOHgrbm5u7Ny5FYCkpEQmTRpLv36D2LJlJ+vXb+bixRB27twGwPXrV1m6dCHTp89my5adbNjwDaVKlc7T2DQazXMfY8OGdXTt2tOi58yNvXu/o0iRInzzzS569uzDypWfZdkmKiqSzz//lE8+WcnGjVt5/PgxZ8/+CqTefJ0yZQb+/m0y7OPp6Unx4sUNfpdzq9DfzElOTiYxMRG1Wo2TCfM/fv/9iWyfV10MwaN7B5SPH+OwZxeJvfuB0ib+ztiMF17w5erVqwB8//1BfH3r0qjRywA4OjoyduwERo4cRteuPfj66w0MGDCY8uUrAKBWq+nSpXuWY8bHx/PJJx9z5cpfKBQK3njjLV59tTUBAc34/vtTABw7doSff/6RqVNnMGfODNzc3Pjnn7+pWrUaJ08eZ926Tfp5Cnr27MTKlWtRKJQsWjSX8PBwAEaNGkudOn6Zzh3HtWv/UvXJ8Nm//vqTZcuWkJSUiIODI1OmTKdcuQrs37+Hn3/+keTkZJKSEpg/fylLly7k+vVraLUaBg8eSrNmr3L//j1mz55OYmICAO+9NwFf37rP9Z7/+OMJBg8eCsCrr7Zm6dKFCCEyXB7fu3eXsmXL4+npCUCDBo04fvwHGjRoRMmSpQBQZvNdbN68JYcPH8zyvjyLQp8o089FaUrbRN269bI8pz7/B+49OqGMjCQpoA3Ra4Nlksxjffp048iRw3l6TH//19i0abtJ22q1Ws6e/Y327TsCcOPGdapXr5lhm9KlyxAfH09cXCw3blyjV69+Ro+7fv0aXFxc2bAhdULotN/HnNy+fYtPPlmBSqVCpxOcPHmMwMAOXLr0Jz4+pShatBgzZkylR4++1K3rR1hYGOPGjeDrrzOW9cqVy1RKNzKsfPkKLF++GrVazW+/nWHVqs+ZM+djAC5dushXX23G09OTFSs+48UXGzJlyofExMTw1lsDadDgJTw9i7J06ec4ODhw+/YtZsyYytq1wVniHz58CPHx8Vmef/fd0TTM1Mf4v/8e4O2d2p1OrVbj4uJKVFQUHh4e+m1Kly7LrVuh3L9/Dy8vb06dOk5KivGab40atVi16nOj25nCBhJlWtegZ7vjrf7tDO69uqKMiSapXXui/7ce7O3zMELJmpKSkhg0qA9hYfeoXr2m/oucuVaTXm5uBpw9+yszZ87VPzalnbxlS39UKhUArVsHsG7dGgIDO3D06CFatw7QHzc09IZ+n7i4OOLj43B2dtE/9/DhQzw8PPWPY2Nj+eijGdy5cwuFQpHhMrthw5f0Nzt//fU0P/54gs2bNwKQnJxEeHgYxYt7sXTpAv799x+UShW3b9/MNv4VK9YYLWOa7LpsZn573dzcGDduEtOnT0apVPLCC3W4d++u0WMXLerJw4cPTY4lJ4U+UT4dvmhaoly4MPWXesKEKahP/4J7764o42JJ7NCZmJVrwM7ObLHaMlNrfnktrY0yNjaWCRPGsHPnNrp370XFipU5f/6PDNvevXsHZ2dnnJ1dqFixEn//fVl/WWuYoYT79Lnk5IxdVRwdHfU/v/BCHe7evU1ERASnTp1g4MA3U48qdKxa9SUODo4Y4uDgkOHYa9Z8Qf36DZg3bxH3799j5Mhh2Z5TCMGcOQspV65ChuOtXbsKT89irF+/GZ1OR+vWTbI9b25qlN7e3jx4EI63dwk0Gg1xcbHZ9k5p2rQ5TZum3mT97rudqFTGr+iSkpKNrpFlqkJ//ZibZSAAFi2az6JF8wEQHh7g6EBi1x7EfLFWJslCzNXVlTFjxrN5czAajYbXXmtLSMgFfvvtDJB6c+fTTxfRp09/AHr3HkBw8Dpu3UqtVel0OrZs2ZjluA0bvsyOHVv1j9N+H4sWLUpo6A10Oh0nTx4zGJdCoaB585YsX76E8uUr4P6kh0Xm4/77799Z9q1QoSJ37tzWP46NjcXLywuA/fv3GDznSy81Zvv2b/R3+P/55woAcXGxFCtWHKVSyaFD+9Fqtdnuv2LFGtav35TlX+YkCdCkSXMOHNgLwPHjR6lfv2G2f1giIh4Dqe/ft99up337TgbjT3P79k0qVsybSWlkosxk/PhJjB8/CQBtjZpEHDxGzPJVoC70lW+bV61aDapUqcaRI4dwcHBk/vzFfPXVWnr37sKAAb2oUaOW/g5ylSpVGTVqHDNmTKVXry4MGNCTR48eZTnmwIFvEhMTTf/+PRg4sDfnzp0F4O23RzBhwhhGjXqbYsVyHqjQunUAhw4doHXr1/TPjRnzPleuXH7SZaY7u3btyLJf+fIViIuLJT4+DoC+fQfwxRef8847g9HpDI++GTToTTQaDQMH9qJ//x6sWfMFAJ07d+fgwb0MHTqI27dvmXRz1Jj27TsSFRVFz56d+Oabr3n77RHp4uij//mTTxbRr193hg9/k379BlKuXHkALl++ROfOr3Ps2BE+/nhehqWmf//9LK+8kn2tN7cUooAN7ExJ0RIZmbVab8iWLV8zatQ7dO/ei88/X210e/vDB1Dev0/iwMHPE6bZeHg456r8+ZWHhzNXrlzGx6e8tUN5bvl52N8333yNs7MLQUGdTNo+P5clt0aMeIu5cxdnW0kKC7uZ5XfPy8vwEOdCX6PMTRul/b49uL3RjyLvj0H95JJLkgqyTp26YWeDTUYRERH06tUvz4YtF/rrSVMvvR127aDIO0P4Q6slsVtPqjVoZInwJMmsHBwcaNs20NphWJynpyctWrTMs9pxoa9RpiXKnLoHOWzbQpG330Sh1dIAaLr9m6x9FCRJslmFvkZp7NLbcVMwru+NQCEEcROmUOfgPtJ33ZAkSSr0iTKnS29FbAzOc2ehEILYqR+SMHocR57c8ZYkSUpjA4nS8MxBwrUIUdu+w+7nH0l8c6ilQ5MkqYAo9IkybdqsIkWe9vZXX7yA5slgfm3NWmhr1rJKbJL1NW/eiEqVqqDVaihZsjTTps3ST0DxPPbv38OVK38xduzEPIhSsrZCfzMncxul89KP8WzdDMevvsx2e1/favj6GhuWJhUWhqZZk6T0Cn2NUt9GWaQIzgvm4LJ4AUKhQBgYAxoeHmbJ8KR8JP00azlNSfbjjydJTEzk3r07NG/+KiNHvgfAvn27CQ5eT/HixSlbtpy+/2JY2H3mzZtFZGQEHh6eTJ78IT4+PsyZMwMHBwdu3gwlLCyMKVOmc+DAXi5dukitWi8wdeqMLDH+8suPfPbZUtzdPahevQb37t1l4cJPWLt2FU5Ozvohlv3792Dhwk8oWbIUhw7tZ/v2LaSkaKhVqzbjxqW2w8+fP1s//VtgYAd69uzL1q2b+fbb7ahUKipUqMjMmfMs8M7nf2ZNlCdPnmTOnDnodDq6d+/O0KEZ2wFTB9/P4cSJEzg6OjJ//nxq166dpzGkJcryXyzHZdUKhEpFzPJVJHXtke32ISFZx8xKluHlbbgLV8yiT0kc8AYAjhvWUWT8aIPb/peLpYbTZJ5mLacpyf799x/WrfsaOzs7+vTpSo8evQEla9euYu3ajbi6ujJq1DCqVk1d+njJkoW0bRtIu3bt2bv3Oz799GPmzVucWq6YaJYt+4IffzzBxIljWblyLRUrVmLIkAH8++/f+mNA6kxHH388j+XLV1OqVGk+/HCK0XKFht7g6NHvWbnyS9RqNYsWzefw4QNUrFiZ//57QHDw1idxpDZRBQevY+vW3djb22eY7d3WmS1RarVaZs2axbp16yhRogTdunWjVatWVKlSRb/NyZMnCQ0N5fDhw1y4cIEZM2awbdu2PItBo9EQHx/HUsBj1QqEWk30qi9JzmE4l4+P6SuzSQWfoWnWcpqSrEGDhri6ugJQoUIlwsLu8/hxBPXqvaifXLZVq9f005BduhTC3LmpSbZt20BWrlymP1aTJs1RKBRUqlSFokWLUrly6vejYsVK3L9/P0OivHUrlFKlSutnUg8IaMPu3d/mWL7ff/+Vv/++zJAhA56UNxFPT0+aNGnOvXt3Wbp0IY0bN9VPUFy5clVmzfqAZs1epVmzV5/tTS2EzJYoQ0JCKF++PGXLlgUgMDCQo0ePZkiUR48epVOnTigUCvz8/IiOjubBgwd4e3vnSQwxMdHMAsYAws6O6DUbSG5ne6MUCgpTa4KJA97Q1y6fl6Fp1nKakiz9kMDUsdGps+iYOk9l+u3SjqVUKjMcV6lUotVmnJw2p2kZVCoVQjwdhZI2vZoQgnbt2meYbCLN+vWb+fXXX9i5cxs//PA9U6Z8yOLFy/jjj9/58ccTrF+/huDgrajlhDDmS5Th4eH4+PjoH5coUYKQkJAct/Hx8SE8PDzHRKlSKfDwcDYximS2KBS8qVbjvX0Hzu1ex9ie77zzNgArV35h4jksS6VS5qL8+ZdKpUShUJg0r6AlYnF3d2Ps2AlMnDiWbt26ExcXR4kSJVCplBw8uFe/nVKpyDZuX19fli1bRGxsNC4uLhw/foQqVaqhUinx9a3LDz8cpl279hw8eJA6derpy69UKlGplFnej/SvpalYsRL37t3lwYMwSpYsxQ8/HNHHVbp0aX766RQqlZK//77M/fv3UKmUNGr0MhMmvEfv3v0oWrQoUVFRxMfH4eTkhJ2dHa1bB1C2bDk++uhDFIrU72TDho2oV68e339/iOTkJBwcCu5E1YZ+vxSK3OQRMybK7P76Zf6La8o2mWm1Ihez59gzc+su/itXCruK1cGE/dauTZ2ded68JSaew7IK0+xBQoh8MVNNWgxVqlSjcuWqHDp0kD59+vPRRzPYvDmY+vUb6rfT6US2cXt6FuONN4YyZMggihcvTtWqNdDptGi1OkaPHs+8ebP4+usN+ps5Wq0OIQQ6nQ6tVqd/nHbc9K+lsbOzZ+zYiYwZ8y7u7h7UqlVbv0/z5i3Zv38v/fv3ombNWpQtWw6tVke5chV46613GD16OELoUKnUjB07EQcHB+bNm4lOl/odHDbsXVJSNMyY8QGxsTEIIejRow/Ozi754jN6FjnNhCRE1jyS0+xBZptm7dy5cyxfvpy1a9cCsGrVKgCGDXt6CTN9+nQaNWpE+/btAWjTpg3BwcE51ihzO80a5C65bNiwDoABeXRpl9cKU6KU06zlXnx8PM7OqX9kFi9eQNmyZenZs2+eHb8wTbOWU1lyO82a2WqUvr6+hIaGcvv2bUqUKMG+fftYvHhxhm1atWrFxo0bCQwM5MKFCxQpUiTP2iefVX5NkJIEsGfPtxw4sA+NJoWqVavTsWNXa4dkE8yWKNVqNdOnT2fIkCFotVq6du1K1apV2bx5MwC9e/emRYsWnDhxgoCAAJycnJg7d66Ro0qSbevZs2+e1iAl0xT6Gc4hd5erhw4dAKBNm3a5js0S5KV3/mMrl6sFTYG49C6o+vdPXRPlwTN0WpZyL6dlYSXJHJ6lbigTZSavvdbW2iHYDLXanri4aFxc3GSylCxCCEFcXDRqde66PMlEmcnGjXJSBEvx9PQiIuI/YmMjrR3Kc1EoFM9US8mPbKEsarU9np5euTqWTJSS1ahUaooXL/hDRgtLuzHIshhi/WERkiRJ+ZxMlJl4e7vhncMsNpIk2R6ZKCVJkowocP0oJUmSLE3WKCVJkoyQiVKSJMkImSglSZKMkIlSkiTJCJkoJUmSjJCJUpIkyYhClShPnjxJmzZtCAgIYPXq1VleF0Lw0UcfERAQQFBQEJcuXbJClMYZK8fu3bsJCgoiKCiIXr16ceXKFStEaRpjZUkTEhJCzZo1OXjwoAWjyx1TynLmzBk6duxIYGAg/fr1s3CEpjFWjpiYGN5++206dOhAYGAgO3bssEKUppk8eTKNGzfWr5KQWZ5950UhodFoROvWrcWtW7dEUlKSCAoKEv/++2+GbY4fPy7efPNNodPpxLlz50S3bt2sFK1hppTj999/F5GRkUKI1DLlx3IIYVpZ0rbr37+/GDJkiDhw4IAVIjXOlLJERUWJdu3aibt37wohhHj48KE1Qs2RKeVYuXKlWLhwoRBCiEePHomGDRuKpKQka4Rr1K+//ir+/PNPERgYmO3refWdLzQ1yvTL49rb2+uXx03P0PK4+Ykp5ahfvz7u7u4A+Pn5ERYWZo1QjTKlLADBwcG0adOGYsWKWSFK05hSlj179hAQEECpUqUA8mV5TCmHQqEgLi7uyZRkcbi7u+fbJWsbNmyo/y5kJ6++84UmUWa3PG54eHiO26Qtj5ufmFKO9LZv307z5s0tEVqumfqZHDlyhF69elk6vFwxpSyhoaFER0fTv39/unTpwq5duywcpXGmlKNv375cu3aNZs2a0aFDB6ZOnYpSWTBTRV595/Pnn4lnIMy0PK6l5SbG06dPs337djZt2mTusJ6JKWWZM2cO48ePR6VSWSqsZ2JKWbRaLZcuXWL9+vUkJibSq1cv6tatS8WKFS0VplGmlOPHH3+kZs2abNiwgVu3bvHGG2/QoEEDXF1dLRVmnsmr73yhSZQ+Pj4ZLkHDw8OzrOiYeZuwsDCrr/qYmSnlALhy5QoffPAB//vf//D09LRkiCYzpSx//vknY8eOBSAiIoITJ06gVqvx9/e3aKzGmPr75enpibOzM87OzjRo0IArV67kq0RpSjl27tzJ0KFDUSgUlC9fnjJlynD9+nXq1Klj6XCfW1595wtmfTob6ZfHTU5OZt++fbRq1SrDNq1atWLXrl0IITh//ny+WB43M1PKce/ePUaOHMnChQvz1ZcwM1PK8sMPP+j/tWnThg8//DDfJUkwrSytW7fm7NmzaDQaEhISCAkJoXLlylaKOHumlKNkyZL88ssvADx8+JAbN25QpkwZa4T73PLqO19oapSFZXlcU8rx+eefExkZycyZMwFQqVTs3LnTmmFny5SyFBSmlKVy5cr6dj2lUkm3bt2oVq2alSPPyJRyDB8+nMmTJxMUFIQQgvHjx1O0aFErR569sWPH8uuvvxIREUHz5s0ZOXIkGo0GyNvvvJxmTZIkyYhCc+ktSZJkLjJRSpIkGSETpSRJkhEyUUqSJBkhE6UkSZIRMlFKJqlZsyYdO3bU/7tz547BbevVq/fc55s0aRKtWrWiY8eOdO7cmXPnzuX6GFOnTuXq1asAfPHFFxley6shk2nvS/v27Xn77beJjo7OcfvLly9z4sSJPDm3ZEHPNJWGZHP8/PzMsq0hEydO1M8kdOrUKdG+ffvnOl5exGTsuBMmTBArVqzIcfsdO3aImTNnmiUWyXxkjVJ6JnFxcQwcOJDOnTsTFBTEkSNHsmzz4MED+vbtq69xnT17FkgdS9yzZ086d+7MqFGjiIuLy/FcDRs25NatWwCsW7eO9u3b0759e9avXw9AfHw8Q4cOpUOHDrRv3579+/cD0L9/fy5evMiiRYtITEykY8eOjBs3Dnha6x0zZkyGGt6kSZM4dOgQWq2WBQsW0LVrV4KCgtiyZYvR98TPz08/4UJISAi9evWiU6dO9OrVi+vXr5OcnMyyZcvYv38/HTt2ZP/+/cTHxzN58mS6du1Kp06dsn0fpXzA2plaKhhq1KghOnToIDp06CCGDx8uUlJSRExMjBAidc5Cf39/odPphBBPa1lr167V17A0Go2IiYkRjx49En369BFxcXFCCCFWrVolPvvssyznS1+j3L9/v+jWrZu4ePGiaN++vYiLixOxsbHi9ddfF5cuXRIHDx4UU6dO1e8bHR0thBCiX79+IiQkJENMadIeHz58WEyYMEEIIURSUpJo3ry5SEhIEFu2bBGff/65/vnOnTuLW7duZYkz7TgajUaMHDlSnDhxQgghRExMjEhJSRFCCPHTTz+JESNGCCGy1igXL14sdu3aJYRInc/ytdde0783Uv5RaIYwSubl6OjId999p3+ckpLCkiVL+O2331AqlYSHh/Pw4UO8vLz02/j6+jJlyhQ0Gg3+/v7UrFmTY8eOcfXqVf3wxZSUFPz8/LI958KFC1m5ciVFixZlzpw5/PLLL/j7++Ps7AxAQEAAZ8+epVmzZixYsICPP/6Yli1b0qBBA5PL1bx5cz766COSk5M5efIkDRo0wNHRkZ9++om///6bQ4cOAamzft+8eZOyZctm2D+tpnr37l1q165NkyZN9NtPnDiRmzdvolAoSElJyfb8P/74Iz/88ANffvklAElJSdy/fz/fjRG3dTJRSs9kz549PH78mJ07d2JnZ0erVq1ISkrKsE3Dhg3ZuHEjJ06cYMKECbz55pu4ubnRpEkTlixZYvQcEyZMoG3btvrHP//8c7bbVaxYkZ07d3LixAkWL15MkyZNGDFihEnlcHBwoFGjRpw6dYoDBw4QGBgIpE7P9cEHH9CsWbMc90/7AxITE8OwYcP4+uuvGTBgAJ9++ikvvfQSn3/+OXfu3GHAgAEGj7Fs2TIqVapkUrySdcg2SumZxMTEUKxYMezs7Dh9+jR3797Nss3du3cpVqwYPXr0oGvXrly6dAk/Pz/++OMPbt68CUBCQgI3btww6ZwNGzbkyJEjJCQkEB8fz5EjR2jQoAHh4eE4OTnRsWNH3nzzTf76668s+6rVaoO1usDAQHbu3MnZs2dp2rQpAE2bNmXz5s36fW7cuEF8fLzB2IoUKcIHH3zAl19+SUpKCjExMZQoUQKAb7/9Vr+di4tLhjbZpk2bsnHjRv28idnFLlmfrFFKzyQoKIh33nmHLl26ULNmzWxrRL/++itr165FrVbj7OzMggULKFq0KPPmzWPs2LEkJycDqTdUTJkurnbt2nTp0oXu3bsD0K1bN2rVqsWpU6dYuHAhSqUStVrNjBkzsuzbo0cPOnToQK1atVi8eHGG15o0acLEiRNp1aoV9vb2AHTv3p27d+/SpUsXhBB4enqyYsWKHOOrVasWNWrUYN++fQwZMoRJkyaxbt06Xn75Zf02L730EqtXr6Zjx44MGzaM4cOHM3fuXDp06IAQgtKlS7Nq1Sqj74VkWXL2IEmSJCPkpbckSZIRMlFKkiQZIROlJEmSETJRSpIkGSETpSRJkhEyUUqSJBkhE6UkSZIRMlFKkiQZ8X+oQw8SP7pmpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = valid_data.classes\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-referable', 'referable'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbf9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Resnet50+RotateToAttend.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
